[{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/20130","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/20130/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/20130/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/20130/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/20130","id":802384457,"node_id":"MDU6SXNzdWU4MDIzODQ0NTc=","number":20130,"title":"Make format of clickhouse-server.log & clickhouse-server.err.log configurable","user":{"login":"den-crane","id":19737682,"node_id":"MDQ6VXNlcjE5NzM3Njgy","avatar_url":"https://avatars.githubusercontent.com/u/19737682?v=4","gravatar_id":"","url":"https://api.github.com/users/den-crane","html_url":"https://github.com/den-crane","followers_url":"https://api.github.com/users/den-crane/followers","following_url":"https://api.github.com/users/den-crane/following{/other_user}","gists_url":"https://api.github.com/users/den-crane/gists{/gist_id}","starred_url":"https://api.github.com/users/den-crane/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/den-crane/subscriptions","organizations_url":"https://api.github.com/users/den-crane/orgs","repos_url":"https://api.github.com/users/den-crane/repos","events_url":"https://api.github.com/users/den-crane/events{/privacy}","received_events_url":"https://api.github.com/users/den-crane/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-02-05T18:32:14Z","updated_at":"2021-02-05T20:10:33Z","closed_at":null,"author_association":"COLLABORATOR","active_lock_reason":null,"body":"I would like to have a setting to log logfiles in JSONEachRow format (i.e.)\r\nIt allows to ingest LOGs using 3d-party tools , or by ClickHouse itself.\r\n\r\n\r\n```\r\n    <logger>\r\n        <level>trace</level>\r\n        <log>/var/log/clickhouse-server/clickhouse-server.log</log>\r\n        <format>JSONEachRow</format>\r\n...\r\n```\r\n\r\npossible formats JSONEachRow, TSV, CSV ...","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/20130/reactions","total_count":6,"+1":6,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/20130/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/20127","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/20127/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/20127/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/20127/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/20127","id":802314037,"node_id":"MDU6SXNzdWU4MDIzMTQwMzc=","number":20127,"title":"Expand Macros Everywhere they Appear","user":{"login":"rlazimi-dev","id":47514208,"node_id":"MDQ6VXNlcjQ3NTE0MjA4","avatar_url":"https://avatars.githubusercontent.com/u/47514208?v=4","gravatar_id":"","url":"https://api.github.com/users/rlazimi-dev","html_url":"https://github.com/rlazimi-dev","followers_url":"https://api.github.com/users/rlazimi-dev/followers","following_url":"https://api.github.com/users/rlazimi-dev/following{/other_user}","gists_url":"https://api.github.com/users/rlazimi-dev/gists{/gist_id}","starred_url":"https://api.github.com/users/rlazimi-dev/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rlazimi-dev/subscriptions","organizations_url":"https://api.github.com/users/rlazimi-dev/orgs","repos_url":"https://api.github.com/users/rlazimi-dev/repos","events_url":"https://api.github.com/users/rlazimi-dev/events{/privacy}","received_events_url":"https://api.github.com/users/rlazimi-dev/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-02-05T16:45:44Z","updated_at":"2021-02-05T16:45:44Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"**Use case**\r\nThere are many – such as the ability to drop zookeeper replicas based on the same macros used to create them.\r\n\r\n**Describe the solution you'd like**\r\nWithin any string, {<macro_name>} will be replaced with value mapped to macro_name in the <macros/> xml tag in the configuration files, unless the curly braces are escaped.\r\n\r\n**Additional context**\r\nIn my case, I unsuccessfully tried to drop a replica that was created by a ReplicatedMergeTree, as such:\r\n\r\nthe table that created the replica:\r\n```\r\nCREATE MATERIALIZED VIEW logs.main\r\nENGINE = ReplicatedMergeTree('/clickhouse/tables/{cluster}/logs/{shard}/main_mv_shard', '{replica}')\r\n--cropped\r\n```\r\n\r\nthe command that fails:\r\n```\r\nSYSTEM DROP REPLICA '{replica}' FROM ZKPATH '/clickhouse/tables/{cluster}/logs/{shard}/main_mv_shard'\r\n```\r\n\r\nthe error I'm getting:\r\n```\r\n--cropped\r\nDB::Exception: Specified path /clickhouse/tables/{cluster}/logs/{shard}/main_mv_shard does not look like a table path\r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/20127/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/20127/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/20126","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/20126/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/20126/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/20126/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/20126","id":802290750,"node_id":"MDU6SXNzdWU4MDIyOTA3NTA=","number":20126,"title":"RBAC: add support to LOCK and UNLOCK user accounts using SQL commands","user":{"login":"vzakaznikov","id":41681088,"node_id":"MDQ6VXNlcjQxNjgxMDg4","avatar_url":"https://avatars.githubusercontent.com/u/41681088?v=4","gravatar_id":"","url":"https://api.github.com/users/vzakaznikov","html_url":"https://github.com/vzakaznikov","followers_url":"https://api.github.com/users/vzakaznikov/followers","following_url":"https://api.github.com/users/vzakaznikov/following{/other_user}","gists_url":"https://api.github.com/users/vzakaznikov/gists{/gist_id}","starred_url":"https://api.github.com/users/vzakaznikov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vzakaznikov/subscriptions","organizations_url":"https://api.github.com/users/vzakaznikov/orgs","repos_url":"https://api.github.com/users/vzakaznikov/repos","events_url":"https://api.github.com/users/vzakaznikov/events{/privacy}","received_events_url":"https://api.github.com/users/vzakaznikov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":2011606513,"node_id":"MDU6TGFiZWwyMDExNjA2NTEz","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-rbac","name":"comp-rbac","color":"b5bcff","default":false,"description":"Access control related"}],"state":"open","locked":false,"assignee":{"login":"vitlibar","id":45142681,"node_id":"MDQ6VXNlcjQ1MTQyNjgx","avatar_url":"https://avatars.githubusercontent.com/u/45142681?v=4","gravatar_id":"","url":"https://api.github.com/users/vitlibar","html_url":"https://github.com/vitlibar","followers_url":"https://api.github.com/users/vitlibar/followers","following_url":"https://api.github.com/users/vitlibar/following{/other_user}","gists_url":"https://api.github.com/users/vitlibar/gists{/gist_id}","starred_url":"https://api.github.com/users/vitlibar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vitlibar/subscriptions","organizations_url":"https://api.github.com/users/vitlibar/orgs","repos_url":"https://api.github.com/users/vitlibar/repos","events_url":"https://api.github.com/users/vitlibar/events{/privacy}","received_events_url":"https://api.github.com/users/vitlibar/received_events","type":"User","site_admin":false},"assignees":[{"login":"vitlibar","id":45142681,"node_id":"MDQ6VXNlcjQ1MTQyNjgx","avatar_url":"https://avatars.githubusercontent.com/u/45142681?v=4","gravatar_id":"","url":"https://api.github.com/users/vitlibar","html_url":"https://github.com/vitlibar","followers_url":"https://api.github.com/users/vitlibar/followers","following_url":"https://api.github.com/users/vitlibar/following{/other_user}","gists_url":"https://api.github.com/users/vitlibar/gists{/gist_id}","starred_url":"https://api.github.com/users/vitlibar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vitlibar/subscriptions","organizations_url":"https://api.github.com/users/vitlibar/orgs","repos_url":"https://api.github.com/users/vitlibar/repos","events_url":"https://api.github.com/users/vitlibar/events{/privacy}","received_events_url":"https://api.github.com/users/vitlibar/received_events","type":"User","site_admin":false}],"milestone":null,"comments":0,"created_at":"2021-02-05T16:13:39Z","updated_at":"2021-02-11T16:22:10Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"Currently there is no way to LOCK or UNLOCK user accounts using RBAC SQL commands.\r\n\r\n**Use case**\r\nLocking an account is needed in various cases to temporarily block user from login without\r\ncompletely dropping the user. \r\n\r\n**Describe the solution you'd like**\r\n```sql\r\nALTER USER [ACCOUNT] LOCK/UNLOCK \r\n```\r\n\r\nThe `SHOW CREATE USER` should list user account and indicate if the account is locked.\r\n\r\nThe `SHOW USERS` command should not list locked users.\r\n\r\nBut we can add support to list all currently locked users.\r\n\r\n```sql\r\nSHOW LOCKED USERS\r\n```\r\n\r\nLocked accounts should not be allowed to login.\r\n\r\n**Bonus feature**\r\n\r\n Add support for account locking policy. For example, lock account after 5 invalid login attempts or just lock account for some period of time.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/20126/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/20126/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/20119","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/20119/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/20119/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/20119/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/20119","id":802101074,"node_id":"MDU6SXNzdWU4MDIxMDEwNzQ=","number":20119,"title":"Lossy/Fuzzy codec compression algorithm?","user":{"login":"mzealey","id":6083471,"node_id":"MDQ6VXNlcjYwODM0NzE=","avatar_url":"https://avatars.githubusercontent.com/u/6083471?v=4","gravatar_id":"","url":"https://api.github.com/users/mzealey","html_url":"https://github.com/mzealey","followers_url":"https://api.github.com/users/mzealey/followers","following_url":"https://api.github.com/users/mzealey/following{/other_user}","gists_url":"https://api.github.com/users/mzealey/gists{/gist_id}","starred_url":"https://api.github.com/users/mzealey/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mzealey/subscriptions","organizations_url":"https://api.github.com/users/mzealey/orgs","repos_url":"https://api.github.com/users/mzealey/repos","events_url":"https://api.github.com/users/mzealey/events{/privacy}","received_events_url":"https://api.github.com/users/mzealey/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-02-05T11:48:01Z","updated_at":"2021-02-05T11:48:13Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"**Use case**\r\n\r\nLet's say we have a table of queries and add a column called `response_time` which is uncorrelated to any of the columns we are ordering by. We were doing this a `Float32` and it didn't compress much - perhaps 3.5 bytes used per row rather than 4. We could also try storing it as a `Int64` in microseconds, but it varies so much (may be 1us or 10s), again it doesn't seem like there is a good way to compress it well.\r\n\r\nBut actually in this case we don't need the retrieved value to be 100% accurate. So I suspect there should be some way to significantly improve compression ratios if you could say \"We need the original value preserved, with an accuracy of X digits\" or \"within Y% of the original number\" or something like this? So we could easily store 123 microseconds or 5.78 +- 0.02 seconds as we don't need to know it took 5.7912345 seconds exactly.\r\n\r\nI'm guessing a more general feature of a lossy compression algorithm (within some guaranteed bounds) would probably find many other uses than this. So rather than `ZSTD()` you could do `LOSSY(some config params)` as the codec on column types that would support this. I guess even for some bit array types this may be useful.\r\n\r\n**Alternatives**\r\n\r\nI doubt that doing a simple truncate+store would actually improve compression very much at the moment with `Float32` types but I did not try this. And for the example above because of the wide range of possible values we'd have to use an `Int64` type if we were storing it all as microseconds, which also doesn't compress so well.\r\n\r\nI guess an alternative could be a new type like `Float8` or some way to specify `Float(exponent, mantissa)` but even then would probably not have such good compression or flexibility as a lossy codec.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/20119/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/20119/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/20098","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/20098/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/20098/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/20098/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/20098","id":801629248,"node_id":"MDU6SXNzdWU4MDE2MjkyNDg=","number":20098,"title":"IPv6 does not convert Strings automatically in Insert select","user":{"login":"den-crane","id":19737682,"node_id":"MDQ6VXNlcjE5NzM3Njgy","avatar_url":"https://avatars.githubusercontent.com/u/19737682?v=4","gravatar_id":"","url":"https://api.github.com/users/den-crane","html_url":"https://github.com/den-crane","followers_url":"https://api.github.com/users/den-crane/followers","following_url":"https://api.github.com/users/den-crane/following{/other_user}","gists_url":"https://api.github.com/users/den-crane/gists{/gist_id}","starred_url":"https://api.github.com/users/den-crane/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/den-crane/subscriptions","organizations_url":"https://api.github.com/users/den-crane/orgs","repos_url":"https://api.github.com/users/den-crane/repos","events_url":"https://api.github.com/users/den-crane/events{/privacy}","received_events_url":"https://api.github.com/users/den-crane/received_events","type":"User","site_admin":false},"labels":[{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-02-04T20:56:51Z","updated_at":"2021-02-04T20:56:51Z","closed_at":null,"author_association":"COLLABORATOR","active_lock_reason":null,"body":"```sql\r\n\r\ncreate table ips_v6(i IPv6) Engine=Memory;\r\n\r\nINSERT INTO ips_v6 SELECT toIPv6('::ffff:127.0.0.1');\r\nINSERT INTO ips_v6 values       ('::ffff:127.0.0.1');\r\nINSERT INTO ips_v6     FORMAT TSV ::ffff:127.0.0.1\r\nINSERT INTO ips_v6 SELECT       ('::ffff:127.0.0.1');\r\n\r\nSELECT *\r\nFROM ips_v6\r\n\r\n┌─i────────────────┐\r\n│ ::ffff:127.0.0.1 │\r\n└──────────────────┘\r\n┌─i────────────────┐\r\n│ ::ffff:127.0.0.1 │\r\n└──────────────────┘\r\n┌─i────────────────┐\r\n│ ::ffff:127.0.0.1 │\r\n└──────────────────┘\r\n┌─i───────────────────────────────────────┐\r\n│ 3a3a:6666:6666:3a31:3237:2e30:2e30:2e31 │\r\n└─────────────────────────────────────────┘\r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/20098/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/20098/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/20065","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/20065/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/20065/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/20065/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/20065","id":801211421,"node_id":"MDU6SXNzdWU4MDEyMTE0MjE=","number":20065,"title":"Replica clone doesn't clone table's metadata","user":{"login":"alesapin","id":3684697,"node_id":"MDQ6VXNlcjM2ODQ2OTc=","avatar_url":"https://avatars.githubusercontent.com/u/3684697?v=4","gravatar_id":"","url":"https://api.github.com/users/alesapin","html_url":"https://github.com/alesapin","followers_url":"https://api.github.com/users/alesapin/followers","following_url":"https://api.github.com/users/alesapin/following{/other_user}","gists_url":"https://api.github.com/users/alesapin/gists{/gist_id}","starred_url":"https://api.github.com/users/alesapin/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alesapin/subscriptions","organizations_url":"https://api.github.com/users/alesapin/orgs","repos_url":"https://api.github.com/users/alesapin/repos","events_url":"https://api.github.com/users/alesapin/events{/privacy}","received_events_url":"https://api.github.com/users/alesapin/received_events","type":"User","site_admin":false},"labels":[{"id":1478073551,"node_id":"MDU6TGFiZWwxNDc4MDczNTUx","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-replication","name":"comp-replication","color":"b5bcff","default":false,"description":"Replicated tables"},{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-02-04T11:50:24Z","updated_at":"2021-02-04T14:16:06Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"When the replica decides to clone from another replica it copies only data, without metadata changes https://github.com/ClickHouse/ClickHouse/blob/master/src/Storages/StorageReplicatedMergeTree.cpp#L2281-L2282. If alter happens then the replica will have an inconsistent schema, but skip `alter` from the log.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/20065/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/20065/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/20043","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/20043/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/20043/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/20043/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/20043","id":800539437,"node_id":"MDU6SXNzdWU4MDA1Mzk0Mzc=","number":20043,"title":"X-ClickHouse-Progress / total_rows_to_read is increased together with read_rows","user":{"login":"ghost","id":10137,"node_id":"MDQ6VXNlcjEwMTM3","avatar_url":"https://avatars.githubusercontent.com/u/10137?v=4","gravatar_id":"","url":"https://api.github.com/users/ghost","html_url":"https://github.com/ghost","followers_url":"https://api.github.com/users/ghost/followers","following_url":"https://api.github.com/users/ghost/following{/other_user}","gists_url":"https://api.github.com/users/ghost/gists{/gist_id}","starred_url":"https://api.github.com/users/ghost/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ghost/subscriptions","organizations_url":"https://api.github.com/users/ghost/orgs","repos_url":"https://api.github.com/users/ghost/repos","events_url":"https://api.github.com/users/ghost/events{/privacy}","received_events_url":"https://api.github.com/users/ghost/received_events","type":"User","site_admin":false},"labels":[{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":12,"created_at":"2021-02-03T17:26:28Z","updated_at":"2021-02-07T23:11:15Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"When using HTTP interface and send_progress_in_http_headers param to execute long-running queries and track progress, \r\n**total_rows_to_read** is just being increased (together with read_rows) for each progress header:\r\n\r\n```\r\nX-ClickHouse-Progress: {\"read_rows\":\"302131\",\"read_bytes\":\"13590681\"...\"total_rows_to_read\":\"749604\"}\r\nX-ClickHouse-Progress: {\"read_rows\":\"621619\",\"read_bytes\":\"27958341\"...\"total_rows_to_read\":\"749604\"}\r\nX-ClickHouse-Progress: {\"read_rows\":\"896389\",\"read_bytes\":\"40329813\"...\"total_rows_to_read\":\"1579786\"}\r\nX-ClickHouse-Progress: {\"read_rows\":\"1240453\",\"read_bytes\":\"55801126\"...\"total_rows_to_read\":\"1579786\"}\r\nX-ClickHouse-Progress: {\"read_rows\":\"1579786\",\"read_bytes\":\"71074500\"...\"total_rows_to_read\":\"2369679\"}\r\nX-ClickHouse-Progress: {\"read_rows\":\"1899274\",\"read_bytes\":\"85437216\"...\"total_rows_to_read\":\"2369679\"}\r\n```\r\n\r\nThis makes impossible to get query execution percentage (as the native clickhouse-client does).\r\n\r\n### How to reproduce\r\n* Server version: ClickHouse client version 21.1.3.32 (official build).\r\n* HTTP interface (command line Curl)\r\n* All settings are default\r\n* Table used\r\n```\r\nCREATE TABLE default.test\r\n(\r\n    `id` UInt64,\r\n    `title` String,\r\n    `time` DateTime\r\n)\r\nENGINE = MergeTree\r\nPARTITION BY toStartOfMonth(time)\r\nORDER BY (id, title, time)\r\nSETTINGS index_granularity = 8192\r\n```\r\n* Data is filled with 40m random rows (from [this tool](https://github.com/zeroapps/clickhouse-data-generator)):\r\n```\r\n┌─id─┬─title─────────────────────────┬────────────────time─┐\r\n│  1 │ CWwkpyQaauyLNkLDh8UQAlrW      │ 2020-02-20 13:07:29 │\r\n│  1 │ F6kf3fIrbi4iV6JzkBvmGuWooMh4f │ 2020-02-20 13:08:40 │\r\n│  1 │ FM4AG7EIgz                    │ 2020-02-19 13:07:42 │\r\n│  1 │ GXvS1X57Noee                  │ 2020-02-28 13:08:49 │\r\n│  1 │ HPrQMxEpa8BQOqP7BG10UPOkc     │ 2020-02-29 13:09:02 │\r\n└────┴───────────────────────────────┴─────────────────────┘\r\n```\r\n* Curl command:\r\n```\r\ncurl -i 'http://localhost:8123/?query=SELECT+count%28%2A%29+FROM+test+WHERE+title+LIKE+%27%25as%27&send_progress_in_http_headers=1'\r\n```\r\n* Query itself (actually works like that for all queries):\r\n```\r\nSELECT count(*) FROM test WHERE title LIKE '%as'\r\n```\r\n\r\n### Expected behavior\r\nHave **total_rows_to_read** being static and showing overall number of rows which clickhouse is going to read for this query. So it is possible to calculate execution progress in percent:\r\n```\r\nprogress_percent = 100 * read_rows / total_rows_to_read\r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/20043/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/20043/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/20013","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/20013/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/20013/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/20013/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/20013","id":799805609,"node_id":"MDU6SXNzdWU3OTk4MDU2MDk=","number":20013,"title":"adaptive index granularity still is not good for uniqState","user":{"login":"den-crane","id":19737682,"node_id":"MDQ6VXNlcjE5NzM3Njgy","avatar_url":"https://avatars.githubusercontent.com/u/19737682?v=4","gravatar_id":"","url":"https://api.github.com/users/den-crane","html_url":"https://github.com/den-crane","followers_url":"https://api.github.com/users/den-crane/followers","following_url":"https://api.github.com/users/den-crane/following{/other_user}","gists_url":"https://api.github.com/users/den-crane/gists{/gist_id}","starred_url":"https://api.github.com/users/den-crane/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/den-crane/subscriptions","organizations_url":"https://api.github.com/users/den-crane/orgs","repos_url":"https://api.github.com/users/den-crane/repos","events_url":"https://api.github.com/users/den-crane/events{/privacy}","received_events_url":"https://api.github.com/users/den-crane/received_events","type":"User","site_admin":false},"labels":[{"id":756395244,"node_id":"MDU6TGFiZWw3NTYzOTUyNDQ=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/performance","name":"performance","color":"c2e0c6","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-02-02T23:14:39Z","updated_at":"2021-02-03T06:21:38Z","closed_at":null,"author_association":"COLLABORATOR","active_lock_reason":null,"body":"```\r\ndrop table z; \r\ndrop table mvz;\r\ndrop table mvz1;\r\n\r\ncreate table z(d Date, z String, u String)  Engine=Null;\r\n\r\nCREATE MATERIALIZED VIEW mvz ENGINE = AggregatingMergeTree \r\norder by (z,d) settings index_granularity = 8\r\nas select d, z,uniqState(u) as us from z group by z,d;\r\n\r\nCREATE MATERIALIZED VIEW mvz1 ENGINE = AggregatingMergeTree \r\norder by (z,d) \r\nas select d, z,uniqState(u) as us from z group by z,d;\r\n\r\ninsert into z select today()-1, toString(rand()%1000),concat('usr',toString(number)) from numbers(100000000);\r\n\r\nselect  (uniqMerge(us)) as unique from mvz prewhere z='555' group by d order by d;\r\n┌─unique─┐\r\n│ 100160 │\r\n└────────┘\r\n\r\n1 rows in set. Elapsed: 0.008 sec.\r\n\r\n\r\nselect  (uniqMerge(us)) as unique from mvz1 prewhere z='555' group by d order by d;\r\n┌─unique─┐\r\n│ 100160 │\r\n└────────┘\r\n\r\n1 rows in set. Elapsed: 0.545 sec. Processed 1.00 thousand rows, 148.87 KB (1.83 thousand rows/s., 273.10 KB/s.)\r\n\r\n\r\nSELECT\r\n    table,\r\n    sum(marks),\r\n    sum(rows)\r\nFROM system.parts\r\nWHERE (table LIKE '%mvz%') AND active\r\nGROUP BY table\r\n\r\nQuery id: 599c7c3d-46c8-4778-a800-218ef9b37731\r\n\r\n┌─table───────┬─sum(marks)─┬─sum(rows)─┐\r\n│ .inner.mvz1 │          2 │      1000 │\r\n│ .inner.mvz  │        126 │      1000 │\r\n└─────────────┴────────────┴───────────┘\r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/20013/reactions","total_count":1,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":1,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/20013/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19981","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19981/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19981/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19981/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/19981","id":799118544,"node_id":"MDU6SXNzdWU3OTkxMTg1NDQ=","number":19981,"title":"JSON DataType (RFC)","user":{"login":"hexiaoting","id":7898329,"node_id":"MDQ6VXNlcjc4OTgzMjk=","avatar_url":"https://avatars.githubusercontent.com/u/7898329?v=4","gravatar_id":"","url":"https://api.github.com/users/hexiaoting","html_url":"https://github.com/hexiaoting","followers_url":"https://api.github.com/users/hexiaoting/followers","following_url":"https://api.github.com/users/hexiaoting/following{/other_user}","gists_url":"https://api.github.com/users/hexiaoting/gists{/gist_id}","starred_url":"https://api.github.com/users/hexiaoting/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/hexiaoting/subscriptions","organizations_url":"https://api.github.com/users/hexiaoting/orgs","repos_url":"https://api.github.com/users/hexiaoting/repos","events_url":"https://api.github.com/users/hexiaoting/events{/privacy}","received_events_url":"https://api.github.com/users/hexiaoting/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2021-02-02T09:50:55Z","updated_at":"2021-04-23T02:15:46Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"In our production environment, we have many semi-structure datasets in json format to analysis.\r\nOur data's features include:\r\n1. have key name\r\n2. value type is multiply, include Number, String, Array and so on, But the value type of the same key name is the same.\r\n3. the schema (the info of keys) is dynamic.\r\n\r\nFor example:\r\n```\r\n{a:1, b:\"xyz\"}\r\n{a:1, b:\"zzz\", c:100}\r\n{a:100, c:200, d:[0,1,2]}\r\n```\r\nAnd our queries are most related to a few columns, So I want to implement a JSON dataType to save every key's values in columnar storage to support this situation.\r\n\r\n\r\n# JSON Type Grammars:\r\n## create table\r\n`create table test (data json) Engine = MergeTree() order by tuple()`\r\n```\r\ndell123 :) desc test\r\n┌─name─┬─type─────────┬─default_type─┬─default_expression─┬─comment─┬─codec_expression─┬─ttl_expression─┐\r\n│ data │ JSON         │              │                    │         │                  │                │\r\n└──────┴──────────────┴──────────────┴────────────────────┴─────────┴──────────────────┴────────────────┘\r\n\r\n## desc table\r\ndell123 :) desc test setting json_schema_expand=1\r\nshows  below 4 columns:\r\ndata:a\r\ndata:b\r\ndata:c\r\ndata:d\r\n```\r\n\r\n## insert table\r\n`insert into test select parse_json(' { \"key1\": \"value1\", \"key2\": \"value2\" } ')`\r\n**Storage for json**\r\n{a:1, b:\"xyz\", c: [1,2,3], d:[{d1: 100, d2: \"zzz\"}, {d1:200, d3:0}]}\r\nit will stored in 6 columns:\r\n| column name |type  |value  |\r\n| --- | --- | --- |\r\n| data:a | UInt32 | 1 |\r\n| data:b | String | \"xyz\" |\r\n| data:c | Array(UInt32) |[1,2,3]  |\r\n| data:d.d1 |Array(UInt32)  |[100,200]  |\r\n| data:d.d2 |Array(String)  |[\"zzz\", NULL]  |\r\n| data:d.d3 |Array(UInt32)  |[NULL, 0] |\r\n\r\n\r\n## select \r\nthe syntax is learned from snowflake，we can access json's data using `.` or `[]`：\r\n`<column>:<level1_element>.<level2_element>.<level3_element>` or\r\n`<column>['<level1_element>']['<level2_element>']`\r\nNote: `data:salesperson.name` equals `data['salesperson']['name']`\r\n\r\nexample:\r\n`select data:key1 from test`  returns value1\r\n\r\n# Implementation\r\nFor the implementation I think we can reference JSONEachRow format(not sure, need discussions)\r\n\r\n# Questions:\r\n1. Is this grammar OK?\r\n2. the restriction for json type is accepted?\r\n    * must have key name\r\n    * the value type of the key name must be the same","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19981/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19981/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19970","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19970/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19970/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19970/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/19970","id":799026103,"node_id":"MDU6SXNzdWU3OTkwMjYxMDM=","number":19970,"title":"full-text search support","user":{"login":"etah000","id":7627204,"node_id":"MDQ6VXNlcjc2MjcyMDQ=","avatar_url":"https://avatars.githubusercontent.com/u/7627204?v=4","gravatar_id":"","url":"https://api.github.com/users/etah000","html_url":"https://github.com/etah000","followers_url":"https://api.github.com/users/etah000/followers","following_url":"https://api.github.com/users/etah000/following{/other_user}","gists_url":"https://api.github.com/users/etah000/gists{/gist_id}","starred_url":"https://api.github.com/users/etah000/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/etah000/subscriptions","organizations_url":"https://api.github.com/users/etah000/orgs","repos_url":"https://api.github.com/users/etah000/repos","events_url":"https://api.github.com/users/etah000/events{/privacy}","received_events_url":"https://api.github.com/users/etah000/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":11,"created_at":"2021-02-02T07:46:24Z","updated_at":"2021-08-19T12:26:27Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"Do we have plan to add support for full-text search by integrating lucene, sphinx，or some similar stuffs?","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19970/reactions","total_count":14,"+1":8,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":6,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19970/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19923","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19923/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19923/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19923/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/19923","id":798285937,"node_id":"MDU6SXNzdWU3OTgyODU5Mzc=","number":19923,"title":"Functions don't check number of arguments, if NULL literal passed.","user":{"login":"CurtizJ","id":20361854,"node_id":"MDQ6VXNlcjIwMzYxODU0","avatar_url":"https://avatars.githubusercontent.com/u/20361854?v=4","gravatar_id":"","url":"https://api.github.com/users/CurtizJ","html_url":"https://github.com/CurtizJ","followers_url":"https://api.github.com/users/CurtizJ/followers","following_url":"https://api.github.com/users/CurtizJ/following{/other_user}","gists_url":"https://api.github.com/users/CurtizJ/gists{/gist_id}","starred_url":"https://api.github.com/users/CurtizJ/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/CurtizJ/subscriptions","organizations_url":"https://api.github.com/users/CurtizJ/orgs","repos_url":"https://api.github.com/users/CurtizJ/repos","events_url":"https://api.github.com/users/CurtizJ/events{/privacy}","received_events_url":"https://api.github.com/users/CurtizJ/received_events","type":"User","site_admin":false},"labels":[{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-02-01T12:04:06Z","updated_at":"2021-02-01T12:04:06Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"**How to reproduce**\r\n```\r\nselect sum(number, NULL) from numbers(100)\r\n\r\n┌─sum(number, NULL)─┐\r\n│ ᴺᵁᴸᴸ              │\r\n└───────────────────┘\r\n```\r\n\r\n```\r\nselect toUInt32(number, NULL) from numbers(1)\r\n\r\n┌─toUInt32(number, NULL)─┐\r\n│ ᴺᵁᴸᴸ                   │\r\n└────────────────────────┘\r\n```\r\n\r\nSometimes it leads to not very meaningful and annoying crashes from fuzzer.\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19923/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19923/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19869","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19869/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19869/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19869/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/19869","id":797660188,"node_id":"MDU6SXNzdWU3OTc2NjAxODg=","number":19869,"title":"(negligible) demonstration of memory growth due to infinite regexp cache.","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":1365579236,"node_id":"MDU6TGFiZWwxMzY1NTc5MjM2","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/minor","name":"minor","color":"FFF8F8","default":false,"description":"Priority: minor"},{"id":1532016596,"node_id":"MDU6TGFiZWwxNTMyMDE2NTk2","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/memory","name":"memory","color":"e99695","default":false,"description":"When memory usage is higher than expected"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-01-31T08:53:08Z","updated_at":"2021-01-31T08:53:40Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"ClickHouse is using infinite cache for compiled regular expressions.\r\nHyperscan can use several megabytes per compiled regexp.\r\nIt makes infinite memory growth possible:\r\n\r\n```\r\nclickhouse-benchmark --query \"SELECT multiFuzzyMatchAny('Hello, world', 5, ['(' || (SELECT toString(rand(1))) || '|' || (SELECT toString(rand(2))) || ')+(' || (SELECT toString(rand(3))) || '|' || (SELECT toString(rand(4))) || ')+(' || (SELECT toString(rand(5))) || ')+'])\"\r\n```\r\n\r\nPossible solutions:\r\n- simply drop cache if its size is 1000 entries;\r\n- replace to LRU cache with 1000 entries.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19869/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19869/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19857","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19857/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19857/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19857/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/19857","id":797494225,"node_id":"MDU6SXNzdWU3OTc0OTQyMjU=","number":19857,"title":"SUM(col) / SUM(SUM(col)) OVER (PARTITION BY col2) aggregate function over WINDOW is not supported.","user":{"login":"UnamedRus","id":9449405,"node_id":"MDQ6VXNlcjk0NDk0MDU=","avatar_url":"https://avatars.githubusercontent.com/u/9449405?v=4","gravatar_id":"","url":"https://api.github.com/users/UnamedRus","html_url":"https://github.com/UnamedRus","followers_url":"https://api.github.com/users/UnamedRus/followers","following_url":"https://api.github.com/users/UnamedRus/following{/other_user}","gists_url":"https://api.github.com/users/UnamedRus/gists{/gist_id}","starred_url":"https://api.github.com/users/UnamedRus/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/UnamedRus/subscriptions","organizations_url":"https://api.github.com/users/UnamedRus/orgs","repos_url":"https://api.github.com/users/UnamedRus/repos","events_url":"https://api.github.com/users/UnamedRus/events{/privacy}","received_events_url":"https://api.github.com/users/UnamedRus/received_events","type":"User","site_admin":false},"labels":[{"id":1397894054,"node_id":"MDU6TGFiZWwxMzk3ODk0MDU0","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unfinished%20code","name":"unfinished code","color":"ff8800","default":false,"description":""},{"id":2607635731,"node_id":"MDU6TGFiZWwyNjA3NjM1NzMx","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-window-functions","name":"comp-window-functions","color":"b5bcff","default":false,"description":""}],"state":"open","locked":false,"assignee":{"login":"novikd","id":10158699,"node_id":"MDQ6VXNlcjEwMTU4Njk5","avatar_url":"https://avatars.githubusercontent.com/u/10158699?v=4","gravatar_id":"","url":"https://api.github.com/users/novikd","html_url":"https://github.com/novikd","followers_url":"https://api.github.com/users/novikd/followers","following_url":"https://api.github.com/users/novikd/following{/other_user}","gists_url":"https://api.github.com/users/novikd/gists{/gist_id}","starred_url":"https://api.github.com/users/novikd/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/novikd/subscriptions","organizations_url":"https://api.github.com/users/novikd/orgs","repos_url":"https://api.github.com/users/novikd/repos","events_url":"https://api.github.com/users/novikd/events{/privacy}","received_events_url":"https://api.github.com/users/novikd/received_events","type":"User","site_admin":false},"assignees":[{"login":"novikd","id":10158699,"node_id":"MDQ6VXNlcjEwMTU4Njk5","avatar_url":"https://avatars.githubusercontent.com/u/10158699?v=4","gravatar_id":"","url":"https://api.github.com/users/novikd","html_url":"https://github.com/novikd","followers_url":"https://api.github.com/users/novikd/followers","following_url":"https://api.github.com/users/novikd/following{/other_user}","gists_url":"https://api.github.com/users/novikd/gists{/gist_id}","starred_url":"https://api.github.com/users/novikd/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/novikd/subscriptions","organizations_url":"https://api.github.com/users/novikd/orgs","repos_url":"https://api.github.com/users/novikd/repos","events_url":"https://api.github.com/users/novikd/events{/privacy}","received_events_url":"https://api.github.com/users/novikd/received_events","type":"User","site_admin":false}],"milestone":null,"comments":6,"created_at":"2021-01-30T18:00:32Z","updated_at":"2022-01-25T14:04:06Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"\r\n**How to reproduce**\r\n\r\n```\r\nSELECT sum(number) / sum(sum(number)) OVER (PARTITION BY (number % 10))\r\nFROM numbers(10000)\r\nGROUP BY number % 10\r\n\r\nQuery id: 76ed1093-b378-45c2-b644-1de44783734a\r\n\r\n\r\n0 rows in set. Elapsed: 0.003 sec.\r\n\r\nReceived exception from server (version 21.2.1):\r\nCode: 47. DB::Exception: Received from localhost:9000. DB::Exception: Unknown identifier: sum(sum(number)) OVER (PARTITION BY number % 10) there are columns: modulo(number, 10), sum(number): While processing sum(number) / sum(sum(number)) OVER (PARTITION BY (number % 10)).\r\n\r\n\r\n\r\npostgres=# SELECT sum(generate_series) / sum(sum(generate_series))  OVER (PARTITION BY (generate_series % 10)) FROM generate_series(0,10000) GROUP BY generate_series % 10;\r\n        ?column?\r\n------------------------\r\n 1.00000000000000000000\r\n 1.00000000000000000000\r\n 1.00000000000000000000\r\n 1.00000000000000000000\r\n 1.00000000000000000000\r\n 1.00000000000000000000\r\n 1.00000000000000000000\r\n 1.00000000000000000000\r\n 1.00000000000000000000\r\n 1.00000000000000000000\r\n(10 rows)\r\n\r\n**Expected behavior**\r\nQuery works","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19857/reactions","total_count":10,"+1":6,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":4},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19857/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19854","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19854/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19854/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19854/events","html_url":"https://github.com/ClickHouse/ClickHouse/pull/19854","id":797387214,"node_id":"MDExOlB1bGxSZXF1ZXN0NTY0Mzk5MjMw","number":19854,"title":"Add aggregation function funnelAnalysis","user":{"login":"fuwhu","id":12389745,"node_id":"MDQ6VXNlcjEyMzg5NzQ1","avatar_url":"https://avatars.githubusercontent.com/u/12389745?v=4","gravatar_id":"","url":"https://api.github.com/users/fuwhu","html_url":"https://github.com/fuwhu","followers_url":"https://api.github.com/users/fuwhu/followers","following_url":"https://api.github.com/users/fuwhu/following{/other_user}","gists_url":"https://api.github.com/users/fuwhu/gists{/gist_id}","starred_url":"https://api.github.com/users/fuwhu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/fuwhu/subscriptions","organizations_url":"https://api.github.com/users/fuwhu/orgs","repos_url":"https://api.github.com/users/fuwhu/repos","events_url":"https://api.github.com/users/fuwhu/events{/privacy}","received_events_url":"https://api.github.com/users/fuwhu/received_events","type":"User","site_admin":false},"labels":[{"id":1309674771,"node_id":"MDU6TGFiZWwxMzA5Njc0Nzcx","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/pr-feature","name":"pr-feature","color":"007700","default":false,"description":"Pull request with new product feature"},{"id":1807683251,"node_id":"MDU6TGFiZWwxODA3NjgzMjUx","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/doc-alert","name":"doc-alert","color":"e51068","default":false,"description":"PR where any documentation work is needed or proceeded"}],"state":"open","locked":false,"assignee":{"login":"Avogar","id":48961922,"node_id":"MDQ6VXNlcjQ4OTYxOTIy","avatar_url":"https://avatars.githubusercontent.com/u/48961922?v=4","gravatar_id":"","url":"https://api.github.com/users/Avogar","html_url":"https://github.com/Avogar","followers_url":"https://api.github.com/users/Avogar/followers","following_url":"https://api.github.com/users/Avogar/following{/other_user}","gists_url":"https://api.github.com/users/Avogar/gists{/gist_id}","starred_url":"https://api.github.com/users/Avogar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Avogar/subscriptions","organizations_url":"https://api.github.com/users/Avogar/orgs","repos_url":"https://api.github.com/users/Avogar/repos","events_url":"https://api.github.com/users/Avogar/events{/privacy}","received_events_url":"https://api.github.com/users/Avogar/received_events","type":"User","site_admin":false},"assignees":[{"login":"Avogar","id":48961922,"node_id":"MDQ6VXNlcjQ4OTYxOTIy","avatar_url":"https://avatars.githubusercontent.com/u/48961922?v=4","gravatar_id":"","url":"https://api.github.com/users/Avogar","html_url":"https://github.com/Avogar","followers_url":"https://api.github.com/users/Avogar/followers","following_url":"https://api.github.com/users/Avogar/following{/other_user}","gists_url":"https://api.github.com/users/Avogar/gists{/gist_id}","starred_url":"https://api.github.com/users/Avogar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Avogar/subscriptions","organizations_url":"https://api.github.com/users/Avogar/orgs","repos_url":"https://api.github.com/users/Avogar/repos","events_url":"https://api.github.com/users/Avogar/events{/privacy}","received_events_url":"https://api.github.com/users/Avogar/received_events","type":"User","site_admin":false}],"milestone":null,"comments":6,"created_at":"2021-01-30T10:36:12Z","updated_at":"2021-12-09T14:59:32Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"draft":false,"pull_request":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/pulls/19854","html_url":"https://github.com/ClickHouse/ClickHouse/pull/19854","diff_url":"https://github.com/ClickHouse/ClickHouse/pull/19854.diff","patch_url":"https://github.com/ClickHouse/ClickHouse/pull/19854.patch","merged_at":null},"body":"I hereby agree to the terms of the CLA available at: https://yandex.ru/legal/cla/?lang=en\r\n\r\nChangelog category (leave one):\r\n- New Feature\r\n\r\n\r\nChangelog entry (a user-readable short description of the changes that goes to CHANGELOG.md):\r\nAdd a new aggregation function called funnelAnalysis which refactor the windowFunnel on pre-aggregated and pre-sorted data to get better performance of funnel analysis.\r\n\r\nDetailed description / Documentation draft:\r\n\r\nUsing windowFunnel, we usually have input data structure like :\r\n       `(user_id, event_id, timestamp)`\r\nAnd then we group by user_id and call the windowFunnel function, like : \r\n       `windowFunnel(3600)(timestamp, event_id='e1', event_id='e2', event_id='e3')`\r\n\r\nIn order to get better performance of funnel analysis, we pre-aggregate the data by (user_id, event_id) when writing the data, then we group and sort the timestamp column to get a sorted timestamp array for each (user_id, event_id) pair. By doing so, our data structure become (user_id, event_id, timestamp_array) and the timestamp_array is sorted. \r\n\r\nThen, when we do the funnel analysis, we just need to merge all the timestamp arrays for each single user_id, which turn the time complexity O(nlogn) of sorting algorithm in windowFunnel to O(nlogk) in which k is the number of timestamp_array to merge.\r\n\r\nAfter this change, we can call the funnelAnalysis function like : \r\n        `funnelAnalysis(3600, 0, 0, 'e1', 'e2', 'e3')(event_id, timestamps)`\r\nthe 2nd and 3th parameter indicates is_strict and is_strict_order.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19854/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19854/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19823","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19823/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19823/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19823/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/19823","id":797040275,"node_id":"MDU6SXNzdWU3OTcwNDAyNzU=","number":19823,"title":"Queries from subquery and view is slow when it has IN condition with subquery","user":{"login":"kolsys","id":6312063,"node_id":"MDQ6VXNlcjYzMTIwNjM=","avatar_url":"https://avatars.githubusercontent.com/u/6312063?v=4","gravatar_id":"","url":"https://api.github.com/users/kolsys","html_url":"https://github.com/kolsys","followers_url":"https://api.github.com/users/kolsys/followers","following_url":"https://api.github.com/users/kolsys/following{/other_user}","gists_url":"https://api.github.com/users/kolsys/gists{/gist_id}","starred_url":"https://api.github.com/users/kolsys/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kolsys/subscriptions","organizations_url":"https://api.github.com/users/kolsys/orgs","repos_url":"https://api.github.com/users/kolsys/repos","events_url":"https://api.github.com/users/kolsys/events{/privacy}","received_events_url":"https://api.github.com/users/kolsys/received_events","type":"User","site_admin":false},"labels":[{"id":756395244,"node_id":"MDU6TGFiZWw3NTYzOTUyNDQ=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/performance","name":"performance","color":"c2e0c6","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-01-29T17:02:43Z","updated_at":"2021-04-29T18:49:51Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Describe the situation**\r\nWhile using subquery in the `IN` condition when make query to the VIEW Engine table or subquery, the request is much slower than directly to source table.\r\n\r\n**How to reproduce**\r\nVersion: 20.11.5, 20.11.6\r\n\r\nTable 1\r\n```SQL\r\ncreate table t1 Engine=MergeTree() ORDER BY date AS select toDate('2010-12-01')+number date, number from numbers(0, 50000)\r\n```\r\nTable 2\r\n```SQL\r\ncreate table t2 Engine=MergeTree() ORDER BY date AS select toDate('2010-12-01')+number date, number from numbers(0, 50000)\r\n```\r\n\r\nQuery 1:\r\n```\r\nSELECT count()\r\nFROM t1\r\nWHERE ((date >= '2015-12-01') AND (date <= '2022-12-31')) AND (number IN \r\n(\r\n    SELECT number\r\n    FROM t2\r\n    WHERE (date >= '2020-12-01') AND (date <= '2020-12-31')\r\n))\r\n\r\nQuery id: 12d7333d-bad0-4536-996f-f6417f7ad3b1\r\n\r\n┌─count()─┐\r\n│      31 │\r\n└─────────┘\r\n\r\n1 rows in set. Elapsed: 0.008 sec. Processed 16.38 thousand rows, 163.84 KB (1.98 million rows/s., 19.80 MB/s.) \r\n```\r\n\r\nQuery 2\r\n```\r\nSELECT count()\r\nFROM \r\n(\r\n    SELECT *\r\n    FROM t1\r\n)\r\nWHERE ((date >= '2015-12-01') AND (date <= '2022-12-31')) AND (number IN \r\n(\r\n    SELECT number\r\n    FROM t2\r\n    WHERE (date >= '2020-12-01') AND (date <= '2020-12-31')\r\n))\r\n\r\nQuery id: e6df58c9-b874-4c84-80bf-4e405604c799\r\n\r\n┌─count()─┐\r\n│      31 │\r\n└─────────┘\r\n\r\n1 rows in set. Elapsed: 0.011 sec. Processed 24.58 thousand rows, 245.76 KB (2.17 million rows/s., 21.69 MB/s.) \r\n```\r\n\r\nQuery 3\r\n```\r\nSELECT count()\r\nFROM \r\n(\r\n    SELECT *\r\n    FROM t1\r\n)\r\nWHERE (date >= '2015-12-01') AND (date <= '2022-12-31')\r\n\r\nQuery id: 56687ca3-b55d-446c-85be-d15b7b2a1aa2\r\n\r\n┌─count()─┐\r\n│    2588 │\r\n└─────────┘\r\n\r\n1 rows in set. Elapsed: 0.006 sec. Processed 8.19 thousand rows, 16.38 KB (1.44 million rows/s., 2.88 MB/s.) \r\n```\r\n\r\n**Expected performance**\r\nThe Query 2 is fast as Query 1. \r\n\r\n**Additional context**\r\nThe Query 1 reads much less rows than Query 2 but if you look at Query 3 you'll see that the query without `IN` condition don't reads all rows from sub-query.\r\n\r\nThe issue is not reproducing if in subquery of `IN` the table with `Set` engine.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19823/reactions","total_count":1,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":1},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19823/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19803","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19803/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19803/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19803/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/19803","id":796718735,"node_id":"MDU6SXNzdWU3OTY3MTg3MzU=","number":19803,"title":"clickhouse-local fails to find the users.xml when users_config in config.xml is a relative path","user":{"login":"zhangjmruc","id":66244986,"node_id":"MDQ6VXNlcjY2MjQ0OTg2","avatar_url":"https://avatars.githubusercontent.com/u/66244986?v=4","gravatar_id":"","url":"https://api.github.com/users/zhangjmruc","html_url":"https://github.com/zhangjmruc","followers_url":"https://api.github.com/users/zhangjmruc/followers","following_url":"https://api.github.com/users/zhangjmruc/following{/other_user}","gists_url":"https://api.github.com/users/zhangjmruc/gists{/gist_id}","starred_url":"https://api.github.com/users/zhangjmruc/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/zhangjmruc/subscriptions","organizations_url":"https://api.github.com/users/zhangjmruc/orgs","repos_url":"https://api.github.com/users/zhangjmruc/repos","events_url":"https://api.github.com/users/zhangjmruc/events{/privacy}","received_events_url":"https://api.github.com/users/zhangjmruc/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""},{"id":2079355812,"node_id":"MDU6TGFiZWwyMDc5MzU1ODEy","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-local","name":"comp-local","color":"b5bcff","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-01-29T09:22:19Z","updated_at":"2021-02-01T14:21:26Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"When config.xml and users.xml files are put in the same directory, clickhouse-server can successfully started with the same relative path, users.xml in users_config of config.xml, however clickhouse-local cannot. \r\nClickhouse-local can work when the users.xml with absolute path. In this case, /home/frank/clickhouse-local/users.xml.\r\nIs this expected for clickhouse-local or not?\r\n\r\n~/clickhouse-local$ ls\r\n**config.xml**  log  preprocessed_configs  **users.xml**\r\n\r\n-- content of config.xml\r\n**$ cat config.xml** \r\n<?xml version=\"1.0\"?>\r\n<yandex>\r\n    <logger>\r\n        <!-- Possible levels: https://github.com/pocoproject/poco/blob/poco-1.9.4-release/Foundation/include/Poco/Logger.h#L105 -->\r\n        <level>trace</level>\r\n\t<log>/home/frank/clickhouse-local/log/clickhouse-local.log</log>\r\n\t<errorlog>/home/frank/clickhouse-local/log/clickhouse-local.err.log</errorlog>\r\n        <size>1000M</size>\r\n        <count>10</count>\r\n    </logger>\r\n\r\n    <!-- Path to data directory, with trailing slash. -->\r\n    <path>/home/frank/clickhouse-local/</path>\r\n\r\n    <!-- Path to temporary data for processing hard queries. -->\r\n    <tmp_path>/home/frank/clickhouse-local/tmp/</tmp_path>\r\n    \r\n    **<users_config>users.xml</users_config>**\r\n\r\n</yandex>\r\n\r\n-- reproduce:\r\n$ echo -e \"1,2\\n3,4\" | ./clickhouse-local --config-file=/home/frank/clickhouse-local/config.xml --structure \"a int, b int\" --input-format \"CSV\" --query \"select * from table\"\r\nProcessing configuration file '/home/frank/clickhouse-local/config.xml'.\r\nSaved preprocessed configuration to '/home/frank/clickhouse-local/preprocessed_configs/config.xml'.\r\nLogging trace to /home/frank/clickhouse-local/log/clickhouse-local.log\r\nLogging errors to /home/frank/clickhouse-local/log/clickhouse-local.err.log\r\nLogging trace to console\r\n2021.01.29 17:12:01.305281 [ 101243 ] {} <Debug> ConfigProcessor: Processing configuration file 'users.xml'.\r\nCode: 107, e.displayText() = DB::Exception: **Configuration file users.xml doesn't exist** (version 21.2.1.1)\r\n2021.01.29 17:12:01.506519 [ 101243 ] {} <Debug> Application: Uninitializing subsystem: Logging Subsystem\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19803/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19803/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19687","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19687/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19687/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19687/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/19687","id":794821471,"node_id":"MDU6SXNzdWU3OTQ4MjE0NzE=","number":19687,"title":"ClickHouse doesn't work correctly with sql aliases.","user":{"login":"demidko","id":26452002,"node_id":"MDQ6VXNlcjI2NDUyMDAy","avatar_url":"https://avatars.githubusercontent.com/u/26452002?v=4","gravatar_id":"","url":"https://api.github.com/users/demidko","html_url":"https://github.com/demidko","followers_url":"https://api.github.com/users/demidko/followers","following_url":"https://api.github.com/users/demidko/following{/other_user}","gists_url":"https://api.github.com/users/demidko/gists{/gist_id}","starred_url":"https://api.github.com/users/demidko/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/demidko/subscriptions","organizations_url":"https://api.github.com/users/demidko/orgs","repos_url":"https://api.github.com/users/demidko/repos","events_url":"https://api.github.com/users/demidko/events{/privacy}","received_events_url":"https://api.github.com/users/demidko/received_events","type":"User","site_admin":false},"labels":[{"id":386401505,"node_id":"MDU6TGFiZWwzODY0MDE1MDU=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/bug","name":"bug","color":"ee0701","default":true,"description":"Confirmed user-visible misbehaviour in official release"},{"id":1357578153,"node_id":"MDU6TGFiZWwxMzU3NTc4MTUz","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-joins","name":"comp-joins","color":"b5bcff","default":false,"description":"JOINs"},{"id":1507867504,"node_id":"MDU6TGFiZWwxNTA3ODY3NTA0","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/st-hold","name":"st-hold","color":"e5b890","default":false,"description":"We've paused the work on issue for some reason"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-01-27T06:44:15Z","updated_at":"2021-06-15T03:50:26Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Latest actual ClickHouse version:\r\nWe are getting a column mismatch error when using sql alias in JOIN query. But if you add the database prefix 'default', then the same query will work. And this is really weird! After all, the error was not talking about this at all and we were already in 'default'.\r\nYou can reproduce the bug using docker-compose here:\r\nhttps://github.com/demidko/ch_prefixes\r\n\r\n```\r\nCREATE MATERIALIZED VIEW competitors_one_day_test\r\n(\r\n             `lemma` String,\r\n             `city` UInt32,\r\n             `date` DateTime,\r\n             `packets` Array(UInt32)\r\n)\r\nENGINE = MergeTree()\r\nORDER BY (date, city)\r\nPOPULATE\r\nAS SELECT\r\n    any(lemma),\r\n    city,\r\n    date,\r\n    arrayReduce('groupUniqArray', groupArray(packet))\r\nFROM\r\n    (SELECT lemma, city, date, packet\r\n\r\n         /*\r\n         We are already in 'default' and sql is correctly, but:\r\n         \r\n         Code: 47. DB::Exception:\r\n         Received from clickhouse:9000.\r\n         DB::Exception:\r\n         Missing columns: 'l.docs'\r\n         while processing query: 'SELECT lemma, city, date, packet FROM default.log ARRAY JOIN docs GLOBAL ALL INNER JOIN default.docs_to_packets_week ON doc = l.docs WHERE (toDate(date) > subtractDays(today(), 1)) AND (city != 0)',\r\n         required columns: 'lemma' 'doc' 'date' 'l.docs' 'packet' 'city',\r\n         maybe you meant:  '['lemma']' '['docs']' '['date']' '['docs']' '['city']',\r\n         joined columns: 'doc' 'packet',\r\n         arrayJoin columns: 'docs'\r\n         */\r\n\r\n     FROM log AS l\r\n         /*\r\n         with 'log.defult': OK\r\n         */\r\n\r\n     ARRAY JOIN docs\r\n     GLOBAL INNER JOIN docs_to_packets_week ON doc = l.docs\r\n     WHERE (toDate(date) > subtractDays(today(), 1)) AND (city != 0))\r\nGROUP BY\r\n    cityHash64(lemma),\r\n    city,\r\n    date;\r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19687/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19687/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19649","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19649/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19649/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19649/events","html_url":"https://github.com/ClickHouse/ClickHouse/pull/19649","id":794203762,"node_id":"MDExOlB1bGxSZXF1ZXN0NTYxNzU5Nzcz","number":19649,"title":"Multi-thread downloading file for S3 tables","user":{"login":"vdimir","id":7023786,"node_id":"MDQ6VXNlcjcwMjM3ODY=","avatar_url":"https://avatars.githubusercontent.com/u/7023786?v=4","gravatar_id":"","url":"https://api.github.com/users/vdimir","html_url":"https://github.com/vdimir","followers_url":"https://api.github.com/users/vdimir/followers","following_url":"https://api.github.com/users/vdimir/following{/other_user}","gists_url":"https://api.github.com/users/vdimir/gists{/gist_id}","starred_url":"https://api.github.com/users/vdimir/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vdimir/subscriptions","organizations_url":"https://api.github.com/users/vdimir/orgs","repos_url":"https://api.github.com/users/vdimir/repos","events_url":"https://api.github.com/users/vdimir/events{/privacy}","received_events_url":"https://api.github.com/users/vdimir/received_events","type":"User","site_admin":false},"labels":[{"id":1304141686,"node_id":"MDU6TGFiZWwxMzA0MTQxNjg2","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/pr-improvement","name":"pr-improvement","color":"007700","default":false,"description":"Pull request with some product improvements"}],"state":"open","locked":false,"assignee":{"login":"nikitamikhaylov","id":25705399,"node_id":"MDQ6VXNlcjI1NzA1Mzk5","avatar_url":"https://avatars.githubusercontent.com/u/25705399?v=4","gravatar_id":"","url":"https://api.github.com/users/nikitamikhaylov","html_url":"https://github.com/nikitamikhaylov","followers_url":"https://api.github.com/users/nikitamikhaylov/followers","following_url":"https://api.github.com/users/nikitamikhaylov/following{/other_user}","gists_url":"https://api.github.com/users/nikitamikhaylov/gists{/gist_id}","starred_url":"https://api.github.com/users/nikitamikhaylov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nikitamikhaylov/subscriptions","organizations_url":"https://api.github.com/users/nikitamikhaylov/orgs","repos_url":"https://api.github.com/users/nikitamikhaylov/repos","events_url":"https://api.github.com/users/nikitamikhaylov/events{/privacy}","received_events_url":"https://api.github.com/users/nikitamikhaylov/received_events","type":"User","site_admin":false},"assignees":[{"login":"nikitamikhaylov","id":25705399,"node_id":"MDQ6VXNlcjI1NzA1Mzk5","avatar_url":"https://avatars.githubusercontent.com/u/25705399?v=4","gravatar_id":"","url":"https://api.github.com/users/nikitamikhaylov","html_url":"https://github.com/nikitamikhaylov","followers_url":"https://api.github.com/users/nikitamikhaylov/followers","following_url":"https://api.github.com/users/nikitamikhaylov/following{/other_user}","gists_url":"https://api.github.com/users/nikitamikhaylov/gists{/gist_id}","starred_url":"https://api.github.com/users/nikitamikhaylov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nikitamikhaylov/subscriptions","organizations_url":"https://api.github.com/users/nikitamikhaylov/orgs","repos_url":"https://api.github.com/users/nikitamikhaylov/repos","events_url":"https://api.github.com/users/nikitamikhaylov/events{/privacy}","received_events_url":"https://api.github.com/users/nikitamikhaylov/received_events","type":"User","site_admin":false}],"milestone":null,"comments":6,"created_at":"2021-01-26T12:46:08Z","updated_at":"2021-12-10T12:13:14Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"draft":true,"pull_request":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/pulls/19649","html_url":"https://github.com/ClickHouse/ClickHouse/pull/19649","diff_url":"https://github.com/ClickHouse/ClickHouse/pull/19649.diff","patch_url":"https://github.com/ClickHouse/ClickHouse/pull/19649.patch","merged_at":null},"body":"I hereby agree to the terms of the CLA available at: https://yandex.ru/legal/cla/?lang=en\r\n\r\nChangelog category (leave one):\r\n- Improvement\r\n\r\n\r\n\r\nChangelog entry (a user-readable short description of the changes that goes to CHANGELOG.md):\r\n\r\n- Multi-thread file downloading for S3 tables\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19649/reactions","total_count":2,"+1":2,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19649/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19627","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19627/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19627/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19627/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/19627","id":794163260,"node_id":"MDU6SXNzdWU3OTQxNjMyNjA=","number":19627,"title":"RFC: Lightweight deletes for MergeTree-family tables.","user":{"login":"filimonov","id":1549571,"node_id":"MDQ6VXNlcjE1NDk1NzE=","avatar_url":"https://avatars.githubusercontent.com/u/1549571?v=4","gravatar_id":"","url":"https://api.github.com/users/filimonov","html_url":"https://github.com/filimonov","followers_url":"https://api.github.com/users/filimonov/followers","following_url":"https://api.github.com/users/filimonov/following{/other_user}","gists_url":"https://api.github.com/users/filimonov/gists{/gist_id}","starred_url":"https://api.github.com/users/filimonov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/filimonov/subscriptions","organizations_url":"https://api.github.com/users/filimonov/orgs","repos_url":"https://api.github.com/users/filimonov/repos","events_url":"https://api.github.com/users/filimonov/events{/privacy}","received_events_url":"https://api.github.com/users/filimonov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":{"login":"Enmk","id":1110183,"node_id":"MDQ6VXNlcjExMTAxODM=","avatar_url":"https://avatars.githubusercontent.com/u/1110183?v=4","gravatar_id":"","url":"https://api.github.com/users/Enmk","html_url":"https://github.com/Enmk","followers_url":"https://api.github.com/users/Enmk/followers","following_url":"https://api.github.com/users/Enmk/following{/other_user}","gists_url":"https://api.github.com/users/Enmk/gists{/gist_id}","starred_url":"https://api.github.com/users/Enmk/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Enmk/subscriptions","organizations_url":"https://api.github.com/users/Enmk/orgs","repos_url":"https://api.github.com/users/Enmk/repos","events_url":"https://api.github.com/users/Enmk/events{/privacy}","received_events_url":"https://api.github.com/users/Enmk/received_events","type":"User","site_admin":false},"assignees":[{"login":"Enmk","id":1110183,"node_id":"MDQ6VXNlcjExMTAxODM=","avatar_url":"https://avatars.githubusercontent.com/u/1110183?v=4","gravatar_id":"","url":"https://api.github.com/users/Enmk","html_url":"https://github.com/Enmk","followers_url":"https://api.github.com/users/Enmk/followers","following_url":"https://api.github.com/users/Enmk/following{/other_user}","gists_url":"https://api.github.com/users/Enmk/gists{/gist_id}","starred_url":"https://api.github.com/users/Enmk/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Enmk/subscriptions","organizations_url":"https://api.github.com/users/Enmk/orgs","repos_url":"https://api.github.com/users/Enmk/repos","events_url":"https://api.github.com/users/Enmk/events{/privacy}","received_events_url":"https://api.github.com/users/Enmk/received_events","type":"User","site_admin":false}],"milestone":null,"comments":17,"created_at":"2021-01-26T11:39:57Z","updated_at":"2021-12-16T09:16:02Z","closed_at":null,"author_association":"COLLABORATOR","active_lock_reason":null,"body":"### Requirements: \r\n0) we want to delete data from MergeTree-family tables efficiently.\r\n1) The cost of those deletes should be close to the cost of a simple SELECT, which matches the same conditions.\r\n   ```\r\n   SELECT count() WHERE <list of conditions>\r\n   ``` \r\n   and \r\n   ```\r\n   DELETE ... WHERE <same list of conditions>\r\n   ```\r\n   should also take a similar amount of time.\r\n2) we can have many `DELETE`s (same limitations on the number of `DELETE`s as for the number of `INSERT`s are ok).\r\n2) `DELETE`s should be synchronous (on a single node), and eventual (go together with replication queue) in a replicated system\r\n3) `DELETE`s should not reprocess significant amounts of data - we don't want to rewrite gigabytes of data to remove a single row. \r\n   That means we need to store a mask of deleted rows instead of deleting them immediately. Real data deletion should happen eventually during normal background operations (merges etc.).\r\n4) Once we calculate the mask of deleted rows (calculation can be expensive), we should use that mask in a very efficient/close to zero cost during further selects. \r\n   ```\r\n      SELECT count() FROM table;\r\n      DELETE FROM table WHERE <conditions expensive to calculate>; <-- that may take a lot of time, it's ok\r\n      SELECT count() FROM table; <-- that should be fast (i.e., we don't want to reapply the same conditions with every select)\r\n   ```\r\n5) data parts should be immutable during `DELETE`s - that is 'must-have' for replication.\r\n6) standard SQL syntax\r\n\r\n### Concept\r\n\r\nGenerally, that means that we need \r\n1) when `DELETE` fired - calculate a mask of deleted rows for every data part (for complicated conditions calculation can be costly)\r\n2) instead of deleting anything, do an insert in some special place the following information\r\n    ```\r\n    data_part_name, mask_of_deleted_rows + may be some meta (like max block number)\r\n    ```\r\n3) selects / merges should check that 'special' place when selecting data, applying it as a row mask (applying the mask should be very cheap)\r\n4) we need to run some upkeeping procedures that  will \r\n    - consolidate those masks in the background: if frequent `DELETE`s happen, we still want\r\n      to keep a minimum number of masks - ideally one per part, and merge several masks into a single mask efficiently\r\n    - remove the masks for parts that were already merged and deleted - to keep that 'special place' compact. \r\n\r\n![lightweight_deletes1](https://user-images.githubusercontent.com/1549571/105839401-b6867200-5fd1-11eb-9ecf-ac04be77d986.png)\r\n\r\n<details>\r\n<summary>Illustration using existing abstactions</summary>\r\n\r\n#### Illustration using existing abstactions\r\n\r\n**Note**: it's just an illustration. Obviously, the feature should be implemented inside MergeTree engine itself, and live together with that as a single logical table, w/o any extra tables. \r\n\r\n0) we have some `my_table` table with `engine=MergeTree` and we want to run DELETEs there.\r\n1) We need to be able to calculate the offset of the row (from part beginning).\r\nimagine we have it as a virtual column named `_part_offset`\r\n2) we have some special storage to store masks for our `my_table` \r\n```\r\nCRATE TABLE _deleted_rows_mask.my_table (\r\n   part_name String,\r\n   mask AggregateFunction(groupBitmap, UInt32) \r\n) engine=AggregatingMergeTree ORDER BY part_name;\r\n```\r\n3) deletes work like \r\n```\r\nINSERT INTO _deleted_rows_mask.my_table SELECT _part, groupBitmapState( _part_offset) FROM my_table WHERE ... \r\n```\r\n4) now MergeTree reader should be able to apply those masks while reading the part\r\n```\r\nSELECT * FROM my_table\r\nWHERE (_part, _part_offset) NOT IN\r\n(\r\n   SELECT part_name, arrayJoin( bitmapToArray(  groupBitmapMerge( mask ) ) )\r\n   FROM _deleted_rows_mask.my_table\r\n   GROUP BY part_name\r\n);\r\n```\r\n</details>\r\n\r\n### Implementation details (updated)\r\n\r\n#### How mutations work\r\n\r\nPARTITION_MINBLOCK_MAXBLOCK_LEVEL + mutation_XXX =  PARTITION_MINBLOCK_MAXBLOCK_LEVEL_XXX\r\n\r\nfor example:\r\n20100101_1_1_0 + mutation_2.txt = 20100101_1_1_0_2 \r\n\r\nDisadvantages:\r\nEven a single row update require 'touching' all the parts (renaming them)\r\nCreates a lot of inactive parts\r\nMakes backups problematic. \r\nALTER DELETE is always IO (read/write) and CPU (unpack/pack) heavy\r\n\r\n#### Lightweight delete:\r\n\r\nget the number in every partition (Replicated) / for a table (nonReplicated) exactly the same as mutation.\r\n\r\nShare numbering with mutations: so after mutation nr. 2, the lightweight mutation will get a number nr. 3.  \r\n\r\nWorks very similar to mutation, and share some invariants, but the result of lightweight mutation is stored 'aside'. \r\n\r\n20100101_1_1_0_2 + lightweight_mutation_3.txt = 20100101_1_1_0_2 + deleted_rows_masks_3.bin ( internally it store a mask for part 20100101_1_1_0_2 )\r\n\r\nObviously, masks need to be stored persistently. (fsyncs?)\r\n\r\nSo we will have one file deleted_rows_masks_3.bin (mutable, appendable) inside the table data folder for every 'lightweight_mutation'.\r\n\r\nLightweight_mutation mask for lightweight_mutations N+1 includes a mask for lightweight_mutations N (and all previous). \r\n\r\nThis way we single lightweight_mutation will write a single file only, and we can keep the last N files. \r\n\r\nThe last lightweight_mutation number is always stored in RAM together with other part metainformation.\r\n\r\nThe last mask **may** also be stored in RAM to make usage of it efficient (questionable - masks for large old parts can be big, so maybe smth like LRU cache + or some smart memory structures may be needed for that).\r\n\r\nWe also need a nice way to read deleted_rows_masks_3.bin for a particular part, so we may also need smth like deleted_rows_masks_3.idx\r\n\r\nSo the how that 'lightweight_mutation' work \r\n\r\n1) `DELETE FROM TABLE ... ` fired\r\n2) we get the block number(s) for delete (just like with ALTER DELETE), let's say 100\r\n3) work very similar to mutation (part by part), but instead of writing new parts - it \r\n   produces `deleted_rows_masks_100.bin`  \r\n   - to achieve speed similar to SELECT - it may be needed to use `max_threads` here. \r\n4) if we get part 'younger' than 100 (for example from another replica, from a merge scheduled before DELETE) we should\r\n   calculate mask for it when the part is added to a working set.\r\n5) merge on 2 parts ( 20100101_1_1_0 + 20100101_2_2_0 ) which have mutation id 3 and masks in\r\n   deleted_rows_masks_3.bin will produce a part with masks applied, and number in the part name, i.e. \r\n   `20100101_1_1_0 + 20100101_2_2_0 + deleted_rows_masks_3.bin = 20100101_1_2_1_3 (and no mask).`\r\n\r\nExisting invariant for mutations: \r\n  'every part which has block numbers and mutation_nr younger than last mutation id considered unmutated' get changed to \r\n  'every part which has block numbers and max( mutation_nr || deleted_rows_masks_last_mutation ) younger than last mutation id considered unmutated'\r\n\r\nIn replicated:\r\n\r\n1) every replica pays the same price for lightweight_mutation and applies it on its own set of parts. \r\n   state of `deleted_rows_masks_X.bin` can differ on different replicas (and will differ, because set of parts on every replica can differ), but eventually, they will get in sync. (after all known parts with block numbers younger than mutation will be processed). \r\n\r\n2) extend FETCH part to send also latest mask together with part. ( Alternatively: introduce deleted_rows_masks exchange, so if some replica has missing masks for some reason it can request from other replica masks for any of parts existing on that replica.)\r\n\r\n### Steps\r\n\r\nA. Plain MergeTree implementation\r\n\r\n1. Prepare simple in-memory storage for masks + API around (mask getter per part, mask setter per mutation_id)\r\n2. parser for SQL deletes, write lightweight mutation to files (similar to mutationXXX.sql)\r\n3. Create a mutation mode that uses lightweight_mutationXXX.sql and creates masks\r\n4. Make MergeTreeReader aware of deleted rows bitmask on SELECT.\r\n   <-- MVP (deletes w/o persistancy)\r\n5. Add serialization for masks to file, pick the best format supporting appending, checksum validation, and indexing for a mask. (reuse the writers from Log family?), support fsync.\r\n6. Cleanup of obsolete mask files\r\n   <-- + persistancy\r\n7. Review / adjust various places where part checks/manipulation happen (server start, merges, normal mutations, alters, etc).\r\n   <-- cover complex scenarios\r\n8. Consider in-memory optimization for mask storage (LRU cache with fixed size?)\r\n9. Consider multithreaded execution of lightweight mutations\r\n   <-- performance optimizations\r\n\r\nB. ReplicatedMergeTree implementation\r\n\r\n1. Extend replication queue with a new type of task.\r\n2. Extend part sending to send also mask (preserve backward compatibility for older ClickHouse)\r\n3. Review / adjust various places where part checks/manipulation happen (server start, merges, normal mutations, alters etc).\r\n4. Extend part-exchange to be able to recover masks from other replicas.\r\n\r\n\r\n<details>\r\n<summary>Implementation details (older, rejected version)</summary>\r\n\r\n### Implementation details (older, rejected version)\r\n\r\nDeclaimer: it's just a concept. Details should be rechecked/reviewed.\r\n\r\nEvery MergeTree table currently has a set of **data parts** inside (it as a structure defined by a user, and can carry a big amount of data), we want to introduce a new set of **deleted_rows_masks parts** with a fixed and predefined structure and normally it will be tiny. It can be one more 'MergeTreeData' object attached to Storage, or just a special 'service' partition with another structure.  The deletes will be transformed into inserts to **deleted_rows_masks parts** (see below).\r\n\r\nWe will need to add to MergeTreeReader option to apply that mask automatically (so both selects and merges will work).\r\n\r\nIn the future, we can also consider adding some optimizations to skip whole ranges during PK analysis. \r\n\r\n#### deleted_rows_mask parts\r\n\r\nThose **deleted_rows_mask parts** can live in a subfolder `deleted_rows_masks`, inside table data directory. Or live together with other parts (but with some other partition name). \r\n\r\nInternally it can have a logical structure similar to:\r\n```\r\n(\r\n   part_name String,\r\n   part_state Enum8('active' = 0, 'eol' = 1),  /* once there is scheduled merge for a part we need to store it's state separately */\r\n   delete_ids AggregateFunction(groupArray, UInt32) /* ids of all deletes / may be just max will be enough */\r\n   mask AggregateFunction(groupBitmap, UInt32),\r\n   deleted_timestamp SimpleAggregateFunction(max, DateTime),\r\n) engine=AggregatingMergeTree\r\nORDER BY (part_name, part_state)\r\nTTL deleted_timestamp + 1 HOUR\r\n```\r\n\r\nFor storing masks of deleted rows per part roaring bitmaps sounds like a good choice:\r\n - they are compact if not too many rows were deleted\r\n - will be able to store up to `MAX_UINT32` offsets for every part (~4 bln, I guess should be enough).\r\n - do 'bitwise or' automatically (needed to merge multiple deletes into a single row per part)\r\n - can be slower/bigger when a lot of random rows were deleted, but that sounds acceptable. \r\n\r\nAlternatively, simple arrays can be used.\r\n\r\n**deleted_rows_masks parts** should be registered in zookeeper the usual way (just like one more 'service' partition), and share the same/single replication queue (this way, we can preserve the proper sequence of `INSERT`s / `DELETE`s / merges). \r\n\r\nThe last state of **deleted_rows_masks** may also live in RAM to avoid reading those parts with every select, so when you add a new part into **deleted_rows_mask** we update that state in RAM.\r\n\r\n## DELETE process for ReplicatedMergeTree\r\n\r\n1) add DELETE to the replication queue. It stored block_number from every partition (just like mutations)\r\n\r\n2) each replica having received a DELETE from the replication queue must apply it to its active set of data parts.\r\n\r\n3) Each part \"younger\" (by its block number) than DELETE must have a mask for this part next to the data part in the version corresponding to the DELETE that occurred. To build that:\r\n\r\n    * iterate data parts sequentially \r\n      \r\n    * for every part with max_block_number lower than DELETE block number we:\r\n        1. first check for non-fetched yet parts **deleted_rows_mask partition** and fetch them. \r\n        2. if we don't have a delete mask for pair of <part_name, DELETE with number X> in a special place (**deleted_rows_mask partition**) then execute the DELETE to calculate the mask.\r\n        3. if there is a merge for that part in the queue we insert it as 'eol' (merges can use only part_state=active).\r\n    \r\n    * skip parts with min_block_number greater than DELETE block number\r\n     \r\n    * if we have a situation: min_block_number < delete block number < max_block_number, and no mask in **deleted_rows_mask partition** - I guess it should be a logical error / should be just forbidden (by preventing the execution of the merges from the queue out of order with deletes, and by extra logic in merge), see also \"merges execution\" below. \r\n    \r\n    * after iterating all the parts form an insert into **deleted_rows_mask partition**. If other replicas already did that - it's ok, deletes are idempotent.\r\n          \r\n    After the DELETE record has been successfully processed by all replicas (and the corresponding masks have been created),\r\n    and all merges which were scheduled before DELETE were finished, then the DELETE record is no longer needed anymore in the replication queue. Now we store the history of deleted rows only as a mask.\r\n    \r\n### execution of merges\r\n* Merge could have been assigned before DELETE or after.\r\n![lightweight_deletes2](https://user-images.githubusercontent.com/1549571/105840084-baff5a80-5fd2-11eb-9e41-e1b37973a101.png)\r\n![lightweight_deletes3](https://user-images.githubusercontent.com/1549571/105840091-bdfa4b00-5fd2-11eb-904b-a8de8ca7b172.png)\r\n    \r\n* Merges start depending not only on the source data parts but also on deletes that were executed BEFORE the merge. So we can not start the merge if one of the source parts is not yet ready, or if some DELETE assigned before the merge is not finished.\r\n![lightweight_deletes4](https://user-images.githubusercontent.com/1549571/105840694-b7b89e80-5fd3-11eb-9077-90fbf71f9b34.png)\r\n\r\n* Any merge should read data by applying \"on the fly\" masks of all DELETEs assigned earlier (i.e. with part_state='active') physically deleting and ignore the masks of those DELETEs that were assigned later than the merge started. Thus, even the lagging merges will produce parts with the same checksums.\r\n\r\n* After the end of the merge, before adding a part to the active set, we should make sure that for the new (merged)\r\npart there are masks for all DELETE operation launched AFTER the merge assignment. If some of them are missing - they need to be downloaded or calculated. \r\n\r\n![lightweight_deletes5](https://user-images.githubusercontent.com/1549571/105840820-e9ca0080-5fd3-11eb-904a-521744da49ac.png)\r\n\r\n### background operations on deleted_rows_mask partition\r\n\r\nWe want masks to be compact and cheap to use.\r\n  \r\n* multiple replicas can add the same row to the partition with masks at the same time (no big deal, deletes are idempotent)\r\n\r\n* masks for the same part are divided into two groups \r\n    - related to DELETE operations fired BEFORE the merge, which should end the lifetime of that part (they will be applied during the merge)\r\n    - and related to DELETE operations fired after the merge is assigned (they will not be applied during the merge but will be applied during the selections).\r\n\r\n* several lines containing masks for the same part can be combined into one line (bitwise OR on masks) within these two groups.\r\n\r\nExample. If 100 deletes happened before the merge was assigned and 25 more after it was assigned. Then you can combine\r\nall 100 in one general mask, and 25 in a separate mask.\r\n * after the part has been removed (as a result of a merge or similar operation), we can safely remove it and related masks\r\n * replica can safely exchange parts with masks just like regular parts.\r\n  whatever\r\n\r\n</details>\r\n\r\n\r\n# UPDATEs? \r\n\r\nExecuting a 'proper' update requires access to the previous state of the row, which may be not available (or can be outdated) due to eventual consistency on any concrete replica. \r\n\r\nThe quite easy thing is a special kind of UPDATE similar to UPSERT (internally DELETE as above + INSERT, w/o accessing the previous state of the row). \r\n\r\nAlternatives: \r\n- wait for `n-1` replication state (finishing all merges/fetches etc assigned before the update) - it can be very long delays.\r\n- apply on the fly till `n-1` replication state will be reached. That may end up with quite strange behavior, when different rows are affected by same update depending on replication state. Questionable: i guess users expect smth similar to ACID rdbms\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19627/reactions","total_count":10,"+1":10,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19627/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19611","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19611/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19611/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19611/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/19611","id":794086571,"node_id":"MDU6SXNzdWU3OTQwODY1NzE=","number":19611,"title":"How to get map type all keys or values or do count aggregation?","user":{"login":"ahutsunshine","id":6041410,"node_id":"MDQ6VXNlcjYwNDE0MTA=","avatar_url":"https://avatars.githubusercontent.com/u/6041410?v=4","gravatar_id":"","url":"https://api.github.com/users/ahutsunshine","html_url":"https://github.com/ahutsunshine","followers_url":"https://api.github.com/users/ahutsunshine/followers","following_url":"https://api.github.com/users/ahutsunshine/following{/other_user}","gists_url":"https://api.github.com/users/ahutsunshine/gists{/gist_id}","starred_url":"https://api.github.com/users/ahutsunshine/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ahutsunshine/subscriptions","organizations_url":"https://api.github.com/users/ahutsunshine/orgs","repos_url":"https://api.github.com/users/ahutsunshine/repos","events_url":"https://api.github.com/users/ahutsunshine/events{/privacy}","received_events_url":"https://api.github.com/users/ahutsunshine/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":6,"created_at":"2021-01-26T09:46:24Z","updated_at":"2021-01-26T11:52:08Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"For the implementation of map type https://github.com/ClickHouse/ClickHouse/pull/15806 and the document https://github.com/ClickHouse/ClickHouse/pull/19592, I dont see how I can iterate the map type and  get all map keys or values? Also, I  want to calculate the map value count  group by the map value, how can I do this? Thanks.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19611/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19611/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19594","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19594/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19594/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19594/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/19594","id":793898521,"node_id":"MDU6SXNzdWU3OTM4OTg1MjE=","number":19594,"title":" Whether the parts of the same partition is a concurrent merge?","user":{"login":"Sallery-X","id":45587738,"node_id":"MDQ6VXNlcjQ1NTg3NzM4","avatar_url":"https://avatars.githubusercontent.com/u/45587738?v=4","gravatar_id":"","url":"https://api.github.com/users/Sallery-X","html_url":"https://github.com/Sallery-X","followers_url":"https://api.github.com/users/Sallery-X/followers","following_url":"https://api.github.com/users/Sallery-X/following{/other_user}","gists_url":"https://api.github.com/users/Sallery-X/gists{/gist_id}","starred_url":"https://api.github.com/users/Sallery-X/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Sallery-X/subscriptions","organizations_url":"https://api.github.com/users/Sallery-X/orgs","repos_url":"https://api.github.com/users/Sallery-X/repos","events_url":"https://api.github.com/users/Sallery-X/events{/privacy}","received_events_url":"https://api.github.com/users/Sallery-X/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-01-26T03:28:28Z","updated_at":"2021-01-26T03:28:28Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19594/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19594/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19586","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19586/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19586/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19586/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/19586","id":793681266,"node_id":"MDU6SXNzdWU3OTM2ODEyNjY=","number":19586,"title":"Code: 198, DB::Exception: Cannot getnameinfo(): Name or service not known","user":{"login":"ben-efiz","id":1567878,"node_id":"MDQ6VXNlcjE1Njc4Nzg=","avatar_url":"https://avatars.githubusercontent.com/u/1567878?v=4","gravatar_id":"","url":"https://api.github.com/users/ben-efiz","html_url":"https://github.com/ben-efiz","followers_url":"https://api.github.com/users/ben-efiz/followers","following_url":"https://api.github.com/users/ben-efiz/following{/other_user}","gists_url":"https://api.github.com/users/ben-efiz/gists{/gist_id}","starred_url":"https://api.github.com/users/ben-efiz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ben-efiz/subscriptions","organizations_url":"https://api.github.com/users/ben-efiz/orgs","repos_url":"https://api.github.com/users/ben-efiz/repos","events_url":"https://api.github.com/users/ben-efiz/events{/privacy}","received_events_url":"https://api.github.com/users/ben-efiz/received_events","type":"User","site_admin":false},"labels":[{"id":845247686,"node_id":"MDU6TGFiZWw4NDUyNDc2ODY=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/usability","name":"usability","color":"ebf28c","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2021-01-25T19:56:30Z","updated_at":"2021-02-02T09:26:10Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"**Describe the bug**\r\nThe ClickHouse setup (more details below) works as expected, including replication, but the error log at `/var/log/clickhouse-server/clickhouse-server.err.log` contains a big amount of unexpected stacktraces, always the same (see below). It seems it can not [resolve the host name](https://github.com/ClickHouse/ClickHouse/blob/80ae2b5138d98c01399c10543c11b69f7b2bad83/src/Common/DNSResolver.cpp#L120).\r\n\r\n**Does it reproduce on recent release?**\r\n21.1.2.15 (official build)\r\n\r\n**How to reproduce**\r\n* its not triggered by a specific query but happens just by running the clickhouse server\r\n\r\n**Expected behavior**\r\nNo error logged if everything works as expected.\r\n\r\n**Error message and/or stacktrace**\r\n```\r\n2021.01.25 19:12:50.043078 [ 59 ] {} <Error> bool DB::DNSResolver::updateCacheImpl(UpdateF &&, ElemsT &&, const DB::String &) [UpdateF = bool (DB::DNSResolver::*)(const Poco::Net::IPAddress &), ElemsT = std::__1::unordered_set<Poco::Net::IPAddress, std::__1::hash<Poco::Net::IPAddress>, std::__1::equal_to<Poco::Net::IPAddress>, std::__1::allocator<Poco::Net::IPAddress>> &]: Code: 198, e.displayText() = DB::Exception: Cannot getnameinfo(::ffff:<IP address redacted>): Name or service not known, Stack trace (when copying this message, always include the lines below):\r\n\r\n0. ? @ 0x869e50d in /usr/bin/clickhouse\r\n1. ? @ 0x869fa83 in /usr/bin/clickhouse\r\n2. DB::DNSResolver::updateAddress(Poco::Net::IPAddress const&) @ 0x86a2308 in /usr/bin/clickhouse\r\n3. bool DB::DNSResolver::updateCacheImpl<bool (DB::DNSResolver::*)(Poco::Net::IPAddress const&), std::__1::unordered_set<Poco::Net::IPAddress, std::__1::hash<Poco::Net::IPAddress>, std::__1::equal_to<Poco::Net::IPAddress>, std::__1::allocator<Poco::Net::IPAddress> >&>(bool (DB::DNSResolver::*&&)(Poco::Net::IPAddress const&), std::__1::unordered_set<Poco::Net::IPAddress, std::__1::hash<Poco::Net::IPAddress>, std::__1::equal_to<Poco::Net::IPAddress>, std::__1::allocator<Poco::Net::IPAddress> >&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) @ 0x86a1d60 in /usr/bin/clickhouse\r\n4. DB::DNSResolver::updateCache() @ 0x86a0d31 in /usr/bin/clickhouse\r\n5. DB::DNSCacheUpdater::run() @ 0xeb6957a in /usr/bin/clickhouse\r\n6. DB::BackgroundSchedulePoolTaskInfo::execute() @ 0xeb39ae2 in /usr/bin/clickhouse\r\n7. DB::BackgroundSchedulePool::threadFunction() @ 0xeb3bf17 in /usr/bin/clickhouse\r\n8. ? @ 0xeb3d191 in /usr/bin/clickhouse\r\n9. ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) @ 0x86415ed in /usr/bin/clickhouse\r\n10. ? @ 0x86451a3 in /usr/bin/clickhouse\r\n11. start_thread @ 0x9609 in /usr/lib/x86_64-linux-gnu/libpthread-2.31.so\r\n12. __clone @ 0x122293 in /usr/lib/x86_64-linux-gnu/libc-2.31.so\r\n (version 21.1.2.15 (official build))\r\n```\r\n\r\n**Additional context**\r\n\r\nThe IP address of the host in the above mentioned stacktrace was redacted but it showed correctly as 10.11.12.13 (as an example).\r\n\r\nThe ClickHouse instance is running using [ClickHouse Operator](https://github.com/Altinity/clickhouse-operator) on Kubernetes cluster using 1 shard, 2 replicas and 3 ZooKeeper instances.\r\n\r\n```\r\nuname -a\r\nLinux chi-ugcluster-production-0-0-0 3.10.0-1062.18.1.el7.x86_64 #1 SMP Tue Mar 17 23:49:17 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\ncat /proc/version                                                                                                                              126 ↵\r\nLinux version 3.10.0-1062.18.1.el7.x86_64 (mockbuild@kbuilder.bsys.centos.org) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC) ) #1 SMP Tue Mar 17 23:49:17 UTC 2020\r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19586/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19586/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19477","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19477/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19477/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19477/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/19477","id":792387230,"node_id":"MDU6SXNzdWU3OTIzODcyMzA=","number":19477,"title":"SQL parser reports wrong error.","user":{"login":"den-crane","id":19737682,"node_id":"MDQ6VXNlcjE5NzM3Njgy","avatar_url":"https://avatars.githubusercontent.com/u/19737682?v=4","gravatar_id":"","url":"https://api.github.com/users/den-crane","html_url":"https://github.com/den-crane","followers_url":"https://api.github.com/users/den-crane/followers","following_url":"https://api.github.com/users/den-crane/following{/other_user}","gists_url":"https://api.github.com/users/den-crane/gists{/gist_id}","starred_url":"https://api.github.com/users/den-crane/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/den-crane/subscriptions","organizations_url":"https://api.github.com/users/den-crane/orgs","repos_url":"https://api.github.com/users/den-crane/repos","events_url":"https://api.github.com/users/den-crane/events{/privacy}","received_events_url":"https://api.github.com/users/den-crane/received_events","type":"User","site_admin":false},"labels":[{"id":845247686,"node_id":"MDU6TGFiZWw4NDUyNDc2ODY=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/usability","name":"usability","color":"ebf28c","default":false,"description":""}],"state":"open","locked":false,"assignee":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"assignees":[{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false}],"milestone":null,"comments":1,"created_at":"2021-01-23T00:22:51Z","updated_at":"2021-01-23T21:09:24Z","closed_at":null,"author_association":"COLLABORATOR","active_lock_reason":null,"body":"```sql\r\n\r\nCREATE TABLE items (\r\n  time DateTime,\r\n  group_id UInt16,\r\n  value UInt32()\r\n) ENGINE = MergeTree()\r\nPARTITION BY toYYYYMM(time)\r\nORDER BY (group_id, time);\r\n\r\nSELECT\r\n  group_id,\r\n  groupArray(time)[1] as time,\r\n  groupArray(value)                       , \r\nFROM ( \r\n  SELECT * FROM items ORDER BY time desc LIMIT 100 BY group_id\r\n)\r\nGROUP BY group_id;\r\n\r\n\r\n(version 21.1.1)\r\nReceived from localhost:9000. DB::Exception: Query argument can only be used in the `view` TableFunction.\r\n\r\n```\r\nbecause of excessive comma  ` groupArray(value)    , `","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19477/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19477/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19429","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19429/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19429/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19429/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/19429","id":792001981,"node_id":"MDU6SXNzdWU3OTIwMDE5ODE=","number":19429,"title":"RBAC - SHOW GRANTS FOR ALL don't check if user is allowed to see grants","user":{"login":"filimonov","id":1549571,"node_id":"MDQ6VXNlcjE1NDk1NzE=","avatar_url":"https://avatars.githubusercontent.com/u/1549571?v=4","gravatar_id":"","url":"https://api.github.com/users/filimonov","html_url":"https://github.com/filimonov","followers_url":"https://api.github.com/users/filimonov/followers","following_url":"https://api.github.com/users/filimonov/following{/other_user}","gists_url":"https://api.github.com/users/filimonov/gists{/gist_id}","starred_url":"https://api.github.com/users/filimonov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/filimonov/subscriptions","organizations_url":"https://api.github.com/users/filimonov/orgs","repos_url":"https://api.github.com/users/filimonov/repos","events_url":"https://api.github.com/users/filimonov/events{/privacy}","received_events_url":"https://api.github.com/users/filimonov/received_events","type":"User","site_admin":false},"labels":[{"id":386401505,"node_id":"MDU6TGFiZWwzODY0MDE1MDU=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/bug","name":"bug","color":"ee0701","default":true,"description":"Confirmed user-visible misbehaviour in official release"},{"id":2011606513,"node_id":"MDU6TGFiZWwyMDExNjA2NTEz","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-rbac","name":"comp-rbac","color":"b5bcff","default":false,"description":"Access control related"}],"state":"open","locked":false,"assignee":{"login":"vitlibar","id":45142681,"node_id":"MDQ6VXNlcjQ1MTQyNjgx","avatar_url":"https://avatars.githubusercontent.com/u/45142681?v=4","gravatar_id":"","url":"https://api.github.com/users/vitlibar","html_url":"https://github.com/vitlibar","followers_url":"https://api.github.com/users/vitlibar/followers","following_url":"https://api.github.com/users/vitlibar/following{/other_user}","gists_url":"https://api.github.com/users/vitlibar/gists{/gist_id}","starred_url":"https://api.github.com/users/vitlibar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vitlibar/subscriptions","organizations_url":"https://api.github.com/users/vitlibar/orgs","repos_url":"https://api.github.com/users/vitlibar/repos","events_url":"https://api.github.com/users/vitlibar/events{/privacy}","received_events_url":"https://api.github.com/users/vitlibar/received_events","type":"User","site_admin":false},"assignees":[{"login":"vitlibar","id":45142681,"node_id":"MDQ6VXNlcjQ1MTQyNjgx","avatar_url":"https://avatars.githubusercontent.com/u/45142681?v=4","gravatar_id":"","url":"https://api.github.com/users/vitlibar","html_url":"https://github.com/vitlibar","followers_url":"https://api.github.com/users/vitlibar/followers","following_url":"https://api.github.com/users/vitlibar/following{/other_user}","gists_url":"https://api.github.com/users/vitlibar/gists{/gist_id}","starred_url":"https://api.github.com/users/vitlibar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vitlibar/subscriptions","organizations_url":"https://api.github.com/users/vitlibar/orgs","repos_url":"https://api.github.com/users/vitlibar/repos","events_url":"https://api.github.com/users/vitlibar/events{/privacy}","received_events_url":"https://api.github.com/users/vitlibar/received_events","type":"User","site_admin":false}],"milestone":null,"comments":0,"created_at":"2021-01-22T13:24:02Z","updated_at":"2021-01-22T13:24:19Z","closed_at":null,"author_association":"COLLABORATOR","active_lock_reason":null,"body":"```\r\nlaptop-5591 :) SHOW GRANTS;\r\n\r\nSHOW GRANTS\r\n\r\nQuery id: 43b4b2ea-7789-4c2a-8ce8-094e17d27538\r\n\r\n┌─GRANTS─────────────────────┐\r\n│ GRANT SELECT ON *.* TO xxx │\r\n└────────────────────────────┘\r\n\r\n1 rows in set. Elapsed: 0.003 sec. \r\n\r\nlaptop-5591 :) select * from system.grants;\r\n\r\nSELECT *\r\nFROM system.grants\r\n\r\nQuery id: 2e159b46-e94a-4e34-98cd-b8c1c573fcf7\r\n\r\n\r\nReceived exception from server (version 20.13.1):\r\nCode: 497. DB::Exception: Received from localhost:9000. DB::Exception: xxx: Not enough privileges. To execute this query it's necessary to have grant SHOW USERS, SHOW ROLES ON *.*. \r\n\r\n0 rows in set. Elapsed: 0.004 sec. \r\n\r\nlaptop-5591 :) SHOW GRANTS FOR ALL;\r\n\r\nSHOW GRANTS FOR ALL\r\n\r\nQuery id: 5c10f791-b010-4190-907d-9ff17bccf7be\r\n\r\n┌─GRANTS FOR ALL────────────────────────────────┐\r\n│ GRANT ALL ON *.* TO admin WITH GRANT OPTION   │\r\n│ GRANT ALL ON *.* TO default WITH GRANT OPTION │\r\n│ GRANT SELECT ON *.* TO xxx                    │\r\n└───────────────────────────────────────────────┘\r\n\r\n3 rows in set. Elapsed: 0.003 sec. \r\n```\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19429/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19429/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19427","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19427/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19427/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19427/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/19427","id":791965040,"node_id":"MDU6SXNzdWU3OTE5NjUwNDA=","number":19427,"title":"Interval syntax like datetime_column + '30 days' is not supported","user":{"login":"UnamedRus","id":9449405,"node_id":"MDQ6VXNlcjk0NDk0MDU=","avatar_url":"https://avatars.githubusercontent.com/u/9449405?v=4","gravatar_id":"","url":"https://api.github.com/users/UnamedRus","html_url":"https://github.com/UnamedRus","followers_url":"https://api.github.com/users/UnamedRus/followers","following_url":"https://api.github.com/users/UnamedRus/following{/other_user}","gists_url":"https://api.github.com/users/UnamedRus/gists{/gist_id}","starred_url":"https://api.github.com/users/UnamedRus/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/UnamedRus/subscriptions","organizations_url":"https://api.github.com/users/UnamedRus/orgs","repos_url":"https://api.github.com/users/UnamedRus/repos","events_url":"https://api.github.com/users/UnamedRus/events{/privacy}","received_events_url":"https://api.github.com/users/UnamedRus/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-01-22T12:25:16Z","updated_at":"2021-01-22T12:30:06Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Use case**\r\nSupport for defining intervals without INTERVAL keyword.\r\nSupport for plural form of interval types.\r\n\r\n**Describe the solution you'd like**\r\n```\r\npostgres=# SELECT now() + '30 day';\r\n           ?column?\r\n-------------------------------\r\n 2021-02-19 04:01:01.766836+03\r\n(1 row)\r\npostgres=# SELECT now() + '30 days';\r\n           ?column?\r\n-------------------------------\r\n 2021-02-19 04:04:31.177359+03\r\n(1 row)\r\n\r\nlocaldomain :) SELECT now() + '30 day'\r\nReceived exception from server (version 21.1.1):\r\nCode: 43. DB::Exception: Received from localhost:9000. DB::Exception: Illegal types DateTime and String of arguments of function plus: While processing now() + '30 day'.\r\n\r\nlocaldomain :) SELECT now() + INTERVAL '30 day';\r\n\r\nSELECT now() + toIntervalDay(30)\r\n\r\nQuery id: cec3b62c-5393-4554-9c31-0f4ca4695fe6\r\n\r\n┌─plus(now(), toIntervalDay(30))─┐\r\n│            2021-02-21 15:22:51 │\r\n└────────────────────────────────┘\r\n\r\nlocaldomain :) SELECT now() + INTERVAL '30 days';\r\n\r\nSyntax error: failed at position 25 (''30 days''):\r\n\r\nSELECT now() + INTERVAL '30 days';\r\n\r\nExpected one of: UNION, LIMIT, WHERE, LIKE, GLOBAL NOT IN, HAVING, AS, DIV, IS, GROUP BY, INTO OUTFILE, OR, identifier, QuestionMark, BETWEEN, OFFSET, NOT LIKE, MOD, PREWHERE, AND, Comma, alias, ORDER BY, string literal, SETTINGS, IN, ILIKE, FROM, FORMAT, Dot, NOT ILIKE, WITH, NOT, token, NOT IN, GLOBAL IN\r\n```\r\n\r\n**Describe alternatives you've considered**\r\nAlways use INTERVAL keyword, but it's better to also support syntax which offered by other databases.\r\n\r\n\r\n\r\n**Additional context**\r\nAdd any other context or screenshots about the feature request here.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19427/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19427/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19426","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19426/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19426/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19426/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/19426","id":791958258,"node_id":"MDU6SXNzdWU3OTE5NTgyNTg=","number":19426,"title":"GROUPING aggregate function","user":{"login":"UnamedRus","id":9449405,"node_id":"MDQ6VXNlcjk0NDk0MDU=","avatar_url":"https://avatars.githubusercontent.com/u/9449405?v=4","gravatar_id":"","url":"https://api.github.com/users/UnamedRus","html_url":"https://github.com/UnamedRus","followers_url":"https://api.github.com/users/UnamedRus/followers","following_url":"https://api.github.com/users/UnamedRus/following{/other_user}","gists_url":"https://api.github.com/users/UnamedRus/gists{/gist_id}","starred_url":"https://api.github.com/users/UnamedRus/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/UnamedRus/subscriptions","organizations_url":"https://api.github.com/users/UnamedRus/orgs","repos_url":"https://api.github.com/users/UnamedRus/repos","events_url":"https://api.github.com/users/UnamedRus/events{/privacy}","received_events_url":"https://api.github.com/users/UnamedRus/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":1464781898,"node_id":"MDU6TGFiZWwxNDY0NzgxODk4","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/st-in-progress","name":"st-in-progress","color":"e5b890","default":false,"description":"We are working on the issue currenlty"},{"id":1507871495,"node_id":"MDU6TGFiZWwxNTA3ODcxNDk1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/st-community-taken","name":"st-community-taken","color":"e5b890","default":false,"description":"External developer is working on that"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2021-01-22T12:15:25Z","updated_at":"2021-05-19T10:46:45Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Use case**\r\nHave ability to distinguish rows being produced by GROUP BY and ROLLUP / CUBE.\r\n\r\n**Describe the solution you'd like**\r\nJust like in oracle or other databases.\r\nhttps://oracle-base.com/articles/misc/rollup-cube-grouping-functions-and-grouping-sets\r\n\r\n**Describe alternatives you've considered**\r\nUsing nulls as suggested in https://github.com/ClickHouse/ClickHouse/issues/8091#issuecomment-563725443, but it's not always applicable.\r\n\r\n**Additional context**\r\nhttps://github.com/ClickHouse/ClickHouse/issues/8091\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19426/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19426/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19392","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19392/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19392/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19392/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/19392","id":791573049,"node_id":"MDU6SXNzdWU3OTE1NzMwNDk=","number":19392,"title":"Best way to select last/first n rows for each group","user":{"login":"alex-klepa","id":1385751,"node_id":"MDQ6VXNlcjEzODU3NTE=","avatar_url":"https://avatars.githubusercontent.com/u/1385751?v=4","gravatar_id":"","url":"https://api.github.com/users/alex-klepa","html_url":"https://github.com/alex-klepa","followers_url":"https://api.github.com/users/alex-klepa/followers","following_url":"https://api.github.com/users/alex-klepa/following{/other_user}","gists_url":"https://api.github.com/users/alex-klepa/gists{/gist_id}","starred_url":"https://api.github.com/users/alex-klepa/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alex-klepa/subscriptions","organizations_url":"https://api.github.com/users/alex-klepa/orgs","repos_url":"https://api.github.com/users/alex-klepa/repos","events_url":"https://api.github.com/users/alex-klepa/events{/privacy}","received_events_url":"https://api.github.com/users/alex-klepa/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2021-01-21T23:43:26Z","updated_at":"2021-01-23T06:43:53Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Hi,\r\n\r\nFirst I want to say thank you to all developers and contributors for this killer product, I start evaluating it for my project and I love it!\r\n\r\nI have a query optimization question, let's say I have following table:\r\n\r\n```sql\r\nCREATE TABLE items (\r\n  time DateTime,\r\n  group_id UInt16,\r\n  value UInt32()\r\n) ENGINE = MergeTree()\r\nPARTITION BY toYYYYMM(time)\r\nORDER BY (group_id, time)\r\n```\r\n\r\nAnd I need to select last n rows for each group, the first most obvious query is this(using CH **LIMIT n BY**), but it's not optimal and can be slow on large data sets:\r\n\r\n```sql\r\nSELECT\r\n  group_id,\r\n  groupArray(time)[1] as time,\r\n  groupArray(value), -- << Here I can calculate moving avergaes, rolling sums, etc.\r\nFROM ( \r\n  SELECT * FROM items ORDER BY time desc LIMIT 100 BY group_id\r\n)\r\nGROUP BY group_id;\r\n```\r\n\r\nIs there a way to optimize this query or different way to do it (different table(s) structure)?","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19392/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19392/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19388","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19388/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19388/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19388/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/19388","id":791519159,"node_id":"MDU6SXNzdWU3OTE1MTkxNTk=","number":19388,"title":"RFC: different priorities for different ClickHouse users ?","user":{"login":"bharatnc","id":9305394,"node_id":"MDQ6VXNlcjkzMDUzOTQ=","avatar_url":"https://avatars.githubusercontent.com/u/9305394?v=4","gravatar_id":"","url":"https://api.github.com/users/bharatnc","html_url":"https://github.com/bharatnc","followers_url":"https://api.github.com/users/bharatnc/followers","following_url":"https://api.github.com/users/bharatnc/following{/other_user}","gists_url":"https://api.github.com/users/bharatnc/gists{/gist_id}","starred_url":"https://api.github.com/users/bharatnc/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bharatnc/subscriptions","organizations_url":"https://api.github.com/users/bharatnc/orgs","repos_url":"https://api.github.com/users/bharatnc/repos","events_url":"https://api.github.com/users/bharatnc/events{/privacy}","received_events_url":"https://api.github.com/users/bharatnc/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2021-01-21T21:50:36Z","updated_at":"2021-01-26T05:31:54Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"As far as I have seen, I don't think ClickHouse has very fine grained control of determining which user get's more priority or which one get's lesser priority while interacting with the database though queries. Closest reference that I could actually find regarding any work that is being planned this year relating to this is the `WorkLoad Management` section in #17623.  Though I might be wrong. But I' anyway going to continue to explain the use case that I have on my mind.\r\n\r\nI'm aiming this issue be a beginning or a RFC or a exploratory conversation. \r\n\r\nTo put this feature in context, many times, we have seen a lot of user intensive queries by many analysts hog entire ClickHouse clusters concurrently affecting production workloads. In such scenarios, if there was a way to set different priorities for production_service_users, and analyst_users, then the queries initiated by our production services could be prioritized and the queries from the analyst_users can be penalized or set to a lower priority.  \r\n\r\n\r\nI am not sure what would be the best way to go about doing this or not sure if this can even be done from an architectural perspective but perhaps this could be implemented in ClickHouse using the [ioprio_set ](https://man7.org/linux/man-pages/man2/ioprio_get.2.html) functions that Linux provides. \r\n\r\n@alexey-milovidov @filimonov just ccing. Would be interested to explore and contribute if:\r\n\r\n- this sounds like a good idea\r\n- provided this doesn't yet exist inside CH (which I think doesn't)\r\n\r\nThank you in advance!","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19388/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19388/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19370","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19370/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19370/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19370/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/19370","id":791201869,"node_id":"MDU6SXNzdWU3OTEyMDE4Njk=","number":19370,"title":"groupArrayArray | DB::Exception: Too large array size: while receiving packet","user":{"login":"hatrena","id":5187173,"node_id":"MDQ6VXNlcjUxODcxNzM=","avatar_url":"https://avatars.githubusercontent.com/u/5187173?v=4","gravatar_id":"","url":"https://api.github.com/users/hatrena","html_url":"https://github.com/hatrena","followers_url":"https://api.github.com/users/hatrena/followers","following_url":"https://api.github.com/users/hatrena/following{/other_user}","gists_url":"https://api.github.com/users/hatrena/gists{/gist_id}","starred_url":"https://api.github.com/users/hatrena/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/hatrena/subscriptions","organizations_url":"https://api.github.com/users/hatrena/orgs","repos_url":"https://api.github.com/users/hatrena/repos","events_url":"https://api.github.com/users/hatrena/events{/privacy}","received_events_url":"https://api.github.com/users/hatrena/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-01-21T15:12:31Z","updated_at":"2021-03-10T11:29:24Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Hi,\r\n\r\nI have a table that has `arr` as `Array(LowCardinality(String))`. Now I am using syntax in my query to result in aggregated info for `arr` like:\r\n\r\n`arrayReduce('sumMap', [groupArrayArray(arr) AS flat_arr], [arrayResize(CAST([], 'Array(UInt64)'), length(flat_arr), toUInt64(1))]) AS arr_stats` \r\n\r\nSo the expected result would be something like:\r\n`A,B,1,3`\r\n\r\nThis query will result in `DB::Exception: Too large array size: while receiving packet` error if I have much data as `groupArrayArray` is flatting the `arr`\r\n\r\nIs there any other way to get the result I need? ","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19370/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19370/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19342","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19342/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19342/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19342/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/19342","id":790632463,"node_id":"MDU6SXNzdWU3OTA2MzI0NjM=","number":19342,"title":"why show create database on mysql engine timeout","user":{"login":"weeway","id":12637868,"node_id":"MDQ6VXNlcjEyNjM3ODY4","avatar_url":"https://avatars.githubusercontent.com/u/12637868?v=4","gravatar_id":"","url":"https://api.github.com/users/weeway","html_url":"https://github.com/weeway","followers_url":"https://api.github.com/users/weeway/followers","following_url":"https://api.github.com/users/weeway/following{/other_user}","gists_url":"https://api.github.com/users/weeway/gists{/gist_id}","starred_url":"https://api.github.com/users/weeway/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/weeway/subscriptions","organizations_url":"https://api.github.com/users/weeway/orgs","repos_url":"https://api.github.com/users/weeway/repos","events_url":"https://api.github.com/users/weeway/events{/privacy}","received_events_url":"https://api.github.com/users/weeway/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-01-21T02:40:32Z","updated_at":"2021-01-21T02:45:00Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"version: \r\n20.10.3.30\r\n\r\ndatabase ddl:\r\n```\r\n CREATE DATABASE mysql_xxx ENGINE = MySQL('xxx:3306', 'xxx', 'xxx', 'xxx') SETTINGS mysql_datatypes_support_level = ''\r\n```\r\n\r\nquery:\r\n```\r\n show create database mysql_kdwadm;\r\n```\r\n\r\nresult:\r\n<img width=\"1419\" alt=\"image\" src=\"https://user-images.githubusercontent.com/12637868/105272764-f534ba80-5bd4-11eb-9ea9-32dbba4d60af.png\">\r\n\r\nDose some know the reason?","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19342/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19342/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19320","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19320/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19320/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19320/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/19320","id":790045669,"node_id":"MDU6SXNzdWU3OTAwNDU2Njk=","number":19320,"title":"Add view function support to mysql/postgresql/odbc table functions.","user":{"login":"UnamedRus","id":9449405,"node_id":"MDQ6VXNlcjk0NDk0MDU=","avatar_url":"https://avatars.githubusercontent.com/u/9449405?v=4","gravatar_id":"","url":"https://api.github.com/users/UnamedRus","html_url":"https://github.com/UnamedRus","followers_url":"https://api.github.com/users/UnamedRus/followers","following_url":"https://api.github.com/users/UnamedRus/following{/other_user}","gists_url":"https://api.github.com/users/UnamedRus/gists{/gist_id}","starred_url":"https://api.github.com/users/UnamedRus/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/UnamedRus/subscriptions","organizations_url":"https://api.github.com/users/UnamedRus/orgs","repos_url":"https://api.github.com/users/UnamedRus/repos","events_url":"https://api.github.com/users/UnamedRus/events{/privacy}","received_events_url":"https://api.github.com/users/UnamedRus/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":6,"created_at":"2021-01-20T14:47:36Z","updated_at":"2022-01-18T01:19:46Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"Just like in https://github.com/ClickHouse/ClickHouse/pull/12567 But for mysql, postgresql and odbc table functions.\r\n\r\n**Use case**\r\nRun arbitrary queries in external databases with support of their sql syntax and functions.\r\n\r\n**Describe the solution you'd like**\r\n```\r\nSELECT * FROM mysql('localhost',view(SELECT GROUP_CONCAT FROM table),'user','password')\r\n```\r\n**Describe alternatives you've considered**\r\nCreate an view on external database side, but it wouldn't work when we have per tenant tables, so we need to use different tables for each query.\r\n\r\n**Additional context**\r\nLoosely related to https://github.com/ClickHouse/ClickHouse/issues/19288\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19320/reactions","total_count":4,"+1":4,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19320/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19319","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19319/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19319/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19319/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/19319","id":790045094,"node_id":"MDU6SXNzdWU3OTAwNDUwOTQ=","number":19319,"title":"Watching task ... is executing longer than distributed_ddl_task_timeout (=180) seconds","user":{"login":"ghuname","id":15207713,"node_id":"MDQ6VXNlcjE1MjA3NzEz","avatar_url":"https://avatars.githubusercontent.com/u/15207713?v=4","gravatar_id":"","url":"https://api.github.com/users/ghuname","html_url":"https://github.com/ghuname","followers_url":"https://api.github.com/users/ghuname/followers","following_url":"https://api.github.com/users/ghuname/following{/other_user}","gists_url":"https://api.github.com/users/ghuname/gists{/gist_id}","starred_url":"https://api.github.com/users/ghuname/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ghuname/subscriptions","organizations_url":"https://api.github.com/users/ghuname/orgs","repos_url":"https://api.github.com/users/ghuname/repos","events_url":"https://api.github.com/users/ghuname/events{/privacy}","received_events_url":"https://api.github.com/users/ghuname/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-01-20T14:46:57Z","updated_at":"2021-01-20T14:46:57Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Why ON CLUSTER commands sometimes work but sometimes don't?\r\n\r\nIn the example bellow, we have 4 nodes (10.241.129.170 - 10.241.129.173).\r\nNode1 and 2 (10.241.129.170 and 10.241.129.171) make the first shard, two other nodes are in second shard.\r\n\r\nI have executed the command bellow on node4 (10.241.129.173):\r\n\r\n[user@node04 ~]$ clickhouse-client  -m\r\nClickHouse client version 21.1.2.15 (official build).\r\nConnecting to localhost:9000 as user default.\r\nConnected to ClickHouse server version 21.1.2 revision 54443.\r\n\r\n```\r\nnode04 :) CREATE TABLE default.test_create_table on cluster grabber (\r\n:-] taskChannelNumber Int32,\r\n:-] taskEndTime DateTime,\r\n:-] taskUuid UUID,\r\n:-] snmpT3TimeoutsDelta Nullable(Int64),\r\n:-] snmpEqualizationData String,\r\n:-] snmpTxPower Nullable(Float32),\r\n:-] insertedOn DateTime,\r\n:-] sign Int8\r\n:-]     )\r\n:-]     ENGINE = ReplicatedCollapsingMergeTree('/clickhouse/tables/{layer}-{shard}/test_create_table', '{replica}', sign)\r\n:-]     PARTITION BY toDate(taskEndTime)\r\n:-]     ORDER BY (taskUuid, taskChannelNumber, snmpEqualizationData)\r\n:-]      TTL taskEndTime + toIntervalDay(14);\r\n\r\nCREATE TABLE default.test_create_table ON CLUSTER grabber\r\n(\r\n    `taskChannelNumber` Int32,\r\n    `taskEndTime` DateTime,\r\n    `taskUuid` UUID,\r\n    `snmpT3TimeoutsDelta` Nullable(Int64),\r\n    `snmpEqualizationData` String,\r\n    `snmpTxPower` Nullable(Float32),\r\n    `insertedOn` DateTime,\r\n    `sign` Int8\r\n)\r\nENGINE = ReplicatedCollapsingMergeTree('/clickhouse/tables/{layer}-{shard}/test_create_table', '{replica}', sign)\r\nPARTITION BY toDate(taskEndTime)\r\nORDER BY (taskUuid, taskChannelNumber, snmpEqualizationData)\r\nTTL taskEndTime + toIntervalDay(14)\r\n\r\nQuery id: aba07d42-67ba-49cf-803b-f8fe1667f028\r\n\r\n┌─host───────────┬─port─┬─status─┬─error─┬─num_hosts_remaining─┬─num_hosts_active─┐\r\n│ 10.241.129.171 │ 9000 │      0 │       │                   3 │                1 │\r\n└────────────────┴──────┴────────┴───────┴─────────────────────┴──────────────────┘\r\n┌─host───────────┬─port─┬─status─┬─error─┬─num_hosts_remaining─┬─num_hosts_active─┐\r\n│ 10.241.129.172 │ 9000 │      0 │       │                   2 │                0 │\r\n└────────────────┴──────┴────────┴───────┴─────────────────────┴──────────────────┘\r\n↙ Progress: 2.00 rows, 116.00 B (0.45 rows/s., 26.12 B/s.) █████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                          49%\r\nReceived exception from server (version 21.1.2):\r\nCode: 159. DB::Exception: Received from localhost:9000. DB::Exception: Watching task /clickhouse/task_queue/ddl/query-0000000691 is executing longer than distributed_ddl_task_timeout (=180) seconds. There are 2 unfinished hosts (0 of them are currently active), they are going to execute the query in background.\r\n\r\n2 rows in set. Elapsed: 180.238 sec.\r\n\r\nnode04 :)\r\n```\r\n\r\nWhen I execute `show create table default.test_create_table` on each node, the table is created on nodes 2 and 3, but not on nodes 1 and 4.\r\n\r\nI don't know whether it is related with this error, but sometimes we get an error \"Metadata on replica is not up to date with common metadata in Zookeeper. Cannot alter\" when trying to alter table when I execute sql with on cluster grabber keyword.\r\n\r\nIf I am doing everything node by node, everything works OK.\r\n\r\nHow to trace this type of errors?\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19319/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19319/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19311","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19311/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19311/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19311/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/19311","id":789924268,"node_id":"MDU6SXNzdWU3ODk5MjQyNjg=","number":19311,"title":"how to write groupBitmapState argument for executing bitmapContains","user":{"login":"l1t1","id":23301704,"node_id":"MDQ6VXNlcjIzMzAxNzA0","avatar_url":"https://avatars.githubusercontent.com/u/23301704?v=4","gravatar_id":"","url":"https://api.github.com/users/l1t1","html_url":"https://github.com/l1t1","followers_url":"https://api.github.com/users/l1t1/followers","following_url":"https://api.github.com/users/l1t1/following{/other_user}","gists_url":"https://api.github.com/users/l1t1/gists{/gist_id}","starred_url":"https://api.github.com/users/l1t1/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/l1t1/subscriptions","organizations_url":"https://api.github.com/users/l1t1/orgs","repos_url":"https://api.github.com/users/l1t1/repos","events_url":"https://api.github.com/users/l1t1/events{/privacy}","received_events_url":"https://api.github.com/users/l1t1/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-01-20T12:11:42Z","updated_at":"2021-01-21T00:16:42Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"```\r\nwith men as\r\n(select number id,mod(id,100)age,mod(id,1000)*60 sal,mod(id,60)nat from system.numbers limit 10000\r\n),t as(select number n,case  when n=0 then 0 when n=1 then 6 when n=2 then 30 end lo ,\r\ncase when n=0 then 5 when n=1 then 29 when n=2 then 99 end hi from system.numbers limit 3),\r\nt2 as(\r\nselect toString(n)name,groupBitmapState(case when age between \r\nlo\r\nand \r\nhi\r\nthen id end)b from men,t group by n\r\n)\r\nselect name,arraySlice([\r\nsum(case when name='0' and bitmapContains(b,toUInt32(id))=1 then sal end) ,\r\nsum(case when name='1' and bitmapContains(b,toUInt32(id))=1 then sal end) ,\r\nsum(case when name='2' and bitmapContains(b,toUInt32(id))=1 then sal end) ],toInt32(name)+1,1) a\r\nfrom men,t2\r\ngroup by name\r\n;\r\n```\r\nreturns\r\n\r\nCode: 43, e.displayText() = DB::Exception: Unexpected type AggregateFunction(groupBitmap, Nullable(UInt64)) of argument of function bitmapContains: while executing 'FUNCTION bitmapContains(b :: 3, toUInt32(id) :: 9) -> bitmapContains(b, toUInt32(id)) UInt8 : 8' (version 21.1.3.16 (official build))\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19311/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19311/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19308","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19308/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19308/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19308/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/19308","id":789893063,"node_id":"MDU6SXNzdWU3ODk4OTMwNjM=","number":19308,"title":"support \"case x when a then b\" express","user":{"login":"l1t1","id":23301704,"node_id":"MDQ6VXNlcjIzMzAxNzA0","avatar_url":"https://avatars.githubusercontent.com/u/23301704?v=4","gravatar_id":"","url":"https://api.github.com/users/l1t1","html_url":"https://github.com/l1t1","followers_url":"https://api.github.com/users/l1t1/followers","following_url":"https://api.github.com/users/l1t1/following{/other_user}","gists_url":"https://api.github.com/users/l1t1/gists{/gist_id}","starred_url":"https://api.github.com/users/l1t1/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/l1t1/subscriptions","organizations_url":"https://api.github.com/users/l1t1/orgs","repos_url":"https://api.github.com/users/l1t1/repos","events_url":"https://api.github.com/users/l1t1/events{/privacy}","received_events_url":"https://api.github.com/users/l1t1/received_events","type":"User","site_admin":false},"labels":[{"id":386401506,"node_id":"MDU6TGFiZWwzODY0MDE1MDY=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/duplicate","name":"duplicate","color":"cccccc","default":true,"description":null},{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":{"login":"kitaisreal","id":22458333,"node_id":"MDQ6VXNlcjIyNDU4MzMz","avatar_url":"https://avatars.githubusercontent.com/u/22458333?v=4","gravatar_id":"","url":"https://api.github.com/users/kitaisreal","html_url":"https://github.com/kitaisreal","followers_url":"https://api.github.com/users/kitaisreal/followers","following_url":"https://api.github.com/users/kitaisreal/following{/other_user}","gists_url":"https://api.github.com/users/kitaisreal/gists{/gist_id}","starred_url":"https://api.github.com/users/kitaisreal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kitaisreal/subscriptions","organizations_url":"https://api.github.com/users/kitaisreal/orgs","repos_url":"https://api.github.com/users/kitaisreal/repos","events_url":"https://api.github.com/users/kitaisreal/events{/privacy}","received_events_url":"https://api.github.com/users/kitaisreal/received_events","type":"User","site_admin":false},"assignees":[{"login":"kitaisreal","id":22458333,"node_id":"MDQ6VXNlcjIyNDU4MzMz","avatar_url":"https://avatars.githubusercontent.com/u/22458333?v=4","gravatar_id":"","url":"https://api.github.com/users/kitaisreal","html_url":"https://github.com/kitaisreal","followers_url":"https://api.github.com/users/kitaisreal/followers","following_url":"https://api.github.com/users/kitaisreal/following{/other_user}","gists_url":"https://api.github.com/users/kitaisreal/gists{/gist_id}","starred_url":"https://api.github.com/users/kitaisreal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kitaisreal/subscriptions","organizations_url":"https://api.github.com/users/kitaisreal/orgs","repos_url":"https://api.github.com/users/kitaisreal/repos","events_url":"https://api.github.com/users/kitaisreal/events{/privacy}","received_events_url":"https://api.github.com/users/kitaisreal/received_events","type":"User","site_admin":false}],"milestone":null,"comments":2,"created_at":"2021-01-20T11:26:50Z","updated_at":"2021-01-27T17:40:34Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"translate\r\n\r\ncase x when a then b when c then d end\r\n\r\nto\r\n\r\ncase when x=a then b when x=c then d end\r\n\r\nnow the 1st express always return null\r\neg.\r\n```sql\r\nselect number n,case n when 0 then 0 when 1 then 6 when 2 then 30 end lo ,\r\ncase n when 0 then 5 when 1 then 29 when 2 then 99 end hi from system.numbers limit 3\r\nn\tlo\thi\r\n0\tᴺᵁᴸᴸ\tᴺᵁᴸᴸ\r\n1\tᴺᵁᴸᴸ\tᴺᵁᴸᴸ\r\n2\tᴺᵁᴸᴸ\tᴺᵁᴸᴸ\r\n```\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19308/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19308/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19307","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19307/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19307/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19307/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/19307","id":789869410,"node_id":"MDU6SXNzdWU3ODk4Njk0MTA=","number":19307,"title":"Azure Blob table function and storage engine","user":{"login":"baibaichen","id":3688732,"node_id":"MDQ6VXNlcjM2ODg3MzI=","avatar_url":"https://avatars.githubusercontent.com/u/3688732?v=4","gravatar_id":"","url":"https://api.github.com/users/baibaichen","html_url":"https://github.com/baibaichen","followers_url":"https://api.github.com/users/baibaichen/followers","following_url":"https://api.github.com/users/baibaichen/following{/other_user}","gists_url":"https://api.github.com/users/baibaichen/gists{/gist_id}","starred_url":"https://api.github.com/users/baibaichen/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/baibaichen/subscriptions","organizations_url":"https://api.github.com/users/baibaichen/orgs","repos_url":"https://api.github.com/users/baibaichen/repos","events_url":"https://api.github.com/users/baibaichen/events{/privacy}","received_events_url":"https://api.github.com/users/baibaichen/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-01-20T10:55:02Z","updated_at":"2021-01-26T14:43:02Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"To allow import and export to Azure Blob  compatible storage.\r\n\r\n**Use case**\r\nUse case and implementation is mostly like file table function and `File` storage:\r\nhttps://clickhouse.yandex/docs/en/query_language/table_functions/file/\r\n\r\n**Describe the solution you'd like**\r\nSimilar with S3, use https://github.com/Azure/azure-storage-cpp to access files on blob\r\n\r\n**Describe alternatives you've considered**\r\nCurrently, we use URL engine to get data from blob, but it failed to use [MKI authenticate](https://techcommunity.microsoft.com/t5/azure-database-support-blog/using-managed-service-identity-msi-to-authenticate-on-azure-sql/ba-p/1288248) which is used by [Azure Marketplace ](https://azure.microsoft.com/en-us/marketplace/)\r\n\r\n**Additional context**\r\nNo\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19307/reactions","total_count":13,"+1":13,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19307/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19306","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19306/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19306/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19306/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/19306","id":789848386,"node_id":"MDU6SXNzdWU3ODk4NDgzODY=","number":19306,"title":"ReplicatedMergeTree: Clean inactive parts code is fragile","user":{"login":"filimonov","id":1549571,"node_id":"MDQ6VXNlcjE1NDk1NzE=","avatar_url":"https://avatars.githubusercontent.com/u/1549571?v=4","gravatar_id":"","url":"https://api.github.com/users/filimonov","html_url":"https://github.com/filimonov","followers_url":"https://api.github.com/users/filimonov/followers","following_url":"https://api.github.com/users/filimonov/following{/other_user}","gists_url":"https://api.github.com/users/filimonov/gists{/gist_id}","starred_url":"https://api.github.com/users/filimonov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/filimonov/subscriptions","organizations_url":"https://api.github.com/users/filimonov/orgs","repos_url":"https://api.github.com/users/filimonov/repos","events_url":"https://api.github.com/users/filimonov/events{/privacy}","received_events_url":"https://api.github.com/users/filimonov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-01-20T10:27:11Z","updated_at":"2021-01-20T10:38:04Z","closed_at":null,"author_association":"COLLABORATOR","active_lock_reason":null,"body":"See `clearOldPartsAndRemoveFromZK`:\r\n\r\nhttps://github.com/ClickHouse/ClickHouse/blob/636049f4657f0943875199cb983eee6d168aaaf8/src/Storages/StorageReplicatedMergeTree.cpp#L5301-L5323\r\n\r\nIt collects the list of all inactive parts and try to remove all of them at once - first from zookeeper, then from filesystem. \r\n\r\nSome scenarios (most typical example - mutations on tables with lot of parts) can create enormous number of inactive parts, which are removed slowly. And while they are removed a lot of bad things can happen:\r\n1) hard restart - if data were already removed from zookeeper but not from filesystem:\r\n- it can prevent clickhouse from restarting (local set of parts is too diffent from zookeeper)\r\n- even in clickhouse will start all those parts will be moved to detached as 'unexpected' and may take a lot of disk space. \r\n2) new mutations creating even more inactive parts - may end up with situations when millions of inactive parts were collected, making the system unusable. \r\n\r\nProposal:\r\n1) change clearOldPartsAndRemoveFromZK to process old parts in bulks (bulk size can be configured via mergetree settings, i guess nice default is about 1000 parts). Every bulk shoud be first removed from zookeeper then from filesystem (as now, but it will not hang for lot of time on filesystem or zookeeper operation and zookeeper and filesystem will mostly be in sync). Maybe introduce and option do process every individual bulk in parallel by several threads simultaniously.\r\n2) Introduce 'too many inactive parts' exception (configurable via merge_tree_setttings similar to parts_to_throw_insert  or to max_parts_in_total), to prevent collecting too many inactive parts (i think that smth about 50K inactive parts in system is something you should worry). \r\n\r\n\r\n\r\n ","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19306/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19306/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19304","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19304/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19304/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19304/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/19304","id":789821429,"node_id":"MDU6SXNzdWU3ODk4MjE0Mjk=","number":19304,"title":"how to get json string","user":{"login":"vegastar002","id":4318676,"node_id":"MDQ6VXNlcjQzMTg2NzY=","avatar_url":"https://avatars.githubusercontent.com/u/4318676?v=4","gravatar_id":"","url":"https://api.github.com/users/vegastar002","html_url":"https://github.com/vegastar002","followers_url":"https://api.github.com/users/vegastar002/followers","following_url":"https://api.github.com/users/vegastar002/following{/other_user}","gists_url":"https://api.github.com/users/vegastar002/gists{/gist_id}","starred_url":"https://api.github.com/users/vegastar002/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vegastar002/subscriptions","organizations_url":"https://api.github.com/users/vegastar002/orgs","repos_url":"https://api.github.com/users/vegastar002/repos","events_url":"https://api.github.com/users/vegastar002/events{/privacy}","received_events_url":"https://api.github.com/users/vegastar002/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-01-20T09:53:22Z","updated_at":"2021-01-20T09:53:22Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"SELECT *\r\nFROM \r\n(\r\n    WITH\r\n        [1, 2, 3] AS d1,\r\n        ['a', 'e', 'f'] AS t1,\r\n        ['x', 'y', 'z'] AS t2\r\n    SELECT\r\n        d1,\r\n        t1,\r\n        t2\r\n)\r\nARRAY JOIN\r\n    d1,\r\n    t1,\r\n    t2\r\nFORMAT JSON\r\n\r\nQuery id: 0077ae25-56b7-49da-b787-66a2b4ffdfdc\r\n\r\n{\r\n\t\"meta\":\r\n\t[\r\n\t\t{\r\n\t\t\t\"name\": \"d1\",\r\n\t\t\t\"type\": \"UInt8\"\r\n\t\t},\r\n\t\t{\r\n\t\t\t\"name\": \"t1\",\r\n\t\t\t\"type\": \"String\"\r\n\t\t},\r\n\t\t{\r\n\t\t\t\"name\": \"t2\",\r\n\t\t\t\"type\": \"String\"\r\n\t\t}\r\n\t],\r\n\t\"data\":\r\n\t[\r\n\t\t{\r\n\t\t\t\"d1\": 1,\r\n\t\t\t\"t1\": \"a\",\r\n\t\t\t\"t2\": \"x\"\r\n\t\t},\r\n\t\t{\r\n\t\t\t\"d1\": 2,\r\n\t\t\t\"t1\": \"e\",\r\n\t\t\t\"t2\": \"y\"\r\n\t\t},\r\n\t\t{\r\n\t\t\t\"d1\": 3,\r\n\t\t\t\"t1\": \"f\",\r\n\t\t\t\"t2\": \"z\"\r\n\t\t}                                                                                                                                      \r\n\t],\r\n\t\"rows\": 3,\r\n\t\"statistics\":\r\n\t{\r\n\t\t\"elapsed\": 0.000619288,\r\n\t\t\"rows_read\": 1,\r\n\t\t\"bytes_read\": 1\r\n\t}\r\n}\r\n\r\n3 rows in set. Elapsed: 0.002 sec. \r\n\r\nI only want get the string :\r\n\r\n\t\"data\":\r\n\t[\r\n\t\t{\r\n\t\t\t\"d1\": 1,\r\n\t\t\t\"t1\": \"a\",\r\n\t\t\t\"t2\": \"x\"\r\n\t\t},\r\n\t\t{\r\n\t\t\t\"d1\": 2,\r\n\t\t\t\"t1\": \"e\",\r\n\t\t\t\"t2\": \"y\"\r\n\t\t},\r\n\t\t{\r\n\t\t\t\"d1\": 3,\r\n\t\t\t\"t1\": \"f\",\r\n\t\t\t\"t2\": \"z\"\r\n\t\t}                                                                                                                                      \r\n\t]\r\n\r\nhow to do ?","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19304/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19304/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19295","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19295/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19295/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19295/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/19295","id":789573464,"node_id":"MDU6SXNzdWU3ODk1NzM0NjQ=","number":19295,"title":"clickhouse连接mycat","user":{"login":"SDUERLLei","id":45259530,"node_id":"MDQ6VXNlcjQ1MjU5NTMw","avatar_url":"https://avatars.githubusercontent.com/u/45259530?v=4","gravatar_id":"","url":"https://api.github.com/users/SDUERLLei","html_url":"https://github.com/SDUERLLei","followers_url":"https://api.github.com/users/SDUERLLei/followers","following_url":"https://api.github.com/users/SDUERLLei/following{/other_user}","gists_url":"https://api.github.com/users/SDUERLLei/gists{/gist_id}","starred_url":"https://api.github.com/users/SDUERLLei/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/SDUERLLei/subscriptions","organizations_url":"https://api.github.com/users/SDUERLLei/orgs","repos_url":"https://api.github.com/users/SDUERLLei/repos","events_url":"https://api.github.com/users/SDUERLLei/events{/privacy}","received_events_url":"https://api.github.com/users/SDUERLLei/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2021-01-20T02:36:13Z","updated_at":"2021-01-20T06:31:38Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"clickhouse中连接mycat查询提示table doesn`t exist","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19295/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19295/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19289","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19289/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19289/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19289/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/19289","id":789271005,"node_id":"MDU6SXNzdWU3ODkyNzEwMDU=","number":19289,"title":"window functions: use storage sorting key","user":{"login":"akuzm","id":36882414,"node_id":"MDQ6VXNlcjM2ODgyNDE0","avatar_url":"https://avatars.githubusercontent.com/u/36882414?v=4","gravatar_id":"","url":"https://api.github.com/users/akuzm","html_url":"https://github.com/akuzm","followers_url":"https://api.github.com/users/akuzm/followers","following_url":"https://api.github.com/users/akuzm/following{/other_user}","gists_url":"https://api.github.com/users/akuzm/gists{/gist_id}","starred_url":"https://api.github.com/users/akuzm/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/akuzm/subscriptions","organizations_url":"https://api.github.com/users/akuzm/orgs","repos_url":"https://api.github.com/users/akuzm/repos","events_url":"https://api.github.com/users/akuzm/events{/privacy}","received_events_url":"https://api.github.com/users/akuzm/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":2607635731,"node_id":"MDU6TGFiZWwyNjA3NjM1NzMx","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-window-functions","name":"comp-window-functions","color":"b5bcff","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2021-01-19T18:49:56Z","updated_at":"2021-11-16T09:49:08Z","closed_at":null,"author_association":"COLLABORATOR","active_lock_reason":null,"body":"To compute a window function, we must first sort data according to `PARTITION BY` and then `ORDER BY` clauses of the window.\r\nWhen the storage sorting key and the `PARTITION BY` + `ORDER BY` of the window have a common prefix, we must avoid sorting the data fully from scratch, and instead read it in (partially) sorted order and then sort incrementally.\r\n\r\nFor large amounts of data, sorting it is not feasible, so this incremental sorting is the only way to compute a window function. See an example we discussed in #18097:\r\n\r\n> 'Crash tests' use case. Imagine a fast trading dataset.\r\n>\r\n> Every second you have up to 10 million transactions with a micro/nanosecond resolution.\r\n> \r\n> The task is to calculate the sum and the number of transactions in the exactly X seconds window prepending the transaction. (not on the second boundary but back from the current event). Single select can extract up to several weeks of data.\r\n> \r\n> This is sum over (order by transaction_time range between 'X seconds' preceding and current row).\r\n> 10M records per second * 30 days per month * 24 * 60 * 60 seconds a day = 25T records, probably about 100TB of data compressed","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19289/reactions","total_count":2,"+1":2,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19289/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19280","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19280/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19280/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19280/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/19280","id":789024943,"node_id":"MDU6SXNzdWU3ODkwMjQ5NDM=","number":19280,"title":"The efficiency of view query is not as expected","user":{"login":"IVitamin-C","id":35019926,"node_id":"MDQ6VXNlcjM1MDE5OTI2","avatar_url":"https://avatars.githubusercontent.com/u/35019926?v=4","gravatar_id":"","url":"https://api.github.com/users/IVitamin-C","html_url":"https://github.com/IVitamin-C","followers_url":"https://api.github.com/users/IVitamin-C/followers","following_url":"https://api.github.com/users/IVitamin-C/following{/other_user}","gists_url":"https://api.github.com/users/IVitamin-C/gists{/gist_id}","starred_url":"https://api.github.com/users/IVitamin-C/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/IVitamin-C/subscriptions","organizations_url":"https://api.github.com/users/IVitamin-C/orgs","repos_url":"https://api.github.com/users/IVitamin-C/repos","events_url":"https://api.github.com/users/IVitamin-C/events{/privacy}","received_events_url":"https://api.github.com/users/IVitamin-C/received_events","type":"User","site_admin":false},"labels":[{"id":756395244,"node_id":"MDU6TGFiZWw3NTYzOTUyNDQ=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/performance","name":"performance","color":"c2e0c6","default":false,"description":null},{"id":2069471772,"node_id":"MDU6TGFiZWwyMDY5NDcxNzcy","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-view","name":"comp-view","color":"b5bcff","default":false,"description":"VIEWs"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":5,"created_at":"2021-01-19T13:31:08Z","updated_at":"2021-01-19T17:06:08Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"version:20.8.8.6 lts\r\ndata rows:10 billion per partition\r\n\r\nCompared with the original table query, the query time of view query is several times slower when the query conditions are consistent.\r\nThanks!\r\nThe following is the operation process:\r\n\r\n```\r\ncreate table test.test_a1  ON CLUSTER testcluster\r\n(\r\ndatatime  DateTime('Asia/Shanghai')\r\nst Int64 MATERIALIZED toYYYYMMDD(datatime)\r\nflag String \r\nuid String\r\nvalue Int64\r\n)\r\nReplicatedMergeTree(\r\n  '/clickhouse/tables/{shard}/test.test_a1', \r\n  '{replica}'\r\n)\r\npartition toYYYYMMDD(datatime)\r\norder by (\r\nst*-1\r\n,flag\r\n,uid\r\n,value\r\n);\r\n\r\nCREATE TABLE IF NOT EXISTS test.test_a1_dis\r\nON CLUSTER testcluster\r\nAS test.test_a1 \r\nENGINE = Distributed(testcluster,test,test_a1,rand());\r\n\r\nCREATE VIEW IF NOT EXISTS test.test_a1_view ON CLUSTER testcluster\r\nas \r\nselect datatime\r\n      ,st\r\n      ,flag\r\n      ,uid\r\n      ,value\r\nfrom  test.test_a1_dis\r\nwhere flag='001'\r\n```\r\n\r\n(1) Query view\r\n```\r\nselect sum(1) from test.test_a1_view where uid<>''   \r\n\r\nsum(1) :10411310174\r\n\r\n1 rows in set .Elapsed: 4.083s. Processed 10.58 billion rows,190.29GB(2.59 billion rows/s.,46.59 GB/s.)\r\n```\r\n\r\n(2) Query Distributed\r\n```\r\nselect sum(1) from test.test_a1_dis where flag='001' and uid<>'' \r\n\r\nsum(1) :10411310174\r\n\r\n1 rows in set .Elapsed: 1.079s. Processed 10.58 billion rows,190.29GB(9.80 billion rows/s.,176.29 GB/s.) \r\n```\r\n\r\nThe same data query results, the efficiency gap is large.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19280/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19280/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19278","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19278/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19278/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19278/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/19278","id":789009093,"node_id":"MDU6SXNzdWU3ODkwMDkwOTM=","number":19278,"title":"\"Table default.xxx doesn't exist..\" Exception occurs when both distributed and local tables are involved","user":{"login":"dgzdot","id":57993550,"node_id":"MDQ6VXNlcjU3OTkzNTUw","avatar_url":"https://avatars.githubusercontent.com/u/57993550?v=4","gravatar_id":"","url":"https://api.github.com/users/dgzdot","html_url":"https://github.com/dgzdot","followers_url":"https://api.github.com/users/dgzdot/followers","following_url":"https://api.github.com/users/dgzdot/following{/other_user}","gists_url":"https://api.github.com/users/dgzdot/gists{/gist_id}","starred_url":"https://api.github.com/users/dgzdot/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dgzdot/subscriptions","organizations_url":"https://api.github.com/users/dgzdot/orgs","repos_url":"https://api.github.com/users/dgzdot/repos","events_url":"https://api.github.com/users/dgzdot/events{/privacy}","received_events_url":"https://api.github.com/users/dgzdot/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""},{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2021-01-19T13:09:14Z","updated_at":"2021-01-19T13:40:39Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"clickhouse server version 20.8.3.18\r\n\r\nreproduce step:\r\n\r\nlocal table:\r\nSHOW CREATE TABLE test_query_local;\r\nCREATE TABLE dgz.test_query_local\r\n(\r\n    `id` UInt64,\r\n    `repo` String\r\n)\r\nENGINE = ReplicatedMergeTree('/clickhouse/dgz/tables/{shard}/test_query_local', '{replica}')\r\nORDER BY id\r\nSETTINGS index_granularity = 8192;\r\n\r\ndistributed table:\r\nSHOW CREATE TABLE test_query_all;\r\nCREATE TABLE dgz.test_query_all\r\n(\r\n    `id` UInt64,\r\n    `repo` String\r\n)\r\nENGINE = Distributed('xxx', 'dgz', 'test_query_local', rand());\r\n\r\nexecute sql:\r\nuse dgz;\r\nSELECT uniq(id) FROM test_query_all WHERE repo = '100'  AND id   IN (SELECT id FROM test_query_local WHERE repo = '200');\r\n\r\nthen exception occurs:\r\nReceived exception from server (version 20.8.3):\r\nCode: 60. DB::Exception: Received from 127.0.0.1:9000. DB::Exception: Received from xxxx:9000. DB::Exception: Table default.test_query_local doesn't exist..\r\n\r\nWhy this sql try to search table in default database in remote clickhouse instance.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19278/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19278/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19275","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19275/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19275/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19275/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/19275","id":788938474,"node_id":"MDU6SXNzdWU3ODg5Mzg0NzQ=","number":19275,"title":"Filter pushdown into S3 (using S3 SELECT API)","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":2020016497,"node_id":"MDU6TGFiZWwyMDIwMDE2NDk3","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-s3","name":"comp-s3","color":"b5bcff","default":false,"description":""},{"id":2588720302,"node_id":"MDU6TGFiZWwyNTg4NzIwMzAy","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/cloud","name":"cloud","color":"006b75","default":false,"description":"Important for Cloud"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-01-19T11:21:33Z","updated_at":"2021-02-18T08:26:53Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"https://docs.aws.amazon.com/AmazonS3/latest/dev/s3-glacier-select-sql-reference-select.html\r\nhttps://docs.min.io/docs/minio-select-api-quickstart-guide.html\r\n\r\n**Use case**\r\nThe user queries data from S3. We take subset of expressions from ClickHouse query and send them to S3 using its API.\r\n\r\n**Implementation**\r\nSimilar to `transformQueryForExternalDatabase`.\r\n\r\n**Additional context**\r\nThe settings\r\n```\r\nInputSerialization={\r\n        'CSV': {\r\n            \"FileHeaderInfo\": \"USE\",\r\n        },\r\n        'CompressionType': 'GZIP',\r\n    },\r\n    OutputSerialization={'CSV': {}},\r\n```\r\nwill be inferred automatically.\r\n\r\nS3 is using slow query engine internally (every query engine is slow comparing to ClickHouse) and in some cases queries with filters may process slower than fetching all data into ClickHouse and processing it, despite the network cost.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19275/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19275/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19274","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19274/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19274/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19274/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/19274","id":788931648,"node_id":"MDU6SXNzdWU3ODg5MzE2NDg=","number":19274,"title":"Show the number of inserted rows.","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":4,"created_at":"2021-01-19T11:11:36Z","updated_at":"2021-10-14T12:50:45Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"Example:\r\n\r\n```\r\nINSERT INTO FUNCTION null('a INT') SELECT *\r\nFROM numbers(10)\r\n\r\nQuery id: 2c8111a0-b23f-4e0a-bb6a-6fe189cca58f\r\n\r\nOk.\r\n\r\n0 rows in set. Elapsed: 0.005 sec.\r\n```\r\n\r\nShould display\r\n\r\n```\r\n10 rows in set. Elapsed: 0.005 sec.\r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19274/reactions","total_count":3,"+1":3,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19274/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19228","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19228/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19228/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19228/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/19228","id":788051318,"node_id":"MDU6SXNzdWU3ODgwNTEzMTg=","number":19228,"title":"RBAC: Stored Object Access Control / DEFINER / SQL SECURITY","user":{"login":"filimonov","id":1549571,"node_id":"MDQ6VXNlcjE1NDk1NzE=","avatar_url":"https://avatars.githubusercontent.com/u/1549571?v=4","gravatar_id":"","url":"https://api.github.com/users/filimonov","html_url":"https://github.com/filimonov","followers_url":"https://api.github.com/users/filimonov/followers","following_url":"https://api.github.com/users/filimonov/following{/other_user}","gists_url":"https://api.github.com/users/filimonov/gists{/gist_id}","starred_url":"https://api.github.com/users/filimonov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/filimonov/subscriptions","organizations_url":"https://api.github.com/users/filimonov/orgs","repos_url":"https://api.github.com/users/filimonov/repos","events_url":"https://api.github.com/users/filimonov/events{/privacy}","received_events_url":"https://api.github.com/users/filimonov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":2011606513,"node_id":"MDU6TGFiZWwyMDExNjA2NTEz","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-rbac","name":"comp-rbac","color":"b5bcff","default":false,"description":"Access control related"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-01-18T08:33:45Z","updated_at":"2021-01-18T08:33:45Z","closed_at":null,"author_association":"COLLABORATOR","active_lock_reason":null,"body":"Typical examples:\r\n* give the user access to the VIEW without giving access to the main table\r\n* allow the user to insert into the table even if he doesn't have explicit permission to insert into some of the MV\r\n\r\n(you can think of more - with all sorts of dictionaries, engine = Merge, Distributed, etc.)\r\n\r\nSee also:\r\n* https://dev.mysql.com/doc/refman/8.0/en/stored-objects-security.html\r\n* https://docs.oracle.com/cd/E17952_01/mysql-5.7-en/stored-objects-security.html","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19228/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19228/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19222","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19222/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19222/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19222/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/19222","id":787865389,"node_id":"MDU6SXNzdWU3ODc4NjUzODk=","number":19222,"title":"why with query cannot accept the talbe alias","user":{"login":"l1t1","id":23301704,"node_id":"MDQ6VXNlcjIzMzAxNzA0","avatar_url":"https://avatars.githubusercontent.com/u/23301704?v=4","gravatar_id":"","url":"https://api.github.com/users/l1t1","html_url":"https://github.com/l1t1","followers_url":"https://api.github.com/users/l1t1/followers","following_url":"https://api.github.com/users/l1t1/following{/other_user}","gists_url":"https://api.github.com/users/l1t1/gists{/gist_id}","starred_url":"https://api.github.com/users/l1t1/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/l1t1/subscriptions","organizations_url":"https://api.github.com/users/l1t1/orgs","repos_url":"https://api.github.com/users/l1t1/repos","events_url":"https://api.github.com/users/l1t1/events{/privacy}","received_events_url":"https://api.github.com/users/l1t1/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2021-01-18T02:27:08Z","updated_at":"2021-01-19T15:28:14Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"```sql\r\nWITH t AS \r\n    (\r\n        SELECT number AS n\r\n        FROM numbers(10000)\r\n    )\r\nSELECT count(*)\r\nFROM t AS a\r\nWHERE a.n < 5000\r\n\r\nQuery id: 1248d8af-bb2a-4212-8fd5-e5b89641dd35\r\n\r\n\r\nReceived exception from server (version 21.1.1):\r\nCode: 47. DB::Exception: Received from localhost:9000. DB::Exception: Missing columns: 'a.n' while processing query: 'WITH t AS (SELECT number AS n FROM numbers(10000)) AS _subquery6 SELECT count() FROM (SELECT number AS n FROM numbers(10000) HAVING n < 5000) AS t WHERE a.n < 5000', required columns: 'a.n' 'a.n'. \r\n\r\n0 rows in set. Elapsed: 0.001 sec. \r\n\r\nkylin-gtj :) with t as(select number n from numbers(10000))select count(*) from t a where t.n<5000;\r\n\r\nWITH t AS \r\n    (\r\n        SELECT number AS n\r\n        FROM numbers(10000)\r\n    )\r\nSELECT count(*)\r\nFROM t AS a\r\nWHERE t.n < 5000\r\n\r\nQuery id: 881b9675-67b8-4a7e-a290-5597d63a9010\r\n\r\n┌─count()─┐\r\n│    5000 │\r\n└─────────┘\r\n\r\n1 rows in set. Elapsed: 0.002 sec. Processed 10.00 thousand rows, 80.00 KB (4.87 million rows/s., 38.96 MB/s.) \r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19222/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19222/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19097","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19097/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19097/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19097/events","html_url":"https://github.com/ClickHouse/ClickHouse/pull/19097","id":786506238,"node_id":"MDExOlB1bGxSZXF1ZXN0NTU1MzYzNTE0","number":19097,"title":"Bitmap join optimization","user":{"login":"templarzq","id":18200917,"node_id":"MDQ6VXNlcjE4MjAwOTE3","avatar_url":"https://avatars.githubusercontent.com/u/18200917?v=4","gravatar_id":"","url":"https://api.github.com/users/templarzq","html_url":"https://github.com/templarzq","followers_url":"https://api.github.com/users/templarzq/followers","following_url":"https://api.github.com/users/templarzq/following{/other_user}","gists_url":"https://api.github.com/users/templarzq/gists{/gist_id}","starred_url":"https://api.github.com/users/templarzq/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/templarzq/subscriptions","organizations_url":"https://api.github.com/users/templarzq/orgs","repos_url":"https://api.github.com/users/templarzq/repos","events_url":"https://api.github.com/users/templarzq/events{/privacy}","received_events_url":"https://api.github.com/users/templarzq/received_events","type":"User","site_admin":false},"labels":[{"id":386401508,"node_id":"MDU6TGFiZWwzODY0MDE1MDg=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/help%20wanted","name":"help wanted","color":"128A0C","default":true,"description":null},{"id":1309683578,"node_id":"MDU6TGFiZWwxMzA5NjgzNTc4","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/pr-performance","name":"pr-performance","color":"007700","default":false,"description":"Pull request with some performance improvements"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":7,"created_at":"2021-01-15T03:37:02Z","updated_at":"2022-01-30T00:24:11Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"draft":true,"pull_request":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/pulls/19097","html_url":"https://github.com/ClickHouse/ClickHouse/pull/19097","diff_url":"https://github.com/ClickHouse/ClickHouse/pull/19097.diff","patch_url":"https://github.com/ClickHouse/ClickHouse/pull/19097.patch","merged_at":null},"body":"I hereby agree to the terms of the CLA available at: https://yandex.ru/legal/cla/?lang=en\r\n\r\nChangelog category (leave one):\r\n- Performance Improvement\r\n   improve bitmap involved join performance \r\n\r\n\r\nChangelog entry (a user-readable short description of the changes that goes to CHANGELOG.md):\r\n\r\n...\r\n\r\n\r\nDetailed description / Documentation draft:\r\n  during the join , bitmap\r\n table1: \r\ndimCol                                             \r\n       -------                                            \r\n              1                                                   \r\n              1\r\n              1\r\n              .....\r\n\r\n\r\ntable2:\r\n      \r\ndimCol    bitmapCol\r\n---------------------------  \r\n    1               large bitmap ( e.g.  contains 30million numbers)\r\n\r\nwhen table1 join tabl2  on dimCol,   the large bitmap will be copied for N times,  N is table1's   same value row count.\r\nso clickhouse will spend much time on bitmap create and destroy,the query execution will be very slow.\r\n\r\nso I modified the code of class AddedColumns in HashJoin.cpp  like below to improve this process:  \r\n```\r\ntemplate <bool has_defaults>\r\nvoid appendFromBlock(const Block & block, size_t row_num)\r\n{\r\n       if constexpr (has_defaults)\r\n            applyLazyDefaults();\r\n        std::unordered_map<Block*, std::unordered_map<size_t,size_t> >::iterator iter;\r\n        std::unordered_map<size_t,size_t>::iterator iter2;\r\n        bool bFound = false;\r\n        size_t pos = 0;\r\n        for (size_t j = 0; j < right_indexes.size(); ++j){\r\n            if (std::string(columns[j]->getFamilyName())!=\"AggregateFunction\"){  //not aggFuncCol,copy data directly\r\n                columns[j]->insertFrom(*block.getByPosition(right_indexes[j]).column, row_num);\r\n            }else{ // copy pointer for same bitmap\r\n              if(!bFound){\r\n                    iter = copiedDataInfo.find((Block*)&block);\r\n                    if(iter!=copiedDataInfo.end()){    //found block\r\n                        iter2 = iter->second.find(row_num);\r\n                        if(iter2!=iter->second.end()){  //found row\r\n                            pos = iter2->first;\r\n                            auto pCol = typeid_cast<ColumnAggregateFunction *>(columns[j].get());\r\n                            pCol->getData().push_back(pCol->getData()[pos]);\r\n                        }else{\r\n                            pos = columns[j]->size();\r\n                            iter->second.insert(std::pair<size_t,size_t>(row_num,pos));\r\n                            columns[j]->insertFrom(*block.getByPosition(right_indexes[j]).column, row_num);\r\n                        }\r\n                    }else{\r\n                        pos = columns[j]->size();\r\n                        std::unordered_map<size_t,size_t> rowInfo;\r\n                        rowInfo.insert(std::pair<size_t,size_t>(row_num,pos));\r\n                        copiedDataInfo.insert(std::pair<Block*, std::unordered_map<size_t,size_t> >((Block*)&block,\r\n                            rowInfo));\r\n                        columns[j]->insertFrom(*block.getByPosition(right_indexes[j]).column, row_num);\r\n                    }\r\n                    bFound = true;\r\n            }else{\r\n                auto pCol = typeid_cast<ColumnAggregateFunction *>(columns[j].get());\r\n                pCol->getData().push_back(pCol->getData()[pos]);\r\n            }\r\n          }\r\n        }\r\n    }\r\n```\r\n\r\n.......\r\n\r\nadd definition of info container in class AddedColumns:\r\n```\r\nprivate:\r\n   ....\r\n   std::unordered_map<Block*, std::unordered_map<size_t,size_t> > copiedDataInfo;\r\n```\r\n\r\nand we should modify ~ColumnAggregateFunction to destroy bitmap  data correctly :\r\n```\r\nColumnAggregateFunction::~ColumnAggregateFunction()\r\n{\r\n    if (!func->hasTrivialDestructor() && !src){\r\n    //    for (auto * val : data)\r\n    //\r\n        for(size_t i=0;i<data.size();++i){\r\n            auto  val = data[i];\r\n            if(val==NULL){\r\n                continue;\r\n            }\r\n\r\n            for(size_t j=i;j<data.size();++j){\r\n                if(data[j]==val){\r\n                    data[j]= NULL;\r\n                }\r\n            }\r\n\r\n            func->destroy(val);\r\n        }\r\n    }\r\n}\r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19097/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19097/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19087","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19087/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19087/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19087/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/19087","id":786131959,"node_id":"MDU6SXNzdWU3ODYxMzE5NTk=","number":19087,"title":"Altering columns on underlying table has no effect on view create statement when using SELECT *","user":{"login":"buyology","id":5368302,"node_id":"MDQ6VXNlcjUzNjgzMDI=","avatar_url":"https://avatars.githubusercontent.com/u/5368302?v=4","gravatar_id":"","url":"https://api.github.com/users/buyology","html_url":"https://github.com/buyology","followers_url":"https://api.github.com/users/buyology/followers","following_url":"https://api.github.com/users/buyology/following{/other_user}","gists_url":"https://api.github.com/users/buyology/gists{/gist_id}","starred_url":"https://api.github.com/users/buyology/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/buyology/subscriptions","organizations_url":"https://api.github.com/users/buyology/orgs","repos_url":"https://api.github.com/users/buyology/repos","events_url":"https://api.github.com/users/buyology/events{/privacy}","received_events_url":"https://api.github.com/users/buyology/received_events","type":"User","site_admin":false},"labels":[{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""},{"id":2069471772,"node_id":"MDU6TGFiZWwyMDY5NDcxNzcy","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-view","name":"comp-view","color":"b5bcff","default":false,"description":"VIEWs"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-01-14T16:29:01Z","updated_at":"2021-01-14T17:39:35Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"on ClickHouse server version 20.12.4 revision 54442:\r\n\r\n```sql\r\nb2344c4eb05b :) CREATE TABLE tbl ( a String ) ENGINE = MergeTree() ORDER BY a\r\n\r\nOk.\r\n\r\n0 rows in set. Elapsed: 0.010 sec.\r\n\r\nb2344c4eb05b :) CREATE VIEW tbl_view AS SELECT * FROM tbl\r\n\r\nOk.\r\n\r\n0 rows in set. Elapsed: 0.008 sec.\r\n\r\nb2344c4eb05b :) ALTER TABLE tbl ADD COLUMN b String ALIAS a\r\n\r\nOk.\r\n\r\n0 rows in set. Elapsed: 0.008 sec.\r\n\r\nb2344c4eb05b :) SELECT b FROM tbl_view\r\n\r\nReceived exception from server (version 20.12.4):\r\nCode: 47. DB::Exception: Received from host.docker.internal:9000. DB::Exception: Missing columns: 'b' while processing query: 'SELECT b FROM (SELECT * FROM default.tbl) AS tbl_view', required columns: 'b', source columns: 'a'.\r\n\r\n0 rows in set. Elapsed: 0.007 sec.\r\n```\r\n\r\nI guess the problem lies in the create tables query:\r\n\r\n```sql\r\nb2344c4eb05b :) SELECT create_table_query FROM system.tables WHERE name = 'tbl_view'\r\n\r\n┌─create_table_query─────────────────────────────────────────────────────┐\r\n│ CREATE VIEW default.tbl_view (`a` String) AS SELECT * FROM default.tbl │\r\n└────────────────────────────────────────────────────────────────────────┘\r\n\r\n1 rows in set. Elapsed: 0.032 sec.\r\n```\r\n\r\nHowever it is not possible to replace the view either:\r\n\r\n```sql\r\nb2344c4eb05b :) CREATE OR REPLACE VIEW tbl_view AS SELECT * FROM tbl\r\n\r\nOk.\r\n\r\n0 rows in set. Elapsed: 0.007 sec.\r\n\r\nb2344c4eb05b :) SELECT create_table_query FROM system.tables WHERE name = 'tbl_view'\r\n\r\n┌─create_table_query─────────────────────────────────────────────────────┐\r\n│ CREATE VIEW default.tbl_view (`a` String) AS SELECT * FROM default.tbl │\r\n└────────────────────────────────────────────────────────────────────────┘\r\n\r\n1 rows in set. Elapsed: 0.035 sec.\r\n```\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19087/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19087/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19067","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19067/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19067/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19067/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/19067","id":785974938,"node_id":"MDU6SXNzdWU3ODU5NzQ5Mzg=","number":19067,"title":"'alter table ATTACH partition'  and 'ON CLUSTER' don't work together","user":{"login":"nereus-east","id":61938735,"node_id":"MDQ6VXNlcjYxOTM4NzM1","avatar_url":"https://avatars.githubusercontent.com/u/61938735?v=4","gravatar_id":"","url":"https://api.github.com/users/nereus-east","html_url":"https://github.com/nereus-east","followers_url":"https://api.github.com/users/nereus-east/followers","following_url":"https://api.github.com/users/nereus-east/following{/other_user}","gists_url":"https://api.github.com/users/nereus-east/gists{/gist_id}","starred_url":"https://api.github.com/users/nereus-east/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nereus-east/subscriptions","organizations_url":"https://api.github.com/users/nereus-east/orgs","repos_url":"https://api.github.com/users/nereus-east/repos","events_url":"https://api.github.com/users/nereus-east/events{/privacy}","received_events_url":"https://api.github.com/users/nereus-east/received_events","type":"User","site_admin":false},"labels":[{"id":1397894054,"node_id":"MDU6TGFiZWwxMzk3ODk0MDU0","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unfinished%20code","name":"unfinished code","color":"ff8800","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-01-14T13:08:41Z","updated_at":"2021-01-14T13:08:41Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"**Describe the unexpected behaviour**\r\nI tried to use ALTER TABLE ON CLUSTER to ATTACH partition after DETACH partition.\r\n\r\n**How to reproduce**\r\n* Which ClickHouse server version to use\r\n    20.6.5.8\r\n* Which interface to use, if matters\r\n    HTTP\r\n* Non-default settings, if any\r\n    N/A\r\n* `CREATE TABLE` statements for all tables involved\r\n```sql\r\n  create table test_with_partition on cluster 'ch' (\r\n    field_uint32 UInt32,\r\n    field_string String,\r\n    field_date_partition Date\r\n  ) ENGINE = ReplicatedMergeTree(\r\n    '/clickhouse/tables/{shard}/{database}/test_with_partition', '{replica}'\r\n  ) partition by field_date_partition order by field_uint32\r\n```\r\n\r\n* Sample data for all these tables, use [clickhouse-obfuscator]\r\n```sql\r\ninsert into\r\n  test_with_partition\r\nvalues\r\n  (1, '3', '2021-01-01'),\r\n  (2, '2', '2021-01-02'),\r\n  (3, '3', '2021-01-03')\r\n```\r\n\r\n\r\n* Queries to run that lead to unexpected result\r\n\r\n```sql\r\n    alter table test_with_partition on cluster 'ch' DETACH PARTITION '2021-01-01'\r\n    alter table test_with_partition on cluster 'ch' ATTACH PARTITION '2021-01-01'\r\n```\r\n\r\n**Expected behavior**\r\n    Partition '2021-01-01' is ATTACHED\r\n\r\n**Error message and/or stacktrace**\r\n```\r\n    Code: 48, e.displayText() = DB::Exception: Unsupported type of ALTER query (version 20.6.5.8)\r\n```\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19067/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/19067/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18937","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18937/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18937/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18937/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/18937","id":783400591,"node_id":"MDU6SXNzdWU3ODM0MDA1OTE=","number":18937,"title":"Cannot select non-english column name when using multiple join in a single query.","user":{"login":"kilik52","id":37238,"node_id":"MDQ6VXNlcjM3MjM4","avatar_url":"https://avatars.githubusercontent.com/u/37238?v=4","gravatar_id":"","url":"https://api.github.com/users/kilik52","html_url":"https://github.com/kilik52","followers_url":"https://api.github.com/users/kilik52/followers","following_url":"https://api.github.com/users/kilik52/following{/other_user}","gists_url":"https://api.github.com/users/kilik52/gists{/gist_id}","starred_url":"https://api.github.com/users/kilik52/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kilik52/subscriptions","organizations_url":"https://api.github.com/users/kilik52/orgs","repos_url":"https://api.github.com/users/kilik52/repos","events_url":"https://api.github.com/users/kilik52/events{/privacy}","received_events_url":"https://api.github.com/users/kilik52/received_events","type":"User","site_admin":false},"labels":[{"id":386401505,"node_id":"MDU6TGFiZWwzODY0MDE1MDU=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/bug","name":"bug","color":"ee0701","default":true,"description":"Confirmed user-visible misbehaviour in official release"},{"id":1357578153,"node_id":"MDU6TGFiZWwxMzU3NTc4MTUz","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-joins","name":"comp-joins","color":"b5bcff","default":false,"description":"JOINs"},{"id":1507867504,"node_id":"MDU6TGFiZWwxNTA3ODY3NTA0","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/st-hold","name":"st-hold","color":"e5b890","default":false,"description":"We've paused the work on issue for some reason"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2021-01-11T14:08:00Z","updated_at":"2021-07-20T07:31:17Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"**Describe the bug**\r\nCannot select non-english column name when using multiple join in a single query.\r\n\r\n**How to reproduce**\r\n\r\n ClickHouse server version 20.11.4 revision 54442.\r\n\r\n* `CREATE TABLE` statements for all tables involved\r\n\r\n````\r\nCREATE TABLE store (id UInt32, \"名称\" String, \"状态\" String) ENGINE=MergeTree() Order by id;\r\nCREATE TABLE location (id UInt32, name String) ENGINE=MergeTree() Order by id;\r\nCREATE TABLE sales (\"日期\" Date, \"店铺\" UInt32, \"地址\" UInt32, \"销售额\" Float32) ENGINE=MergeTree() Order by \"日期\";\r\n````\r\n\r\n* Sample data for all these tables\r\n\r\n````\r\nINSERT INTO store VALUES (1,'店铺1','启用'),(2,'店铺2','停用');\r\nINSERT INTO location VALUES (1,'上海市'),(2,'北京市');\r\nINSERT INTO sales VALUES ('2021-01-01',1,1,10),('2021-01-02',2,2,20);\r\n````\r\n\r\n**Query which cause error**\r\n\r\n````\r\nSELECT\r\n    `日期`,\r\n    location.name,\r\n    store.`状态`\r\nFROM sales\r\nLEFT JOIN store ON store.id = `店铺`\r\nLEFT JOIN location ON location.id = `地址`\r\n````\r\n\r\n**Error message and/or stacktrace**\r\n\r\nCode: 47. DB::Exception: Received from localhost:9000. DB::Exception: Missing columns: '状态' while processing query: 'SELECT `地址`, `店铺`, `日期`, `状态`, id AS `--store.id` FROM sales ALL LEFT JOIN (SELECT * FROM store) AS store ON `--store.id` = `店铺`', required columns: '地址' '店铺' '日期' 'id' '状态', source columns: '销售额' '地址' '店铺' '日期', joined columns: 'id' 'store.名称' 'store.状态'. \r\n\r\n**Additional context**\r\n\r\nI can select `english column name` when using multiple left join: \r\n\r\n````\r\nSELECT\r\n    `日期`,\r\n    location.name,\r\n    store.id\r\nFROM sales\r\nLEFT JOIN store ON store.id = `店铺`\r\nLEFT JOIN location ON location.id = `地址`\r\n````\r\n\r\nResult: \r\n\r\n````\r\nQuery id: f352f76b-575c-4f2d-873f-63aae289a61d\r\n\r\n┌───────日期─┬─location.name─┬─store.id─┐\r\n│ 2021-01-01 │ 上海市        │        1 │\r\n│ 2021-01-02 │ 北京市        │        2 │\r\n└────────────┴───────────────┴──────────┘\r\n\r\n2 rows in set. Elapsed: 0.016 sec. \r\n````\r\n\r\n\r\nI can select `non-english column name` when using **single** left join: \r\n\r\n````\r\nSELECT store.`状态`\r\nFROM sales\r\nLEFT JOIN store ON store.id = `店铺`\r\n````\r\n\r\nResult: \r\n\r\n````\r\nQuery id: f70f9b1e-ff0f-43a4-a9e0-9bbf31c93333\r\n\r\n┌─store.状态─┐\r\n│ 启用       │\r\n│ 停用       │\r\n└────────────┘\r\n\r\n2 rows in set. Elapsed: 0.014 sec. \r\n````\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18937/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18937/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18925","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18925/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18925/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18925/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/18925","id":783281217,"node_id":"MDU6SXNzdWU3ODMyODEyMTc=","number":18925,"title":"Add support of complex structures to Avro/AvroConfluent formats","user":{"login":"bochkarevnv","id":35523301,"node_id":"MDQ6VXNlcjM1NTIzMzAx","avatar_url":"https://avatars.githubusercontent.com/u/35523301?v=4","gravatar_id":"","url":"https://api.github.com/users/bochkarevnv","html_url":"https://github.com/bochkarevnv","followers_url":"https://api.github.com/users/bochkarevnv/followers","following_url":"https://api.github.com/users/bochkarevnv/following{/other_user}","gists_url":"https://api.github.com/users/bochkarevnv/gists{/gist_id}","starred_url":"https://api.github.com/users/bochkarevnv/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bochkarevnv/subscriptions","organizations_url":"https://api.github.com/users/bochkarevnv/orgs","repos_url":"https://api.github.com/users/bochkarevnv/repos","events_url":"https://api.github.com/users/bochkarevnv/events{/privacy}","received_events_url":"https://api.github.com/users/bochkarevnv/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":1401255404,"node_id":"MDU6TGFiZWwxNDAxMjU1NDA0","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-formats","name":"comp-formats","color":"b5bcff","default":false,"description":"Input / output formats"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-01-11T11:13:36Z","updated_at":"2021-02-19T07:35:28Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"**Use case**\r\nThere is currently no way to access the array of records in Avro. For example data:\r\n`{\"a\": 1, \"b\": [{\"c\": 100, \"d\": \"Q\"}, {\"c\": 200, \"d\": \"W\"}]}` \r\nI can select field \"a\", but not field \"b\":\r\n```\r\n# clickhouse-local --query \"CREATE TABLE T (a Nullable(Int64)) ENGINE = File(Avro, '/etc/a.avro'); select * from T;\"\r\n1\r\n```\r\n```\r\n# clickhouse-local --query \"CREATE TABLE T (a Nullable(Int64), b Array(String)) ENGINE = File(Avro, '/etc/a.avro'); select * from T;\"\r\nCode: 44, e.displayText() = DB::Exception: Type Array(String) is not compatible with Avro union:\r\n[\r\n    \"null\",\r\n    {\r\n        \"type\": \"array\",\r\n        \"items\": {\r\n            \"type\": \"record\",\r\n            \"namespace\": \"org.apache.nifi\",\r\n            \"name\": \"bType\",\r\n            \"fields\": [\r\n                {\r\n                    \"name\": \"c\",\r\n                    \"type\": [\r\n                        \"null\",\r\n                        \"long\"\r\n                    ]\r\n                },\r\n                {\r\n                    \"name\": \"d\",\r\n                    \"type\": [\r\n                        \"null\",\r\n                        \"string\"\r\n                    ]\r\n                }\r\n            ]\r\n        }\r\n    }\r\n]: column b: While executing File (version 20.12.3.3 (official build))\r\n```\r\nexample of Avro file - [a.zip](https://github.com/ClickHouse/ClickHouse/files/5795323/a.zip)\r\n\r\n**Describe the solution you'd like**\r\nIt is possible to solve by converting non-root record to json or by implementation complex subcolumns (https://github.com/ClickHouse/ClickHouse/pull/17310) for Avro/AvroConfluent\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18925/reactions","total_count":3,"+1":3,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18925/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18843","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18843/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18843/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18843/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/18843","id":781397773,"node_id":"MDU6SXNzdWU3ODEzOTc3NzM=","number":18843,"title":"has/hasAll/hasAny should optimize in presence of const arguments","user":{"login":"adrian17","id":4729533,"node_id":"MDQ6VXNlcjQ3Mjk1MzM=","avatar_url":"https://avatars.githubusercontent.com/u/4729533?v=4","gravatar_id":"","url":"https://api.github.com/users/adrian17","html_url":"https://github.com/adrian17","followers_url":"https://api.github.com/users/adrian17/followers","following_url":"https://api.github.com/users/adrian17/following{/other_user}","gists_url":"https://api.github.com/users/adrian17/gists{/gist_id}","starred_url":"https://api.github.com/users/adrian17/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/adrian17/subscriptions","organizations_url":"https://api.github.com/users/adrian17/orgs","repos_url":"https://api.github.com/users/adrian17/repos","events_url":"https://api.github.com/users/adrian17/events{/privacy}","received_events_url":"https://api.github.com/users/adrian17/received_events","type":"User","site_admin":false},"labels":[{"id":756395244,"node_id":"MDU6TGFiZWw3NTYzOTUyNDQ=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/performance","name":"performance","color":"c2e0c6","default":false,"description":null},{"id":1401233890,"node_id":"MDU6TGFiZWwxNDAxMjMzODkw","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-arrays","name":"comp-arrays","color":"b5bcff","default":false,"description":"Arrays / array joins / higher order"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-01-07T15:30:11Z","updated_at":"2021-01-07T16:40:01Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"`with range(1000) as set select sum(has(set, number)) from numbers(100000)`\r\nThis executes in 0.5s; `has()` appears to do a linear lookup.\r\n\r\n`with range(1000) as set select sum(number in set) from numbers(100000);`\r\nThis executes in 0.002s, as AFAIK the right side uses an index.\r\n\r\nThe engine could recognize that `has()` argument is a constant and optimize for this case.\r\n\r\nSimilarly, I recently saw a big (>5x) performance boost in some queries by manually converting this:\r\n\r\n`where hasAny(array_column, %(list_of_600_numbers)s)`\r\nTo use an `in` operator:\r\n`where arrayExists(x -> x in %(list_of_600_numbers)s, array_column)`\r\nThe engine, again, could detect that the second argument is a constant and optimize the lookups.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18843/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18843/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18842","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18842/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18842/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18842/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/18842","id":781375674,"node_id":"MDU6SXNzdWU3ODEzNzU2NzQ=","number":18842,"title":"Minicrawl dataset","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":785082162,"node_id":"MDU6TGFiZWw3ODUwODIxNjI=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-documentation","name":"comp-documentation","color":"b5bcff","default":false,"description":"Used to run automatic builds of the documentation"},{"id":3360106261,"node_id":"MDU6TGFiZWwzMzYwMTA2MjYx","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/dataset","name":"dataset","color":"00CCCC","default":false,"description":""}],"state":"open","locked":false,"assignee":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"assignees":[{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false}],"milestone":null,"comments":8,"created_at":"2021-01-07T15:00:01Z","updated_at":"2021-10-21T02:49:14Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"Download front pages of several million websites with curl.\r\nRecord all metadata such as: headers, redirects, TLS version, cipher... as well as data (HTTP body).\r\nCreate a dataset from it. The dataset will allow to do research similar to https://w3techs.com/\r\n\r\nSee also: https://commoncrawl.org/\r\nSee also: https://www.rukv.ru/ (created and abandoned by Aleksey Tutubalin)","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18842/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18842/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18841","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18841/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18841/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18841/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/18841","id":781372061,"node_id":"MDU6SXNzdWU3ODEzNzIwNjE=","number":18841,"title":"Choose Decimal/Float interpretation from literal values ","user":{"login":"UnamedRus","id":9449405,"node_id":"MDQ6VXNlcjk0NDk0MDU=","avatar_url":"https://avatars.githubusercontent.com/u/9449405?v=4","gravatar_id":"","url":"https://api.github.com/users/UnamedRus","html_url":"https://github.com/UnamedRus","followers_url":"https://api.github.com/users/UnamedRus/followers","following_url":"https://api.github.com/users/UnamedRus/following{/other_user}","gists_url":"https://api.github.com/users/UnamedRus/gists{/gist_id}","starred_url":"https://api.github.com/users/UnamedRus/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/UnamedRus/subscriptions","organizations_url":"https://api.github.com/users/UnamedRus/orgs","repos_url":"https://api.github.com/users/UnamedRus/repos","events_url":"https://api.github.com/users/UnamedRus/events{/privacy}","received_events_url":"https://api.github.com/users/UnamedRus/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-01-07T14:55:15Z","updated_at":"2021-01-07T14:55:15Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"In certain cases, clickhouse can determine the resulting type of values interpretation without explicit conversion declaration.\r\nAnd we can have settings which would control that kind of behavior.\r\n\r\n**Use case**\r\n```\r\nSELECT toDecimal64(1.4,10) UNION ALL SELECT 1.5 ;\r\n\r\nCode: 386. DB::Exception: Received from localhost:9000. DB::Exception: There is no supertype for types Decimal(18, 10), Float64 because some of them have no lossless conversion to Decimal.\r\n\r\nCREATE TABLE test_float(`id` UInt64,`decimal_column` Decimal64(10)) ENGINE = MergeTree ORDER BY id\r\n\r\nINSERT INTO test_float (decimal_column) SELECT 1.5\r\n\r\nQuery id: f1e03fab-e6a4-4b0a-8264-94fa715b1e8f\r\n\r\nOk.\r\n\r\nINSERT INTO test_float (decimal_column) SELECT 1.5\r\nFROM view_test_float\r\nUNION ALL\r\nSELECT decimal_column\r\nFROM view_test_float\r\n\r\nQuery id: 8e0761af-44e8-4389-b942-2cc0789a7e44\r\n\r\n\r\nReceived exception from server (version 20.13.1):\r\nCode: 386. DB::Exception: Received from localhost:9000. DB::Exception: There is no supertype for types Float64, Decimal(18, 10) because some of them have no lossless conversion to Decimal.\r\n\r\n```\r\n\r\n**Describe the solution you'd like**\r\nClickhouse would automatically interpret 1.5 as decimal when other values are decimal.\r\n\r\n**Describe alternatives you've considered**\r\nUse toDecimal() functions.\r\n\r\n**Additional context**\r\nhttps://github.com/ClickHouse/ClickHouse/issues/9881#issuecomment-657261973\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18841/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18841/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18794","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18794/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18794/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18794/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/18794","id":780715464,"node_id":"MDU6SXNzdWU3ODA3MTU0NjQ=","number":18794,"title":"Sanity checks on startup","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":3086255531,"node_id":"MDU6TGFiZWwzMDg2MjU1NTMx","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/warmup%20task","name":"warmup task","color":"FBCA04","default":false,"description":"The task for new ClickHouse team members. Low risk, moderate complexity, no urgency."}],"state":"open","locked":false,"assignee":{"login":"serxa","id":1014716,"node_id":"MDQ6VXNlcjEwMTQ3MTY=","avatar_url":"https://avatars.githubusercontent.com/u/1014716?v=4","gravatar_id":"","url":"https://api.github.com/users/serxa","html_url":"https://github.com/serxa","followers_url":"https://api.github.com/users/serxa/followers","following_url":"https://api.github.com/users/serxa/following{/other_user}","gists_url":"https://api.github.com/users/serxa/gists{/gist_id}","starred_url":"https://api.github.com/users/serxa/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/serxa/subscriptions","organizations_url":"https://api.github.com/users/serxa/orgs","repos_url":"https://api.github.com/users/serxa/repos","events_url":"https://api.github.com/users/serxa/events{/privacy}","received_events_url":"https://api.github.com/users/serxa/received_events","type":"User","site_admin":false},"assignees":[{"login":"serxa","id":1014716,"node_id":"MDQ6VXNlcjEwMTQ3MTY=","avatar_url":"https://avatars.githubusercontent.com/u/1014716?v=4","gravatar_id":"","url":"https://api.github.com/users/serxa","html_url":"https://github.com/serxa","followers_url":"https://api.github.com/users/serxa/followers","following_url":"https://api.github.com/users/serxa/following{/other_user}","gists_url":"https://api.github.com/users/serxa/gists{/gist_id}","starred_url":"https://api.github.com/users/serxa/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/serxa/subscriptions","organizations_url":"https://api.github.com/users/serxa/orgs","repos_url":"https://api.github.com/users/serxa/repos","events_url":"https://api.github.com/users/serxa/events{/privacy}","received_events_url":"https://api.github.com/users/serxa/received_events","type":"User","site_admin":false}],"milestone":null,"comments":9,"created_at":"2021-01-06T17:17:43Z","updated_at":"2022-01-27T18:52:38Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"We should check some information about OS at startup and provide warnings.\r\n\r\nExamples of the typical gotchas:\r\n- too low ulimit on number of files;\r\n- too low ulimit on number of threads;\r\n- too low free memory (2 GiB or less);\r\n- memory overcommit is set to 2;\r\n- CPU scaling governor is not \"performance\";\r\n- Linux is not using fast \"TSC\" timer;\r\n- low disk space in a volume with logs (less than 1 GiB);\r\n- low disk space in a volume with data (less than 1 GiB);\r\n- transparent huge pages are set to \"always\" (on old Linux kernels);\r\n- disk readahead is disabled and it is rotational;\r\n- RAID 5 or 6 is used with unsufficient stripe cache size;\r\n- the number of corrected ECC errors is high;\r\n- there are thermal throttling events recently;\r\n- TurboBoost is disabled;\r\n- checksum of the loaded code segment does not correspond to some record in ELF file;\r\n- none of the data volumes are on the largest mounted fs;\r\n- data volume is using Docker overlay fs;\r\n- too low value of /proc/sys/kernel/pid_max or /proc/sys/kernel/threads-max, should be more than 30000;\r\n- too low system-wide limit on the number of opened files: https://github.com/ClickHouse/ClickHouse/issues/25994#issuecomment-874153421\r\n- Linux kernel version is old and this version has known bugs;","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18794/reactions","total_count":6,"+1":6,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18794/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18767","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18767/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18767/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18767/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/18767","id":779313058,"node_id":"MDU6SXNzdWU3NzkzMTMwNTg=","number":18767,"title":"CASE/multiIf to transform optimization.","user":{"login":"UnamedRus","id":9449405,"node_id":"MDQ6VXNlcjk0NDk0MDU=","avatar_url":"https://avatars.githubusercontent.com/u/9449405?v=4","gravatar_id":"","url":"https://api.github.com/users/UnamedRus","html_url":"https://github.com/UnamedRus","followers_url":"https://api.github.com/users/UnamedRus/followers","following_url":"https://api.github.com/users/UnamedRus/following{/other_user}","gists_url":"https://api.github.com/users/UnamedRus/gists{/gist_id}","starred_url":"https://api.github.com/users/UnamedRus/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/UnamedRus/subscriptions","organizations_url":"https://api.github.com/users/UnamedRus/orgs","repos_url":"https://api.github.com/users/UnamedRus/repos","events_url":"https://api.github.com/users/UnamedRus/events{/privacy}","received_events_url":"https://api.github.com/users/UnamedRus/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":756395244,"node_id":"MDU6TGFiZWw3NTYzOTUyNDQ=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/performance","name":"performance","color":"c2e0c6","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-01-05T17:16:21Z","updated_at":"2021-01-05T20:04:38Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"In certain conditions it's possible to rewrite CASE or multiIf to transform statement which is faster by 30-40%.\r\n\r\n**Use case**\r\n\r\nClickhouse 20.13\r\n\r\nFrom Int to String\r\n```\r\nSELECT multiIf(key = 0, 'string1', key = 1, 'string2', key = 2, 'string3', key = 3, 'string4', 'string')\r\nFROM\r\n(\r\n    SELECT number % 5 AS key\r\n    FROM numbers(100000000)\r\n)\r\nFORMAT Null\r\n\r\n0 rows in set. Elapsed: 1.338 sec. Processed 100.03 million rows, 800.21 MB (74.75 million rows/s., 597.97 MB/s.)\r\n\r\n\r\nSELECT transform(key, [0, 1, 2, 3], ['string1', 'string2', 'string3', 'string4'], 'string')\r\nFROM\r\n(\r\n    SELECT number % 5 AS key\r\n    FROM numbers(100000000)\r\n)\r\nFORMAT Null\r\n\r\n0 rows in set. Elapsed: 0.776 sec. Processed 100.03 million rows, 800.21 MB (128.96 million rows/s., 1.03 GB/s.)\r\n```\r\n\r\nEnum just to compare(as we have static set in transform function, would it make sense to have Enum as result datatype??)\r\n\r\n```\r\nSELECT cast(if(key > 3, key, 4), 'Enum(\\'string1\\' = 0, \\'string2\\' = 1, \\'string3\\' = 2, \\'string4\\' = 3, \\'string\\' = 4)')\r\nFROM\r\n(\r\n    SELECT number % 5 AS key\r\n    FROM numbers(100000000)\r\n)\r\nFORMAT Null\r\n\r\n0 rows in set. Elapsed: 0.244 sec. Processed 100.03 million rows, 800.21 MB (410.62 million rows/s., 3.28 GB/s.)\r\n```\r\nFrom String to Int\r\n\r\n```\r\nCREATE TABLE test_table_transform\r\n(\r\n    `key` String\r\n)\r\nENGINE = MergeTree\r\nORDER BY key\r\n\r\nINSERT INTO test_table_transform SELECT concat('string', toString(number % 5)) AS key\r\nFROM numbers(100000000)\r\n\r\n\r\nSELECT multiIf(key = 'string0', 0, key = 'string1', 1, key = 'string2', 2, key = 'string3', 3, key = 'string4', 4, 5)\r\nFROM test_table_transform\r\nFORMAT Null\r\n\r\n0 rows in set. Elapsed: 0.524 sec. Processed 100.00 million rows, 1.60 GB (190.82 million rows/s., 3.05 GB/s.)\r\n\r\nSELECT transform(key, ['string0', 'string1', 'string2', 'string3', 'string4'], [0, 1, 2, 3, 4], 5)\r\nFROM test_table_transform\r\nFORMAT Null\r\n\r\n0 rows in set. Elapsed: 0.300 sec. Processed 100.00 million rows, 1.60 GB (333.68 million rows/s., 5.34 GB/s.)\r\n\r\n\r\nSELECT cast(key, 'Enum(\\'string0\\' = 0, \\'string1\\' = 1, \\'string2\\' = 2, \\'string3\\' = 3, \\'string4\\' = 4)')\r\nFROM test_table_transform\r\nFORMAT Null\r\n\r\n0 rows in set. Elapsed: 0.324 sec. Processed 100.00 million rows, 1.60 GB (308.53 million rows/s., 4.94 GB/s.)\r\n\r\n```\r\n\r\n**Describe alternatives you've considered**\r\nDo it by hand, but not all users of clickhouse are aware about the transform function.\r\n\r\n**Additional context**\r\nIf dst array is String, consider use of Enum?\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18767/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18767/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18716","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18716/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18716/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18716/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/18716","id":777909845,"node_id":"MDU6SXNzdWU3Nzc5MDk4NDU=","number":18716,"title":"Fatal error: Uncaught ClickHouseDB\\Exception\\QueryException: Empty reply from server","user":{"login":"mitzsu","id":19756818,"node_id":"MDQ6VXNlcjE5NzU2ODE4","avatar_url":"https://avatars.githubusercontent.com/u/19756818?v=4","gravatar_id":"","url":"https://api.github.com/users/mitzsu","html_url":"https://github.com/mitzsu","followers_url":"https://api.github.com/users/mitzsu/followers","following_url":"https://api.github.com/users/mitzsu/following{/other_user}","gists_url":"https://api.github.com/users/mitzsu/gists{/gist_id}","starred_url":"https://api.github.com/users/mitzsu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mitzsu/subscriptions","organizations_url":"https://api.github.com/users/mitzsu/orgs","repos_url":"https://api.github.com/users/mitzsu/repos","events_url":"https://api.github.com/users/mitzsu/events{/privacy}","received_events_url":"https://api.github.com/users/mitzsu/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":5,"created_at":"2021-01-04T08:11:59Z","updated_at":"2021-09-08T10:48:33Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Hi Team,\r\n\r\nI am getting an issue while fetching 5 months data from ClickHouse and I have already set execution time as 0 and memory usage as 0 for infinite time and memory respectively in the configuration settings.\r\n\r\nI tried on some lesser date range and then I was getting rows but it was taking more time like 2.5 min and I have a data set in billions rows.\r\n\r\nHow can I get rid of it or there is any other information required please let me know?\r\n\r\nAnd I also get following one when I add more columns-\r\n`Fatal error: Uncaught ClickHouseDB\\Exception\\QueryException: HttpCode:500 ; ;Code: 173, e.displayText() = DB::ErrnoException: Allocator: Cannot mmap 64.00 MiB., errno: 12, strerror: Cannot allocate memory: While executing ConvertingAggregatedToChunksTransform (version 20.3.12.112)`\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18716/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18716/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18711","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18711/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18711/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18711/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/18711","id":777767302,"node_id":"MDU6SXNzdWU3Nzc3NjczMDI=","number":18711,"title":"Randomize wall clock time for tests","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":521113272,"node_id":"MDU6TGFiZWw1MjExMTMyNzI=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/build","name":"build","color":"800000","default":false,"description":""}],"state":"open","locked":false,"assignee":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"assignees":[{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false}],"milestone":null,"comments":1,"created_at":"2021-01-04T02:01:02Z","updated_at":"2021-01-04T21:02:26Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"Provide wrapper functions for libc (similar to libfaketime) to randomize time:\r\n- start time from random point;\r\n- increment time by random intervals at every call.\r\n\r\nIt will help to catch more errors in tests (time bombs, lack of DST support, etc).\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18711/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18711/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18695","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18695/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18695/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18695/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/18695","id":777669326,"node_id":"MDU6SXNzdWU3Nzc2NjkzMjY=","number":18695,"title":"Subpartition (RFC)","user":{"login":"amosbird","id":5085485,"node_id":"MDQ6VXNlcjUwODU0ODU=","avatar_url":"https://avatars.githubusercontent.com/u/5085485?v=4","gravatar_id":"","url":"https://api.github.com/users/amosbird","html_url":"https://github.com/amosbird","followers_url":"https://api.github.com/users/amosbird/followers","following_url":"https://api.github.com/users/amosbird/following{/other_user}","gists_url":"https://api.github.com/users/amosbird/gists{/gist_id}","starred_url":"https://api.github.com/users/amosbird/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/amosbird/subscriptions","organizations_url":"https://api.github.com/users/amosbird/orgs","repos_url":"https://api.github.com/users/amosbird/repos","events_url":"https://api.github.com/users/amosbird/events{/privacy}","received_events_url":"https://api.github.com/users/amosbird/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":1365579236,"node_id":"MDU6TGFiZWwxMzY1NTc5MjM2","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/minor","name":"minor","color":"FFF8F8","default":false,"description":"Priority: minor"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":7,"created_at":"2021-01-03T16:17:28Z","updated_at":"2021-12-05T20:28:26Z","closed_at":null,"author_association":"COLLABORATOR","active_lock_reason":null,"body":"Subpartitions are parts of a MergeTree table's partition. It's defined by an expression based on minmax columns (not the partition expr). It provides the ability to confine merges inside a single partition, and allows user to select a subset of parts of a given partition during ALTER PARTITION commands, notably, REPLACE PARTITION. It's useful to support dynamic partitioning, which helps with applications related to the \"lambda architecture\".\r\n\r\n### Subpartition Examples:\r\n```\r\ncreate table x (dt DateTime) engine MergeTree partition by toYYYYMM(dt);\r\nalter table x add partition expr hourly toStartOfHour(dt) where toDate(dt) >= today() - 3 days;\r\nalter table x add partition expr daily toDate(dt) where toDate(dt) >= today() - 7 days;\r\nalter table x replace partition expr hourly = '2021-01-01 00:00:00' from x_base;\r\n```\r\n\r\nAll the partition manipulating commands will be extended.\r\n\r\n### Subpartition Internals:\r\n\r\nGiven a partition expr, the table's part merging process will be confined to only merge parts with the same value of the expr. It also requires the parts to be in the same partition. Block insertion will also split into the finest granule based on all partition exprs. The `WHERE` clause presents the effectiveness of a partition expr. We can select parts to replace using the expr directly, as shown in the example.\r\n\r\nThe partition expr requires to be monotonic. If there are any selected parts containing more than one value of the expr. The alter command will fail with informative error messages.\r\n\r\nThe name `expr` is used for now. Other names might be `identifier`, `tag` or `rule`. Any suggestions are very much appreciated.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18695/reactions","total_count":7,"+1":7,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18695/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18681","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18681/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18681/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18681/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/18681","id":777314106,"node_id":"MDU6SXNzdWU3NzczMTQxMDY=","number":18681,"title":"Merge table skip missing columns for underlying tables.","user":{"login":"UnamedRus","id":9449405,"node_id":"MDQ6VXNlcjk0NDk0MDU=","avatar_url":"https://avatars.githubusercontent.com/u/9449405?v=4","gravatar_id":"","url":"https://api.github.com/users/UnamedRus","html_url":"https://github.com/UnamedRus","followers_url":"https://api.github.com/users/UnamedRus/followers","following_url":"https://api.github.com/users/UnamedRus/following{/other_user}","gists_url":"https://api.github.com/users/UnamedRus/gists{/gist_id}","starred_url":"https://api.github.com/users/UnamedRus/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/UnamedRus/subscriptions","organizations_url":"https://api.github.com/users/UnamedRus/orgs","repos_url":"https://api.github.com/users/UnamedRus/repos","events_url":"https://api.github.com/users/UnamedRus/events{/privacy}","received_events_url":"https://api.github.com/users/UnamedRus/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2021-01-01T16:44:45Z","updated_at":"2021-01-01T19:22:44Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Use case**\r\nGive the ability for the user to skip missing columns when querying the Merge table engine and some underlying tables have missing columns.\r\nIt's possible to populate them with Null values (in case Nullable columns) or default values for certain data type.\r\n\r\nPoor man dynamic table structure.\r\n\r\n**Describe the solution you'd like**\r\nsetting (table engine setting?)\r\n\r\n**Describe alternatives you've considered**\r\nUse condition in WHERE with _table virtual column.\r\n\r\n**Additional context**\r\n```\r\nCREATE TABLE test_table_1\r\n(\r\n    `key` UInt32,\r\n    `value_1` UInt32,\r\n    `value_2` UInt32\r\n)\r\nENGINE = MergeTree\r\nPARTITION BY tuple()\r\nORDER BY key\r\n\r\nCREATE TABLE test_table_2\r\n(\r\n    `key` UInt32,\r\n    `value_3` UInt32,\r\n    `value_4` UInt32\r\n)\r\nENGINE = MergeTree\r\nPARTITION BY tuple()\r\nORDER BY key\r\n\r\nINSERT INTO test_table_1 SELECT\r\n    number,\r\n    rand(),\r\n    rand()\r\nFROM numbers(100)\r\n\r\nINSERT INTO test_table_2 SELECT\r\n    number,\r\n    rand(),\r\n    rand()\r\nFROM numbers(100)\r\n\r\nCREATE TABLE test_table_2\r\n(\r\n    `key` UInt32,\r\n    `value_1` UInt32,\r\n    `value_2` UInt32,\r\n    `value_3` UInt32,\r\n    `value_4` UInt32\r\n)\r\nENGINE = Merge(test, test_table)\r\n\r\nSELECT *\r\nFROM merge_table\r\n\r\nQuery id: 982f624d-7b95-4d8c-b1c9-b07f0eb0809f\r\n\r\n\r\nReceived exception from server (version 20.13.1):\r\nCode: 16. DB::Exception: Received from localhost:9000. DB::Exception: There is no column with name `value_3` in table test.test_table_1 (20cd2ece-8b22-4f3d-9d17-a24939b5028f). There are columns: key, value_1, value_2, _part, _part_index, _partition_id, _sample_factor.\r\n\r\n\r\nSELECT\r\n    key,\r\n    value_1,\r\n    value_2\r\nFROM merge_table\r\nWHERE _table = 'test_table_1'\r\n\r\n┌─key─┬────value_1─┬────value_2─┐\r\n│   0 │ 2824904617 │ 2824904617 │\r\n│   1 │ 2636881554 │ 2636881554 │\r\n│   2 │ 2923242285 │ 2923242285 │\r\n│   3 │ 1406688622 │ 1406688622 │\r\n└─────┴────────────┴────────────┘\r\n```\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18681/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18681/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18680","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18680/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18680/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18680/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/18680","id":777309171,"node_id":"MDU6SXNzdWU3NzczMDkxNzE=","number":18680,"title":"Double format output when settings in ASTSelectQuery is a format setting.","user":{"login":"ucasfl","id":22127746,"node_id":"MDQ6VXNlcjIyMTI3NzQ2","avatar_url":"https://avatars.githubusercontent.com/u/22127746?v=4","gravatar_id":"","url":"https://api.github.com/users/ucasfl","html_url":"https://github.com/ucasfl","followers_url":"https://api.github.com/users/ucasfl/followers","following_url":"https://api.github.com/users/ucasfl/following{/other_user}","gists_url":"https://api.github.com/users/ucasfl/gists{/gist_id}","starred_url":"https://api.github.com/users/ucasfl/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ucasfl/subscriptions","organizations_url":"https://api.github.com/users/ucasfl/orgs","repos_url":"https://api.github.com/users/ucasfl/repos","events_url":"https://api.github.com/users/ucasfl/events{/privacy}","received_events_url":"https://api.github.com/users/ucasfl/received_events","type":"User","site_admin":false},"labels":[{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-01-01T16:12:15Z","updated_at":"2021-01-05T11:33:48Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"```sql\r\nselect * from action format CSV SETTINGS format_csv_delimiter=' '\r\n\r\nSELECT *\r\nFROM action\r\nSETTINGS format_csv_delimiter = ' '\r\nFORMAT CSV\r\nSETTINGS format_csv_delimiter = ' '\r\n```\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18680/reactions","total_count":1,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":1},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18680/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18670","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18670/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18670/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18670/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/18670","id":776929949,"node_id":"MDU6SXNzdWU3NzY5Mjk5NDk=","number":18670,"title":"Dropping index timeouts","user":{"login":"OmarBazaraa","id":6713329,"node_id":"MDQ6VXNlcjY3MTMzMjk=","avatar_url":"https://avatars.githubusercontent.com/u/6713329?v=4","gravatar_id":"","url":"https://api.github.com/users/OmarBazaraa","html_url":"https://github.com/OmarBazaraa","followers_url":"https://api.github.com/users/OmarBazaraa/followers","following_url":"https://api.github.com/users/OmarBazaraa/following{/other_user}","gists_url":"https://api.github.com/users/OmarBazaraa/gists{/gist_id}","starred_url":"https://api.github.com/users/OmarBazaraa/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/OmarBazaraa/subscriptions","organizations_url":"https://api.github.com/users/OmarBazaraa/orgs","repos_url":"https://api.github.com/users/OmarBazaraa/repos","events_url":"https://api.github.com/users/OmarBazaraa/events{/privacy}","received_events_url":"https://api.github.com/users/OmarBazaraa/received_events","type":"User","site_admin":false},"labels":[{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2020-12-31T11:33:26Z","updated_at":"2020-12-31T14:04:27Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"Dropping an index takes too long till the command timeouts.\r\n\r\n```sql\r\nALTER TABLE my_db.my_table_local\r\n    DROP INDEX my_index\r\n\r\nTimeout exceeded while receiving data from server. Waited for 300 seconds, timeout is 300 seconds.\r\nCancelling query.\r\n```\r\n\r\n**Server Version:** 20.10.2\r\n\r\nAnd here are the corresponding logs:\r\n\r\n```\r\n$ sudo cat clickhouse-server.log | grep \"a2e3d869-d18f-406e-9a93-86634b9e39ca\"\r\n\r\n2020.12.31 11:17:27.528057 [ 18722 ] {a2e3d869-d18f-406e-9a93-86634b9e39ca} <Debug> executeQuery: (from [::ffff:127.0.0.1]:58814) ALTER TABLE my_db.my_table_local DROP INDEX my_index;\r\n2020.12.31 11:17:27.528158 [ 18722 ] {a2e3d869-d18f-406e-9a93-86634b9e39ca} <Trace> ContextAccess (default): Access granted: ALTER DROP INDEX ON my_db.my_table_local\r\n2020.12.31 11:17:27.612437 [ 18722 ] {a2e3d869-d18f-406e-9a93-86634b9e39ca} <Debug> my_db.my_table_local: Updated shared metadata nodes in ZooKeeper. Waiting for replicas to apply changes.\r\n2020.12.31 11:17:27.612505 [ 18722 ] {a2e3d869-d18f-406e-9a93-86634b9e39ca} <Debug> my_db.my_table_local: Waiting for 1 to pull log-0000979232 to queue\r\n2020.12.31 11:17:27.662234 [ 18722 ] {a2e3d869-d18f-406e-9a93-86634b9e39ca} <Debug> my_db.my_table_local: Looking for node corresponding to log-0000979232 in 1 queue\r\n2020.12.31 11:17:27.678776 [ 18722 ] {a2e3d869-d18f-406e-9a93-86634b9e39ca} <Debug> my_db.my_table_local: Waiting for queue-0000979232 to disappear from 1 queue\r\n```\r\n\r\nAs per the documentation, dropping indexes should is a lightweight operation. So, I am not sure what is the problem.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18670/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18670/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18649","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18649/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18649/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18649/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/18649","id":776616513,"node_id":"MDU6SXNzdWU3NzY2MTY1MTM=","number":18649,"title":"Preallocate all or percentage of max_server_memory_usage to clickhouse process","user":{"login":"siradjev","id":10959667,"node_id":"MDQ6VXNlcjEwOTU5NjY3","avatar_url":"https://avatars.githubusercontent.com/u/10959667?v=4","gravatar_id":"","url":"https://api.github.com/users/siradjev","html_url":"https://github.com/siradjev","followers_url":"https://api.github.com/users/siradjev/followers","following_url":"https://api.github.com/users/siradjev/following{/other_user}","gists_url":"https://api.github.com/users/siradjev/gists{/gist_id}","starred_url":"https://api.github.com/users/siradjev/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/siradjev/subscriptions","organizations_url":"https://api.github.com/users/siradjev/orgs","repos_url":"https://api.github.com/users/siradjev/repos","events_url":"https://api.github.com/users/siradjev/events{/privacy}","received_events_url":"https://api.github.com/users/siradjev/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2020-12-30T20:05:26Z","updated_at":"2021-11-20T10:20:01Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"**Use case**\r\nClickhouse is frequently used on productions systems with some predefined capacity identified through some sizing methodology (mean concurrent queries, query sizes/durations distribution, etc) and elastic resource usage is less typical use case for large productions. \r\nIt would be useful to be able to instruct clickhouse to preallocate memory (100% of max_server_memory_usage or certain fraction of it), and keep it throughout clickhouse lifetime. \r\n\r\nThis provides several benefits such as:\r\n- Allow to use transparent huge pages efficiently to increase performance further\r\n- Prevent case when system falls into swap or query OOMed due to other co-host apps that is releasing memory lazily (.NET, Java based ones). \r\n- Avoid frequent questions caused by uncertainty of jemalloc that is not immediately releasing the allocated memory =)\r\n- Reduce potentially useless population and spoiling of filesystem page/buffer cache, when queries tend to use big % of overall memory. \r\n- More deterministic monitoring/operations\r\n\r\n\r\n**Describe the solution you'd like**\r\nIntroduce parameter preallocate_server_memory_percentage=0 by default to keep backward compatibility (technically it's not entirely true as loaded dictionaries are kind of preallocated memory). \r\n\r\nOptionally, custom ALTER SYSTEM commands can be supported such as ALTER SYSTEM PREALLOC MEMORYPCT [0-100] , although there is probably no need.  \r\n\r\n**Describe alternatives you've considered**\r\nNo alternatives found. \r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18649/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18649/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18612","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18612/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18612/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18612/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/18612","id":775953754,"node_id":"MDU6SXNzdWU3NzU5NTM3NTQ=","number":18612,"title":"Add support for TIMEDIFF function in MySQL Wire protocol (Mysql.Data .NET driver)","user":{"login":"siradjev","id":10959667,"node_id":"MDQ6VXNlcjEwOTU5NjY3","avatar_url":"https://avatars.githubusercontent.com/u/10959667?v=4","gravatar_id":"","url":"https://api.github.com/users/siradjev","html_url":"https://github.com/siradjev","followers_url":"https://api.github.com/users/siradjev/followers","following_url":"https://api.github.com/users/siradjev/following{/other_user}","gists_url":"https://api.github.com/users/siradjev/gists{/gist_id}","starred_url":"https://api.github.com/users/siradjev/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/siradjev/subscriptions","organizations_url":"https://api.github.com/users/siradjev/orgs","repos_url":"https://api.github.com/users/siradjev/repos","events_url":"https://api.github.com/users/siradjev/events{/privacy}","received_events_url":"https://api.github.com/users/siradjev/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":628291301,"node_id":"MDU6TGFiZWw2MjgyOTEzMDE=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/sql-compatibility","name":"sql-compatibility","color":"006b75","default":false,"description":""},{"id":2121263626,"node_id":"MDU6TGFiZWwyMTIxMjYzNjI2","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-mysql","name":"comp-mysql","color":"b5bcff","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2020-12-29T15:36:27Z","updated_at":"2021-01-04T15:15:02Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"**Use case**\r\nMysql.Data is the default way to connect to mysql DB in .NET. \r\nhttps://dev.mysql.com/doc/connector-net/en/connector-net-versions.html\r\nCurrently it's not possible to connect due to driver trying to call TIMEDIFF after connection. \r\n\r\nError returned\r\n```\r\nMySql.Data.MySqlClient.MySqlException: 'Code: 46, e.displayText() = DB::Exception: Unknown function TIMEDIFF. Maybe you meant: ['dateDiff'] (version 20.8.9.6 (official build))'\r\n```\r\nExample snippet to check. \r\n```\r\n            using (MySqlConnection conn = new MySqlConnection(\"Database=db;Data Source=server; Port=9004;User Id=mtest;Password=mtest\"))\r\n            {\r\n                conn.Open(); // throws exception\r\n            }\r\n\r\n```\r\n\r\n**Describe the solution you'd like**\r\nAdd TIMEDIFF meta-function support to mysql wire protocol in Clickhouse as a part of overall effort to improve MySQL compatibility #9336.\r\n\r\n\r\n**Describe alternatives you've considered**\r\nNo other real alternative is available. \r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18612/reactions","total_count":2,"+1":2,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18612/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18611","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18611/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18611/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18611/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/18611","id":775946651,"node_id":"MDU6SXNzdWU3NzU5NDY2NTE=","number":18611,"title":"Partial or Full support of extended queries for postgresql wire protocol to allow npgsql.NET to connect","user":{"login":"siradjev","id":10959667,"node_id":"MDQ6VXNlcjEwOTU5NjY3","avatar_url":"https://avatars.githubusercontent.com/u/10959667?v=4","gravatar_id":"","url":"https://api.github.com/users/siradjev","html_url":"https://github.com/siradjev","followers_url":"https://api.github.com/users/siradjev/followers","following_url":"https://api.github.com/users/siradjev/following{/other_user}","gists_url":"https://api.github.com/users/siradjev/gists{/gist_id}","starred_url":"https://api.github.com/users/siradjev/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/siradjev/subscriptions","organizations_url":"https://api.github.com/users/siradjev/orgs","repos_url":"https://api.github.com/users/siradjev/repos","events_url":"https://api.github.com/users/siradjev/events{/privacy}","received_events_url":"https://api.github.com/users/siradjev/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2020-12-29T15:22:03Z","updated_at":"2021-11-18T03:06:37Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"**Use case**\r\nNpgsql is the most popular .NET driver for postgresql wire protocol. (https://www.npgsql.org)\r\n\r\n\r\nCurrently it's not possible to use .NET driver for postgres to connect to clickhouse because it uses extended queries on opening connection. \r\n```\r\n0A000: ClickHouse doesn't support extended query mechanism\r\n```\r\nExample snippet to check. \r\n```\r\n            using (NpgsqlConnection conn = new NpgsqlConnection(\"Server=server; Port=5432; User Id=ptest; Password=ptest; Database=ptest\"))\r\n            {\r\n                conn.Open(); // throws exception\r\n            }\r\n\r\n```\r\n**Describe the solution you'd like**\r\nSupport extended queries and schema DB to allow drivers operate correctly. \r\n\r\n**Describe alternatives you've considered**\r\nNo other real alternative is available. \r\n\r\n**Additional context**\r\nAdd any other context or screenshots about the feature request here.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18611/reactions","total_count":2,"+1":2,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18611/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18568","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18568/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18568/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18568/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/18568","id":775396327,"node_id":"MDU6SXNzdWU3NzUzOTYzMjc=","number":18568,"title":"User Defined Types (aka type aliases): draft, discussion","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":1464781898,"node_id":"MDU6TGFiZWwxNDY0NzgxODk4","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/st-in-progress","name":"st-in-progress","color":"e5b890","default":false,"description":"We are working on the issue currenlty"}],"state":"open","locked":false,"assignee":{"login":"kitaisreal","id":22458333,"node_id":"MDQ6VXNlcjIyNDU4MzMz","avatar_url":"https://avatars.githubusercontent.com/u/22458333?v=4","gravatar_id":"","url":"https://api.github.com/users/kitaisreal","html_url":"https://github.com/kitaisreal","followers_url":"https://api.github.com/users/kitaisreal/followers","following_url":"https://api.github.com/users/kitaisreal/following{/other_user}","gists_url":"https://api.github.com/users/kitaisreal/gists{/gist_id}","starred_url":"https://api.github.com/users/kitaisreal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kitaisreal/subscriptions","organizations_url":"https://api.github.com/users/kitaisreal/orgs","repos_url":"https://api.github.com/users/kitaisreal/repos","events_url":"https://api.github.com/users/kitaisreal/events{/privacy}","received_events_url":"https://api.github.com/users/kitaisreal/received_events","type":"User","site_admin":false},"assignees":[{"login":"kitaisreal","id":22458333,"node_id":"MDQ6VXNlcjIyNDU4MzMz","avatar_url":"https://avatars.githubusercontent.com/u/22458333?v=4","gravatar_id":"","url":"https://api.github.com/users/kitaisreal","html_url":"https://github.com/kitaisreal","followers_url":"https://api.github.com/users/kitaisreal/followers","following_url":"https://api.github.com/users/kitaisreal/following{/other_user}","gists_url":"https://api.github.com/users/kitaisreal/gists{/gist_id}","starred_url":"https://api.github.com/users/kitaisreal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kitaisreal/subscriptions","organizations_url":"https://api.github.com/users/kitaisreal/orgs","repos_url":"https://api.github.com/users/kitaisreal/repos","events_url":"https://api.github.com/users/kitaisreal/events{/privacy}","received_events_url":"https://api.github.com/users/kitaisreal/received_events","type":"User","site_admin":false}],"milestone":null,"comments":6,"created_at":"2020-12-28T13:18:29Z","updated_at":"2021-12-06T16:54:43Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"User defined type is determined by:\r\n- its name;\r\n- underlying type for in-memory representation and binary serialization;\r\n- expressions to convert from/to String;\r\n- default expression;\r\n- constraints on internal representation;\r\n- constraints on input string;\r\n- function overloads;\r\n\r\n**Details**\r\n\r\n1. User defined type can map to parametrized type with fixed parameters:\r\n```\r\nCREATE TYPE Point2D AS Tuple(Float64, Float64)\r\n```\r\n\r\nIt can also be parametrized itself. Then parameters can be substituted to the parameters of the underlying type:\r\n```\r\nCREATE TYPE Point2D(T) AS Tuple(T, T)\r\n```\r\n\r\n```\r\nCREATE TYPE DecimalPoint2D(N, M) AS Tuple(Decimal(N, M), Decimal(N, M))\r\n```\r\n\r\nIt can map to a simple type as well.\r\n\r\n2. Expressions to convert from/to String can be composed from SQL functions.\r\nIt's in question how it's better to specify these expressions:\r\n- as expressions with predefined argument name (`value`, `string`), e.g. `OUTPUT IPv4NumToString(value)`\r\n- as lambda functions, e.g. `OUTPUT x -> IPv4NumToString(x)`\r\n\r\nIf we choose the first variant, we can write constraints on binary or string representations in uniform way, e.g. `CONSTRAINT isValidUTF8(value)` (in this example, `value` is the internal representation).\r\n\r\n3. There are multiple possible options to specify which functions will be available:\r\n- we can enable all existing functions that work on underlying type to also work on aliased type; but in some cases it can be undesired;\r\n- we can provide custom overloads for some functions (e.g. `length AS lengthUTF8(value)`) or define some functions with custom names (e.g. `area AS (value.x1 - value.x2) * (value.y1 - value.y2)`);\r\n- it can be desired for some functions to work automatically by converting some of arguments from String, e.g. `equals(T, String)`\r\n\r\nIt is uncrear how to define all these options.\r\n\r\n\r\n**Examples**\r\n\r\nThese examples are probably impractical, just to illustrate the idea:\r\n\r\n```\r\nCREATE TYPE IPv4 AS UInt32\r\nINPUT IPv4StringToNum(string)\r\nOUTPUT IPv4NumToString(value)\r\nDEFAULT IPv4StringToNum('127.0.0.1')\r\n```\r\n\r\n```\r\nCREATE TYPE UTF8String AS String\r\nCONSTRAINT isValidUTF8(value)\r\nFUNCTION length: value -> lengthUTF8(value)\r\nFUNCTION substring: value, n, m -> substringUTF8(value, n, m)\r\n```\r\n\r\n**References**\r\n\r\nhttps://www.postgresql.org/docs/9.5/sql-createtype.html\r\n\r\nIt's not required to do anything similar. But we need to look what is offered by other DBMS.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18568/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18568/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18561","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18561/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18561/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18561/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/18561","id":775251334,"node_id":"MDU6SXNzdWU3NzUyNTEzMzQ=","number":18561,"title":"Problem while using Prewhere with Storage View","user":{"login":"BhavyaRajSharma","id":40774184,"node_id":"MDQ6VXNlcjQwNzc0MTg0","avatar_url":"https://avatars.githubusercontent.com/u/40774184?v=4","gravatar_id":"","url":"https://api.github.com/users/BhavyaRajSharma","html_url":"https://github.com/BhavyaRajSharma","followers_url":"https://api.github.com/users/BhavyaRajSharma/followers","following_url":"https://api.github.com/users/BhavyaRajSharma/following{/other_user}","gists_url":"https://api.github.com/users/BhavyaRajSharma/gists{/gist_id}","starred_url":"https://api.github.com/users/BhavyaRajSharma/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/BhavyaRajSharma/subscriptions","organizations_url":"https://api.github.com/users/BhavyaRajSharma/orgs","repos_url":"https://api.github.com/users/BhavyaRajSharma/repos","events_url":"https://api.github.com/users/BhavyaRajSharma/events{/privacy}","received_events_url":"https://api.github.com/users/BhavyaRajSharma/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""},{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":2069471772,"node_id":"MDU6TGFiZWwyMDY5NDcxNzcy","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-view","name":"comp-view","color":"b5bcff","default":false,"description":"VIEWs"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2020-12-28T07:28:30Z","updated_at":"2020-12-29T05:41:23Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"**Use Case:**\r\nWe are using ReplacingMergeTree on Local tables.\r\nThis is needed as we are mimicing update with inserting latest \"Versioned\" row.\r\nDeletes are handled by inserting new row with Isactive column set to 0.\r\nDid not want consumer to add conditions to remove duplicates and remove inactive rows.\r\nHence created a view (NOT materialized) which comparises of these logic and have asked end user to use these views.\r\n\r\n\r\n**Problem Statement:**\r\nI am getting an exception while trying to use prewhere with storage view. I tried the below query.\r\n`select count(*) from myView prewhere id='422'`\r\nAfter running the above query I got the following exception:\r\n```\r\nReceived exception from server (version 20.8.9):\r\nCode: 182. DB::Exception: Received from localhost:9100. DB::Exception: Storage View doesn't support PREWHERE. \r\n\r\n0 rows in set. Elapsed: 0.002 sec. \r\n\r\n```\r\nAlso \"where\" does not get converted to \"prewhere\" in case of views.\r\n\r\nIs there any way (enabling some configs) I can use prewhere with the views? or is it planned for future?\r\n\r\n**ClickHouse Version Used**\r\nClickHouse client version 20.8.9.6 (official build).\r\nConnected to ClickHouse server version 20.8.9 revision 54438.\r\n\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18561/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18561/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18557","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18557/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18557/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18557/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/18557","id":775144354,"node_id":"MDU6SXNzdWU3NzUxNDQzNTQ=","number":18557,"title":"MUTATE_PART operations get stuck if always_fetch_merged_part set","user":{"login":"c3mb0","id":13203252,"node_id":"MDQ6VXNlcjEzMjAzMjUy","avatar_url":"https://avatars.githubusercontent.com/u/13203252?v=4","gravatar_id":"","url":"https://api.github.com/users/c3mb0","html_url":"https://github.com/c3mb0","followers_url":"https://api.github.com/users/c3mb0/followers","following_url":"https://api.github.com/users/c3mb0/following{/other_user}","gists_url":"https://api.github.com/users/c3mb0/gists{/gist_id}","starred_url":"https://api.github.com/users/c3mb0/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/c3mb0/subscriptions","organizations_url":"https://api.github.com/users/c3mb0/orgs","repos_url":"https://api.github.com/users/c3mb0/repos","events_url":"https://api.github.com/users/c3mb0/events{/privacy}","received_events_url":"https://api.github.com/users/c3mb0/received_events","type":"User","site_admin":false},"labels":[{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2020-12-28T01:21:37Z","updated_at":"2020-12-28T15:29:54Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Using v20.9.2, as the title says. I have 2 replicas, one of them configured with:\r\n\r\n```\r\n<merge_tree>\r\n    <replicated_can_become_leader>0</replicated_can_become_leader>\r\n    <always_fetch_merged_part>1</always_fetch_merged_part>\r\n</merge_tree>\r\n```\r\n\r\nWhen I issue an `ALTER TABLE x DROP COLUMN y` on the leader replica, follower gets flooded with `MUTATE_PART` operations that are unable to be processed. I've lost the content of the error message, but it was something along the lines of \"cannot merge parts because max allowed size is 0.0KB\". I assume the max bytes to merge cap is set to 0.0KB when `always_fetch_merged_part` is set, thus these operations get stuck.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18557/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18557/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18536","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18536/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18536/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18536/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/18536","id":774815354,"node_id":"MDU6SXNzdWU3NzQ4MTUzNTQ=","number":18536,"title":"add ANALYZE COMPRESSION query","user":{"login":"UnamedRus","id":9449405,"node_id":"MDQ6VXNlcjk0NDk0MDU=","avatar_url":"https://avatars.githubusercontent.com/u/9449405?v=4","gravatar_id":"","url":"https://api.github.com/users/UnamedRus","html_url":"https://github.com/UnamedRus","followers_url":"https://api.github.com/users/UnamedRus/followers","following_url":"https://api.github.com/users/UnamedRus/following{/other_user}","gists_url":"https://api.github.com/users/UnamedRus/gists{/gist_id}","starred_url":"https://api.github.com/users/UnamedRus/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/UnamedRus/subscriptions","organizations_url":"https://api.github.com/users/UnamedRus/orgs","repos_url":"https://api.github.com/users/UnamedRus/repos","events_url":"https://api.github.com/users/UnamedRus/events{/privacy}","received_events_url":"https://api.github.com/users/UnamedRus/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2020-12-26T03:29:45Z","updated_at":"2020-12-26T03:29:45Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Use case**\r\nGive users an easy way to automatically check/test multiple codecs and suggest a good enough combination of them.\r\n\r\n**Describe the solution you'd like**\r\nLike amazon redshift has \r\nhttps://docs.aws.amazon.com/redshift/latest/dg/r_ANALYZE_COMPRESSION.html","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18536/reactions","total_count":3,"+1":3,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18536/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18510","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18510/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18510/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18510/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/18510","id":774649684,"node_id":"MDU6SXNzdWU3NzQ2NDk2ODQ=","number":18510,"title":"Missing PREWHERE optimization","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":756395244,"node_id":"MDU6TGFiZWw3NTYzOTUyNDQ=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/performance","name":"performance","color":"c2e0c6","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2020-12-25T06:36:30Z","updated_at":"2021-02-17T09:09:42Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"```\r\ngithub-explorer.ru-central1.internal :) WITH wordShingleMinhashCaseInsensitive(body) AS hashes, wordShingleMinhashCaseInsensitive('Hi! Thank you very much, very useful! In what release will this be seen?') AS search SELECT actor_login, repo_name, number, body FROM github_events WHERE event_type = 'IssueCommentEvent' AND action = 'created' AND actor_login = 'alexey-milovidov' AND length(body) <= 30000 AND (hashes.1 = search.1 OR hashes.2 = search.2)\r\n\r\nWITH\r\n    wordShingleMinhashCaseInsensitive(body) AS hashes,\r\n    wordShingleMinhashCaseInsensitive('Hi! Thank you very much, very useful! In what release will this be seen?') AS search\r\nSELECT\r\n    actor_login,\r\n    repo_name,\r\n    number,\r\n    body\r\nFROM github_events\r\nWHERE (event_type = 'IssueCommentEvent') AND (action = 'created') AND (actor_login = 'alexey-milovidov') AND (length(body) <= 30000) AND (((hashes.1) = (search.1)) OR ((hashes.2) = (search.2)))\r\n\r\nQuery id: eefac94f-6f9c-4947-b838-03be99e15f80\r\n\r\nOk.\r\n\r\n0 rows in set. Elapsed: 32.380 sec. Processed 221.26 million rows, 105.99 GB (6.83 million rows/s., 3.27 GB/s.) \r\n\r\ngithub-explorer.ru-central1.internal :) WITH wordShingleMinhashCaseInsensitive(body) AS hashes, wordShingleMinhashCaseInsensitive('Hi! Thank you very much, very useful! In what release will this be seen?') AS search SELECT actor_login, repo_name, number, body FROM github_events PREWHERE actor_login = 'alexey-milovidov' WHERE event_type = 'IssueCommentEvent' AND action = 'created' AND length(body) <= 30000 AND (hashes.1 = search.1 OR hashes.2 = search.2)\r\n\r\nWITH\r\n    wordShingleMinhashCaseInsensitive(body) AS hashes,\r\n    wordShingleMinhashCaseInsensitive('Hi! Thank you very much, very useful! In what release will this be seen?') AS search\r\nSELECT\r\n    actor_login,\r\n    repo_name,\r\n    number,\r\n    body\r\nFROM github_events\r\nPREWHERE actor_login = 'alexey-milovidov'\r\nWHERE (event_type = 'IssueCommentEvent') AND (action = 'created') AND (length(body) <= 30000) AND (((hashes.1) = (search.1)) OR ((hashes.2) = (search.2)))\r\n\r\nQuery id: 96bc12fb-e301-4a1c-b7c0-da7b6fd6682a\r\n\r\nOk.\r\n\r\n0 rows in set. Elapsed: 0.149 sec. Processed 221.26 million rows, 4.33 GB (1.49 billion rows/s., 29.08 GB/s.)\r\n```\r\n\r\n32 sec vs. 0.149 sec.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18510/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18510/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18507","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18507/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18507/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18507/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/18507","id":774617772,"node_id":"MDU6SXNzdWU3NzQ2MTc3NzI=","number":18507,"title":"Gradually enforce green checks in PRs (proposal)","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":521113272,"node_id":"MDU6TGFiZWw1MjExMTMyNzI=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/build","name":"build","color":"800000","default":false,"description":""},{"id":1507886722,"node_id":"MDU6TGFiZWwxNTA3ODg2NzIy","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/st-discussion","name":"st-discussion","color":"e5b890","default":false,"description":"The story requires discussion /research / expert help / design & decomposition before will be taken"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2020-12-25T03:51:13Z","updated_at":"2020-12-25T03:55:00Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"## Intro\r\n\r\nWe have one of the best testing infrastructure for open-source products:\r\n- it's run for every commit and PR and logs, builds, artifacts are available publicly to everyone;\r\n- we involve as many ways to maintain quality as possible: static and dynamic analysis, every available sanitizer, variety of fuzzers and stress tests, performance tests, tests for tests, etc...\r\n\r\nIt allows our contributors to do quick development iterations.\r\n\r\nWe also have some rules for merging pull requests:\r\n- we should merge with green checks, but it's totally Ok to merge with failed checks if failures are unrelated, already known or being investigated.\r\n\r\nIt's unavoidable to sometimes merge with some failed checks, because we continuously add more sophisticated tests and checks and continuously stabilize our CI infrastructure. For example, if you run only checks that we have had one year ago - they will be 100% green as our product quality and CI infrastructure constantly becomes better.\r\n\r\n## Proposal\r\n\r\n### Green checks\r\n\r\nSometimes developer can accidentially break the rules and merge a PR without classification and investigation of failed checks. Let's make sure that it does not happen.\r\n\r\nLet's make merge button to be active only if all checks are green except possibly:\r\n- third-party checks that we do not control: Yandex checks and Testflows checks;\r\n- checks that did not finish in 8 hours;\r\n- checks that have mention by their name in comments;\r\n- or when there is a special comment to simply allow merge in emergent cases.\r\n\r\nThe latter will force to at least make yourself aware of the failed checks.\r\nReviewer will look at the failed checks and make a comment like \"Integration (thread) - docker rate limit exceeded (infrastructure error)\".\r\n\r\nThe main requirement is to unlock merge as soon as possible without further delay.\r\nWe will not require to do rebasing (maybe we can introduce a robot that will make automatic rebase or PRs).\r\n\r\n### Review requirement\r\n\r\nWe have a rule that every PR should be reviewed. But we permit self-review and it's totally Ok (I appreciate confidence and responsibility among developers).\r\nWhen developer is doing self review, they assign theirselves to the PR. GitHub does not permit to add \"approve\" to your own PR.\r\n\r\nLet's just make sure that PR is only available to merge if it was assigned to someone.\r\n\r\n### Automatic rollback\r\n\r\nWe have a database with all test runs and we can automate rollback of failed PRs. But it should not work very aggressively. \r\n\r\nFor example, if there is a test that is:\r\n- failed in PR;\r\n- failed in the corresponding \"Merge pull request\" commit in master;\r\n- this is the first failure of that specific test in master;\r\n\r\nWe will create rollback pull request automatically.\r\n\r\n## Alternatives\r\n\r\nThere is \"Mergify\" bot. We tried it last year and it was lead to a disaster. We cannot fine tune its behaviour and its usage is considered infeasible.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18507/reactions","total_count":2,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":2},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18507/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18501","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18501/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18501/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18501/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/18501","id":774601760,"node_id":"MDU6SXNzdWU3NzQ2MDE3NjA=","number":18501,"title":"Huge tests","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":1507886722,"node_id":"MDU6TGFiZWwxNTA3ODg2NzIy","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/st-discussion","name":"st-discussion","color":"e5b890","default":false,"description":"The story requires discussion /research / expert help / design & decomposition before will be taken"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2020-12-25T02:16:24Z","updated_at":"2020-12-25T02:20:16Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"**Use case**\r\n\r\nSome bugs can be found only on datasets of TB+ size.\r\nBut functional and integration tests are limited on max 5 min per test and about 3 hours per suite.\r\nWe want to test scenarious that can run for up to tens of hours on terabytes of data.\r\n\r\n**Describe the solution you'd like**\r\n\r\nA test suite that will not run for every PR, neither for every commit. It will not use Sandbox infrastructure.\r\nInstead, we allocate at least two separate servers or VMs. They will select the most recent green (?) commit and run the test suite. After it is done, next commit is selected (we will get maybe only a few complete runs each day). It's not necessarily to post test results on GitHub as they will be difficult to find.\r\n\r\nHow the test suite will be written:\r\n- a bunch of .sh scripts;\r\n- makefile for dependencies?\r\n\r\n(let's start with something really simple as we already have a good CI system, but this task is a little bit different)\r\n\r\nQuestions:\r\n- do we need special logic to run multiple servers in a cluster?\r\n- do we need isolation of tests of any kind (probably not - our goal is to make something similar to production server than can run multiple scenarios simultaneously).\r\n\r\n**Examples**\r\n\r\nDownload and unpack a dataset. Perform OPTIMIZE FINAL. Validate some queries. Create a distributed table and validate some queries again.\r\n\r\n**Caveats**\r\n\r\nThese tests will not have a good coverage and they have very limited use. They will spend a huge amount of time and hardware resources to test just a few cases. Actually most of production use cases do not cover even a small ratio of ClickHouse features. (We maintain a decent code coverage by using large amount of functional and integrational tests that we run on per-commit basis). It is unclear if these kind of tests will be beneficial at all.\r\n\r\nThese tests will not test integration with third-party systems (to avoid complexity). We already have integrational tests for that.\r\n\r\n**Alternatives**\r\n\r\nMaintain a number of real production services and do not fear to deploy binaries from master as frequent as possible.\r\nFor example, I have [a service](https://gh.clickhouse.tech/explorer/) and I deploy the most recent build to it.\r\n\r\nMaybe we need to develop a few more toy services, examples:\r\n- free log collection and observability for ClickHouse with ClickHouse.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18501/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18501/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18465","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18465/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18465/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18465/events","html_url":"https://github.com/ClickHouse/ClickHouse/pull/18465","id":774349748,"node_id":"MDExOlB1bGxSZXF1ZXN0NTQ1Mjc5NTYy","number":18465,"title":"Prototype - limit pushdown optimization in order to reduce network traffic","user":{"login":"achimbab","id":36371084,"node_id":"MDQ6VXNlcjM2MzcxMDg0","avatar_url":"https://avatars.githubusercontent.com/u/36371084?v=4","gravatar_id":"","url":"https://api.github.com/users/achimbab","html_url":"https://github.com/achimbab","followers_url":"https://api.github.com/users/achimbab/followers","following_url":"https://api.github.com/users/achimbab/following{/other_user}","gists_url":"https://api.github.com/users/achimbab/gists{/gist_id}","starred_url":"https://api.github.com/users/achimbab/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/achimbab/subscriptions","organizations_url":"https://api.github.com/users/achimbab/orgs","repos_url":"https://api.github.com/users/achimbab/repos","events_url":"https://api.github.com/users/achimbab/events{/privacy}","received_events_url":"https://api.github.com/users/achimbab/received_events","type":"User","site_admin":false},"labels":[{"id":1309674771,"node_id":"MDU6TGFiZWwxMzA5Njc0Nzcx","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/pr-feature","name":"pr-feature","color":"007700","default":false,"description":"Pull request with new product feature"},{"id":1807683251,"node_id":"MDU6TGFiZWwxODA3NjgzMjUx","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/doc-alert","name":"doc-alert","color":"e51068","default":false,"description":"PR where any documentation work is needed or proceeded"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":7,"created_at":"2020-12-24T11:47:26Z","updated_at":"2022-01-24T11:50:33Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"draft":false,"pull_request":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/pulls/18465","html_url":"https://github.com/ClickHouse/ClickHouse/pull/18465","diff_url":"https://github.com/ClickHouse/ClickHouse/pull/18465.diff","patch_url":"https://github.com/ClickHouse/ClickHouse/pull/18465.patch","merged_at":null},"body":"I hereby agree to the terms of the CLA available at: https://yandex.ru/legal/cla/?lang=en\r\n\r\nChangelog category (leave one):\r\n- New Feature\r\n\r\n\r\nChangelog entry (a user-readable short description of the changes that goes to CHANGELOG.md):\r\n\r\nLimit pushdown optimization\r\n\r\n\r\n\r\nDetailed description / Documentation draft:\r\n\r\nI'm developing `limit pushdown optimization`.\r\n\r\nLimit pushdown is used in some databases.\r\n* Druid\r\n  * https://druid.apache.org/docs/latest/querying/groupbyquery.html#limit-pushdown-optimization\r\n  * TopNs are approximate in that each data process will rank their top K results and only return those top K results to the Broker. K, by default in Druid, is max(1000, threshold) (https://druid.apache.org/docs/latest/querying/topnquery.html)\r\n* CitusDB\r\n  * https://docs.citusdata.com/en/v4.x/user_guide/limit_pushdown.html\r\n\r\nIn my prototype, there are significant improvement of query speed in some cases.\r\n\r\n![image](https://user-images.githubusercontent.com/36371084/103086846-036cd680-4629-11eb-8ac1-269b82b6e839.png)\r\n\r\n\r\n### Test Environment\r\n50 shards and 4.3 billions data rows\r\n\r\n### Test Queries\r\n```SQL\r\nCREATE TABLE test (\r\n  date Date, \r\n  type String, \r\n  url Nullable(String), \r\n  user UInt64\r\n) ENGINE = MergeTree() PARTITION BY date ORDER BY type;\r\n\r\nCREATE TABLE test_dist (\r\n  date Date. \r\n  type String, \r\n  url Nullable(String), \r\n  user UInt64\r\n) ENGINE = Distributed(test_cluster, default, test);\r\n```\r\n\r\n```\r\nINSERT 4.3 billions rows with high carinality URLs.\r\n```\r\n\r\n```SQL\r\nSELECT\r\n    url,\r\n    uniq(user) AS uv\r\nFROM default.test_dist\r\nWHERE (date = ‘2020-12-21) AND isNotNull(url)\r\nGROUP BY url\r\nORDER BY uv DESC\r\nLIMIT 11\r\n```\r\nThis query takes 15626 ms.\r\n\r\n```SQL\r\nSELECT\r\n    url,\r\n    uniq(user) AS uv\r\nFROM default.test_dist\r\nWHERE (date = ‘2020-12-21) AND isNotNull(url)\r\nGROUP BY url\r\nORDER BY uv DESC\r\nLIMIT 11\r\nSETTINGS enable_pushdown_limit_to_shards = 1\r\n```\r\nIt takes only 2981 ms with enable_pushdown_limit_to_shards.\r\n\r\n### Network Usage\r\n\r\nThe performance improvement has gained from reduction of network traffic.\r\n\r\nWithout limit pushdown, most of the query processing time takes to transfer data to the network.\r\n\r\n```\r\n$ sar -n DEV 1\r\n\r\nAverage:        IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s   %ifutil\r\n06:56:04 PM      eth0     21.00     16.00      2.19      3.19      0.00      0.00      0.00      0.00\r\n06:56:05 PM      eth0   6793.00   2033.00   9017.65    202.54      0.00      0.00      1.00      0.74\r\n06:56:06 PM      eth0  39645.00   4927.00  56481.04   3204.88      0.00      0.00      0.00      4.63\r\n06:56:07 PM      eth0 415794.00  38223.00 614667.75   2888.71      0.00      0.00      1.00     50.35\r\n06:56:08 PM      eth0 386278.00  31833.00 571020.08   2283.62      0.00      0.00      0.00     46.78\r\n06:56:09 PM      eth0 487369.00  42011.00 720508.87   3013.95      0.00      0.00      1.00     59.02\r\n06:56:10 PM      eth0 520461.00  45570.00 768986.62   3300.04      0.00      0.00      0.00     63.00\r\n06:56:11 PM      eth0 418554.00  39842.00 617393.73   5675.11      0.00      0.00      1.00     50.58\r\n06:56:12 PM      eth0 455938.00  42076.00 673957.46   3057.37      0.00      0.00      0.00     55.21\r\n06:56:13 PM      eth0 465344.00  40287.00 687819.36   2902.51      0.00      0.00      2.00     56.35\r\n06:56:14 PM      eth0 422321.00  36946.00 624330.39   2665.36      0.00      0.00      0.00     51.15\r\n06:56:15 PM      eth0 466596.00  43117.00 689505.17   3100.22      0.00      0.00      1.00     56.48\r\n06:56:16 PM      eth0 477206.00  45230.00 703521.69   5987.43      0.00      0.00      0.00     57.63                                                                                                                                                                                                                         06:56:17 PM      eth0 416650.00  38405.00 615946.10   2786.70      0.00      0.00      1.00     50.46                                                                                                                                                                                                                         06:56:18 PM      eth0 480367.00  43164.00 710139.43   3087.77      0.00      0.00      0.00     58.17                                                                                                                                  \r\n06:56:19 PM      eth0 462243.00  39168.00 683321.77   2840.51      0.00      0.00      1.00     55.98                \r\n06:56:20 PM      eth0  71877.00   7235.00 105656.70    518.24      0.00      0.00      0.00      8.66\r\n```\r\n\r\nWith limit_pushdown, it takes less network traffic \r\n```\r\n$ sar -n DEV 1\r\n\r\nAverage:        IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s   %ifutil\r\n06:56:39 PM      eth0    566.00    699.00     50.51    118.47      0.00      0.00      1.00      0.01                                                                                                                                                                                                                         \r\n06:56:40 PM      eth0  77015.00   3908.00 112779.34    269.95      0.00      0.00      0.00      9.24                                                                                                                                  \r\n06:56:41 PM      eth0  12380.00   3682.00  16610.94   3043.61      0.00      0.00      1.00      1.36   \r\n06:56:42 PM      eth0     20.00     17.00      1.44      5.89      0.00      0.00      0.00      0.00\r\n```\r\n\r\n### Loss of accuracy\r\nThe results of a query with limit_pushdown may be inaccurate because each remote shard would rank their results and only return those top (N * limit_pushdown_fetch_multiplier) to  the Initiator Node. \r\nBy increasing limit_pushdown_fetch_multiplier, the result of the query could be more accurate.\r\n\r\n### TODO\r\n~~Support simple expressions like `ifNull(uniq(user), 0) as uv`.~~ But, it couldn't support complex expressions.\r\n\r\n\r\nThank you.\r\n\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18465/reactions","total_count":2,"+1":2,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18465/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18452","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18452/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18452/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18452/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/18452","id":774227180,"node_id":"MDU6SXNzdWU3NzQyMjcxODA=","number":18452,"title":"Any solution or plan for supporting read-write separation ?","user":{"login":"liuyonghengheng","id":56812134,"node_id":"MDQ6VXNlcjU2ODEyMTM0","avatar_url":"https://avatars.githubusercontent.com/u/56812134?v=4","gravatar_id":"","url":"https://api.github.com/users/liuyonghengheng","html_url":"https://github.com/liuyonghengheng","followers_url":"https://api.github.com/users/liuyonghengheng/followers","following_url":"https://api.github.com/users/liuyonghengheng/following{/other_user}","gists_url":"https://api.github.com/users/liuyonghengheng/gists{/gist_id}","starred_url":"https://api.github.com/users/liuyonghengheng/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/liuyonghengheng/subscriptions","organizations_url":"https://api.github.com/users/liuyonghengheng/orgs","repos_url":"https://api.github.com/users/liuyonghengheng/repos","events_url":"https://api.github.com/users/liuyonghengheng/events{/privacy}","received_events_url":"https://api.github.com/users/liuyonghengheng/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":845267693,"node_id":"MDU6TGFiZWw4NDUyNjc2OTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/st-need-info","name":"st-need-info","color":"e5b890","default":false,"description":"We need extra data to continue"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":14,"created_at":"2020-12-24T06:56:21Z","updated_at":"2021-10-28T05:26:11Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"### Background  \r\n\r\nAt present, when users insert a large amount of records into the mergetree distributed table, the insertion task will take up a large amount of computing resources, which leads to the **performance decline** or even failure of the query. As a DBA, I want to ensure that clickhouse's performance is good and stable.\r\n\r\nAs far as I know, some clickhouse users/developers leverage clickhouse mergetree engine's library and external compute engine(such as spark) to generate mergetree files, and move them directly to all local table path corresponding to the specific distributed table. However, this way depends on extra development to reinvent the wheel (also need good understanding to the internal of Clickhouse) and it is not user friendly.  \r\n\r\n### Question  \r\n\r\nIf clickhouse can support the built-in read-write separation function, all insertion operations will be carried out on the write node, and the write node will compact/merge input records, and then the merged files will be distributed to the corresponding read nodes according to shard, so that the impact of insert operation on query node can be reduced, thus ensuring the stability of query performance. So my question is, do community have a plan to support the **built-in read-write separation** function ?\r\n\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18452/reactions","total_count":7,"+1":5,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":2},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18452/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18432","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18432/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18432/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18432/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/18432","id":773828491,"node_id":"MDU6SXNzdWU3NzM4Mjg0OTE=","number":18432,"title":"Documentation markup is ugly.","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":785082162,"node_id":"MDU6TGFiZWw3ODUwODIxNjI=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-documentation","name":"comp-documentation","color":"b5bcff","default":false,"description":"Used to run automatic builds of the documentation"},{"id":2668414603,"node_id":"MDU6TGFiZWwyNjY4NDE0NjAz","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/bug%20on%20website","name":"bug on website","color":"EA39C8","default":false,"description":""}],"state":"open","locked":false,"assignee":{"login":"rfraposa","id":5323324,"node_id":"MDQ6VXNlcjUzMjMzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/5323324?v=4","gravatar_id":"","url":"https://api.github.com/users/rfraposa","html_url":"https://github.com/rfraposa","followers_url":"https://api.github.com/users/rfraposa/followers","following_url":"https://api.github.com/users/rfraposa/following{/other_user}","gists_url":"https://api.github.com/users/rfraposa/gists{/gist_id}","starred_url":"https://api.github.com/users/rfraposa/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rfraposa/subscriptions","organizations_url":"https://api.github.com/users/rfraposa/orgs","repos_url":"https://api.github.com/users/rfraposa/repos","events_url":"https://api.github.com/users/rfraposa/events{/privacy}","received_events_url":"https://api.github.com/users/rfraposa/received_events","type":"User","site_admin":false},"assignees":[{"login":"rfraposa","id":5323324,"node_id":"MDQ6VXNlcjUzMjMzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/5323324?v=4","gravatar_id":"","url":"https://api.github.com/users/rfraposa","html_url":"https://github.com/rfraposa","followers_url":"https://api.github.com/users/rfraposa/followers","following_url":"https://api.github.com/users/rfraposa/following{/other_user}","gists_url":"https://api.github.com/users/rfraposa/gists{/gist_id}","starred_url":"https://api.github.com/users/rfraposa/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rfraposa/subscriptions","organizations_url":"https://api.github.com/users/rfraposa/orgs","repos_url":"https://api.github.com/users/rfraposa/repos","events_url":"https://api.github.com/users/rfraposa/events{/privacy}","received_events_url":"https://api.github.com/users/rfraposa/received_events","type":"User","site_admin":false}],"milestone":null,"comments":1,"created_at":"2020-12-23T14:23:25Z","updated_at":"2022-01-16T03:23:34Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"1. Light-orange on gray is inhumane:\r\n\r\n![Screenshot_20201223_172100](https://user-images.githubusercontent.com/18581488/103006821-64ba7a00-4543-11eb-81a6-dbc278bbe706.png)\r\n\r\n2. Copy button is not sticky, it looks weird:\r\n\r\n![Screenshot_20201223_172113](https://user-images.githubusercontent.com/18581488/103006889-7d2a9480-4543-11eb-9e76-2aac4902b68d.png)\r\n\r\n3. Idiotic highlighling by default (no highlighting is better):\r\n\r\n![Screenshot_20201223_172136](https://user-images.githubusercontent.com/18581488/103006928-8ca9dd80-4543-11eb-9e91-e2bc875cc8b6.png)\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18432/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18432/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18408","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18408/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18408/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18408/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/18408","id":773719600,"node_id":"MDU6SXNzdWU3NzM3MTk2MDA=","number":18408,"title":"Functions to obtain ClientInfo","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2020-12-23T12:29:13Z","updated_at":"2020-12-28T12:54:05Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"See `ClientInfo.h` and its usage in `system.query_log` (`QueryLog.h`).\r\n\r\n**Use case**\r\nWhen multiple clients are sending INSERT queries, we may want to have a materialized column with e.g. client hostname to automatically record where INSERT comes from.\r\n\r\n**Describe the solution you'd like**\r\nA single function `clientInfo('attr_name')` (its return type will depend on attr name) or a set of functions.\r\n\r\n**Describe alternatives you've considered**\r\nIt's always doable with custom API middleware.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18408/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18408/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18407","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18407/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18407/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18407/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/18407","id":773713265,"node_id":"MDU6SXNzdWU3NzM3MTMyNjU=","number":18407,"title":"Fire and forget mode or limited number of retries for distributed sends.","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2020-12-23T12:16:44Z","updated_at":"2021-11-11T21:20:06Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"**Use case**\r\n\r\n1. Mirror data from production to testing environment with MATERIALIZED VIEW with Distributed engine. The testing cluster should not affect production in any way: better to skip data when testing is unavailable than to accumulate it.\r\n\r\n2. Send query_log, metric_log, text_log, etc. to third-party unreliable service. If the third-party service is unavailable just skip sending the data batch.\r\n\r\n**Describe the solution you'd like**\r\n\r\nA table-level setting to Distributed table.\r\nEither simple fire-and-forget mode (no retries) or specify the maximum number of retries before dropping the data (better).\r\n\r\n**Alternatives**\r\n\r\nA table with URL engine. But we should also introduce mode to ignore sending errors or do retries.\r\nIt can be even more flexible than Distributed table.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18407/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18407/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18384","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18384/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18384/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18384/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/18384","id":773351209,"node_id":"MDU6SXNzdWU3NzMzNTEyMDk=","number":18384,"title":"Apply optimize_aggregation_in_order even if group by matches the sort key partially ","user":{"login":"cyberhuman","id":979624,"node_id":"MDQ6VXNlcjk3OTYyNA==","avatar_url":"https://avatars.githubusercontent.com/u/979624?v=4","gravatar_id":"","url":"https://api.github.com/users/cyberhuman","html_url":"https://github.com/cyberhuman","followers_url":"https://api.github.com/users/cyberhuman/followers","following_url":"https://api.github.com/users/cyberhuman/following{/other_user}","gists_url":"https://api.github.com/users/cyberhuman/gists{/gist_id}","starred_url":"https://api.github.com/users/cyberhuman/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/cyberhuman/subscriptions","organizations_url":"https://api.github.com/users/cyberhuman/orgs","repos_url":"https://api.github.com/users/cyberhuman/repos","events_url":"https://api.github.com/users/cyberhuman/events{/privacy}","received_events_url":"https://api.github.com/users/cyberhuman/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":1401777979,"node_id":"MDU6TGFiZWwxNDAxNzc3OTc5","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-optimizers","name":"comp-optimizers","color":"b5bcff","default":false,"description":"Query optimizations"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2020-12-23T01:24:54Z","updated_at":"2020-12-23T05:22:13Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"**Use case**\r\n\r\nGiven some table with a sort key (k1, k2, k3):\r\n```\r\nCREATE TABLE test (k1 Int32, k2 Int32, k3 Int32)\r\nENGINE = MergeTree()\r\nORDER BY (k1, k2, k3);\r\n```\r\nIt's possible to use the group by optimization when querying it:\r\n```\r\nSELECT k1, k2, k3\r\nFROM test\r\nGROUP BY k1, k2, k3\r\nSETTINGS optimize_aggregation_in_order = 1;\r\n```\r\nThis helps when the cardinality of k1 is very high.\r\nHowever, if one wants to group by k1 and k3 (assuming the number of different k3 for each k1 is small), the optimization is turned off completely:\r\n```\r\nSELECT k1, sum(k2), k3\r\nFROM test\r\nGROUP BY k1, k3\r\nSETTINGS optimize_aggregation_in_order = 1; -- <= doesn't have any effect\r\n```\r\n\r\n**Describe the solution you'd like**\r\nIt would be nice if optimization still worked for grouping by k1, and the query was processed in RAM inside of each bucket.\r\n\r\n**Describe alternatives you've considered**\r\nIn some cases, a workaround is possible using `array*` functions. However, it's hard to both write and read:\r\n```\r\nSELECT\r\n  t.k1 AS k1,\r\n  (\r\n    arrayJoin(\r\n      arrayMap(x -> ((x.1)[1], arraySum(x.2)),\r\n      arraySplit(\r\n        (x, y) -> y != 0,\r\n        arraySort(\r\n          x -> x.1,\r\n          groupArray((t.k3, t.k2))\r\n        ) AS row,\r\n        arrayDifference(x -> x.1, row)\r\n      )\r\n    ) AS out\r\n  ).2 AS k2,\r\n  out.1 AS k3\r\nFROM test AS t\r\nGROUP BY k1\r\nSETTINGS optimize_aggregation_in_order = 1;\r\n```\r\n\r\n**Additional context**\r\nAdd any other context or screenshots about the feature request here.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18384/reactions","total_count":2,"+1":2,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18384/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18371","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18371/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18371/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18371/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/18371","id":773059462,"node_id":"MDU6SXNzdWU3NzMwNTk0NjI=","number":18371,"title":"Storages can receive incorrectly rewritten queries in 'read' method.","user":{"login":"DimasKovas","id":34828390,"node_id":"MDQ6VXNlcjM0ODI4Mzkw","avatar_url":"https://avatars.githubusercontent.com/u/34828390?v=4","gravatar_id":"","url":"https://api.github.com/users/DimasKovas","html_url":"https://github.com/DimasKovas","followers_url":"https://api.github.com/users/DimasKovas/followers","following_url":"https://api.github.com/users/DimasKovas/following{/other_user}","gists_url":"https://api.github.com/users/DimasKovas/gists{/gist_id}","starred_url":"https://api.github.com/users/DimasKovas/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/DimasKovas/subscriptions","organizations_url":"https://api.github.com/users/DimasKovas/orgs","repos_url":"https://api.github.com/users/DimasKovas/repos","events_url":"https://api.github.com/users/DimasKovas/events{/privacy}","received_events_url":"https://api.github.com/users/DimasKovas/received_events","type":"User","site_admin":false},"labels":[{"id":1546440057,"node_id":"MDU6TGFiZWwxNTQ2NDQwMDU3","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/development","name":"development","color":"fc80df","default":false,"description":"Developement process & source code & implementation details"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2020-12-22T16:06:18Z","updated_at":"2020-12-23T04:51:32Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"(you don't have to strictly follow this form)\r\n\r\n**Describe the bug**\r\nStorages receive incorrectly rewritten query in 'read' method in some cases.\r\nFor instance, the initial query is\r\n\r\n> with test as (select number as a from numbers(10)) select * from log_t0 full join test using a\r\n\r\nBut  Storage::read receives this query in query_info.query:\r\n\r\n> WITH test AS (SELECT number AS a FROM numbers(10)) AS _subquery1\r\nSELECT a FROM log_t0\r\nALL FULL OUTER JOIN\r\n(SELECT number AS a FROM numbers(10)) AS test\r\nUSING (a)\r\n\r\nWhere the construction 'with test as (...) as _subquery1' is not correct and AST can not be parsed from this string.\r\n\r\nThis behavior was found by reading logs. I did not find any queries affected by this, but it can break something in the future.\r\n\r\n**How to reproduce**\r\nFirst of all add debug log at the beginning of read method in storage (e.g. [here](https://github.com/ClickHouse/ClickHouse/blob/3b2f8c1a97cd80164e5f3eeb1ed570dc2bee6bbe/src/Storages/StorageTinyLog.cpp#L436)). I used a StorageTinyLog in the example but it also works for other storages.\r\n\r\n> LOG_DEBUG(log, \"XXX Reading from tiny log (Query: {})\", DB::serializeAST(*query_info.query));\r\n\r\nDo not forget to include <Parsers/formatAST.h>\r\n\r\n* Which ClickHouse server version to use\r\n\r\nI used the latest ClickHouse version from Arcadia.\r\n\r\n* `CREATE TABLE` statements for all tables involved\r\ncreate table \r\n\r\n> create table log_t0 (a UInt64) engine=TinyLog()\r\n\r\n* Queries to run that lead to unexpected result\r\n\r\n> with test as (select number as a from numbers(10)) select * from log_t0 full join test using a\r\n\r\n\r\n**Error message and/or stacktrace**\r\nThe following line can be found in the log:\r\n\r\n> XXX Reading from tiny log (Query: WITH test AS (SELECT number AS a FROM numbers(10)) AS _subquery1 SELECT a FROM log_t0 ALL FULL OUTER JOIN (SELECT number AS a FROM numbers(10)) AS test USING (a))\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18371/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18371/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18283","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18283/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18283/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18283/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/18283","id":771869061,"node_id":"MDU6SXNzdWU3NzE4NjkwNjE=","number":18283,"title":"test.clickhouse.tech contains outdated documentation","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":785082162,"node_id":"MDU6TGFiZWw3ODUwODIxNjI=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-documentation","name":"comp-documentation","color":"b5bcff","default":false,"description":"Used to run automatic builds of the documentation"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":4,"created_at":"2020-12-21T05:58:02Z","updated_at":"2020-12-23T13:52:39Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"Figure out how to remove it.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18283/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18283/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18276","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18276/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18276/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18276/events","html_url":"https://github.com/ClickHouse/ClickHouse/pull/18276","id":771621781,"node_id":"MDExOlB1bGxSZXF1ZXN0NTQzMDg5OTU5","number":18276,"title":"Support merging finalized aggregation result from different servers on initiator node","user":{"login":"fuwhu","id":12389745,"node_id":"MDQ6VXNlcjEyMzg5NzQ1","avatar_url":"https://avatars.githubusercontent.com/u/12389745?v=4","gravatar_id":"","url":"https://api.github.com/users/fuwhu","html_url":"https://github.com/fuwhu","followers_url":"https://api.github.com/users/fuwhu/followers","following_url":"https://api.github.com/users/fuwhu/following{/other_user}","gists_url":"https://api.github.com/users/fuwhu/gists{/gist_id}","starred_url":"https://api.github.com/users/fuwhu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/fuwhu/subscriptions","organizations_url":"https://api.github.com/users/fuwhu/orgs","repos_url":"https://api.github.com/users/fuwhu/repos","events_url":"https://api.github.com/users/fuwhu/events{/privacy}","received_events_url":"https://api.github.com/users/fuwhu/received_events","type":"User","site_admin":false},"labels":[{"id":1304141686,"node_id":"MDU6TGFiZWwxMzA0MTQxNjg2","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/pr-improvement","name":"pr-improvement","color":"007700","default":false,"description":"Pull request with some product improvements"}],"state":"open","locked":false,"assignee":{"login":"CurtizJ","id":20361854,"node_id":"MDQ6VXNlcjIwMzYxODU0","avatar_url":"https://avatars.githubusercontent.com/u/20361854?v=4","gravatar_id":"","url":"https://api.github.com/users/CurtizJ","html_url":"https://github.com/CurtizJ","followers_url":"https://api.github.com/users/CurtizJ/followers","following_url":"https://api.github.com/users/CurtizJ/following{/other_user}","gists_url":"https://api.github.com/users/CurtizJ/gists{/gist_id}","starred_url":"https://api.github.com/users/CurtizJ/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/CurtizJ/subscriptions","organizations_url":"https://api.github.com/users/CurtizJ/orgs","repos_url":"https://api.github.com/users/CurtizJ/repos","events_url":"https://api.github.com/users/CurtizJ/events{/privacy}","received_events_url":"https://api.github.com/users/CurtizJ/received_events","type":"User","site_admin":false},"assignees":[{"login":"CurtizJ","id":20361854,"node_id":"MDQ6VXNlcjIwMzYxODU0","avatar_url":"https://avatars.githubusercontent.com/u/20361854?v=4","gravatar_id":"","url":"https://api.github.com/users/CurtizJ","html_url":"https://github.com/CurtizJ","followers_url":"https://api.github.com/users/CurtizJ/followers","following_url":"https://api.github.com/users/CurtizJ/following{/other_user}","gists_url":"https://api.github.com/users/CurtizJ/gists{/gist_id}","starred_url":"https://api.github.com/users/CurtizJ/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/CurtizJ/subscriptions","organizations_url":"https://api.github.com/users/CurtizJ/orgs","repos_url":"https://api.github.com/users/CurtizJ/repos","events_url":"https://api.github.com/users/CurtizJ/events{/privacy}","received_events_url":"https://api.github.com/users/CurtizJ/received_events","type":"User","site_admin":false}],"milestone":null,"comments":4,"created_at":"2020-12-20T16:10:31Z","updated_at":"2021-12-09T14:59:32Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"draft":false,"pull_request":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/pulls/18276","html_url":"https://github.com/ClickHouse/ClickHouse/pull/18276","diff_url":"https://github.com/ClickHouse/ClickHouse/pull/18276.diff","patch_url":"https://github.com/ClickHouse/ClickHouse/pull/18276.patch","merged_at":null},"body":"I hereby agree to the terms of the CLA available at: https://yandex.ru/legal/cla/?lang=en\r\n\r\nChangelog category (leave one):\r\n- Improvement\r\n\r\nChangelog entry (a user-readable short description of the changes that goes to CHANGELOG.md):\r\nsupport merging finalized aggregation result from different servers on initiator node, implemented for countDistinct.\r\nfix #18275 ","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18276/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18276/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18275","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18275/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18275/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18275/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/18275","id":771614000,"node_id":"MDU6SXNzdWU3NzE2MTQwMDA=","number":18275,"title":"Support running aggregation to final status on different servers and merge final result on initiator node for distributed query","user":{"login":"fuwhu","id":12389745,"node_id":"MDQ6VXNlcjEyMzg5NzQ1","avatar_url":"https://avatars.githubusercontent.com/u/12389745?v=4","gravatar_id":"","url":"https://api.github.com/users/fuwhu","html_url":"https://github.com/fuwhu","followers_url":"https://api.github.com/users/fuwhu/followers","following_url":"https://api.github.com/users/fuwhu/following{/other_user}","gists_url":"https://api.github.com/users/fuwhu/gists{/gist_id}","starred_url":"https://api.github.com/users/fuwhu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/fuwhu/subscriptions","organizations_url":"https://api.github.com/users/fuwhu/orgs","repos_url":"https://api.github.com/users/fuwhu/repos","events_url":"https://api.github.com/users/fuwhu/events{/privacy}","received_events_url":"https://api.github.com/users/fuwhu/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":9,"created_at":"2020-12-20T15:36:01Z","updated_at":"2021-05-11T12:35:43Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Scenario Description**\r\nIn some scenarios, data is written to different shards of one distributed table according to sharding key, eg. user_id.\r\nWhen we read these data and do some aggregation functions on the distributed table, it may be expensive to read aggregation states from different servers and do the merge on initiator node, because the aggregation state may be huge.\r\n\r\nOne solution here is to set distributed_group_by_no_merge and get final aggregation result from different servers in case we are sure that the different server own different data for the aggregation functions.\r\n\r\nThe problem of the solution above is that the result returned to user may need further merging to generate global final result.\r\n\r\n**Sample Case**\r\nwe have local table testtbl on 2 nodes (node-1 and node-2) : \r\n```\r\nCREATE TABLE testtbl\r\n(\r\n    `id` String,\r\n    `dt` String\r\n)\r\nENGINE = MergeTree\r\nPARTITION BY dt\r\nORDER BY id\r\n```\r\nand distributed table testtbl_dst : \r\n```\r\nCREATE TABLE testtbl_dst\r\n(\r\n    `id` String,\r\n    `dt` String\r\n)\r\nENGINE = Distributed('test_cluster_two_shards', 'testdb', 'testtbl', sipHash64(id))\r\n```\r\nAnd we have data ('1', '2020-01-01') on node-1, and (2, '2020-01-01') on node-2.\r\nif we run below SQL : \r\n```\r\nSELECT\r\n    dt,\r\n    countDistinct(id) AS dst_cnt\r\nFROM testtbl_dst\r\nGROUP BY dt\r\nSETTINGS distributed_group_by_no_merge = 1\r\n```\r\nwe get : \r\n```\r\n┌─dt─────────┬─dst_cnt─┐\r\n│ 2020-01-01 │       1 │\r\n└────────────┴─────────┘\r\n┌─dt─────────┬─dst_cnt─┐\r\n│ 2020-01-01 │       1 │\r\n└────────────┴─────────┘\r\n```\r\nbut what we want is ('2020-01-01', 2).\r\n\r\n**Solution Description**\r\nWe can modify the IAggregationFunction interface a little bit to make it possible to support different ways of merging finalized result on initiator node for different aggregation functions.\r\n\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18275/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18275/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18273","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18273/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18273/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18273/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/18273","id":771581392,"node_id":"MDU6SXNzdWU3NzE1ODEzOTI=","number":18273,"title":"Add `max_insert_block_ms` setting.","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2020-12-20T12:51:00Z","updated_at":"2020-12-20T12:51:00Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"The setting is similar to `max_insert_block_size`.\r\n\r\n**Use case**\r\n\r\nClient opens HTTP connection to the server and sends records row by row in POST request for INSERT query.\r\nServer will write blocks to a table every `max_insert_block_size` rows or every `max_insert_block_ms`, whatever comes first.\r\n\r\nTLDR: simply open a connection to the server and stream data to it.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18273/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18273/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18242","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18242/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18242/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18242/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/18242","id":771374564,"node_id":"MDU6SXNzdWU3NzEzNzQ1NjQ=","number":18242,"title":"Permanent merge of pieces of type TTL_DELETE is in progress","user":{"login":"k0st1an","id":426513,"node_id":"MDQ6VXNlcjQyNjUxMw==","avatar_url":"https://avatars.githubusercontent.com/u/426513?v=4","gravatar_id":"","url":"https://api.github.com/users/k0st1an","html_url":"https://github.com/k0st1an","followers_url":"https://api.github.com/users/k0st1an/followers","following_url":"https://api.github.com/users/k0st1an/following{/other_user}","gists_url":"https://api.github.com/users/k0st1an/gists{/gist_id}","starred_url":"https://api.github.com/users/k0st1an/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/k0st1an/subscriptions","organizations_url":"https://api.github.com/users/k0st1an/orgs","repos_url":"https://api.github.com/users/k0st1an/repos","events_url":"https://api.github.com/users/k0st1an/events{/privacy}","received_events_url":"https://api.github.com/users/k0st1an/received_events","type":"User","site_admin":false},"labels":[{"id":386401505,"node_id":"MDU6TGFiZWwzODY0MDE1MDU=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/bug","name":"bug","color":"ee0701","default":true,"description":"Confirmed user-visible misbehaviour in official release"},{"id":1401282669,"node_id":"MDU6TGFiZWwxNDAxMjgyNjY5","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-ttl","name":"comp-ttl","color":"b5bcff","default":false,"description":"TTL"},{"id":1507888214,"node_id":"MDU6TGFiZWwxNTA3ODg4MjE0","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/st-accepted","name":"st-accepted","color":"e5b890","default":false,"description":"The issue is in our backlog, ready to take"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":9,"created_at":"2020-12-19T12:45:15Z","updated_at":"2021-07-02T23:37:42Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"**Describe the bug**\r\n\r\nPermanent merge of pieces of type TTL_DELETE is in progress. The process takes a long time with little progress. Then it starts to consume a lot of memory and falls as it runs into the memory limit (30GB). And the merge starts over. And so endlessly. At the same time, neighboring merges with different types pass without problems.\r\n\r\n`system.merges`:\r\n\r\n```\r\nelapsed:          458.42945129\r\nprogress:         0.09986469705947837\r\npartition_id:     202005\r\nresult_part_name: 202005_0_53094_42\r\nmemory_usage:     120.49 MiB\r\nmerge_type:       TTL_DELETE\r\n```\r\n\r\n`system.parts`:\r\n\r\n```\r\npartition_id:  202005\r\nname:          202005_0_53094_41\r\nbytes_on_disk: 106.91 GiB\r\n```\r\n\r\n**Which ClickHouse server version to use**\r\n\r\n```\r\n┌─version()──┐\r\n│ 20.11.4.13 │\r\n└────────────┘\r\n```\r\n\r\n**`CREATE TABLE` statements for all tables involved**\r\n\r\n```\r\nCREATE TABLE DATABASE.TABLE ON CLUSTER name (\r\ntimestamp DateTime,\r\n  ...\r\n  timestamp DateTime,\r\n  bundle String,\r\n  ifa         String,\r\n  bid_id String\r\n)\r\nENGINE ReplicatedMergeTree('/clickhouse/{cluster}/{shard}/database/table', '{replica}')\r\n  PARTITION BY toYYYYMM(timestamp)\r\n  ORDER BY (bundle, ifa, timestamp)\r\n  TTL timestamp + INTERVAL 2 YEAR\r\n  SETTINGS storage_policy = 'slow_storage';\r\n```\r\n\r\n**Expected behavior**\r\n\r\nMerge parts should not lead to a drop in the merge process. The merge should complete successfully.\r\n\r\n**Error message and/or stacktrace**\r\n\r\n```\r\n2020.12.19 12:16:28.108008 [ 8944 ] {} <Error> DATABASE.TABLE: auto DB::StorageReplicatedMergeTree::queueTask()::(anonymous class)::operator()(DB::StorageReplicatedMergeTree::LogEntryPtr &) const: Code: 241, e.displayText() = DB::Exception: Memory limit (total) exceeded: would use 30.83 GiB (attempt to allocate chunk of 4245904 bytes), maximum: 30.83 GiB: (while reading column bid_id): (while reading from part /var/lib/clickhouse/cold/data/DATABASE/TABLE/202005_0_53094_41/ from mark 408392 with max_rows_to_read = 8192): While executing MergeTreeSequentialSource, Stack trace (when copying this message, always include the lines below):\r\n\r\n0. DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int) @ 0x7b46e2e in /usr/bin/clickhouse\r\n1. MemoryTracker::alloc(long) @ 0x7b3b016 in /usr/bin/clickhouse\r\n2. MemoryTracker::alloc(long) @ 0x7b3ac1d in /usr/bin/clickhouse\r\n3. MemoryTracker::alloc(long) @ 0x7b3ac1d in /usr/bin/clickhouse\r\n4. DB::DataTypeString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const @ 0xd5a8164 in /usr/bin/clickhouse\r\n5. DB::MergeTreeReaderWide::readData(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, DB::IDataType const&, DB::IColumn&, unsigned long, bool, unsigned long, bool) @ 0xe1c2c79 in /usr/bin/clickhouse\r\n6. DB::MergeTreeReaderWide::readRows(unsigned long, bool, unsigned long, std::__1::vector<COW<DB::IColumn>::immutable_ptr<DB::IColumn>, std::__1::allocator<COW<DB::IColumn>::immutable_ptr<DB::IColumn> > >&) @ 0xe1c1f90 in /usr/bin/clickhouse\r\n7. DB::MergeTreeSequentialSource::generate() @ 0xe1d36c9 in /usr/bin/clickhouse\r\n8. DB::ISource::work() @ 0xe36459a in /usr/bin/clickhouse\r\n9. DB::SourceWithProgress::work() @ 0xe4c927a in /usr/bin/clickhouse\r\n10. ? @ 0xe39d37c in /usr/bin/clickhouse\r\n11. DB::PipelineExecutor::executeStepImpl(unsigned long, unsigned long, std::__1::atomic<bool>*) @ 0xe39a4a7 in /usr/bin/clickhouse\r\n12. DB::PipelineExecutor::executeStep(std::__1::atomic<bool>*) @ 0xe39918c in /usr/bin/clickhouse\r\n13. DB::PullingPipelineExecutor::pull(DB::Chunk&) @ 0xe3a5ac8 in /usr/bin/clickhouse\r\n14. DB::PullingPipelineExecutor::pull(DB::Block&) @ 0xe3a5d10 in /usr/bin/clickhouse\r\n15. DB::PipelineExecutingBlockInputStream::readImpl() @ 0xe395444 in /usr/bin/clickhouse\r\n16. DB::IBlockInputStream::read() @ 0xd4f2625 in /usr/bin/clickhouse\r\n17. DB::TTLBlockInputStream::readImpl() @ 0xe11eedb in /usr/bin/clickhouse\r\n18. DB::IBlockInputStream::read() @ 0xd4f2625 in /usr/bin/clickhouse\r\n19. DB::MergeTreeDataMergerMutator::mergePartsToTemporaryPart(DB::FutureMergedMutatedPart const&, std::__1::shared_ptr<DB::StorageInMemoryMetadata const> const&, DB::BackgroundProcessListEntry<DB::MergeListElement, DB::MergeInfo>&, std::__1::shared_ptr<DB::RWLockImpl::LockHolderImpl>&, long, DB::Context const&, std::__1::unique_ptr<DB::IReservation, std::__1::default_delete<DB::IReservation> > const&, bool) @ 0xe0fc7b7 in /usr/bin/clickhouse\r\n20. DB::StorageReplicatedMergeTree::tryExecuteMerge(DB::ReplicatedMergeTreeLogEntry const&) @ 0xdef4c04 in /usr/bin/clickhouse\r\n21. DB::StorageReplicatedMergeTree::executeLogEntry(DB::ReplicatedMergeTreeLogEntry&) @ 0xdee6d6c in /usr/bin/clickhouse\r\n22. ? @ 0xdf5af7c in /usr/bin/clickhouse\r\n23. DB::ReplicatedMergeTreeQueue::processEntry(std::__1::function<std::__1::shared_ptr<zkutil::ZooKeeper> ()>, std::__1::shared_ptr<DB::ReplicatedMergeTreeLogEntry>&, std::__1::function<bool (std::__1::shared_ptr<DB::ReplicatedMergeTreeLogEntry>&)>) @ 0xe23f2b5 in /usr/bin/clickhouse\r\n24. DB::StorageReplicatedMergeTree::queueTask() @ 0xdf16e8b in /usr/bin/clickhouse\r\n25. DB::BackgroundProcessingPool::workLoopFunc() @ 0xe05e3b3 in /usr/bin/clickhouse\r\n26. ? @ 0xe05eef1 in /usr/bin/clickhouse\r\n27. ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) @ 0x7b7293d in /usr/bin/clickhouse\r\n28. ? @ 0x7b76463 in /usr/bin/clickhouse\r\n29. start_thread @ 0x76db in /lib/x86_64-linux-gnu/libpthread-2.27.so\r\n30. __clone @ 0x12171f in /lib/x86_64-linux-gnu/libc-2.27.so\r\n (version 20.11.4.13 (official build))\r\n```\r\n\r\n**Additional context**\r\n\r\nDeleted the TTL from the table, but the `TTL_DELETE` merge did not stop.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18242/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18242/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18239","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18239/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18239/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18239/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/18239","id":771208666,"node_id":"MDU6SXNzdWU3NzEyMDg2NjY=","number":18239,"title":"Inconsistent error message for filter function on a nullable column in arrayFirst and arrayFirstIndex","user":{"login":"gviamont","id":26227696,"node_id":"MDQ6VXNlcjI2MjI3Njk2","avatar_url":"https://avatars.githubusercontent.com/u/26227696?v=4","gravatar_id":"","url":"https://api.github.com/users/gviamont","html_url":"https://github.com/gviamont","followers_url":"https://api.github.com/users/gviamont/followers","following_url":"https://api.github.com/users/gviamont/following{/other_user}","gists_url":"https://api.github.com/users/gviamont/gists{/gist_id}","starred_url":"https://api.github.com/users/gviamont/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/gviamont/subscriptions","organizations_url":"https://api.github.com/users/gviamont/orgs","repos_url":"https://api.github.com/users/gviamont/repos","events_url":"https://api.github.com/users/gviamont/events{/privacy}","received_events_url":"https://api.github.com/users/gviamont/received_events","type":"User","site_admin":false},"labels":[{"id":845247686,"node_id":"MDU6TGFiZWw4NDUyNDc2ODY=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/usability","name":"usability","color":"ebf28c","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2020-12-18T22:36:32Z","updated_at":"2020-12-18T22:36:32Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"When running arrayFilter in the following example, a very helpful error message is generated which clues the user into the problem with the query which is that the filter function is operating on a nullable column.  arrayFirst and arrayFirstIndex which also make use of filter functions report the same error in a much more cryptic way.  **The suggestion I have is to modify the relevant exception messages of arrayFirst and arrayFirstIndex to match what arrayFilter provides.**  In a complex query, it may save users a lot of time debugging.\r\n\r\nConsider:\r\n\r\n```\r\nwith col as (select toNullable(arrayJoin([3])) val)\r\nselect \r\n        arrayFilter(\r\n            x -> greaterOrEquals(x, val),\r\n            [1, 2, 3, 4, 5]\r\n        )\r\nfrom col\r\n```\r\n\r\nwhich produces the exception message:\r\n\r\n```\r\nCode: 43. DB::Exception: Received from localhost:9000. DB::Exception: Expression for function arrayFilter must return UInt8, found Nullable(UInt8): While processing arrayFilter(x -> (x >= val), [1, 2, 3, 4, 5]).\r\n```\r\n\r\nThis is an excellent message and provides the key clue that val is a nullable column.\r\n\r\nHowever, consider:\r\n\r\n```\r\nwith col as (select toNullable(arrayJoin([3])) val)\r\nselect  \r\n        arrayFirstIndex(\r\n            x -> greaterOrEquals(x, val),\r\n            [1, 2, 3, 4, 5]\r\n        )   \r\nfrom col\r\n```\r\n\r\nwhich produces the exception message:\r\n\r\n```\r\nCode: 44. DB::Exception: Received from localhost:9000. DB::Exception: Unexpected type of filter column: while executing FUNCTION arrayFirstIndex(__lambda :: 2, [1, 2, 3, 4, 5] :: 1) -> arrayFirstIndex(lambda(tuple(x), greaterOrEquals(x, val)), [1, 2, 3, 4, 5]) UInt32 : 0'.\r\n```\r\n\r\nThis seems much harder to interpret, and most importantly it does not clue you into the issue which is that val is a nullable column.  arrayFirst produces a similar message.\r\n\r\nThanks in advance for considering this issue.  ClickHouse is an excellent DBMS!","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18239/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18239/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18237","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18237/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18237/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18237/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/18237","id":771191849,"node_id":"MDU6SXNzdWU3NzExOTE4NDk=","number":18237,"title":"MV inserted rows are taken into account as inserted/affected by insert. This confuses ETL systems.","user":{"login":"den-crane","id":19737682,"node_id":"MDQ6VXNlcjE5NzM3Njgy","avatar_url":"https://avatars.githubusercontent.com/u/19737682?v=4","gravatar_id":"","url":"https://api.github.com/users/den-crane","html_url":"https://github.com/den-crane","followers_url":"https://api.github.com/users/den-crane/followers","following_url":"https://api.github.com/users/den-crane/following{/other_user}","gists_url":"https://api.github.com/users/den-crane/gists{/gist_id}","starred_url":"https://api.github.com/users/den-crane/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/den-crane/subscriptions","organizations_url":"https://api.github.com/users/den-crane/orgs","repos_url":"https://api.github.com/users/den-crane/repos","events_url":"https://api.github.com/users/den-crane/events{/privacy}","received_events_url":"https://api.github.com/users/den-crane/received_events","type":"User","site_admin":false},"labels":[{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2020-12-18T21:56:27Z","updated_at":"2020-12-18T22:01:14Z","closed_at":null,"author_association":"COLLABORATOR","active_lock_reason":null,"body":"```sql\r\nmysql -h 127.0.0.1 -P9004 -u default\r\n\r\ncreate table t(a String) Engine=Memory;\r\n\r\ninsert into t values(1);\r\nQuery OK, 1 row affected (0.001 sec)    <-------------   1 row affected\r\n\r\ncreate materialized view mvt Engine=Memory as select * from t;\r\ninsert into t values(1);\r\nQuery OK, 2 rows affected (0.001 sec)   <-------------   2 row affected ????\r\n```\r\n\r\n```\r\necho 1|curl -v POST 'http://localhost:8123/?input_format_skip_unknown_fields=1&send_progress_in_http_headers=1&query=INSERT+INTO+t+format+TSV' --data-binary -\r\n\r\n< X-ClickHouse-Summary: { .... ,\"written_rows\":\"2\"   .....}\r\n\r\n```\r\n\r\nenterprise ETL systems and my (own) systems check how many rows were inserted to verify consistency, but current the behavior (number_rows_inserted_into_table+number_rows_inserted_into_MVs) makes this check impossible.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18237/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18237/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18203","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18203/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18203/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18203/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/18203","id":770240963,"node_id":"MDU6SXNzdWU3NzAyNDA5NjM=","number":18203,"title":"Collect stack traces from the place of thread creation and print along with other stack traces.","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":1365579236,"node_id":"MDU6TGFiZWwxMzY1NTc5MjM2","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/minor","name":"minor","color":"FFF8F8","default":false,"description":"Priority: minor"},{"id":1546440057,"node_id":"MDU6TGFiZWwxNTQ2NDQwMDU3","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/development","name":"development","color":"fc80df","default":false,"description":"Developement process & source code & implementation details"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2020-12-17T17:38:33Z","updated_at":"2021-09-12T03:37:42Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"**Use case**\r\nStack trace should looks like this:\r\n```\r\n0. /home/milovidov/work/ClickHouse/build/../contrib/libcxx/include/exception:129: Poco::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int) @ 0x10462adc in /home/milovidov/work/ClickHouse/build/programs/clickhouse\r\n1. /home/milovidov/work/ClickHouse/build/../src/Common/Exception.cpp:55: DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int) @ 0x85c5a8d in /home/milovidov/work/ClickHouse/build/programs/clickhouse\r\n2. DB::(anonymous namespace)::FunctionThrowIf::executeImpl(std::__1::vector<DB::ColumnWithTypeAndName, std::__1::allocator<DB::ColumnWithTypeAndName> > const&, std::__1::shared_ptr<DB::IDataType const> const&, unsigned long) const @ 0xc0c63a1 in /home/milovidov/work/ClickHouse/build/programs/clickhouse\r\n\r\n...\r\n\r\nThread TID was created from here:\r\n0. /home/milovidov/work/ClickHouse/build/../contrib/libcxx/include/exception:129: Poco::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int) @ 0x10462adc in /home/milovidov/work/ClickHouse/build/programs/clickhouse\r\n...\r\n\r\nThread TID was created from here:\r\n0. /home/milovidov/work/ClickHouse/build/../contrib/libcxx/include/exception:129: Poco::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int) @ 0x10462adc in /home/milovidov/work/ClickHouse/build/programs/clickhouse\r\n...\r\n```\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18203/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18203/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18196","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18196/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18196/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18196/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/18196","id":769962542,"node_id":"MDU6SXNzdWU3Njk5NjI1NDI=","number":18196,"title":"suggest auto convert in LIKE expr","user":{"login":"l1t1","id":23301704,"node_id":"MDQ6VXNlcjIzMzAxNzA0","avatar_url":"https://avatars.githubusercontent.com/u/23301704?v=4","gravatar_id":"","url":"https://api.github.com/users/l1t1","html_url":"https://github.com/l1t1","followers_url":"https://api.github.com/users/l1t1/followers","following_url":"https://api.github.com/users/l1t1/following{/other_user}","gists_url":"https://api.github.com/users/l1t1/gists{/gist_id}","starred_url":"https://api.github.com/users/l1t1/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/l1t1/subscriptions","organizations_url":"https://api.github.com/users/l1t1/orgs","repos_url":"https://api.github.com/users/l1t1/repos","events_url":"https://api.github.com/users/l1t1/events{/privacy}","received_events_url":"https://api.github.com/users/l1t1/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":628291301,"node_id":"MDU6TGFiZWw2MjgyOTEzMDE=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/sql-compatibility","name":"sql-compatibility","color":"006b75","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2020-12-17T12:25:51Z","updated_at":"2020-12-17T20:05:45Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"auto onvert in IN expr but not in LIKE expr now. \r\n```\r\nLAPTOP-TJ9I4Q1C.localdomain :) with t as(select 1 a union all select 10)select * from t where a in('1','2');\r\n\r\n\r\n\r\nWITH t AS\r\n\r\n    (\r\n\r\n        SELECT 1 AS a\r\n\r\n        UNION ALL\r\n\r\n        SELECT 10\r\n\r\n    )\r\n\r\nSELECT *\r\n\r\nFROM t\r\n\r\nWHERE a IN ('1', '2')\r\n\r\n\r\n\r\nQuery id: 1907e596-5af8-4d85-8a8e-954a964ed0af\r\n\r\n\r\n\r\n┌─a─┐\r\n\r\n│ 1 │\r\n\r\n└───┘\r\n\r\n\r\n\r\n1 rows in set. Elapsed: 0.003 sec.\r\n\r\n\r\n\r\nLAPTOP-TJ9I4Q1C.localdomain :) with t as(select 1 a union all select 10)select * from t where a like '1%';\r\n\r\n\r\n\r\nWITH t AS\r\n\r\n    (\r\n\r\n        SELECT 1 AS a\r\n\r\n        UNION ALL\r\n\r\n        SELECT 10\r\n\r\n    )\r\n\r\nSELECT *\r\n\r\nFROM t\r\n\r\nWHERE a LIKE '1%'\r\n\r\n\r\n\r\nQuery id: 5ea252f0-cc1c-4694-955e-36566794ab2f\r\n\r\n\r\n\r\n\r\n\r\nReceived exception from server (version 20.12.3):\r\n\r\nCode: 43. DB::Exception: Received from localhost:9000. DB::Exception: Illegal type UInt8 of argument of function like: While processing (1 AS a) LIKE '1%'.\r\n\r\n\r\n\r\n0 rows in set. Elapsed: 0.059 sec.\r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18196/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18196/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18149","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18149/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18149/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18149/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/18149","id":769074404,"node_id":"MDU6SXNzdWU3NjkwNzQ0MDQ=","number":18149,"title":"Add system table with information about zookeeper requests and responses.","user":{"login":"alesapin","id":3684697,"node_id":"MDQ6VXNlcjM2ODQ2OTc=","avatar_url":"https://avatars.githubusercontent.com/u/3684697?v=4","gravatar_id":"","url":"https://api.github.com/users/alesapin","html_url":"https://github.com/alesapin","followers_url":"https://api.github.com/users/alesapin/followers","following_url":"https://api.github.com/users/alesapin/following{/other_user}","gists_url":"https://api.github.com/users/alesapin/gists{/gist_id}","starred_url":"https://api.github.com/users/alesapin/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alesapin/subscriptions","organizations_url":"https://api.github.com/users/alesapin/orgs","repos_url":"https://api.github.com/users/alesapin/repos","events_url":"https://api.github.com/users/alesapin/events{/privacy}","received_events_url":"https://api.github.com/users/alesapin/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2020-12-16T16:33:32Z","updated_at":"2020-12-16T16:37:53Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"Add a table for tracking all interactions with ZooKeeper server from ClickHouse zookeeper client.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18149/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18149/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18134","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18134/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18134/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18134/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/18134","id":768614776,"node_id":"MDU6SXNzdWU3Njg2MTQ3NzY=","number":18134,"title":"Unexpected groupArrayMoving* behaviour with unevenly spaced time series","user":{"login":"tsybinAndrey","id":40664434,"node_id":"MDQ6VXNlcjQwNjY0NDM0","avatar_url":"https://avatars.githubusercontent.com/u/40664434?v=4","gravatar_id":"","url":"https://api.github.com/users/tsybinAndrey","html_url":"https://github.com/tsybinAndrey","followers_url":"https://api.github.com/users/tsybinAndrey/followers","following_url":"https://api.github.com/users/tsybinAndrey/following{/other_user}","gists_url":"https://api.github.com/users/tsybinAndrey/gists{/gist_id}","starred_url":"https://api.github.com/users/tsybinAndrey/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tsybinAndrey/subscriptions","organizations_url":"https://api.github.com/users/tsybinAndrey/orgs","repos_url":"https://api.github.com/users/tsybinAndrey/repos","events_url":"https://api.github.com/users/tsybinAndrey/events{/privacy}","received_events_url":"https://api.github.com/users/tsybinAndrey/received_events","type":"User","site_admin":false},"labels":[{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2020-12-16T09:12:35Z","updated_at":"2020-12-16T16:11:24Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Relates to issue: ClickHouse/ClickHouse#8747\r\n\r\nThe problem here is that, NULL values are skipped in `groupArrayMovingAvg` function and make it not possible to use due to resulting in unequal array length in `ARRAY JOIN`\r\n\r\nWe work with unevenly spaced time series and count moving average using `groupArrayMovingAvg`. By the way it is very common when you’ve got spaces in your data for some reason. For example, when you failed getting it from the source or it is spaced by it nature.\r\n\r\nFor that reason it is important to fill spaces in time series with NULL values to make normal time series, make it possible to use `groupArrayMovingAvg` and make it statistically correct. It worth menthion, that time series analysis based on count of dimensions(lines) won't be statistically correct for unevenly spaced time series. Instead time series analysis based on time interval will be correct.\r\n\r\nFor example, we can use `WITH FILL` for that. But this doesn't work for our case, because we need to fill not only value field, but also use algorithm to fill values in other columns.\r\n\r\nThe huge problem is when time window contains only NULL values. `groupArrayMoving*` do not insert element in array, which not allow us to make something with the data, because we do not know what specific index contains.\r\nSuggestion: May be it make sense to add setting for `groupArrayMoving*` to not skip NULL values or change default behavior of this function for Nullable columns. Then user can decide what to do with this NULL values skip it or no.\r\n\r\nExample for `groupArrayMovingAvg` with null values:\r\n```sql\r\nCREATE TABLE IF NOT EXISTS metrics (\r\n  event_date Date MATERIALIZED toDate(event_time),\r\n  event_time DateTime,\r\n  value Nullable(Float64)\r\n)\r\nENGINE = MergeTree()\r\nPARTITION BY toYYYYMM(event_date)\r\nORDER BY (event_date, metric);\r\n```\r\n\r\nData in table, imagine that data already filled with NULL and evenly spaced:\r\n```\r\n┌──────────event_time─┬─value─┐\r\n│ 2020-10-01 00:00:00 │  ᴺᵁᴸᴸ │\r\n│ 2020-10-02 00:00:00 │  ᴺᵁᴸᴸ │\r\n│ 2020-10-03 00:00:00 │    66 │\r\n│ 2020-10-04 00:00:00 │  ᴺᵁᴸᴸ │\r\n│ 2020-10-05 00:00:00 │  ᴺᵁᴸᴸ │\r\n│ 2020-10-06 00:00:00 │  ᴺᵁᴸᴸ │\r\n│ 2020-10-07 00:00:00 │   498 │\r\n│ 2020-10-08 00:00:00 │   100 │\r\n└─────────────────────┴───────┘\r\n```\r\n\r\nExample of query:\r\n```sql\r\nSELECT \r\n  time,\r\n  metric\r\nFROM (\r\n    SELECT\r\n        groupArray(event_time) as time_arr,\r\n        groupArrayMovingAvg(3)(value) as metric_arr\r\n     FROM (\r\n        SELECT \r\n            event_time,\r\n            value\r\n        FROM bb.processes\r\n        ORDER BY event_time\r\n    )\r\n)\r\nARRAY JOIN\r\n\ttime_arr as time,\r\n\tmetric_arr as metric\r\n```\r\n\r\n\r\nIf we make SELECT request above we will see that we have unequal array sizes for `time_arr` and `metric_arr`.\r\nThis results in error when we try to use ARRAY JOIN: `Sizes of ARRAY-JOIN-ed arrays do not match.`\r\n\r\nExpected query result:\r\n```\r\n┌──────────event_time─┬─value─┐\r\n│ 2020-10-01 00:00:00 │  ᴺᵁᴸᴸ │\r\n│ 2020-10-02 00:00:00 │  ᴺᵁᴸᴸ │\r\n│ 2020-10-03 00:00:00 │    66 │\r\n│ 2020-10-04 00:00:00 │    66 │\r\n│ 2020-10-05 00:00:00 │    66 │\r\n│ 2020-10-06 00:00:00 │  ᴺᵁᴸᴸ │\r\n│ 2020-10-07 00:00:00 │   498 │\r\n│ 2020-10-08 00:00:00 │   299 │\r\n└─────────────────────┴───────┘\r\n```\r\n\r\nExample of another problem for WITH FILL and multiple field to fill:\r\n\r\nCurrent table\r\n```\r\n┌──────────event_time─┬─metric────┬─value─┐\r\n│ 2020-10-01 00:00:00 │ metric1   │  10   │\r\n│ 2020-10-01 00:00:00 │ metric2   │  20   │\r\n│ 2020-10-03 00:00:00 │ metric1   │  1    │\r\n│ 2020-10-03 00:00:00 │ metric2   │  3    │\r\n└─────────────────────┴───────────┴───────┘\r\n```\r\nDesired query result after with FILL\r\n```\r\n┌──────────event_time─┬─metric────┬─value─┐\r\n│ 2020-10-01 00:00:00 │ metric1   │  10   │\r\n│ 2020-10-01 00:00:00 │ metric2   │  20   │\r\n│ 2020-10-02 00:00:00 │ metric1   │ null  │\r\n│ 2020-10-02 00:00:00 │ metric2   │ null  │\r\n│ 2020-10-03 00:00:00 │ metric1   │  1    │\r\n│ 2020-10-03 00:00:00 │ metric2   │  3    │\r\n└─────────────────────┴───────────┴───────┘\r\n```\r\n\r\n\r\nHere is simplified query we use to avoid both problem (`groupArrayMovingAvg` null-only windows skipping and `WITH FILL`), but it looks very clumsy:\r\n```sql\r\n    SELECT\r\n\tmetric,\r\n        event_date,\r\n\t/*\r\n         * Reproduces correct logic with preserving null windows \r\n\t */\r\n        arrayMap(\r\n            pair -> pair.2,\r\n            arrayFilter(pair -> event_date - pair.1 BETWEEN 0 AND ($window_size_days - 1), pairs)\r\n        ) AS values_in_window,\r\n        arraySum(values_in_window) / length(values_in_window) AS MA\r\n    FROM (\r\n        SELECT\r\n\t   metric,\r\n\t   /*\r\n            * Resolves WITH FILL problem - allows to make FILL for every `metric` group\r\n            */\r\n            arrayMap(\r\n                n -> toDate(n),\r\n                range(CAST(toDate($from) AS UInt32), CAST(toDate($to) AS UInt32) + 1)\r\n            ) AS event_dates,\r\n            groupArray((event_date, value)) AS pairs\r\n        FROM (\r\n            SELECT *\r\n            FROM metrics FINAL\r\n            WHERE event_date BETWEEN toDate($from) - INTERVAL $window_size_days DAY AND toDate($to)\r\n            ORDER BY event_date\r\n        )\r\n\tGROUP BY metric\r\n    )\r\n    ARRAY JOIN\r\n        event_dates AS event_date\r\n    WHERE event_date >= toDate($from)\r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18134/reactions","total_count":2,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":1},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18134/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18133","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18133/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18133/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18133/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/18133","id":768598920,"node_id":"MDU6SXNzdWU3Njg1OTg5MjA=","number":18133,"title":"untuple expand fields can not be accessed again","user":{"login":"melin","id":1145830,"node_id":"MDQ6VXNlcjExNDU4MzA=","avatar_url":"https://avatars.githubusercontent.com/u/1145830?v=4","gravatar_id":"","url":"https://api.github.com/users/melin","html_url":"https://github.com/melin","followers_url":"https://api.github.com/users/melin/followers","following_url":"https://api.github.com/users/melin/following{/other_user}","gists_url":"https://api.github.com/users/melin/gists{/gist_id}","starred_url":"https://api.github.com/users/melin/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/melin/subscriptions","organizations_url":"https://api.github.com/users/melin/orgs","repos_url":"https://api.github.com/users/melin/repos","events_url":"https://api.github.com/users/melin/events{/privacy}","received_events_url":"https://api.github.com/users/melin/received_events","type":"User","site_admin":false},"labels":[{"id":1397894054,"node_id":"MDU6TGFiZWwxMzk3ODk0MDU0","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unfinished%20code","name":"unfinished code","color":"ff8800","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":4,"created_at":"2020-12-16T08:54:16Z","updated_at":"2021-09-24T13:36:15Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"untuple expand fields can not be accessed again\r\n\r\n```sql\r\nselect ACTIVITY_RAW, parseDateTime64BestEffort(toString(S_D_EVENTOCCURTIME)) from (\r\n  SELECT JSONExtractRaw(activity_json, 'activity') as ACTIVITY_RAW,\r\n    untuple(JSONExtract(ACTIVITY_RAW, 'Tuple(S_S_PARTNERCODE String, S_S_EVENTTYPE String, S_S_EVENTID String, \r\n    S_E_INVOKETYPE String, S_D_EVENTOCCURTIME Int64')) activity\r\n  FROM activity_result\r\n);\r\n```\r\n![image](https://user-images.githubusercontent.com/1145830/102325747-7c7f8480-3fbe-11eb-999d-03a04d0367cd.png)\r\n\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18133/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18133/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18119","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18119/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18119/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18119/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/18119","id":768288490,"node_id":"MDU6SXNzdWU3NjgyODg0OTA=","number":18119,"title":"20.11+ Missing columns when filtering on Nested in a join with subquery and enable_optimize_predicate_expression","user":{"login":"SaltTan","id":20357526,"node_id":"MDQ6VXNlcjIwMzU3NTI2","avatar_url":"https://avatars.githubusercontent.com/u/20357526?v=4","gravatar_id":"","url":"https://api.github.com/users/SaltTan","html_url":"https://github.com/SaltTan","followers_url":"https://api.github.com/users/SaltTan/followers","following_url":"https://api.github.com/users/SaltTan/following{/other_user}","gists_url":"https://api.github.com/users/SaltTan/gists{/gist_id}","starred_url":"https://api.github.com/users/SaltTan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/SaltTan/subscriptions","organizations_url":"https://api.github.com/users/SaltTan/orgs","repos_url":"https://api.github.com/users/SaltTan/repos","events_url":"https://api.github.com/users/SaltTan/events{/privacy}","received_events_url":"https://api.github.com/users/SaltTan/received_events","type":"User","site_admin":false},"labels":[{"id":386401505,"node_id":"MDU6TGFiZWwzODY0MDE1MDU=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/bug","name":"bug","color":"ee0701","default":true,"description":"Confirmed user-visible misbehaviour in official release"},{"id":2510117577,"node_id":"MDU6TGFiZWwyNTEwMTE3NTc3","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/v20.11-affected","name":"v20.11-affected","color":"c2bfff","default":false,"description":""}],"state":"open","locked":false,"assignee":{"login":"CurtizJ","id":20361854,"node_id":"MDQ6VXNlcjIwMzYxODU0","avatar_url":"https://avatars.githubusercontent.com/u/20361854?v=4","gravatar_id":"","url":"https://api.github.com/users/CurtizJ","html_url":"https://github.com/CurtizJ","followers_url":"https://api.github.com/users/CurtizJ/followers","following_url":"https://api.github.com/users/CurtizJ/following{/other_user}","gists_url":"https://api.github.com/users/CurtizJ/gists{/gist_id}","starred_url":"https://api.github.com/users/CurtizJ/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/CurtizJ/subscriptions","organizations_url":"https://api.github.com/users/CurtizJ/orgs","repos_url":"https://api.github.com/users/CurtizJ/repos","events_url":"https://api.github.com/users/CurtizJ/events{/privacy}","received_events_url":"https://api.github.com/users/CurtizJ/received_events","type":"User","site_admin":false},"assignees":[{"login":"CurtizJ","id":20361854,"node_id":"MDQ6VXNlcjIwMzYxODU0","avatar_url":"https://avatars.githubusercontent.com/u/20361854?v=4","gravatar_id":"","url":"https://api.github.com/users/CurtizJ","html_url":"https://github.com/CurtizJ","followers_url":"https://api.github.com/users/CurtizJ/followers","following_url":"https://api.github.com/users/CurtizJ/following{/other_user}","gists_url":"https://api.github.com/users/CurtizJ/gists{/gist_id}","starred_url":"https://api.github.com/users/CurtizJ/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/CurtizJ/subscriptions","organizations_url":"https://api.github.com/users/CurtizJ/orgs","repos_url":"https://api.github.com/users/CurtizJ/repos","events_url":"https://api.github.com/users/CurtizJ/events{/privacy}","received_events_url":"https://api.github.com/users/CurtizJ/received_events","type":"User","site_admin":false}],"milestone":null,"comments":1,"created_at":"2020-12-15T23:14:16Z","updated_at":"2021-04-08T08:46:17Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"The issue does not exist in 20.10.\r\n```\r\nSELECT count()\r\nFROM system.parts AS p\r\nINNER JOIN\r\n(\r\n    SELECT name\r\n    FROM system.tables\r\n) AS t ON p.table = t.name\r\nWHERE (p.move_ttl_info.expression[1]) = ''\r\n\r\nReceived exception from server (version 20.12.3):\r\nCode: 47. DB::Exception: Received from localhost:9000. DB::Exception: Missing columns: 'move_ttl_info.expression' while processing query: 'SELECT name FROM system.tables WHERE (move_ttl_info.expression[1]) = ''', required columns: 'name' 'move_ttl_info.expression', source columns: 'total_bytes' 'sampling_key' 'primary_key' 'create_table_query' 'dependencies_table' 'storage_policy' 'is_temporary' 'dependencies_database' 'data_paths' 'name' 'metadata_modification_time' 'engine' 'uuid' 'lifetime_bytes' 'partition_key' 'engine_full' 'metadata_path' 'lifetime_rows' 'total_rows' 'sorting_key' 'database'.\r\n\r\n-- Disable enable_optimize_predicate_expression helps\r\n\r\nSELECT count()\r\nFROM system.parts AS p\r\nINNER JOIN\r\n(\r\n    SELECT name\r\n    FROM system.tables\r\n) AS t ON p.table = t.name\r\nWHERE (p.move_ttl_info.expression[1]) = ''\r\nSETTINGS enable_optimize_predicate_expression = 0\r\n\r\n┌─count()─┐\r\n│     169 │\r\n└─────────┘\r\n\r\n-- Backticks help\r\n\r\nSELECT count()\r\nFROM system.parts AS p\r\nINNER JOIN\r\n(\r\n    SELECT name\r\n    FROM system.tables\r\n) AS t ON p.table = t.name\r\nWHERE (p.`move_ttl_info.expression`[1]) = ''\r\n\r\n┌─count()─┐\r\n│     175 │\r\n└─────────┘\r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18119/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18119/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18117","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18117/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18117/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18117/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/18117","id":768231449,"node_id":"MDU6SXNzdWU3NjgyMzE0NDk=","number":18117,"title":"intel qat compression hardware acceleration support ?","user":{"login":"mcarbonneaux","id":8479023,"node_id":"MDQ6VXNlcjg0NzkwMjM=","avatar_url":"https://avatars.githubusercontent.com/u/8479023?v=4","gravatar_id":"","url":"https://api.github.com/users/mcarbonneaux","html_url":"https://github.com/mcarbonneaux","followers_url":"https://api.github.com/users/mcarbonneaux/followers","following_url":"https://api.github.com/users/mcarbonneaux/following{/other_user}","gists_url":"https://api.github.com/users/mcarbonneaux/gists{/gist_id}","starred_url":"https://api.github.com/users/mcarbonneaux/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mcarbonneaux/subscriptions","organizations_url":"https://api.github.com/users/mcarbonneaux/orgs","repos_url":"https://api.github.com/users/mcarbonneaux/repos","events_url":"https://api.github.com/users/mcarbonneaux/events{/privacy}","received_events_url":"https://api.github.com/users/mcarbonneaux/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":756395244,"node_id":"MDU6TGFiZWw3NTYzOTUyNDQ=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/performance","name":"performance","color":"c2e0c6","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2020-12-15T21:46:57Z","updated_at":"2020-12-17T18:25:20Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"While be possible to add support Intel QAT compression acceleration ?\r\nBecause they are integrate in new intel scalable cpu ! \r\n\r\nseem to 30% boost on hadoop :\r\nhttps://www.intel.com/content/www/us/en/architecture-and-technology/faster-hadoop-run-times-quickassist-technology.html","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18117/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18117/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18110","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18110/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18110/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18110/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/18110","id":767766125,"node_id":"MDU6SXNzdWU3Njc3NjYxMjU=","number":18110,"title":"Some system tables show too much info to a user without privileges.","user":{"login":"MyroTk","id":44327070,"node_id":"MDQ6VXNlcjQ0MzI3MDcw","avatar_url":"https://avatars.githubusercontent.com/u/44327070?v=4","gravatar_id":"","url":"https://api.github.com/users/MyroTk","html_url":"https://github.com/MyroTk","followers_url":"https://api.github.com/users/MyroTk/followers","following_url":"https://api.github.com/users/MyroTk/following{/other_user}","gists_url":"https://api.github.com/users/MyroTk/gists{/gist_id}","starred_url":"https://api.github.com/users/MyroTk/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/MyroTk/subscriptions","organizations_url":"https://api.github.com/users/MyroTk/orgs","repos_url":"https://api.github.com/users/MyroTk/repos","events_url":"https://api.github.com/users/MyroTk/events{/privacy}","received_events_url":"https://api.github.com/users/MyroTk/received_events","type":"User","site_admin":false},"labels":[{"id":386401507,"node_id":"MDU6TGFiZWwzODY0MDE1MDc=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/enhancement","name":"enhancement","color":"84b6eb","default":true,"description":null},{"id":2011606513,"node_id":"MDU6TGFiZWwyMDExNjA2NTEz","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-rbac","name":"comp-rbac","color":"b5bcff","default":false,"description":"Access control related"}],"state":"open","locked":false,"assignee":{"login":"vitlibar","id":45142681,"node_id":"MDQ6VXNlcjQ1MTQyNjgx","avatar_url":"https://avatars.githubusercontent.com/u/45142681?v=4","gravatar_id":"","url":"https://api.github.com/users/vitlibar","html_url":"https://github.com/vitlibar","followers_url":"https://api.github.com/users/vitlibar/followers","following_url":"https://api.github.com/users/vitlibar/following{/other_user}","gists_url":"https://api.github.com/users/vitlibar/gists{/gist_id}","starred_url":"https://api.github.com/users/vitlibar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vitlibar/subscriptions","organizations_url":"https://api.github.com/users/vitlibar/orgs","repos_url":"https://api.github.com/users/vitlibar/repos","events_url":"https://api.github.com/users/vitlibar/events{/privacy}","received_events_url":"https://api.github.com/users/vitlibar/received_events","type":"User","site_admin":false},"assignees":[{"login":"vitlibar","id":45142681,"node_id":"MDQ6VXNlcjQ1MTQyNjgx","avatar_url":"https://avatars.githubusercontent.com/u/45142681?v=4","gravatar_id":"","url":"https://api.github.com/users/vitlibar","html_url":"https://github.com/vitlibar","followers_url":"https://api.github.com/users/vitlibar/followers","following_url":"https://api.github.com/users/vitlibar/following{/other_user}","gists_url":"https://api.github.com/users/vitlibar/gists{/gist_id}","starred_url":"https://api.github.com/users/vitlibar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vitlibar/subscriptions","organizations_url":"https://api.github.com/users/vitlibar/orgs","repos_url":"https://api.github.com/users/vitlibar/repos","events_url":"https://api.github.com/users/vitlibar/events{/privacy}","received_events_url":"https://api.github.com/users/vitlibar/received_events","type":"User","site_admin":false}],"milestone":null,"comments":0,"created_at":"2020-12-15T16:19:02Z","updated_at":"2021-01-18T23:09:50Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Describe the bug**\r\nThe following `system` tables are accessible to a user with no privileges and show sensitive information such as queries, table names, user info, etc. :\r\n * processes \r\n * query_log \r\n * query_thread_log \r\n * clusters \r\n * events \r\n * graphite_retentions \r\n * stack_trace \r\n * trace_log\r\n * user_directories \r\n * zookeeper \r\n * macros\r\n\r\n**How to reproduce**\r\n* ClickHouse server version 20.13.1 revision 54442","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18110/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18110/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18099","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18099/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18099/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18099/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/18099","id":767621231,"node_id":"MDU6SXNzdWU3Njc2MjEyMzE=","number":18099,"title":"Extraction float64 value from JSON fails","user":{"login":"cetver","id":1411914,"node_id":"MDQ6VXNlcjE0MTE5MTQ=","avatar_url":"https://avatars.githubusercontent.com/u/1411914?v=4","gravatar_id":"","url":"https://api.github.com/users/cetver","html_url":"https://github.com/cetver","followers_url":"https://api.github.com/users/cetver/followers","following_url":"https://api.github.com/users/cetver/following{/other_user}","gists_url":"https://api.github.com/users/cetver/gists{/gist_id}","starred_url":"https://api.github.com/users/cetver/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/cetver/subscriptions","organizations_url":"https://api.github.com/users/cetver/orgs","repos_url":"https://api.github.com/users/cetver/repos","events_url":"https://api.github.com/users/cetver/events{/privacy}","received_events_url":"https://api.github.com/users/cetver/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2020-12-15T13:55:56Z","updated_at":"2020-12-15T19:19:05Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"**Describe the bug**\r\nThe `JSONExtract` functions can't extract the float64 value\r\n\r\n**How to reproduce**\r\n```sql\r\nSELECT\r\n    JSONExtract(json, 'value', 'String') str,\r\n    JSONExtract(json, 'value', 'Float64') int,\r\n    JSONExtractRaw(json) raw,\r\n    type\r\nFROM (\r\n    SELECT '{\"value\":99999999999999999999}' json, 'float' type\r\n    UNION ALL\r\n    SELECT '{\"value\":\"99999999999999999999\"}' json, 'string' type\r\n);\r\n-- Float64\r\nSELECT toTypeName(99999999999999999999);\r\n```\r\n* Which ClickHouse server version to use\r\n20.11.4.13\r\n\r\n**Expected behavior**\r\n\r\nACTUAL\r\n```\r\n+----------------------+-----+----------------------------------+--------+\r\n| str                  | int | raw                              | type   |\r\n+----------------------+-----+----------------------------------+--------+\r\n|                      | 0   |                                  | float  |\r\n+----------------------+-----+----------------------------------+--------+\r\n| 99999999999999999999 | 0   | {\"value\":\"99999999999999999999\"} | string |\r\n+----------------------+-----+----------------------------------+--------+\r\n```\r\n\r\nEXPECTED\r\n\r\n```\r\n+----------------------+----------------------+----------------------------------+--------+\r\n| str                  | int                  | raw                              | type   |\r\n+----------------------+----------------------+----------------------------------+--------+\r\n| 99999999999999999999 | 99999999999999999999 | {\"value\":99999999999999999999}   | float  |\r\n+----------------------+----------------------+----------------------------------+--------+\r\n| 99999999999999999999 | 0                    | {\"value\":\"99999999999999999999\"} | string |\r\n+----------------------+----------------------+----------------------------------+--------+\r\n```\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18099/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18099/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18016","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18016/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18016/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18016/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/18016","id":763003260,"node_id":"MDU6SXNzdWU3NjMwMDMyNjA=","number":18016,"title":"Compact  parts+old syntax + mutation","user":{"login":"den-crane","id":19737682,"node_id":"MDQ6VXNlcjE5NzM3Njgy","avatar_url":"https://avatars.githubusercontent.com/u/19737682?v=4","gravatar_id":"","url":"https://api.github.com/users/den-crane","html_url":"https://github.com/den-crane","followers_url":"https://api.github.com/users/den-crane/followers","following_url":"https://api.github.com/users/den-crane/following{/other_user}","gists_url":"https://api.github.com/users/den-crane/gists{/gist_id}","starred_url":"https://api.github.com/users/den-crane/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/den-crane/subscriptions","organizations_url":"https://api.github.com/users/den-crane/orgs","repos_url":"https://api.github.com/users/den-crane/repos","events_url":"https://api.github.com/users/den-crane/events{/privacy}","received_events_url":"https://api.github.com/users/den-crane/received_events","type":"User","site_admin":false},"labels":[{"id":386401505,"node_id":"MDU6TGFiZWwzODY0MDE1MDU=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/bug","name":"bug","color":"ee0701","default":true,"description":"Confirmed user-visible misbehaviour in official release"},{"id":1365579236,"node_id":"MDU6TGFiZWwxMzY1NTc5MjM2","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/minor","name":"minor","color":"FFF8F8","default":false,"description":"Priority: minor"}],"state":"open","locked":false,"assignee":{"login":"den-crane","id":19737682,"node_id":"MDQ6VXNlcjE5NzM3Njgy","avatar_url":"https://avatars.githubusercontent.com/u/19737682?v=4","gravatar_id":"","url":"https://api.github.com/users/den-crane","html_url":"https://github.com/den-crane","followers_url":"https://api.github.com/users/den-crane/followers","following_url":"https://api.github.com/users/den-crane/following{/other_user}","gists_url":"https://api.github.com/users/den-crane/gists{/gist_id}","starred_url":"https://api.github.com/users/den-crane/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/den-crane/subscriptions","organizations_url":"https://api.github.com/users/den-crane/orgs","repos_url":"https://api.github.com/users/den-crane/repos","events_url":"https://api.github.com/users/den-crane/events{/privacy}","received_events_url":"https://api.github.com/users/den-crane/received_events","type":"User","site_admin":false},"assignees":[{"login":"den-crane","id":19737682,"node_id":"MDQ6VXNlcjE5NzM3Njgy","avatar_url":"https://avatars.githubusercontent.com/u/19737682?v=4","gravatar_id":"","url":"https://api.github.com/users/den-crane","html_url":"https://github.com/den-crane","followers_url":"https://api.github.com/users/den-crane/followers","following_url":"https://api.github.com/users/den-crane/following{/other_user}","gists_url":"https://api.github.com/users/den-crane/gists{/gist_id}","starred_url":"https://api.github.com/users/den-crane/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/den-crane/subscriptions","organizations_url":"https://api.github.com/users/den-crane/orgs","repos_url":"https://api.github.com/users/den-crane/repos","events_url":"https://api.github.com/users/den-crane/events{/privacy}","received_events_url":"https://api.github.com/users/den-crane/received_events","type":"User","site_admin":false}],"milestone":null,"comments":0,"created_at":"2020-12-11T22:39:04Z","updated_at":"2021-04-17T00:25:29Z","closed_at":null,"author_association":"COLLABORATOR","active_lock_reason":null,"body":"https://t.me/clickhouse_ru/195704\r\n\r\nПривет! Удаляли колонку, на одной из реплик вылезла ошибка:\r\nCode: 47, e.displayText() = DB::Exception: Missing columns: 'some_column' while processing query ...\r\nПеред дропом этой колонки в describe table не было. На двух остальных репликах мутации прошли отлично. На проблемной мутация тоже прошла(is_done 1), но в replication_queue висит mutate_part.\r\nСмотрел метадаты и колонки в зукипере, всё совпадает, там нет ни дропнутой колонки, ни той, которую он потерял на проблемной реплике.\r\n\r\n>вылезла ошибка на что? select ?\r\n\r\nНа mutate_part в last_exception и latest_fail_reason в system.mutations.\r\nЯ посмотрел в parts_columns, там действительно есть эта колонка, которой нет в описании таблицы и зукипере. Можно ли как-то из парта удалить её?\r\n\r\n>ошибка какая в логе при мутации?\r\n\r\n2020.12.11 21:12:27.597542 [ 1623 ] {} <Error> default.rawlog_shard: auto DB::StorageReplicatedMergeTree::queueTask()::(anonymous class)::operator()(DB::StorageReplicatedMergeTree::LogEntryPtr &) const: Code: 47, e.displayText() = DB::Exception: Missing columns: 't_hash_id_placement_sub1' while processing query: 't_hash_id_placement_sub1, na_batch_landings_result, n_rtb2_bid, b_x_forward, id_bidder_request, j_denies, id_os, n_bidder_ecpm, d_event_date, b_no_cookie, n_batch_landings_required_count, id_input_shard, id_ad_unit, n_net, b_web_view, id_country, ida_action, t_useragent, t_conversion_currency_code, id_zone, n_lpc_state, id_user, \r\nhttps://t.me/clickhouse_ru/195723\r\n\r\n\r\nПо этому парту видно, что он какой-то особенный, потому что когда на соседних уровень мёржа уже 16, то этот так и висит на первом.\r\nПлюс если глянуть в system.parts_columns по этому парту, то как раз там указана эта проблемная колонка, которую он не может найти. Плюс осталась та колонка которую дропали.\r\n\r\n>как выглядит имя парта? _16 это не уровень мержа я думаю, это уровень мутации\r\n\r\n![image](https://user-images.githubusercontent.com/19737682/101961315-d8719400-3bdf-11eb-8418-dcb9d5827def.png)\r\n\r\nENGINE = ReplicatedMergeTree('/clickhouse/tables/{shard}/rawlog_shard', '{replica}', d_event_date, (id_publisher, id_zone, id_placement, id_ad_unit, id_advertiser, id_campaign, id_banner, id_landing), 8192)\r\n\r\nversion 20.10.3.30\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18016/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18016/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18006","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18006/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18006/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18006/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/18006","id":762349013,"node_id":"MDU6SXNzdWU3NjIzNDkwMTM=","number":18006,"title":"Select filtering results of group by K in table ordered by K takes huge amount of memory (instead of O(1))","user":{"login":"hrissan","id":754735,"node_id":"MDQ6VXNlcjc1NDczNQ==","avatar_url":"https://avatars.githubusercontent.com/u/754735?v=4","gravatar_id":"","url":"https://api.github.com/users/hrissan","html_url":"https://github.com/hrissan","followers_url":"https://api.github.com/users/hrissan/followers","following_url":"https://api.github.com/users/hrissan/following{/other_user}","gists_url":"https://api.github.com/users/hrissan/gists{/gist_id}","starred_url":"https://api.github.com/users/hrissan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/hrissan/subscriptions","organizations_url":"https://api.github.com/users/hrissan/orgs","repos_url":"https://api.github.com/users/hrissan/repos","events_url":"https://api.github.com/users/hrissan/events{/privacy}","received_events_url":"https://api.github.com/users/hrissan/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":756395244,"node_id":"MDU6TGFiZWw3NTYzOTUyNDQ=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/performance","name":"performance","color":"c2e0c6","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":8,"created_at":"2020-12-11T13:35:49Z","updated_at":"2021-01-26T19:45:26Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"Minimal working example\r\n\r\nCREATE TABLE example (k Int32, v Int32) ENGINE=MergeTree ORDER BY(k)\r\n\r\nLet's populated example table with 8GB of uncompressed data. \r\n\r\nCREATE TABLE example_generator (k Int32, v Int32) ENGINE = GenerateRandom(1, 5, 3)\r\nINSERT INTO example SELECT * FROM example_generator LIMIT 1000000000\r\n\r\nLet's select keys which have max value of 100.\r\n\r\nSELECT k, max(v) AS max_v FROM example GROUP BY k HAVING max_v == 100\r\nOR\r\nSELECT k, max_v FROM (SELECT k, max(v) AS max_v FROM example GROUP BY k) WHERE max_v == 100\r\n\r\nWe know there is an efficient plan of executing this query, as table parts are sorted by k, all v corresponding to the same k go together, we can create the merge sorting reader, which will iterate over k, aggregating max_v until k changes, then apply HAVING filter to max_v either dropping it or including in result, thus using just O(1) of memory (plus merge sorting reader).\r\n\r\nInstead, ClickHouse starts performing grouping into huge in-memory table, with intent to apply HAVING filter to this table later, unfortunately this plan results in quitting with OOM on step 1.\r\n\r\nWithout this optimization, it is impossible to use Merge* engine family (like AggregatedMergeTree) to perform many (most?) requests over aggregated data on any production-size table.\r\n\r\nHow hard is to make this optimization? Where in the source code should I start looking?\r\n\r\nI'm running version\r\n\r\nClickHouse client version 20.11.4.13 (official build).\r\nClickHouse server version 20.11.4.13 (official build).","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18006/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/18006/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/17959","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/17959/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/17959/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/17959/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/17959","id":761035195,"node_id":"MDU6SXNzdWU3NjEwMzUxOTU=","number":17959,"title":"Settings constraints - readonly all, but allow changing some of","user":{"login":"filimonov","id":1549571,"node_id":"MDQ6VXNlcjE1NDk1NzE=","avatar_url":"https://avatars.githubusercontent.com/u/1549571?v=4","gravatar_id":"","url":"https://api.github.com/users/filimonov","html_url":"https://github.com/filimonov","followers_url":"https://api.github.com/users/filimonov/followers","following_url":"https://api.github.com/users/filimonov/following{/other_user}","gists_url":"https://api.github.com/users/filimonov/gists{/gist_id}","starred_url":"https://api.github.com/users/filimonov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/filimonov/subscriptions","organizations_url":"https://api.github.com/users/filimonov/orgs","repos_url":"https://api.github.com/users/filimonov/repos","events_url":"https://api.github.com/users/filimonov/events{/privacy}","received_events_url":"https://api.github.com/users/filimonov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":1365579236,"node_id":"MDU6TGFiZWwxMzY1NTc5MjM2","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/minor","name":"minor","color":"FFF8F8","default":false,"description":"Priority: minor"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2020-12-10T08:46:07Z","updated_at":"2021-06-27T21:12:23Z","closed_at":null,"author_association":"COLLABORATOR","active_lock_reason":null,"body":"Now you need to list all settings which should be readonly.\r\n\r\nWe want to limit all, but allow changing some of them.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/17959/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/17959/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/17941","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/17941/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/17941/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/17941/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/17941","id":760563556,"node_id":"MDU6SXNzdWU3NjA1NjM1NTY=","number":17941,"title":"optimize_read_in_order with respect to PARTITION KEY","user":{"login":"UnamedRus","id":9449405,"node_id":"MDQ6VXNlcjk0NDk0MDU=","avatar_url":"https://avatars.githubusercontent.com/u/9449405?v=4","gravatar_id":"","url":"https://api.github.com/users/UnamedRus","html_url":"https://github.com/UnamedRus","followers_url":"https://api.github.com/users/UnamedRus/followers","following_url":"https://api.github.com/users/UnamedRus/following{/other_user}","gists_url":"https://api.github.com/users/UnamedRus/gists{/gist_id}","starred_url":"https://api.github.com/users/UnamedRus/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/UnamedRus/subscriptions","organizations_url":"https://api.github.com/users/UnamedRus/orgs","repos_url":"https://api.github.com/users/UnamedRus/repos","events_url":"https://api.github.com/users/UnamedRus/events{/privacy}","received_events_url":"https://api.github.com/users/UnamedRus/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":1401777979,"node_id":"MDU6TGFiZWwxNDAxNzc3OTc5","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-optimizers","name":"comp-optimizers","color":"b5bcff","default":false,"description":"Query optimizations"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2020-12-09T18:20:01Z","updated_at":"2020-12-10T13:58:52Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Use case**\r\nUsually we have partitioned our tables by month/day/etc, that means we do know that some partitions would have more recent data than others, and we can use that information for reading in order, even if we can't use table ORDER BY for it.\r\n\r\n```\r\n INSERT INTO table_test SELECT now() + toIntervalSecond(intDiv(number,10)) as timestamp, number %4 as key_a, rand() % 5 as key_b, rand() % 20 as value FROM numbers(100000000);\r\n CREATE TABLE default.table_test\r\n(\r\n    `timestamp` DateTime,\r\n    `key_a` UInt32,\r\n    `key_b` UInt32,\r\n    `value` UInt32\r\n)\r\nENGINE = MergeTree\r\nPARTITION BY toYYYYMM(timestamp)\r\nORDER BY (key_a, key_b, timestamp)\r\nSETTINGS index_granularity = 8192\r\n\r\nSELECT *\r\nFROM table_test\r\nORDER BY timestamp DESC\r\nLIMIT 10\r\n\r\nQuery id: 2ddce7e1-3a3a-464d-8efc-a1af4b15602d\r\n\r\n┌───────────timestamp─┬─key_a─┬─key_b─┬─value─┐\r\n│ 2021-04-04 14:50:02 │     2 │     2 │     2 │\r\n│ 2021-04-04 14:50:02 │     3 │     1 │    16 │\r\n│ 2021-04-04 14:50:02 │     3 │     2 │    17 │\r\n│ 2021-04-04 14:50:02 │     2 │     2 │    12 │\r\n│ 2021-04-04 14:50:02 │     3 │     4 │     4 │\r\n│ 2021-04-04 14:50:02 │     0 │     1 │     1 │\r\n│ 2021-04-04 14:50:02 │     0 │     3 │    18 │\r\n│ 2021-04-04 14:50:02 │     1 │     4 │     9 │\r\n│ 2021-04-04 14:50:02 │     1 │     3 │    13 │\r\n│ 2021-04-04 14:50:02 │     2 │     0 │    10 │\r\n└─────────────────────┴───────┴───────┴───────┘\r\n\r\n10 rows in set. Elapsed: 0.823 sec. Processed 100.00 million rows, 1.60 GB (121.52 million rows/s., 1.94 GB/s.)\r\n```\r\n\r\n**Describe the solution you'd like**\r\noptimize_read_in_order would try to read partitions in order (if they don't have intersections in min/max index).","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/17941/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/17941/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/17937","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/17937/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/17937/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/17937/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/17937","id":760492579,"node_id":"MDU6SXNzdWU3NjA0OTI1Nzk=","number":17937,"title":"filesystem* functions produces wrong result in case of distributed queries.","user":{"login":"UnamedRus","id":9449405,"node_id":"MDQ6VXNlcjk0NDk0MDU=","avatar_url":"https://avatars.githubusercontent.com/u/9449405?v=4","gravatar_id":"","url":"https://api.github.com/users/UnamedRus","html_url":"https://github.com/UnamedRus","followers_url":"https://api.github.com/users/UnamedRus/followers","following_url":"https://api.github.com/users/UnamedRus/following{/other_user}","gists_url":"https://api.github.com/users/UnamedRus/gists{/gist_id}","starred_url":"https://api.github.com/users/UnamedRus/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/UnamedRus/subscriptions","organizations_url":"https://api.github.com/users/UnamedRus/orgs","repos_url":"https://api.github.com/users/UnamedRus/repos","events_url":"https://api.github.com/users/UnamedRus/events{/privacy}","received_events_url":"https://api.github.com/users/UnamedRus/received_events","type":"User","site_admin":false},"labels":[{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2020-12-09T16:46:37Z","updated_at":"2020-12-10T21:01:55Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Describe the bug**\r\nfilesystem* functions in case of remote/distributed queries return results either from local eiter from remote server.\r\n\r\n**How to reproduce**\r\n```\r\nSELECT\r\n    hostName() AS host,\r\n    version() AS version,\r\n    now64() AS now,\r\n    formatReadableSize(filesystemFree()) AS free_space,\r\n    formatReadableSize(filesystemCapacity()) AS total_space,\r\n    round(100 * (1 - (filesystemFree() / filesystemCapacity())), 1) AS used_percentage\r\nFROM remote('host_1', system.one)\r\nORDER BY\r\n    hostName() ASC,\r\n    used_percentage ASC\r\n\r\n┌─host──────────────────────┬─version───┬─────────────────────now─┬─free_space─┬─total_space─┬─used_percentage─┐\r\n│ host_1                    │ 20.8.7.15 │ 2020-12-09 16:42:20.457 │ 97.01 GiB  │ 98.31 GiB   │             1.3 │\r\n└───────────────────────────┴───────────┴─────────────────────────┴────────────┴─────────────┴─────────────────┘\r\nexplain pipeline:\r\n┌─explain─────────────┐\r\n│ (Converting)        │\r\n│ Converting          │\r\n│   (ReadFromStorage) │\r\n└─────────────────────┘\r\n\r\nnext execution:\r\n\r\n┌─host──────────────────────┬─version───┬─────────────────────now─┬─free_space─┬─total_space─┬─used_percentage─┐\r\n│ host_1                    │ 20.8.7.15 │ 2020-12-09 16:42:19.918 │ 95.25 GiB  │ 98.31 GiB   │             3.1 │\r\n└───────────────────────────┴───────────┴─────────────────────────┴────────────┴─────────────┴─────────────────┘\r\nexplain pipeline\r\n┌─explain───────────┐\r\n│ (ReadFromStorage) │\r\n└───────────────────┘\r\n```\r\nhttps://github.com/ClickHouse/ClickHouse/blob/bac1def5f974564b221a43c5bbc21bf65906774b/src/Functions/hostName.cpp#L47\r\n\r\nhttps://github.com/ClickHouse/ClickHouse/blob/bac1def5f974564b221a43c5bbc21bf65906774b/src/Functions/filesystem.cpp\r\n\r\n\r\n**Additional context**\r\nIt would work correctly if we use materialize() on top of function.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/17937/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/17937/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/17936","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/17936/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/17936/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/17936/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/17936","id":760476784,"node_id":"MDU6SXNzdWU3NjA0NzY3ODQ=","number":17936,"title":"Pushdown WHERE clause with key columns from LIMIT BY","user":{"login":"UnamedRus","id":9449405,"node_id":"MDQ6VXNlcjk0NDk0MDU=","avatar_url":"https://avatars.githubusercontent.com/u/9449405?v=4","gravatar_id":"","url":"https://api.github.com/users/UnamedRus","html_url":"https://github.com/UnamedRus","followers_url":"https://api.github.com/users/UnamedRus/followers","following_url":"https://api.github.com/users/UnamedRus/following{/other_user}","gists_url":"https://api.github.com/users/UnamedRus/gists{/gist_id}","starred_url":"https://api.github.com/users/UnamedRus/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/UnamedRus/subscriptions","organizations_url":"https://api.github.com/users/UnamedRus/orgs","repos_url":"https://api.github.com/users/UnamedRus/repos","events_url":"https://api.github.com/users/UnamedRus/events{/privacy}","received_events_url":"https://api.github.com/users/UnamedRus/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2020-12-09T16:26:20Z","updated_at":"2020-12-09T16:26:20Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Use case**\r\nQuery with WHERE condition and subquery with LIMIT BY.\r\n\r\n**Describe the solution you'd like**\r\n\r\nsubquery:\r\n```\r\nEXPLAIN SYNTAX\r\nSELECT\r\n    key_a,\r\n    sum\r\nFROM\r\n(\r\n    SELECT\r\n        key_a,\r\n        value AS sum\r\n    FROM table_test\r\n    LIMIT 1 BY key_a\r\n)\r\nWHERE key_a = 3\r\n\r\n┌─explain──────────────┐\r\n│ SELECT               │\r\n│     key_a,           │\r\n│     sum              │\r\n│ FROM                 │\r\n│ (                    │\r\n│     SELECT           │\r\n│         key_a,       │\r\n│         value AS sum │\r\n│     FROM table_test  │\r\n│     LIMIT 1 BY key_a │\r\n│ )                    │\r\n│ WHERE key_a = 3      │\r\n└──────────────────────┘\r\n```\r\nview:\r\n```\r\nEXPLAIN SYNTAX\r\nSELECT *\r\nFROM view_test_2\r\nWHERE key_a = 3\r\n\r\nQuery id: 3557bc30-8b51-469a-b1dd-cae7279aa57c\r\n\r\n┌─explain─────────────────────┐\r\n│ SELECT                      │\r\n│     key_a,                  │\r\n│     sum                     │\r\n│ FROM                        │\r\n│ (                           │\r\n│     SELECT                  │\r\n│         key_a,              │\r\n│         value AS sum        │\r\n│     FROM default.table_test │\r\n│     LIMIT 1 BY key_a        │\r\n│ ) AS view_test_2            │\r\n│ WHERE key_a = 3             │\r\n└─────────────────────────────┘\r\n```\r\n\r\n**Describe alternatives you've considered**\r\nWrite that kind of optimizations by hand in case of subquery, but it is not possible to do that with VIEW.\r\n\r\n**Additional context**\r\nEXPLAIN SYNTAX a bit misleading about pushdown WHERE condition in VIEW, it actually push not to HAVING but further (as WHERE).\r\n\r\nsubquery:\r\n```\r\nEXPLAIN SYNTAX\r\nSELECT\r\n    key_a,\r\n    sum\r\nFROM\r\n(\r\n    SELECT\r\n        key_a,\r\n        value AS sum\r\n    FROM table_test\r\n    LIMIT 1 BY key_a\r\n)\r\nWHERE key_a = 3\r\n\r\n┌─explain───────────────────┐\r\n│ SELECT                    │\r\n│     key_a,                │\r\n│     sum                   │\r\n│ FROM                      │\r\n│ (                         │\r\n│     SELECT                │\r\n│         key_a,            │\r\n│         sum(value) AS sum │\r\n│     FROM table_test       │\r\n│     WHERE key_a = 3       │\r\n│     GROUP BY key_a        │\r\n│ )                         │\r\n│ WHERE key_a = 3           │\r\n└───────────────────────────┘\r\n```\r\nview:\r\n \r\n```\r\nEXPLAIN SYNTAX\r\nSELECT *\r\nFROM view_test\r\nWHERE key_a = 3\r\n\r\nQuery id: ec1ec566-a038-493d-b1b3-9640a84dc5ac\r\n\r\n┌─explain─────────────────────┐\r\n│ SELECT                      │\r\n│     key_a,                  │\r\n│     sum                     │\r\n│ FROM                        │\r\n│ (                           │\r\n│     SELECT                  │\r\n│         key_a,              │\r\n│         sum(value) AS sum   │\r\n│     FROM default.table_test │\r\n│     GROUP BY key_a          │\r\n│     HAVING key_a = 3        │\r\n│ ) AS view_test              │\r\n│ WHERE key_a = 3             │\r\n└─────────────────────────────┘\r\n```\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/17936/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/17936/timeline","performed_via_github_app":null}]

[{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23900","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23900/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23900/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23900/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/23900","id":876611305,"node_id":"MDU6SXNzdWU4NzY2MTEzMDU=","number":23900,"title":"Valid query fails on Clickhouse parser","user":{"login":"chickony","id":68716325,"node_id":"MDQ6VXNlcjY4NzE2MzI1","avatar_url":"https://avatars.githubusercontent.com/u/68716325?v=4","gravatar_id":"","url":"https://api.github.com/users/chickony","html_url":"https://github.com/chickony","followers_url":"https://api.github.com/users/chickony/followers","following_url":"https://api.github.com/users/chickony/following{/other_user}","gists_url":"https://api.github.com/users/chickony/gists{/gist_id}","starred_url":"https://api.github.com/users/chickony/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/chickony/subscriptions","organizations_url":"https://api.github.com/users/chickony/orgs","repos_url":"https://api.github.com/users/chickony/repos","events_url":"https://api.github.com/users/chickony/events{/privacy}","received_events_url":"https://api.github.com/users/chickony/received_events","type":"User","site_admin":false},"labels":[{"id":386401509,"node_id":"MDU6TGFiZWwzODY0MDE1MDk=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/invalid","name":"invalid","color":"e6e6e6","default":true,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-05-05T16:05:07Z","updated_at":"2021-05-19T05:27:05Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"You have to provide the following information whenever possible.\r\n\r\n**Describe the bug**\r\nThe following valid query fails on Clickhouse Playground.\r\n\r\n`SELECT '2013-07-15' as  EventDate         \r\nFROM `hits_100m_obfuscated` g\r\nWHERE g.EventDate = '2013-07-15'\r\nLIMIT 100;  `\r\n\r\n\r\n\r\n**Does it reproduce on recent release?**\r\nThe issue reproduces on recent release\r\n\r\n**How to reproduce**\r\n* Which ClickHouse server version to use - 20.8\r\n* Which interface to use, if matters - does not matter\r\n* Non-default settings, if any -irrelevant\r\n\r\n\r\n**Expected behavior**\r\nThe query should returns results, changing the alias name is a workaround\r\n\r\n**Error message and/or stacktrace**\r\nCode: 47, e.displayText() = DB::Exception: Unknown identifier: EventDate there are columns: IsEvent (version 20.8.17.25 (official build))\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23900/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23900/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23890","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23890/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23890/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23890/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/23890","id":876018777,"node_id":"MDU6SXNzdWU4NzYwMTg3Nzc=","number":23890,"title":"Support table property setting table compression method？","user":{"login":"melin","id":1145830,"node_id":"MDQ6VXNlcjExNDU4MzA=","avatar_url":"https://avatars.githubusercontent.com/u/1145830?v=4","gravatar_id":"","url":"https://api.github.com/users/melin","html_url":"https://github.com/melin","followers_url":"https://api.github.com/users/melin/followers","following_url":"https://api.github.com/users/melin/following{/other_user}","gists_url":"https://api.github.com/users/melin/gists{/gist_id}","starred_url":"https://api.github.com/users/melin/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/melin/subscriptions","organizations_url":"https://api.github.com/users/melin/orgs","repos_url":"https://api.github.com/users/melin/repos","events_url":"https://api.github.com/users/melin/events{/privacy}","received_events_url":"https://api.github.com/users/melin/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-05-05T04:00:36Z","updated_at":"2021-05-23T22:56:07Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"Support table property setting table compression method, Avoiding global changes\r\n\r\n```\r\nCREATE TABLE bigdata.demo\r\n(\r\n\r\n    `userid` String,\r\n\r\n    `city` String\r\n)\r\nENGINE = MergeTree\r\nORDER BY userid\r\nSETTINGS index_granularity = 8192, compression='zstd';\r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23890/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23890/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23889","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23889/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23889/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23889/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/23889","id":875863147,"node_id":"MDU6SXNzdWU4NzU4NjMxNDc=","number":23889,"title":"Quotas not working as expected","user":{"login":"OmarBazaraa","id":6713329,"node_id":"MDQ6VXNlcjY3MTMzMjk=","avatar_url":"https://avatars.githubusercontent.com/u/6713329?v=4","gravatar_id":"","url":"https://api.github.com/users/OmarBazaraa","html_url":"https://github.com/OmarBazaraa","followers_url":"https://api.github.com/users/OmarBazaraa/followers","following_url":"https://api.github.com/users/OmarBazaraa/following{/other_user}","gists_url":"https://api.github.com/users/OmarBazaraa/gists{/gist_id}","starred_url":"https://api.github.com/users/OmarBazaraa/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/OmarBazaraa/subscriptions","organizations_url":"https://api.github.com/users/OmarBazaraa/orgs","repos_url":"https://api.github.com/users/OmarBazaraa/repos","events_url":"https://api.github.com/users/OmarBazaraa/events{/privacy}","received_events_url":"https://api.github.com/users/OmarBazaraa/received_events","type":"User","site_admin":false},"labels":[{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":5,"created_at":"2021-05-04T21:43:41Z","updated_at":"2021-05-05T11:55:13Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"I created a simple quota as follows:\r\n\r\n```sql\r\nCREATE QUOTA OR REPLACE my_quota ON CLUSTER clickhouse_cluster\r\nFOR INTERVAL 240 second\r\nMAX queries = 5\r\nTO my_user_1, my_user_2;\r\n```\r\n\r\nAfterwards I started issuing `SELECT` queries and nothing was blocked. I issued over 10 queries using each user separately within the 240 seconds interval!\r\n\r\nI tested this scenario on versions `21.1.2.15` and `20.10.2` and they're both behaving the same to me!","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23889/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23889/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23888","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23888/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23888/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23888/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/23888","id":875846829,"node_id":"MDU6SXNzdWU4NzU4NDY4Mjk=","number":23888,"title":"HHMMSSxxxxxxxxx to DateTime64","user":{"login":"kimmolinna","id":4527697,"node_id":"MDQ6VXNlcjQ1Mjc2OTc=","avatar_url":"https://avatars.githubusercontent.com/u/4527697?v=4","gravatar_id":"","url":"https://api.github.com/users/kimmolinna","html_url":"https://github.com/kimmolinna","followers_url":"https://api.github.com/users/kimmolinna/followers","following_url":"https://api.github.com/users/kimmolinna/following{/other_user}","gists_url":"https://api.github.com/users/kimmolinna/gists{/gist_id}","starred_url":"https://api.github.com/users/kimmolinna/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kimmolinna/subscriptions","organizations_url":"https://api.github.com/users/kimmolinna/orgs","repos_url":"https://api.github.com/users/kimmolinna/repos","events_url":"https://api.github.com/users/kimmolinna/events{/privacy}","received_events_url":"https://api.github.com/users/kimmolinna/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-05-04T21:19:52Z","updated_at":"2021-05-04T21:19:52Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"What is the best way to replace the following code `parseDateTime64BestEffort(concat('20201210',substring(time,1,6),'.',substring(time,7,9)),9) as time`\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23888/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23888/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23870","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23870/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23870/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23870/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/23870","id":874834149,"node_id":"MDU6SXNzdWU4NzQ4MzQxNDk=","number":23870,"title":"Dictionaries with 'update_field' use more memory","user":{"login":"SaltTan","id":20357526,"node_id":"MDQ6VXNlcjIwMzU3NTI2","avatar_url":"https://avatars.githubusercontent.com/u/20357526?v=4","gravatar_id":"","url":"https://api.github.com/users/SaltTan","html_url":"https://github.com/SaltTan","followers_url":"https://api.github.com/users/SaltTan/followers","following_url":"https://api.github.com/users/SaltTan/following{/other_user}","gists_url":"https://api.github.com/users/SaltTan/gists{/gist_id}","starred_url":"https://api.github.com/users/SaltTan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/SaltTan/subscriptions","organizations_url":"https://api.github.com/users/SaltTan/orgs","repos_url":"https://api.github.com/users/SaltTan/repos","events_url":"https://api.github.com/users/SaltTan/events{/privacy}","received_events_url":"https://api.github.com/users/SaltTan/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":756395244,"node_id":"MDU6TGFiZWw3NTYzOTUyNDQ=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/performance","name":"performance","color":"c2e0c6","default":false,"description":null},{"id":1351463315,"node_id":"MDU6TGFiZWwxMzUxNDYzMzE1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-dictionary","name":"comp-dictionary","color":"b5bcff","default":false,"description":"Dictionaries"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-05-03T19:13:20Z","updated_at":"2021-05-04T12:11:48Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"Tested on 21.6.1.6748\r\n```\r\nname          | type             | bytes_allocated | element_count | source                                 | length(attribute.names)\r\n--------------+------------------+-----------------+---------------+----------------------------------------+------------------------\r\ndict_flat1    | Flat             |        44689464 |        838596 | MySQL: db.table_flat                   |                      11\r\ndict_flat     | Flat             |        55437368 |        838596 | MySQL: db.table_flat + update_field    |                      11\r\n\r\ndict_hashed1  | Hashed           |        10865896 |        180240 | MySQL: db.table_hashed                 |                      12\r\ndict_hashed   | Hashed           |        15338728 |        180240 | MySQL: db.table_hashed + update_field  |                      12\r\n\r\ndict_complex1 | ComplexKeyHashed |       999847480 |      10450665 | MySQL: db.table_complex                |                      45\r\ndict_complex  | ComplexKeyHashed |      1156085304 |      10450665 | MySQL: db.table_complex + update_field |                      45\r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23870/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23870/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23867","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23867/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23867/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23867/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/23867","id":874760165,"node_id":"MDU6SXNzdWU4NzQ3NjAxNjU=","number":23867,"title":"Column TTL does not work as expected","user":{"login":"ntrhieu89","id":7258025,"node_id":"MDQ6VXNlcjcyNTgwMjU=","avatar_url":"https://avatars.githubusercontent.com/u/7258025?v=4","gravatar_id":"","url":"https://api.github.com/users/ntrhieu89","html_url":"https://github.com/ntrhieu89","followers_url":"https://api.github.com/users/ntrhieu89/followers","following_url":"https://api.github.com/users/ntrhieu89/following{/other_user}","gists_url":"https://api.github.com/users/ntrhieu89/gists{/gist_id}","starred_url":"https://api.github.com/users/ntrhieu89/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ntrhieu89/subscriptions","organizations_url":"https://api.github.com/users/ntrhieu89/orgs","repos_url":"https://api.github.com/users/ntrhieu89/repos","events_url":"https://api.github.com/users/ntrhieu89/events{/privacy}","received_events_url":"https://api.github.com/users/ntrhieu89/received_events","type":"User","site_admin":false},"labels":[{"id":1401282669,"node_id":"MDU6TGFiZWwxNDAxMjgyNjY5","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-ttl","name":"comp-ttl","color":"b5bcff","default":false,"description":"TTL"},{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":{"login":"CurtizJ","id":20361854,"node_id":"MDQ6VXNlcjIwMzYxODU0","avatar_url":"https://avatars.githubusercontent.com/u/20361854?v=4","gravatar_id":"","url":"https://api.github.com/users/CurtizJ","html_url":"https://github.com/CurtizJ","followers_url":"https://api.github.com/users/CurtizJ/followers","following_url":"https://api.github.com/users/CurtizJ/following{/other_user}","gists_url":"https://api.github.com/users/CurtizJ/gists{/gist_id}","starred_url":"https://api.github.com/users/CurtizJ/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/CurtizJ/subscriptions","organizations_url":"https://api.github.com/users/CurtizJ/orgs","repos_url":"https://api.github.com/users/CurtizJ/repos","events_url":"https://api.github.com/users/CurtizJ/events{/privacy}","received_events_url":"https://api.github.com/users/CurtizJ/received_events","type":"User","site_admin":false},"assignees":[{"login":"CurtizJ","id":20361854,"node_id":"MDQ6VXNlcjIwMzYxODU0","avatar_url":"https://avatars.githubusercontent.com/u/20361854?v=4","gravatar_id":"","url":"https://api.github.com/users/CurtizJ","html_url":"https://github.com/CurtizJ","followers_url":"https://api.github.com/users/CurtizJ/followers","following_url":"https://api.github.com/users/CurtizJ/following{/other_user}","gists_url":"https://api.github.com/users/CurtizJ/gists{/gist_id}","starred_url":"https://api.github.com/users/CurtizJ/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/CurtizJ/subscriptions","organizations_url":"https://api.github.com/users/CurtizJ/orgs","repos_url":"https://api.github.com/users/CurtizJ/repos","events_url":"https://api.github.com/users/CurtizJ/events{/privacy}","received_events_url":"https://api.github.com/users/CurtizJ/received_events","type":"User","site_admin":false}],"milestone":null,"comments":10,"created_at":"2021-05-03T17:25:37Z","updated_at":"2021-08-04T03:08:16Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"I tested the column TTL feature but it does not work as expected. Clickhouse version is `21.3.8.76`. Steps to reproduce:\r\n\r\n1. Create the table: \r\n\r\n```\r\nCREATE TABLE default.tbl_col_ttl\r\n(\r\n    `id` UInt64,\r\n    `name` String,\r\n    `cnt` Int32 TTL eventts + toIntervalDay(1),\r\n    `eventts` DateTime\r\n)\r\nENGINE = MergeTree\r\nPARTITION BY toYYYYMMDD(eventts)\r\nORDER BY (id, name)\r\nSETTINGS index_granularity = 8192\r\n```\r\n\r\n2. Insert some rows in the table:\r\n\r\n```\r\nINSERT INTO tbl_col_ttl VALUES (1, 'john', 33, now()), (1, 'john', 32, now()), (2, 'mary', 35, now())\r\n```\r\n\r\n3. After several days, I expect to see all values of column `cnt` becomes 0, but nothing happens\r\n\r\n```\r\nSELECT * FROM tbl_col_ttl\r\n\r\n┌─id─┬─name─┬─cnt─┬─────────────eventts─┐\r\n│  1 │ john │  33 │ 2021-04-29 23:28:32 │\r\n│  1 │ john │  32 │ 2021-04-29 23:28:32 │\r\n│  2 │ mary │  35 │ 2021-04-29 23:28:32 │\r\n└────┴──────┴─────┴─────────────────────┘\r\n```\r\n\r\nExecuting `OPTIMIZE FINAL` on the table does not help. Only when I execute `ALTER TABLE tbl_col_ttl MATERIALIZE TTL` the values of `cnt` are set to 0. \r\n\r\nWhat I expect is the values of `cnt` should be updated after around 1 day of row creation as specified in the table schema, but it did not happen.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23867/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23867/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23865","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23865/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23865/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23865/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/23865","id":874690273,"node_id":"MDU6SXNzdWU4NzQ2OTAyNzM=","number":23865,"title":"issue with nested CTE + Distributed + IN subquery ","user":{"login":"filimonov","id":1549571,"node_id":"MDQ6VXNlcjE1NDk1NzE=","avatar_url":"https://avatars.githubusercontent.com/u/1549571?v=4","gravatar_id":"","url":"https://api.github.com/users/filimonov","html_url":"https://github.com/filimonov","followers_url":"https://api.github.com/users/filimonov/followers","following_url":"https://api.github.com/users/filimonov/following{/other_user}","gists_url":"https://api.github.com/users/filimonov/gists{/gist_id}","starred_url":"https://api.github.com/users/filimonov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/filimonov/subscriptions","organizations_url":"https://api.github.com/users/filimonov/orgs","repos_url":"https://api.github.com/users/filimonov/repos","events_url":"https://api.github.com/users/filimonov/events{/privacy}","received_events_url":"https://api.github.com/users/filimonov/received_events","type":"User","site_admin":false},"labels":[{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""},{"id":2788693937,"node_id":"MDU6TGFiZWwyNzg4NjkzOTM3","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-cte","name":"comp-cte","color":"b5bcff","default":false,"description":"common table expression (WITH ... SELECT)"}],"state":"open","locked":false,"assignee":{"login":"amosbird","id":5085485,"node_id":"MDQ6VXNlcjUwODU0ODU=","avatar_url":"https://avatars.githubusercontent.com/u/5085485?v=4","gravatar_id":"","url":"https://api.github.com/users/amosbird","html_url":"https://github.com/amosbird","followers_url":"https://api.github.com/users/amosbird/followers","following_url":"https://api.github.com/users/amosbird/following{/other_user}","gists_url":"https://api.github.com/users/amosbird/gists{/gist_id}","starred_url":"https://api.github.com/users/amosbird/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/amosbird/subscriptions","organizations_url":"https://api.github.com/users/amosbird/orgs","repos_url":"https://api.github.com/users/amosbird/repos","events_url":"https://api.github.com/users/amosbird/events{/privacy}","received_events_url":"https://api.github.com/users/amosbird/received_events","type":"User","site_admin":false},"assignees":[{"login":"amosbird","id":5085485,"node_id":"MDQ6VXNlcjUwODU0ODU=","avatar_url":"https://avatars.githubusercontent.com/u/5085485?v=4","gravatar_id":"","url":"https://api.github.com/users/amosbird","html_url":"https://github.com/amosbird","followers_url":"https://api.github.com/users/amosbird/followers","following_url":"https://api.github.com/users/amosbird/following{/other_user}","gists_url":"https://api.github.com/users/amosbird/gists{/gist_id}","starred_url":"https://api.github.com/users/amosbird/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/amosbird/subscriptions","organizations_url":"https://api.github.com/users/amosbird/orgs","repos_url":"https://api.github.com/users/amosbird/repos","events_url":"https://api.github.com/users/amosbird/events{/privacy}","received_events_url":"https://api.github.com/users/amosbird/received_events","type":"User","site_admin":false}],"milestone":null,"comments":2,"created_at":"2021-05-03T15:47:15Z","updated_at":"2021-07-29T18:42:23Z","closed_at":null,"author_association":"COLLABORATOR","active_lock_reason":null,"body":"```\r\ncreate table table_local engine = Log AS select * from numbers(10);\r\n\r\ncreate table table_dist engine = Distributed('test_cluster_two_shards',default,table_local) AS table_local;\r\n\r\nwith\r\n x as (select number from numbers(10) where number % 3=0),\r\n y as ( \r\n     select number, count() from table_dist\r\n     where number in (select * from x) group by number\r\n)\r\n  select * from y;\r\n  \r\nReceived exception from server (version 21.4.6):\r\nCode: 60. DB::Exception: Received from localhost:9000. DB::Exception: Received from 127.0.0.2:9000. DB::Exception: Table default.x doesn't exist: While processing number IN ((SELECT * FROM x) AS _subquery10). \r\n```\r\n\r\n/cc @amosbird ","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23865/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23865/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23858","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23858/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23858/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23858/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/23858","id":874435282,"node_id":"MDU6SXNzdWU4NzQ0MzUyODI=","number":23858,"title":"Decrease the logging level for health checks","user":{"login":"filimonov","id":1549571,"node_id":"MDQ6VXNlcjE1NDk1NzE=","avatar_url":"https://avatars.githubusercontent.com/u/1549571?v=4","gravatar_id":"","url":"https://api.github.com/users/filimonov","html_url":"https://github.com/filimonov","followers_url":"https://api.github.com/users/filimonov/followers","following_url":"https://api.github.com/users/filimonov/following{/other_user}","gists_url":"https://api.github.com/users/filimonov/gists{/gist_id}","starred_url":"https://api.github.com/users/filimonov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/filimonov/subscriptions","organizations_url":"https://api.github.com/users/filimonov/orgs","repos_url":"https://api.github.com/users/filimonov/repos","events_url":"https://api.github.com/users/filimonov/events{/privacy}","received_events_url":"https://api.github.com/users/filimonov/received_events","type":"User","site_admin":false},"labels":[{"id":386401508,"node_id":"MDU6TGFiZWwzODY0MDE1MDg=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/help%20wanted","name":"help wanted","color":"128A0C","default":true,"description":null},{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":845247686,"node_id":"MDU6TGFiZWw4NDUyNDc2ODY=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/usability","name":"usability","color":"ebf28c","default":false,"description":""},{"id":1365579236,"node_id":"MDU6TGFiZWwxMzY1NTc5MjM2","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/minor","name":"minor","color":"FFF8F8","default":false,"description":"Priority: minor"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":5,"created_at":"2021-05-03T10:11:48Z","updated_at":"2022-01-21T12:06:00Z","closed_at":null,"author_association":"COLLABORATOR","active_lock_reason":null,"body":"\"SSL connection unexpectedly closed\" - that creates a lot of noise in logs when automatic health check just opens & closes the SSL port.\r\n\r\n> @filimonov Let's create another task with a feature request to decrease the logging level in this place.\r\n> \r\n> _Originally posted by @alexey-milovidov in https://github.com/ClickHouse/ClickHouse/issues/10935#issuecomment-830537542_","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23858/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23858/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23853","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23853/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23853/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23853/events","html_url":"https://github.com/ClickHouse/ClickHouse/pull/23853","id":873945465,"node_id":"MDExOlB1bGxSZXF1ZXN0NjI4NjEzMDMx","number":23853,"title":"Add feature: creating user defined data types with serialization and deserialization","user":{"login":"Realist007","id":38961935,"node_id":"MDQ6VXNlcjM4OTYxOTM1","avatar_url":"https://avatars.githubusercontent.com/u/38961935?v=4","gravatar_id":"","url":"https://api.github.com/users/Realist007","html_url":"https://github.com/Realist007","followers_url":"https://api.github.com/users/Realist007/followers","following_url":"https://api.github.com/users/Realist007/following{/other_user}","gists_url":"https://api.github.com/users/Realist007/gists{/gist_id}","starred_url":"https://api.github.com/users/Realist007/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Realist007/subscriptions","organizations_url":"https://api.github.com/users/Realist007/orgs","repos_url":"https://api.github.com/users/Realist007/repos","events_url":"https://api.github.com/users/Realist007/events{/privacy}","received_events_url":"https://api.github.com/users/Realist007/received_events","type":"User","site_admin":false},"labels":[{"id":1309674771,"node_id":"MDU6TGFiZWwxMzA5Njc0Nzcx","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/pr-feature","name":"pr-feature","color":"007700","default":false,"description":"Pull request with new product feature"},{"id":1807683251,"node_id":"MDU6TGFiZWwxODA3NjgzMjUx","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/doc-alert","name":"doc-alert","color":"e51068","default":false,"description":"PR where any documentation work is needed or proceeded"}],"state":"open","locked":false,"assignee":{"login":"kitaisreal","id":22458333,"node_id":"MDQ6VXNlcjIyNDU4MzMz","avatar_url":"https://avatars.githubusercontent.com/u/22458333?v=4","gravatar_id":"","url":"https://api.github.com/users/kitaisreal","html_url":"https://github.com/kitaisreal","followers_url":"https://api.github.com/users/kitaisreal/followers","following_url":"https://api.github.com/users/kitaisreal/following{/other_user}","gists_url":"https://api.github.com/users/kitaisreal/gists{/gist_id}","starred_url":"https://api.github.com/users/kitaisreal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kitaisreal/subscriptions","organizations_url":"https://api.github.com/users/kitaisreal/orgs","repos_url":"https://api.github.com/users/kitaisreal/repos","events_url":"https://api.github.com/users/kitaisreal/events{/privacy}","received_events_url":"https://api.github.com/users/kitaisreal/received_events","type":"User","site_admin":false},"assignees":[{"login":"kitaisreal","id":22458333,"node_id":"MDQ6VXNlcjIyNDU4MzMz","avatar_url":"https://avatars.githubusercontent.com/u/22458333?v=4","gravatar_id":"","url":"https://api.github.com/users/kitaisreal","html_url":"https://github.com/kitaisreal","followers_url":"https://api.github.com/users/kitaisreal/followers","following_url":"https://api.github.com/users/kitaisreal/following{/other_user}","gists_url":"https://api.github.com/users/kitaisreal/gists{/gist_id}","starred_url":"https://api.github.com/users/kitaisreal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kitaisreal/subscriptions","organizations_url":"https://api.github.com/users/kitaisreal/orgs","repos_url":"https://api.github.com/users/kitaisreal/repos","events_url":"https://api.github.com/users/kitaisreal/events{/privacy}","received_events_url":"https://api.github.com/users/kitaisreal/received_events","type":"User","site_admin":false}],"milestone":null,"comments":1,"created_at":"2021-05-02T13:40:28Z","updated_at":"2021-12-09T14:59:32Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"draft":false,"pull_request":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/pulls/23853","html_url":"https://github.com/ClickHouse/ClickHouse/pull/23853","diff_url":"https://github.com/ClickHouse/ClickHouse/pull/23853.diff","patch_url":"https://github.com/ClickHouse/ClickHouse/pull/23853.patch","merged_at":null},"body":"I hereby agree to the terms of the CLA available at: https://yandex.ru/legal/cla/?lang=en\r\n\r\nChangelog category (leave one):\r\n- New Feature\r\n\r\nChangelog entry (a user-readable short description of the changes that goes to CHANGELOG.md):\r\n\r\nNew feature for creating user-defined data type as an alias to the other type\r\n\r\n\r\nDetailed description / Documentation draft:\r\n\r\nYou can create your own data type with the command 'create type MyType as {existing type}'. For example, existing type can be int, tuple, and other.\r\n\r\nBy adding documentation, you'll allow users to try your new feature immediately, not when someone else will have time to document it later. Documentation is necessary for all features that affect user experience in any way. You can add brief documentation draft above, or add documentation right into your patch as Markdown files in [docs](https://github.com/ClickHouse/ClickHouse/tree/master/docs) folder.\r\n\r\nIf you are doing this for the first time, it's recommended to read the lightweight [Contributing to ClickHouse Documentation](https://github.com/ClickHouse/ClickHouse/tree/master/docs/README.md) guide first.\r\n\r\n\r\nInformation about CI checks: https://clickhouse.tech/docs/en/development/continuous-integration/\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23853/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23853/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23804","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23804/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23804/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23804/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/23804","id":872597317,"node_id":"MDU6SXNzdWU4NzI1OTczMTc=","number":23804,"title":"Missing column in multiple join with backticked identifiers","user":{"login":"CurtizJ","id":20361854,"node_id":"MDQ6VXNlcjIwMzYxODU0","avatar_url":"https://avatars.githubusercontent.com/u/20361854?v=4","gravatar_id":"","url":"https://api.github.com/users/CurtizJ","html_url":"https://github.com/CurtizJ","followers_url":"https://api.github.com/users/CurtizJ/followers","following_url":"https://api.github.com/users/CurtizJ/following{/other_user}","gists_url":"https://api.github.com/users/CurtizJ/gists{/gist_id}","starred_url":"https://api.github.com/users/CurtizJ/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/CurtizJ/subscriptions","organizations_url":"https://api.github.com/users/CurtizJ/orgs","repos_url":"https://api.github.com/users/CurtizJ/repos","events_url":"https://api.github.com/users/CurtizJ/events{/privacy}","received_events_url":"https://api.github.com/users/CurtizJ/received_events","type":"User","site_admin":false},"labels":[{"id":386401505,"node_id":"MDU6TGFiZWwzODY0MDE1MDU=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/bug","name":"bug","color":"ee0701","default":true,"description":"Confirmed user-visible misbehaviour in official release"},{"id":1357578153,"node_id":"MDU6TGFiZWwxMzU3NTc4MTUz","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-joins","name":"comp-joins","color":"b5bcff","default":false,"description":"JOINs"},{"id":1507867504,"node_id":"MDU6TGFiZWwxNTA3ODY3NTA0","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/st-hold","name":"st-hold","color":"e5b890","default":false,"description":"We've paused the work on issue for some reason"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-04-30T14:19:54Z","updated_at":"2021-06-17T02:46:20Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"**Describe the bug**\r\nThe following example fails:\r\n\r\n```sql\r\n\r\nCREATE TABLE t1 (`1a` Nullable(Int64), `2b` Nullable(String)) engine = Memory;\r\nCREATE TABLE t2 (`3c` Nullable(Int64), `4d` Nullable(String)) engine = Memory;\r\nCREATE TABLE t3 (`5e` Nullable(Int64), `6f` Nullable(String)) engine = Memory;\r\n\r\nSELECT\r\n    `1a`,\r\n    `2b`\r\nFROM default.t1 AS tt1\r\nINNER JOIN \r\n(\r\n    SELECT `3c`\r\n    FROM default.t2\r\n) AS tt2 ON tt1.`1a` = tt2.`3c`\r\nINNER JOIN \r\n(\r\n    SELECT `6f`\r\n    FROM default.t3\r\n) AS tt3 ON tt1.`2b` = tt3.`6f`;\r\n\r\nReceived exception from server (version 21.6.1):\r\nCode: 47. DB::Exception: Received from localhost:9000. DB::Exception: Missing columns: '3c' while processing query: 'SELECT `2b`, `1a`, `3c` FROM default.t1 AS tt1 ALL INNER JOIN (SELECT `3c` FROM default.t2) AS tt2 ON `1a` = `3c`', required columns: '2b' '1a' '3c', maybe you meant: ['2b','1a'], joined columns: 'tt2.3c'.\r\n\r\n```\r\n\r\nSince identifiers start from digit, they are wrapped into back ticks and then are not found during join rewriting. Such identifiers are auto-generated as some hex hash. Example with regular ascii identifiers succeeds:\r\n\r\n```sql\r\nCREATE TABLE t1 (`a` Nullable(Int64), `b` Nullable(String)) engine = Memory;\r\nCREATE TABLE t2 (`c` Nullable(Int64), `d` Nullable(String)) engine = Memory;\r\nCREATE TABLE t3 (`e` Nullable(Int64), `f` Nullable(String)) engine = Memory;\r\n\r\nSELECT\r\n    a,\r\n    b\r\nFROM default.t1 AS tt1\r\nINNER JOIN \r\n(\r\n    SELECT c\r\n    FROM default.t2\r\n) AS tt2 ON tt1.a = tt2.c\r\nINNER JOIN \r\n(\r\n    SELECT f\r\n    FROM default.t3\r\n) AS tt3 ON tt1.b = tt3.f\r\n\r\nOk.\r\n```\r\n\r\n**Does it reproduce on recent release?**\r\nReproduces on master.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23804/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23804/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23785","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23785/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23785/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23785/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/23785","id":872142591,"node_id":"MDU6SXNzdWU4NzIxNDI1OTE=","number":23785,"title":"Same query, different result","user":{"login":"ronhuizer","id":53538583,"node_id":"MDQ6VXNlcjUzNTM4NTgz","avatar_url":"https://avatars.githubusercontent.com/u/53538583?v=4","gravatar_id":"","url":"https://api.github.com/users/ronhuizer","html_url":"https://github.com/ronhuizer","followers_url":"https://api.github.com/users/ronhuizer/followers","following_url":"https://api.github.com/users/ronhuizer/following{/other_user}","gists_url":"https://api.github.com/users/ronhuizer/gists{/gist_id}","starred_url":"https://api.github.com/users/ronhuizer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ronhuizer/subscriptions","organizations_url":"https://api.github.com/users/ronhuizer/orgs","repos_url":"https://api.github.com/users/ronhuizer/repos","events_url":"https://api.github.com/users/ronhuizer/events{/privacy}","received_events_url":"https://api.github.com/users/ronhuizer/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2021-04-30T08:08:54Z","updated_at":"2021-04-30T22:08:35Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Hi,\r\n\r\nI'm pretty new to OLAP databases so I feel a bit like a lost lamb in an abattoir, but here goes...\r\n\r\nI'm trying to get my first database to work. I got 1 server, 1 cluster, 1 database, 2 tables. The 2 tables are virtually the same, only the sorting (and primary) key differs.\r\nIn order to test the performance of both table configurations I loaded up both table with the same data, 1 year of vessel AIS data, 7.8 billion records in each table. Both tables contain the same amount of data and same amount of rows.\r\n\r\nWhen I perform a bounding-box-like query on both tables, the answer from table 1 differs from table 2. When I perform the same query multiple times all the answers from table1 are the same, same goes for table2, so the differences between the 2 are consistent as well.\r\n\r\nI don't get any warnings or error messages, just different results.\r\nquery: select * from AIS.dynamics where mmsi = 235089333 and lon > -45 and lat > -3\r\n\r\ntable one:\r\nCREATE TABLE AIS.dynamics\r\n(\r\n    `message_type` Int8,\r\n    `channel` FixedString(1),\r\n    `cog` Nullable(Float32),\r\n    `commstate` Int8,\r\n    `heading` Nullable(Int16),\r\n    `position_accuracy` Nullable(Int8),\r\n    `lat` Float32,\r\n    `lon` Float32,\r\n    `point` String,\r\n    `message_id` Int8,\r\n    `mmsi` Int32,\r\n    `nav_status` Int8,\r\n    `raimflag` Int8,\r\n    `rot` Nullable(Float32),\r\n    `sog` Nullable(Float32),\r\n    `source_type` Int8,\r\n    `timestamp` DateTime\r\n)\r\nENGINE = MergeTree\r\nPRIMARY KEY (mmsi, timestamp)\r\nORDER BY (mmsi, timestamp)\r\nSETTINGS index_granularity = 8192\r\n\r\ntable2:\r\nCREATE TABLE AIS.dynamics3\r\n(\r\n    `message_type` Int8,\r\n    `channel` FixedString(1),\r\n    `cog` Nullable(Float32),\r\n    `commstate` Int8,\r\n    `heading` Nullable(Int16),\r\n    `position_accuracy` Nullable(Int8),\r\n    `lat` Float32,\r\n    `lon` Float32,\r\n    `point` String,\r\n    `message_id` Int8,\r\n    `mmsi` Int32,\r\n    `nav_status` Int8,\r\n    `raimflag` Int8,\r\n    `rot` Nullable(Float32),\r\n    `sog` Nullable(Float32),\r\n    `source_type` Int8,\r\n    `timestamp` DateTime\r\n)\r\nENGINE = MergeTree\r\nPRIMARY KEY (mmsi, lat, lon, timestamp)\r\nORDER BY (mmsi, lat, lon, timestamp)\r\nSETTINGS index_granularity = 8192","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23785/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23785/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23784","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23784/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23784/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23784/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/23784","id":872135636,"node_id":"MDU6SXNzdWU4NzIxMzU2MzY=","number":23784,"title":"Support for (scalar) CTE in mutations","user":{"login":"filimonov","id":1549571,"node_id":"MDQ6VXNlcjE1NDk1NzE=","avatar_url":"https://avatars.githubusercontent.com/u/1549571?v=4","gravatar_id":"","url":"https://api.github.com/users/filimonov","html_url":"https://github.com/filimonov","followers_url":"https://api.github.com/users/filimonov/followers","following_url":"https://api.github.com/users/filimonov/following{/other_user}","gists_url":"https://api.github.com/users/filimonov/gists{/gist_id}","starred_url":"https://api.github.com/users/filimonov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/filimonov/subscriptions","organizations_url":"https://api.github.com/users/filimonov/orgs","repos_url":"https://api.github.com/users/filimonov/repos","events_url":"https://api.github.com/users/filimonov/events{/privacy}","received_events_url":"https://api.github.com/users/filimonov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":1351290474,"node_id":"MDU6TGFiZWwxMzUxMjkwNDc0","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-mutations","name":"comp-mutations","color":"b5bcff","default":false,"description":"ALTER UPDATE/DELETE"},{"id":2788693937,"node_id":"MDU6TGFiZWwyNzg4NjkzOTM3","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-cte","name":"comp-cte","color":"b5bcff","default":false,"description":"common table expression (WITH ... SELECT)"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-04-30T07:59:58Z","updated_at":"2021-04-30T08:00:10Z","closed_at":null,"author_association":"COLLABORATOR","active_lock_reason":null,"body":"The main use case - avoid many repetitions of the same expression in the UPDATE query\r\n```\r\nALTER TABLE table WITH (unhex('0000000000000000000000000000'), unhex('000000000000000000000'), unhex('00000000000000000000000000000'), unhex('0000000000000000000')) as (key1, iv1, key2, iv2) UPDATE\r\ns1 = encrypt('aes-256-ctr', decrypt('aes-256-ctr', s1, key1, iv1), key2, iv2),\r\ns2 = encrypt('aes-256-ctr', decrypt('aes-256-ctr', s2, key1, iv1), key2, iv2)\r\nWHERE 1 \r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23784/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23784/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23738","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23738/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23738/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23738/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/23738","id":870037797,"node_id":"MDU6SXNzdWU4NzAwMzc3OTc=","number":23738,"title":"Issue during ReplicatedMergeTreeCleanupThread may lead to replication delays","user":{"login":"filimonov","id":1549571,"node_id":"MDQ6VXNlcjE1NDk1NzE=","avatar_url":"https://avatars.githubusercontent.com/u/1549571?v=4","gravatar_id":"","url":"https://api.github.com/users/filimonov","html_url":"https://github.com/filimonov","followers_url":"https://api.github.com/users/filimonov/followers","following_url":"https://api.github.com/users/filimonov/following{/other_user}","gists_url":"https://api.github.com/users/filimonov/gists{/gist_id}","starred_url":"https://api.github.com/users/filimonov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/filimonov/subscriptions","organizations_url":"https://api.github.com/users/filimonov/orgs","repos_url":"https://api.github.com/users/filimonov/repos","events_url":"https://api.github.com/users/filimonov/events{/privacy}","received_events_url":"https://api.github.com/users/filimonov/received_events","type":"User","site_admin":false},"labels":[{"id":1401894928,"node_id":"MDU6TGFiZWwxNDAxODk0OTI4","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-zookeeper","name":"comp-zookeeper","color":"b5bcff","default":false,"description":"Zookeeper"},{"id":1478073551,"node_id":"MDU6TGFiZWwxNDc4MDczNTUx","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-replication","name":"comp-replication","color":"b5bcff","default":false,"description":"Replicated tables"},{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-04-28T14:52:52Z","updated_at":"2021-04-28T16:02:05Z","closed_at":null,"author_association":"COLLABORATOR","active_lock_reason":null,"body":"Scenario: single node (staging) cluster with zookeeper and replicated tables::\r\n\r\n1) connection lost to zookeeper during `ReplicatedMergeTreeCleanupThread`\r\n\r\n```\r\n2021.04.06 08:04:41.357047 [ 84 ] {} <Error> dbname.table_table (ReplicatedMergeTreeCleanupThread): void DB::ReplicatedMergeTreeCleanupThread::run(): Code: 999, e.displayText() = Coordination::Exception: Session expired (Session expired), Stack trace (when copying this message, always include the lines below):\r\n```\r\n\r\n2) 2 minutes later clickhouse was restarted, and during restart, it found 82 parts in the zookeeper which did not exist locally\r\n```\r\n2021.04.06 08:06:01.489762 [ 45 ] {} <Error> dbname.table_table: Removing locally missing part from ZooKeeper and queueing a fetch: 20210315_3463_3463_0\r\n2021.04.06 08:06:01.489786 [ 45 ] {} <Error> dbname.table_table: Removing locally missing part from ZooKeeper and queueing a fetch: 20210315_2274_2274_0\r\n2021.04.06 08:06:01.490090 [ 45 ] {} <Error> dbname.table_table: Removing locally missing part from ZooKeeper and queueing a fetch: 20210315_3583_3583_0\r\n2021.04.06 08:06:01.490125 [ 45 ] {} <Error> dbname.table_table: Removing locally missing part from ZooKeeper and queueing a fetch: 20210315_3575_3579_1\r\n...\r\n```\r\nSo I can guess that ReplicatedMergeTreeCleanupThread before removed 82 old parts of some obsolete partition from the filesystem, and during removing them from zookeeper it lost the connection.\r\n\r\n3) Later `ReplicatedMergeTreePartCheckThread` was waking up from time to time, and reporting that one of the missing parts lost forever. (quite obvious as no other replicas exist, even \"queueing a fetch\" was a wrong decision).\r\n\r\n```\r\n2021.04.06 08:08:06.592611 [ 84 ] {} <Warning> dbname.table_table (ReplicatedMergeTreePartCheckThread): Checking part 20210315_2470_2470_0\r\n2021.04.06 08:08:06.594488 [ 84 ] {} <Warning> dbname.table_table (ReplicatedMergeTreePartCheckThread): Checking if anyone has a part covering 20210315_2470_2470_0.\r\n2021.04.06 08:08:06.596532 [ 84 ] {} <Error> dbname.table_table (ReplicatedMergeTreePartCheckThread): No replica has part covering 20210315_2470_2470_0 and a merge is impossible: we didn't find smaller parts with either the same min block or the same max block.\r\n2021.04.06 08:08:06.599973 [ 84 ] {} <Error> dbname.table_table (ReplicatedMergeTreePartCheckThread): Part 20210315_2470_2470_0 is lost forever.\r\n2021.04.06 08:08:41.555526 [ 54 ] {} <Warning> dbname.table_table (ReplicatedMergeTreePartCheckThread): Checking part 20210315_3589_3589_0\r\n2021.04.06 08:08:41.556580 [ 54 ] {} <Warning> dbname.table_table (ReplicatedMergeTreePartCheckThread): Checking if anyone has a part covering 20210315_3589_3589_0.\r\n2021.04.06 08:08:41.557861 [ 54 ] {} <Error> dbname.table_table (ReplicatedMergeTreePartCheckThread): No replica has part covering 20210315_3589_3589_0 and a merge is impossible: we didn't find smaller parts with either the same min block or the same max block.\r\n2021.04.06 08:08:41.560091 [ 54 ] {} <Error> dbname.table_table (ReplicatedMergeTreePartCheckThread): Part 20210315_3589_3589_0 is lost forever.\r\n```\r\n\r\n4) `SelectStreamFactory` started reporting huge replication delay\r\n\r\n```\r\n2021.04.06 08:27:11.502129 [ 2921 ] {b9595ce1-a82a-4ba9-a99b-3080d9dcff58} <Warning> ClusterProxy::SelectStreamFactory: Local replica of shard 1 is stale (delay: 1894978s.)\r\n```\r\n\r\nI have no clear explanation of 1894978s, it looks like it corresponds to the time interval between the part date (20210315) and the date of the event (2021.04.06).\r\n\r\n5) The problem resolved on its own 30 minutes later - it looks like at the moment when the last part was checked and marked as 'lost forever'.\r\n\r\n\r\nThe same problem happened on the same system before, but it led to 'too many parts' (i guess the number of parts was higher the first time and replication stuck fully).\r\n\r\nRelates to #19306\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23738/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23738/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23735","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23735/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23735/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23735/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/23735","id":869932997,"node_id":"MDU6SXNzdWU4Njk5MzI5OTc=","number":23735,"title":"How to copy the whole DB data/schema from one machine to another?","user":{"login":"q0987","id":16629186,"node_id":"MDQ6VXNlcjE2NjI5MTg2","avatar_url":"https://avatars.githubusercontent.com/u/16629186?v=4","gravatar_id":"","url":"https://api.github.com/users/q0987","html_url":"https://github.com/q0987","followers_url":"https://api.github.com/users/q0987/followers","following_url":"https://api.github.com/users/q0987/following{/other_user}","gists_url":"https://api.github.com/users/q0987/gists{/gist_id}","starred_url":"https://api.github.com/users/q0987/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/q0987/subscriptions","organizations_url":"https://api.github.com/users/q0987/orgs","repos_url":"https://api.github.com/users/q0987/repos","events_url":"https://api.github.com/users/q0987/events{/privacy}","received_events_url":"https://api.github.com/users/q0987/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2021-04-28T13:12:05Z","updated_at":"2021-05-12T02:57:56Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Hello all,\r\n\r\nI have two machines(i.e. A and B) and machine A has ClickHouseDB installed.\r\nNow I need to duplicate the same setup(data/schema) from machine A to machine B.\r\n\r\nCan I copy all directories under /var/lib/clickhouse/ from machine A to machine B?\r\n\r\n```\r\n$ ls -l /var/lib/clickhouse/\r\ntotal 28\r\ndrwxr-xr-x 2 clickhouse clickhouse 4096 Apr 27 10:35 cores\r\ndrwxr-xr-x 4 clickhouse clickhouse 4096 Apr 27 10:35 data\r\ndrwxr-xr-x 2 clickhouse clickhouse 4096 Apr 27 10:35 flags\r\ndrwxr-xr-x 2 clickhouse clickhouse 4096 Apr 27 10:35 format_schemas\r\ndrwxr-xr-x 4 clickhouse clickhouse 4096 Apr 27 10:35 metadata\r\ndrwxr-xr-x 2 clickhouse clickhouse 4096 Apr 27 10:35 tmp\r\ndrwxr-xr-x 2 clickhouse clickhouse 4096 Apr 27 10:35 user_files\r\n```\r\n\r\nThank you\r\n\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23735/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23735/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23731","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23731/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23731/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23731/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/23731","id":869840319,"node_id":"MDU6SXNzdWU4Njk4NDAzMTk=","number":23731,"title":"StorageMergeTree mutation performance scales badly with batch sizes","user":{"login":"Algunenano","id":664253,"node_id":"MDQ6VXNlcjY2NDI1Mw==","avatar_url":"https://avatars.githubusercontent.com/u/664253?v=4","gravatar_id":"","url":"https://api.github.com/users/Algunenano","html_url":"https://github.com/Algunenano","followers_url":"https://api.github.com/users/Algunenano/followers","following_url":"https://api.github.com/users/Algunenano/following{/other_user}","gists_url":"https://api.github.com/users/Algunenano/gists{/gist_id}","starred_url":"https://api.github.com/users/Algunenano/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Algunenano/subscriptions","organizations_url":"https://api.github.com/users/Algunenano/orgs","repos_url":"https://api.github.com/users/Algunenano/repos","events_url":"https://api.github.com/users/Algunenano/events{/privacy}","received_events_url":"https://api.github.com/users/Algunenano/received_events","type":"User","site_admin":false},"labels":[{"id":756395244,"node_id":"MDU6TGFiZWw3NTYzOTUyNDQ=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/performance","name":"performance","color":"c2e0c6","default":false,"description":null},{"id":1351290474,"node_id":"MDU6TGFiZWwxMzUxMjkwNDc0","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-mutations","name":"comp-mutations","color":"b5bcff","default":false,"description":"ALTER UPDATE/DELETE"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-04-28T11:27:53Z","updated_at":"2021-04-29T18:59:19Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Describe the situation**\r\n\r\nThis is related to https://github.com/ClickHouse/ClickHouse/issues/23503. While doing an investigation reducing the number of ast elements allowed in each mutation batch (as generated by `StorageMergeTree::selectPartsToMutate`) I've noticed that this batching isn't only bad memory wise (crashing the stack in 20.8) but also making things much slower.\r\n\r\n**How to reproduce**\r\n\r\nI have a stopped cluster with a table that has **9303402 rows, 300 partitions and 21051** partition files.\r\n\r\nThe table looks like this:\r\n\r\n```\r\nCREATE TABLE d_073c5e.t_3b2dc2a7eadf4220826aa88a53b561b4\r\n(\r\n    `id` Int32,\r\n    `col1` Nullable(Int32) DEFAULT NULL,\r\n    `col2` Nullable(DateTime) DEFAULT NULL,\r\n    `col3` Nullable(DateTime) DEFAULT NULL,\r\n    `col4` Nullable(DateTime) DEFAULT NULL,\r\n    `col5` Nullable(DateTime) DEFAULT NULL,\r\n    `col6` Nullable(Int8) DEFAULT NULL,\r\n    `col7` Nullable(Int32) DEFAULT NULL,\r\n    `col8` Nullable(Int32) DEFAULT NULL,\r\n    `col9` Nullable(Int32) DEFAULT NULL,\r\n    `col10` Nullable(String) DEFAULT NULL,\r\n    `col11` Nullable(String) DEFAULT NULL,\r\n    `col12` Nullable(Int8) DEFAULT NULL,\r\n    `col13` Nullable(String) DEFAULT NULL,\r\n    `col14` Nullable(Int32) DEFAULT NULL,\r\n    `col15` Nullable(Int32) DEFAULT NULL,\r\n    `col16` Nullable(Int32) DEFAULT NULL,\r\n    `col17` Nullable(String) DEFAULT NULL,\r\n    `col18` Nullable(String) DEFAULT NULL,\r\n    `col19` Nullable(DateTime) DEFAULT NULL,\r\n    `col20` Nullable(DateTime) DEFAULT NULL,\r\n    `col21` Nullable(DateTime) DEFAULT NULL,\r\n    `col22` Nullable(String) DEFAULT NULL,\r\n    `col23` Nullable(String) DEFAULT NULL,\r\n    `col24` Nullable(Int32) DEFAULT NULL,\r\n    `col25` Nullable(Int32) DEFAULT NULL,\r\n    `col26` Nullable(Int8) DEFAULT NULL,\r\n    `col27` Nullable(String) DEFAULT NULL,\r\n    `col28` Nullable(String) DEFAULT NULL,\r\n    `col29` Nullable(String) DEFAULT NULL,\r\n    `col30` Nullable(Int64) DEFAULT NULL,\r\n    `col31` Nullable(Int32) DEFAULT NULL,\r\n    `col32` Nullable(Int32) DEFAULT NULL,\r\n    `col33` Nullable(String) DEFAULT NULL,\r\n    `col34` Nullable(String) DEFAULT NULL,\r\n    `col35` Nullable(DateTime) DEFAULT NULL,\r\n    `col36` Nullable(DateTime) DEFAULT NULL,\r\n    `col37` Nullable(String) DEFAULT NULL,\r\n    `col38` Nullable(DateTime) DEFAULT NULL,\r\n    `col39` Nullable(String) DEFAULT NULL,\r\n    `col40` Nullable(String) DEFAULT NULL,\r\n    `col41` Nullable(Int8) DEFAULT NULL,\r\n    `col42` Nullable(String) DEFAULT NULL,\r\n    `col43` DateTime DEFAULT now()\r\n)\r\nENGINE = MergeTree()\r\nORDER BY id\r\nSETTINGS index_granularity = 8192\r\n```\r\n\r\n\r\nAnd the mutations look like this (most of them modify 15-20 columns):\r\n```\r\nformat version: 1\r\ncreate time: 2021-04-22 03:05:51\r\ncommands: UPDATE col1 = 10000, col2 = \\'2021-05-21 12:15:00\\', col3 = \\'2021-06-21 03:51:51\\', col4 = \\'2021-04-22 03:01:35\\', col5 = \\'2021-05-21 12:15:00\\', col7 = 10000, col8 = 10000, col13 = \\'col6\\', col16 = 10000, col26 = 10000, col30 = 10000, col31 = 10000, col33 = \\'value\\', col34 = \\'VALUE\\', col35 = \\'2021-04-22 03:01:35\\', col36 = \\'2021-04-22 03:01:35\\', col39 = \\'VALUE\\', col41 = 100000, col43 = \\'2021-05-21 12:15:00\\' WHERE id = 11998071 \r\n```\r\n\r\nWhat I'm doing to test is start the server and wait until the migrations are applied and the migration files are deleted (keeping 100 of them per table as per configuration). To test again I stop the server, do any configuration changes, restore the data directory and retry.\r\n\r\nI'm doing tests with 20.8 (cd9831e9c332226903a4323d0fdb8afe25627711) and master (1d5d69f6514c5f10e117d3187942870b9e4f73a5). Except max_expanded_ast_elements the rest is the default configuration, so `background_pool_size : 16` and `number_of_free_entries_in_pool_to_execute_mutation : 10`, so it's expected to be using 6 threads to do mutations. The PC uses a i7-5820K (6 cores, 12 threads).\r\n\r\nHere are the timings (measuring since `clickhouse-server` is called):\r\n* 20.8, default max_expanded_ast_elements (500k): Crash OOM (reported https://github.com/ClickHouse/ClickHouse/issues/23503).\r\n* 20.8, max_expanded_ast_elements = `100000` : **55 minutes**\r\n* 20.8, max_expanded_ast_elements = `20000` : **12 minutes**\r\n* 20.8, max_expanded_ast_elements = `500` : **38 seconds**\r\n* master, default max_expanded_ast_elements (500k): Most of the mutations are cancelled due to OOM, other times the OOM killer stops the process, but CH doesn't crash.\r\n* master, max_expanded_ast_elements = `100000`: I stopped it after **12 hours**. It still had 17k active mutations (although some of them might have been partially processed).\r\n* master, max_expanded_ast_elements = `20000`: It finished in **2 hours and 20 minutes**.\r\n* master, max_expanded_ast_elements = `500`: **28 seconds**\r\n\r\nI see two things here:\r\n* having a low `max_expanded_ast_elements`, that is a small `MutationCommands`, seems to be way faster than the default.\r\n* The process used to scale better with size in 20.8, although even then it was faster to use small batches of mutations.\r\n\r\n**Expected performance**\r\n\r\nI would expect the batches to be as fast or faster when they grow, as otherwise I don't see a point to create batches and it might be better to just do mutations one by one. \r\n\r\n**Additional context**\r\n\r\nI know this could be considered an extreme case right now, but please understand that the situation wasn't reached by adding 20k mutations at once, instead what happens is that with a constant flow of mutations the moment the batch size starts to grow you are doomed since it means that it now takes more time to finish, so more mutations get queued up, which leads to longer times (scaling worse that O(N)), etc.\r\n\r\nLowering `max_expanded_ast_elements` isn't a long term solution since that setting is used to validate queries. Maybe it should be a different setting altogether?","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23731/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23731/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23730","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23730/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23730/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23730/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/23730","id":869807365,"node_id":"MDU6SXNzdWU4Njk4MDczNjU=","number":23730,"title":"max_concurrent_queries_for_user change requires restart","user":{"login":"vsop-479","id":14228334,"node_id":"MDQ6VXNlcjE0MjI4MzM0","avatar_url":"https://avatars.githubusercontent.com/u/14228334?v=4","gravatar_id":"","url":"https://api.github.com/users/vsop-479","html_url":"https://github.com/vsop-479","followers_url":"https://api.github.com/users/vsop-479/followers","following_url":"https://api.github.com/users/vsop-479/following{/other_user}","gists_url":"https://api.github.com/users/vsop-479/gists{/gist_id}","starred_url":"https://api.github.com/users/vsop-479/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vsop-479/subscriptions","organizations_url":"https://api.github.com/users/vsop-479/orgs","repos_url":"https://api.github.com/users/vsop-479/repos","events_url":"https://api.github.com/users/vsop-479/events{/privacy}","received_events_url":"https://api.github.com/users/vsop-479/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":6,"created_at":"2021-04-28T10:47:12Z","updated_at":"2021-06-15T02:42:11Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"I modified max_concurrent_queries_for_user in users.xml, and it changed in system.settings.\r\nBut users suffered  too many simultaneous queries with old max_concurrent_queries_for_user value, I had to restart the server to make new value effect.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23730/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23730/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23727","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23727/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23727/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23727/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/23727","id":869793238,"node_id":"MDU6SXNzdWU4Njk3OTMyMzg=","number":23727,"title":"Replacing partition with a non-existent one leads to data loss","user":{"login":"lisuml","id":6093882,"node_id":"MDQ6VXNlcjYwOTM4ODI=","avatar_url":"https://avatars.githubusercontent.com/u/6093882?v=4","gravatar_id":"","url":"https://api.github.com/users/lisuml","html_url":"https://github.com/lisuml","followers_url":"https://api.github.com/users/lisuml/followers","following_url":"https://api.github.com/users/lisuml/following{/other_user}","gists_url":"https://api.github.com/users/lisuml/gists{/gist_id}","starred_url":"https://api.github.com/users/lisuml/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/lisuml/subscriptions","organizations_url":"https://api.github.com/users/lisuml/orgs","repos_url":"https://api.github.com/users/lisuml/repos","events_url":"https://api.github.com/users/lisuml/events{/privacy}","received_events_url":"https://api.github.com/users/lisuml/received_events","type":"User","site_admin":false},"labels":[{"id":845247686,"node_id":"MDU6TGFiZWw4NDUyNDc2ODY=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/usability","name":"usability","color":"ebf28c","default":false,"description":""},{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-04-28T10:29:59Z","updated_at":"2021-04-29T19:06:24Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Describe the bug**\r\nIt's possible to replace an existing partition with a non-existing one, essentially destroying destination table's data for that partition.\r\n\r\n**Does it reproduce on recent release?**\r\nYes.\r\n\r\n**How to reproduce**\r\n* Which ClickHouse server version to use\r\n20.8.11.17\r\n\r\n* Which interface to use, if matters\r\nN/A\r\n\r\n* Non-default settings, if any\r\nN/A\r\n\r\n* `CREATE TABLE` statements for all tables involved\r\n```\r\nCREATE TABLE default.events_src\r\n(\r\n    `ddate` Date,\r\n    `date_time` DateTime\r\n)\r\nENGINE = ReplicatedMergeTree('/clickhouse/tables/{shard}/events_src', '{replica}')\r\nPARTITION BY toYYYYMMDDhhmmss(toStartOfHour(date_time))\r\nORDER BY ddate\r\nSETTINGS index_granularity = 8192\r\n```\r\n```\r\nCREATE TABLE default.events_dst\r\n(\r\n    `ddate` Date,\r\n    `date_time` DateTime\r\n)\r\nENGINE = ReplicatedMergeTree('/clickhouse/tables/{shard}/events_dst', '{replica}')\r\nPARTITION BY toYYYYMMDDhhmmss(toStartOfHour(date_time))\r\nORDER BY ddate\r\nSETTINGS index_granularity = 8192\r\n```\r\n* Sample data for all these tables\r\n`events_src` is a table with no data\r\n`events_dst` has some data:\r\n```\r\n┌──────ddate─┬───────────date_time─┐\r\n│ 2021-03-24 │ 2021-03-24 11:12:02 │\r\n│ 2021-03-24 │ 2021-03-24 11:12:02 │\r\n│ 2021-03-24 │ 2021-03-24 11:12:02 │\r\n│ 2021-03-24 │ 2021-03-24 11:12:02 │\r\n│ 2021-03-24 │ 2021-03-24 11:12:02 │\r\n│ 2021-03-24 │ 2021-03-24 11:12:02 │\r\n│ 2021-03-24 │ 2021-03-24 11:12:02 │\r\n│ 2021-03-24 │ 2021-03-24 11:12:02 │\r\n│ 2021-03-24 │ 2021-03-24 11:12:02 │\r\n│ 2021-03-24 │ 2021-03-24 11:12:02 │\r\n│ 2021-03-24 │ 2021-03-24 11:12:02 │\r\n│ 2021-03-24 │ 2021-03-24 11:12:03 │\r\n│ 2021-03-24 │ 2021-03-24 11:12:02 │\r\n│ 2021-03-24 │ 2021-03-24 11:12:03 │\r\n│ 2021-03-24 │ 2021-03-24 11:12:02 │\r\n└────────────┴─────────────────────┘\r\n```\r\n\r\n* Queries to run that lead to unexpected result\r\n```\r\nSELECT partition AS p\r\nFROM system.parts\r\nWHERE table = 'events_src'\r\nGROUP BY p\r\nORDER BY p ASC\r\n\r\nOk.\r\n\r\n0 rows in set. Elapsed: 0.002 sec.\r\n```\r\n\r\n^^^ events_src doesn't has any partitions\r\n\r\n```\r\nSELECT partition AS p\r\nFROM system.parts\r\nWHERE table = 'events_dst'\r\nGROUP BY p\r\nORDER BY p ASC\r\n\r\n┌─p──────────────┐\r\n│ 20210324110000 │\r\n└────────────────┘\r\n\r\n1 rows in set. Elapsed: 0.003 sec.\r\n```\r\n\r\n^^^ events_dst has the partition\r\n\r\n```\r\nALTER TABLE events_dst\r\n    REPLACE PARTITION 20210324110000 FROM events_src\r\n\r\n\r\nOk.\r\n\r\n0 rows in set. Elapsed: 0.010 sec.\r\n```\r\n\r\n^^^ it worked, but in the result it destroyed data in the `events_dst` table for the affected partition:\r\n\r\n```\r\nSELECT partition AS p\r\nFROM system.parts\r\nWHERE table = 'events_dst'\r\nGROUP BY p\r\nORDER BY p ASC\r\n\r\nOk.\r\n```\r\n\r\n**Expected behavior**\r\nClickHouse should refuse to replace partition if the source one doesn't exist.\r\n\r\n**Error message and/or stacktrace**\r\nN/A\r\n\r\n**Additional context**\r\nCurrent behaviour doesn't make sense and may lead to severe issues. It also doesn't seem logical, as the destination data is replaced from where exactly? I think having ClickHouse do additional test for source partition existence before replacing / moving / copying partition wouldn't hurt.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23727/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23727/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23684","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23684/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23684/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23684/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/23684","id":868719226,"node_id":"MDU6SXNzdWU4Njg3MTkyMjY=","number":23684,"title":"AggregateFunction type of error cannot be verified when the table is created","user":{"login":"IVitamin-C","id":35019926,"node_id":"MDQ6VXNlcjM1MDE5OTI2","avatar_url":"https://avatars.githubusercontent.com/u/35019926?v=4","gravatar_id":"","url":"https://api.github.com/users/IVitamin-C","html_url":"https://github.com/IVitamin-C","followers_url":"https://api.github.com/users/IVitamin-C/followers","following_url":"https://api.github.com/users/IVitamin-C/following{/other_user}","gists_url":"https://api.github.com/users/IVitamin-C/gists{/gist_id}","starred_url":"https://api.github.com/users/IVitamin-C/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/IVitamin-C/subscriptions","organizations_url":"https://api.github.com/users/IVitamin-C/orgs","repos_url":"https://api.github.com/users/IVitamin-C/repos","events_url":"https://api.github.com/users/IVitamin-C/events{/privacy}","received_events_url":"https://api.github.com/users/IVitamin-C/received_events","type":"User","site_admin":false},"labels":[{"id":845247686,"node_id":"MDU6TGFiZWw4NDUyNDc2ODY=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/usability","name":"usability","color":"ebf28c","default":false,"description":""},{"id":1397894054,"node_id":"MDU6TGFiZWwxMzk3ODk0MDU0","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unfinished%20code","name":"unfinished code","color":"ff8800","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-04-27T10:46:39Z","updated_at":"2021-04-29T14:50:11Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"case:\r\n\r\n```sql\r\ncreate table test.test_aggregate_func_col_data_input\r\n(\r\n    id Int32\r\n)\r\nENGINE=MergeTree()\r\norder by id \r\n\r\nCREATE TABLE test.test_aggregate_func_col_data\r\n(\r\n    `id` Int32,\r\n    `pv` AggregateFunction(sum, Int32)\r\n)\r\nENGINE = AggregatingMergeTree()\r\nORDER BY id\r\n\r\nOk.\r\n\r\n0 rows in set. Elapsed: 0.002 sec.\r\n\r\ncreate MATERIALIZED VIEW test.test_aggregate_func_col_data_mv to test.test_aggregate_func_col_data\r\n(\r\n    `id` Int32,\r\n    `pv` AggregateFunction(sum, Int32)\r\n)\r\nas \r\nselect id \r\n     ,sumState(1) as pv \r\nfrom test.test_aggregate_func_col_data_input\r\ngroup by id \r\n\r\nOk.\r\n\r\n0 rows in set. Elapsed: 0.002 sec.\r\n\r\nINSERT INTO test.test_aggregate_func_col_data_input SELECT toInt32(number % 1000) AS id\r\nFROM numbers(100000)\r\n\r\n\r\nReceived exception from server (version 20.8.4):\r\nCode: 70. DB::Exception: Received from mmdcchsvrnewsz6:21671. DB::Exception: Conversion from AggregateFunction(sum, UInt8) to AggregateFunction(sum, Int32) is not supported: while converting source column pv to destination column pv: while pushing to view test.test_aggregate_func_col_data_mv: While executing SinkToOutputStream. \r\n\r\n0 rows in set. Elapsed: 0.012 sec. \r\n```\r\n\r\nWhen creating the table, you should check whether the query field and the written field are consistent.\r\n\r\ncreate : `pv` AggregateFunction(sum, Int32)\r\nwrite:  sumState(1)  as pv -->AggregateFunction(sum, UInt8)\r\n\r\n```sql\r\nSELECT toTypeName(sumState(1))\r\n\r\n┌─toTypeName(sumState(1))───────┐\r\n│ AggregateFunction(sum, UInt8) │\r\n└───────────────────────────────┘\r\n```\r\n\r\nI think it may be that the corresponding verification function of AggregateFunction has not been developed.\r\nAt the same time, this problem will also lead to a huge cost of using materialized views, because this operation will hinder the inflow of all data in this batch. Errors occur in the background, and it is difficult for developers to perceive in time.\r\n\r\nThanks!\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23684/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23684/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23659","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23659/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23659/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23659/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/23659","id":868379439,"node_id":"MDU6SXNzdWU4NjgzNzk0Mzk=","number":23659,"title":"Whether all replicas are single-threaded the processQueueEntry？","user":{"login":"Sallery-X","id":45587738,"node_id":"MDQ6VXNlcjQ1NTg3NzM4","avatar_url":"https://avatars.githubusercontent.com/u/45587738?v=4","gravatar_id":"","url":"https://api.github.com/users/Sallery-X","html_url":"https://github.com/Sallery-X","followers_url":"https://api.github.com/users/Sallery-X/followers","following_url":"https://api.github.com/users/Sallery-X/following{/other_user}","gists_url":"https://api.github.com/users/Sallery-X/gists{/gist_id}","starred_url":"https://api.github.com/users/Sallery-X/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Sallery-X/subscriptions","organizations_url":"https://api.github.com/users/Sallery-X/orgs","repos_url":"https://api.github.com/users/Sallery-X/repos","events_url":"https://api.github.com/users/Sallery-X/events{/privacy}","received_events_url":"https://api.github.com/users/Sallery-X/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-04-27T02:28:02Z","updated_at":"2021-04-27T02:28:02Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23659/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23659/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23649","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23649/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23649/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23649/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/23649","id":867793376,"node_id":"MDU6SXNzdWU4Njc3OTMzNzY=","number":23649,"title":"Request througth gRPC , output in JSON","user":{"login":"andrelec1","id":3273204,"node_id":"MDQ6VXNlcjMyNzMyMDQ=","avatar_url":"https://avatars.githubusercontent.com/u/3273204?v=4","gravatar_id":"","url":"https://api.github.com/users/andrelec1","html_url":"https://github.com/andrelec1","followers_url":"https://api.github.com/users/andrelec1/followers","following_url":"https://api.github.com/users/andrelec1/following{/other_user}","gists_url":"https://api.github.com/users/andrelec1/gists{/gist_id}","starred_url":"https://api.github.com/users/andrelec1/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/andrelec1/subscriptions","organizations_url":"https://api.github.com/users/andrelec1/orgs","repos_url":"https://api.github.com/users/andrelec1/repos","events_url":"https://api.github.com/users/andrelec1/events{/privacy}","received_events_url":"https://api.github.com/users/andrelec1/received_events","type":"User","site_admin":false},"labels":[{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-04-26T14:53:25Z","updated_at":"2021-04-28T14:50:42Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"I try to connect to a clickhouse server througth gRPC in Dart ...\r\n\r\nFor my testing i use a simple request like `SELECT * FROM computed_datum LIMIT xxxx;` , i increase the xxxx value  ....\r\n\r\nSo i use the `executeQueryWithStreamOutput` from the gRPC proto ...\r\n\r\ni make this function : \r\n\r\n```dart \r\n  FutureOr<dynamic> _getResultsStream(String query) async {\r\n    QueryInfo queryInfo = this._getQueryInfo(query);\r\n    queryInfo.outputFormat = 'JSON';\r\n    print(query);\r\n    ResponseStream<Result> streamResult = this.client.executeQueryWithStreamOutput(queryInfo);\r\n    int length = 0;\r\n    await for (Result value in streamResult) {\r\n      print(value.output);\r\n      print('----');\r\n      length++;\r\n    }\r\n\r\n    return length;\r\n  }\r\n```\r\n\r\nOutput for limit 1 look like : \r\n\r\n```\r\nSELECT * FROM computed_datum LIMIT 1;\r\n{\r\n\t\"meta\":\r\n\t[\r\n\t\t{\r\n\t\t\t\"name\": \"EventDateTime\",\r\n\t\t\t\"type\": \"DateTime('UTC')\"\r\n\t\t},\r\n\t\t{\r\n\t\t\t\"name\": \"insert\",\r\n\t\t\t\"type\": \"String\"\r\n\t\t},\r\n\t\t{\r\n\t\t\t\"name\": \"uuid\",\r\n\t\t\t\"type\": \"String\"\r\n\t\t},\r\n\t\t{\r\n\t\t\t\"name\": \"datetime_value\",\r\n\t\t\t\"type\": \"DateTime('UTC')\"\r\n\t\t},\r\n\t\t{\r\n\t\t\t\"name\": \"computed_id\",\r\n\t\t\t\"type\": \"Int32\"\r\n\t\t},\r\n\t\t{\r\n\t\t\t\"name\": \"computed_kind\",\r\n\t\t\t\"type\": \"String\"\r\n\t\t},\r\n\t\t{\r\n\t\t\t\"name\": \"computed_type\",\r\n\t\t\t\"type\": \"String\"\r\n\t\t},\r\n\t\t{\r\n\t\t\t\"name\": \"value\",\r\n\t\t\t\"type\": \"Float64\"\r\n\t\t},\r\n\t\t{\r\n\t\t\t\"name\": \"flags\",\r\n\t\t\t\"type\": \"String\"\r\n\t\t}\r\n\t],\r\n\r\n\t\"data\":\r\n\t[\r\n\t\t{\r\n\t\t\t\"EventDateTime\": \"2020-05-26 07:18:46\",\r\n\t\t\t\"insert\": \"2020-05-26T09:18:46.287Z\",\r\n\t\t\t\"uuid\": \"9970bf0d-4afb-47ea-99b9-f8abbc226ffd\",\r\n\t\t\t\"datetime_value\": \"2000-01-01 00:00:00\",\r\n\t\t\t\"computed_id\": 11,\r\n\t\t\t\"computed_kind\": \"testData\",\r\n\t\t\t\"computed_type\": \"extensive.some\",\r\n\t\t\t\"value\": 145,\r\n\t\t\t\"flags\": \"\"\r\n\t\t}\r\n\t],\r\n\r\n\t\"rows\": 1,\r\n\r\n\t\"statistics\":\r\n\t{\r\n\t\t\"elapsed\": 0.001071028,\r\n\t\t\"rows_read\": 0,\r\n\t\t\"bytes_read\": 0\r\n\t}\r\n}\r\n\r\n----\r\n1\r\n```\r\n\r\nlook good ...\r\nif i use LIMIT 250 in my request i have this :\r\n( i strip to top ... )\r\n```\r\n\t\t\t\"flags\": \"\"\r\n\t\t},\r\n\t\t{\r\n\t\t\t\"EventDateTime\": \"2020-05-26 07:18:49\",\r\n\t\t\t\"insert\": \"2020-05-26T09:18:48.971Z\",\r\n\t\t\t\"uuid\": \"9ffe1595-984f-4045-a870-7ee628d4aa47\",\r\n\t\t\t\"datetime_value\": \"2000-01-02 17:10:00\",\r\n\t\t\t\"computed_id\": 11,\r\n\t\t\t\"computed_kind\": \"testDa\r\n----\r\nta\",\r\n\t\t\t\"computed_type\": \"extensive.some\",\r\n\t\t\t\"value\": 680,\r\n\t\t\t\"flags\": \"\"\r\n\t\t},\r\n\t\t{\r\n\t\t\t\"EventDateTime\": \"2020-05-26 07:18:49\",\r\n\t\t\t\"insert\": \"2020-05-26T09:18:48.971Z\",\r\n\t\t\t\"uuid\": \"058ca1ed-26cb-42ac-9bda-5f2ef103fdc7\",\r\n\t\t\t\"datetime_value\": \"2000-01-02 17:20:00\",\r\n\t\t\t\"computed_id\": 11,\r\n\t\t\t\"computed_kind\": \"testData\",\r\n\t\t\t\"computed_type\": \"extensive.some\",\r\n\t\t\t\"value\": 681,\r\n\t\t\t\"flags\": \"\"\r\n\t\t},\r\n\t\t{\r\n\t\t\t\"EventDateTime\": \"2020-05-26 07:18:49\",\r\n\t\t\t\"insert\": \"2020-05-26T09:18:48.971Z\",\r\n\t\t\t\"uuid\": \"34c766ec-4ab3-4c47-994d-70810a791c02\",\r\n\t\t\t\"datetime_value\": \"2000-01-02 17:30:00\",\r\n\t\t\t\"computed_id\": 11,\r\n\t\t\t\"computed_kind\": \"testData\",\r\n\t\t\t\"computed_type\": \"extensive.some\",\r\n\t\t\t\"value\": 682,\r\n\t\t\t\"flags\": \"\"\r\n\t\t}\r\n\t],\r\n\r\n\t\"rows\": 250,\r\n\r\n\t\"statistics\":\r\n\t{\r\n\t\t\"elapsed\": 1.353628734,\r\n\t\t\"rows_read\": 0,\r\n\t\t\"bytes_read\": 0\r\n\t}\r\n}\r\n\r\n----\r\n2\r\n```\r\n\r\nso data seem split in middle of nower but that work ...\r\nBut if my request return more than 270 elements ... i only get the first element of the stream  :/\r\n\r\nI change the outputFormat to CSV and i can see all the data ...\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23649/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23649/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23560","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23560/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23560/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23560/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/23560","id":866490974,"node_id":"MDU6SXNzdWU4NjY0OTA5NzQ=","number":23560,"title":"How to model a 1:N relationship with aggregation?","user":{"login":"mauidude","id":823384,"node_id":"MDQ6VXNlcjgyMzM4NA==","avatar_url":"https://avatars.githubusercontent.com/u/823384?v=4","gravatar_id":"","url":"https://api.github.com/users/mauidude","html_url":"https://github.com/mauidude","followers_url":"https://api.github.com/users/mauidude/followers","following_url":"https://api.github.com/users/mauidude/following{/other_user}","gists_url":"https://api.github.com/users/mauidude/gists{/gist_id}","starred_url":"https://api.github.com/users/mauidude/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mauidude/subscriptions","organizations_url":"https://api.github.com/users/mauidude/orgs","repos_url":"https://api.github.com/users/mauidude/repos","events_url":"https://api.github.com/users/mauidude/events{/privacy}","received_events_url":"https://api.github.com/users/mauidude/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":4,"created_at":"2021-04-23T23:35:11Z","updated_at":"2021-04-24T03:06:26Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"So I posted this on stackoverflow but it didn't seem to get any responses. Maybe someone here can help me.... Maybe nested types can help me here but I am not sure how those would aggregate...\r\n\r\nOriginal stackoverflow question:\r\n\r\nI have a series of events that I want to put into Clickhouse and they tie back to a single entity via an `id` field. Each event type has a different part of the entity and most of the event types occur once, but some occur multiple times. I am trying to figure out how to model this so that the table has one row (after an `OPTIMIZE`) to represent that entity (even though there are multiple events per entity).\r\n\r\nMy data is something like this, where event D is the one that can occur multiple times:\r\n```\r\nEvent type A:\r\n{\r\n  \"id\": <string identifier>,\r\n  \"a\": <data for field a>\r\n  \"aa\": <data for field aa>\r\n}\r\n\r\nEvent type B:\r\n{\r\n  \"id\": <string identifier>,\r\n  \"b\": <data for field b>,\r\n  \"bb\": <data for field bb>\r\n}\r\n\r\nEvent type C:\r\n{\r\n  \"id\": <string identifier>,\r\n  \"c\": <data for field c>,\r\n  \"cc\": <data for field cc>\r\n}\r\n\r\nEvent type D:\r\n{\r\n  \"id\": <string identifier>,\r\n  \"d\": <data for field d>,\r\n  \"dd\": <data for field dd>\r\n}\r\n```\r\n\r\nWhat I want a table in Clickhouse to look like is something like this:\r\n\r\n```\r\nCREATE TABLE events\r\n(\r\n  id String,\r\n  a Nullable(String),\r\n  aa Nullable(String),\r\n  b Nullable(String),\r\n  bb Nullable(String),\r\n  c Nullable(String),\r\n  cc Nullable(String),\r\n  d Nullable(Array(String)),\r\n  dd Nullable(Array(String))\r\n)\r\n```\r\nwhere the elements of column `d` and `dd` are ordered the same, e.g. `d[1]` and `dd[1]` should be from the same instance of event D.\r\n\r\nWhat I am having trouble with is coming up with the correct engine that would give me this. I naturally went to the `AggregatingMergeTree` for this and using `id` as the sort key, but I don't know how to aggregate the fields from event D. I think it might be because of the apparent lack of an aggregate function that would aggregate values into an array of that type (e.g. aggregating `Nullable(String)` into `Array(String)`). \r\n\r\nIs there such a function or table engine that would accomplish what I'm trying to do or am I even thinking about this correctly? I realize I could write the D events to a separate table but I want to avoid a join if possible.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23560/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23560/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23516","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23516/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23516/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23516/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/23516","id":865249191,"node_id":"MDU6SXNzdWU4NjUyNDkxOTE=","number":23516,"title":"Support of dynamic subcolumns in tables.","user":{"login":"CurtizJ","id":20361854,"node_id":"MDQ6VXNlcjIwMzYxODU0","avatar_url":"https://avatars.githubusercontent.com/u/20361854?v=4","gravatar_id":"","url":"https://api.github.com/users/CurtizJ","html_url":"https://github.com/CurtizJ","followers_url":"https://api.github.com/users/CurtizJ/followers","following_url":"https://api.github.com/users/CurtizJ/following{/other_user}","gists_url":"https://api.github.com/users/CurtizJ/gists{/gist_id}","starred_url":"https://api.github.com/users/CurtizJ/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/CurtizJ/subscriptions","organizations_url":"https://api.github.com/users/CurtizJ/orgs","repos_url":"https://api.github.com/users/CurtizJ/repos","events_url":"https://api.github.com/users/CurtizJ/events{/privacy}","received_events_url":"https://api.github.com/users/CurtizJ/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":1507886722,"node_id":"MDU6TGFiZWwxNTA3ODg2NzIy","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/st-discussion","name":"st-discussion","color":"e5b890","default":false,"description":"The story requires discussion /research / expert help / design & decomposition before will be taken"}],"state":"open","locked":false,"assignee":{"login":"CurtizJ","id":20361854,"node_id":"MDQ6VXNlcjIwMzYxODU0","avatar_url":"https://avatars.githubusercontent.com/u/20361854?v=4","gravatar_id":"","url":"https://api.github.com/users/CurtizJ","html_url":"https://github.com/CurtizJ","followers_url":"https://api.github.com/users/CurtizJ/followers","following_url":"https://api.github.com/users/CurtizJ/following{/other_user}","gists_url":"https://api.github.com/users/CurtizJ/gists{/gist_id}","starred_url":"https://api.github.com/users/CurtizJ/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/CurtizJ/subscriptions","organizations_url":"https://api.github.com/users/CurtizJ/orgs","repos_url":"https://api.github.com/users/CurtizJ/repos","events_url":"https://api.github.com/users/CurtizJ/events{/privacy}","received_events_url":"https://api.github.com/users/CurtizJ/received_events","type":"User","site_admin":false},"assignees":[{"login":"CurtizJ","id":20361854,"node_id":"MDQ6VXNlcjIwMzYxODU0","avatar_url":"https://avatars.githubusercontent.com/u/20361854?v=4","gravatar_id":"","url":"https://api.github.com/users/CurtizJ","html_url":"https://github.com/CurtizJ","followers_url":"https://api.github.com/users/CurtizJ/followers","following_url":"https://api.github.com/users/CurtizJ/following{/other_user}","gists_url":"https://api.github.com/users/CurtizJ/gists{/gist_id}","starred_url":"https://api.github.com/users/CurtizJ/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/CurtizJ/subscriptions","organizations_url":"https://api.github.com/users/CurtizJ/orgs","repos_url":"https://api.github.com/users/CurtizJ/repos","events_url":"https://api.github.com/users/CurtizJ/events{/privacy}","received_events_url":"https://api.github.com/users/CurtizJ/received_events","type":"User","site_admin":false}],"milestone":null,"comments":37,"created_at":"2021-04-22T17:44:45Z","updated_at":"2022-01-21T14:58:50Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"Inroduce new data type `Object(<schema format>)`, which will get the name of format for semi-structured data (`JSON`, `XML`, etc.).\r\nInitially it will work only with `MergeTree` tables. Maybe later will add some other storages.\r\n\r\nValues will be inserted as strings to columns of that type. Then separate subcolumns will be parsed according to schema format and written in columnar format.\r\n\r\nSubcolumns of type `Object` will be stored in the lowest common type in which all values of subcolumn can be represented.\r\n\r\nColumns of type `Object` will support reading of subcolumns and slices at arbitrary level of nesting.\r\n\r\nFor example if we will write in the column with name `user` and type `Object` the following `JSON`:\r\n```json\r\n{\r\n    \"name\" : \"John\",\r\n    \"age\" : 42,\r\n    \"location\" : {\r\n        \"country\" : \"USA\",\r\n        \"city\" : \"New York\"\r\n    }\r\n}\r\n```\r\n\r\nThere will be 4 columns, available for reading: `user.name`, `user.age`, `user.location.country`, `user.location.city`. Also slice `user.location.*`.\r\n\r\nPreferred type of subcolumn in query should be specified with operator `::`, e.g. `user.age::UInt8`. If it will be omitted, subcolumn will be converted to `String`.\r\n\r\n### Implementation details\r\n\r\nIntroduce `DataTypeObject`, `SerializationObject` and `ColumnObject`.\r\n\r\nMetadata of storage will store `DataTypeObject` for column. It will know nothing about its subcolumns. There will be concrete data types (named tuples) in data parts, which will be deduced from data. For queries there are 2 approaches:\r\n\r\n- Don't get any information about all subcolumns from table. In inserts always allow to insert new subcolumns. In selects it's not a problem for query analysis, because type will be specified in query (or will be `String`). If it will be absent in some parts (possibly all) column will be filled by defaults.\r\nCaveats: in inserts we won't be able to return error in case, when new type of subcolumn is totally incompatible with old type, (f.e. `String` and `Array(UInt32)`). However we always can write data as string, but any small mistake will lead to writing garbage to the table. In selects we won't be able to read slices (`user.location.*` from example above).\r\n\r\n- Before execution of query get types of all subcolumns. We can deduce common type from parts.\r\nCaveats: may be too slow due to large number of parts and subcolumns. Also some races are possible and maybe additional synchronisation will be required.\r\n\r\nFor now I am not sure which one is better.\r\n\r\n`ColumnObject` will store map from keys to regular columns.\r\n\r\nInsertion will be supported from row-based input formats. Structure (JSON and similar) will be parsed for every row, then all paths will be extracted and added to `ColumnObject` as strings. When new key will appear, new subcolumn with all defaults will be added to `ColumnObject`. After all rows will be parsed, types of every subcolumns will be optimized to lowest common for all values. And finally `DataTypeObject` will be converted to named `Tuple`, which will be written in part metadata. It's ok to use path as keys, because serialization of such flat tuple will be the same as complex structure of tuple, f.e. for types ```Tuple(a String, b Tuple(c UInt32, d UInt32))``` and ```Tuple(a String, `b.c` UInt32 `b.d` UInt32)```.\r\n\r\nCaveats: it will be harder to read intermediate structure as tuple, but anyway you can't do very much with tuples in ClickHouse. Some problems may exist with `Nested` type with multiple levels.\r\n\r\nBefore merge for every subcolumn of type `Object` will be deduced the least common type among all parts and in new part it will be written in that type.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23516/reactions","total_count":18,"+1":18,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23516/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23513","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23513/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23513/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23513/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/23513","id":865083854,"node_id":"MDU6SXNzdWU4NjUwODM4NTQ=","number":23513,"title":"Allow to wait for any asynchronous queries","user":{"login":"abyss7","id":5627721,"node_id":"MDQ6VXNlcjU2Mjc3MjE=","avatar_url":"https://avatars.githubusercontent.com/u/5627721?v=4","gravatar_id":"","url":"https://api.github.com/users/abyss7","html_url":"https://github.com/abyss7","followers_url":"https://api.github.com/users/abyss7/followers","following_url":"https://api.github.com/users/abyss7/following{/other_user}","gists_url":"https://api.github.com/users/abyss7/gists{/gist_id}","starred_url":"https://api.github.com/users/abyss7/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/abyss7/subscriptions","organizations_url":"https://api.github.com/users/abyss7/orgs","repos_url":"https://api.github.com/users/abyss7/repos","events_url":"https://api.github.com/users/abyss7/events{/privacy}","received_events_url":"https://api.github.com/users/abyss7/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-04-22T15:28:18Z","updated_at":"2021-08-08T23:37:54Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"Introduce the new WAIT-query.\r\n\r\nSyntax:\r\n\r\n    waitStmt: WAIT (QUERY STRING_LITERAL | query);\r\n\r\nBlocks the client until the asynchronous query is complete and returns it's result (if any). If the `query` is synchronous, then it's the same as just executing the query without waiting. This command doesn't allow to wait for other executing sync queries via query id, i.e. executed from different clients.\r\n\r\nThe list of all executing at the moment async queries can be issued from the system table `system.asynchronous_queries` with columns: `query_id String` - we can't show the query body to prevent security problems.\r\n\r\nAlso original query id can be obtained from the response to the client.\r\n\r\nIf there is no such query id then WAIT-query assumes that query has finished and returns immediately. Probably we can consult the query-log for the result of such query, or even for it's existance.\r\n\r\nThe examples of async queries:\r\n- DDL queries\r\n- ON CLUSTER queries\r\n- queries with Distributed tables","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23513/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23513/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23511","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23511/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23511/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23511/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/23511","id":864994913,"node_id":"MDU6SXNzdWU4NjQ5OTQ5MTM=","number":23511,"title":"Include client IP address in error message about authentication failure in server log.","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-04-22T14:06:56Z","updated_at":"2021-04-24T01:22:32Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23511/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23511/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23496","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23496/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23496/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23496/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/23496","id":864728613,"node_id":"MDU6SXNzdWU4NjQ3Mjg2MTM=","number":23496,"title":"Best approach to implement set operation","user":{"login":"arun-prasat","id":70636618,"node_id":"MDQ6VXNlcjcwNjM2NjE4","avatar_url":"https://avatars.githubusercontent.com/u/70636618?v=4","gravatar_id":"","url":"https://api.github.com/users/arun-prasat","html_url":"https://github.com/arun-prasat","followers_url":"https://api.github.com/users/arun-prasat/followers","following_url":"https://api.github.com/users/arun-prasat/following{/other_user}","gists_url":"https://api.github.com/users/arun-prasat/gists{/gist_id}","starred_url":"https://api.github.com/users/arun-prasat/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/arun-prasat/subscriptions","organizations_url":"https://api.github.com/users/arun-prasat/orgs","repos_url":"https://api.github.com/users/arun-prasat/repos","events_url":"https://api.github.com/users/arun-prasat/events{/privacy}","received_events_url":"https://api.github.com/users/arun-prasat/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":4,"created_at":"2021-04-22T09:16:23Z","updated_at":"2021-05-12T02:08:55Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"(you don't have to strictly follow this form)\r\n\r\n**Describe the issue**\r\nI like to implement a set operation in clickhouse, Set operation will be dynamic and it may change in the runtime. Please let me know the best approach to implement the set operation clickhouse.\r\n\r\nEX :\r\n(Subquery A UNION ALL subquery B) UNION (Subquery C INTERSECT Subquery D) EXCEPT (Subquery E)\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23496/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23496/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23494","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23494/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23494/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23494/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/23494","id":864665245,"node_id":"MDU6SXNzdWU4NjQ2NjUyNDU=","number":23494,"title":"s3 / hfds partition prunning / index scan by virtual columns (_file, _path)","user":{"login":"UnamedRus","id":9449405,"node_id":"MDQ6VXNlcjk0NDk0MDU=","avatar_url":"https://avatars.githubusercontent.com/u/9449405?v=4","gravatar_id":"","url":"https://api.github.com/users/UnamedRus","html_url":"https://github.com/UnamedRus","followers_url":"https://api.github.com/users/UnamedRus/followers","following_url":"https://api.github.com/users/UnamedRus/following{/other_user}","gists_url":"https://api.github.com/users/UnamedRus/gists{/gist_id}","starred_url":"https://api.github.com/users/UnamedRus/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/UnamedRus/subscriptions","organizations_url":"https://api.github.com/users/UnamedRus/orgs","repos_url":"https://api.github.com/users/UnamedRus/repos","events_url":"https://api.github.com/users/UnamedRus/events{/privacy}","received_events_url":"https://api.github.com/users/UnamedRus/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":1507888214,"node_id":"MDU6TGFiZWwxNTA3ODg4MjE0","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/st-accepted","name":"st-accepted","color":"e5b890","default":false,"description":"The issue is in our backlog, ready to take"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-04-22T08:04:41Z","updated_at":"2021-04-22T21:57:15Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Use case**\r\nBecause clickhouse run listObject command first, we can actually calculate and apply any kind of conditions over _file, _path columns before processing files.\r\n\r\n**Describe the solution you'd like**\r\n\r\n```\r\nSELECT _file\r\nFROM s3('https://storage.yandexcloud.net/my-test-bucket-768/{some,another}_prefix/some_file_{1..3}.csv', 'CSV', 'name String, value UInt32')\r\nWHERE _file = 'some_file_2.csv'\r\n\r\n\r\n┌─_file───────────┐\r\n│ some_file_2.csv │\r\n│ some_file_2.csv │\r\n│ some_file_2.csv │\r\n└─────────────────┘\r\n┌─_file───────────┐\r\n│ some_file_2.csv │\r\n│ some_file_2.csv │\r\n│ some_file_2.csv │\r\n└─────────────────┘\r\n\r\n <Information> executeQuery: Read 18 rows, 720.00 B in 0.2335566 sec., 77 rows/sec., 3.01 KiB/sec.\r\n```\r\n\r\n**Additional context**\r\nJust like https://github.com/ClickHouse/ClickHouse/pull/21401\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23494/reactions","total_count":3,"+1":3,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23494/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23485","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23485/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23485/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23485/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/23485","id":864631422,"node_id":"MDU6SXNzdWU4NjQ2MzE0MjI=","number":23485,"title":"sumMap/minMap/maxMap aggregation optimization for sorted keys","user":{"login":"stfaun","id":15967395,"node_id":"MDQ6VXNlcjE1OTY3Mzk1","avatar_url":"https://avatars.githubusercontent.com/u/15967395?v=4","gravatar_id":"","url":"https://api.github.com/users/stfaun","html_url":"https://github.com/stfaun","followers_url":"https://api.github.com/users/stfaun/followers","following_url":"https://api.github.com/users/stfaun/following{/other_user}","gists_url":"https://api.github.com/users/stfaun/gists{/gist_id}","starred_url":"https://api.github.com/users/stfaun/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/stfaun/subscriptions","organizations_url":"https://api.github.com/users/stfaun/orgs","repos_url":"https://api.github.com/users/stfaun/repos","events_url":"https://api.github.com/users/stfaun/events{/privacy}","received_events_url":"https://api.github.com/users/stfaun/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-04-22T07:24:57Z","updated_at":"2021-04-22T07:24:57Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"In my business, I store a sparse Array into ClickHouse with two columns. e.g.\r\n\r\n```\r\nCREATE TABLE sparse_array(\r\n    array_index Array(Int32),\r\n    array_value Array(Int32)\r\n) ENGINE = Log;\r\n```\r\n\r\nNow, I want to merge the Array, so I use sumMap aggregation function. e.g.\r\n\r\n```\r\nSELECT\r\n    sumMap(array_index, array_value)\r\nFROM sparse_array\r\n```\r\n\r\nBut the performance of the aggregation is not good enough for me. \r\n\r\nI find that sumMap use a map to calculate the result for sumMap aggregation. I think if the key argument Array is sorted, it should get a better performance for the aggregation.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23485/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23485/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23448","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23448/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23448/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23448/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/23448","id":864036012,"node_id":"MDU6SXNzdWU4NjQwMzYwMTI=","number":23448,"title":"Support quantile(level, expr)","user":{"login":"cw9","id":6710599,"node_id":"MDQ6VXNlcjY3MTA1OTk=","avatar_url":"https://avatars.githubusercontent.com/u/6710599?v=4","gravatar_id":"","url":"https://api.github.com/users/cw9","html_url":"https://github.com/cw9","followers_url":"https://api.github.com/users/cw9/followers","following_url":"https://api.github.com/users/cw9/following{/other_user}","gists_url":"https://api.github.com/users/cw9/gists{/gist_id}","starred_url":"https://api.github.com/users/cw9/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/cw9/subscriptions","organizations_url":"https://api.github.com/users/cw9/orgs","repos_url":"https://api.github.com/users/cw9/repos","events_url":"https://api.github.com/users/cw9/events{/privacy}","received_events_url":"https://api.github.com/users/cw9/received_events","type":"User","site_admin":false},"labels":[{"id":845247686,"node_id":"MDU6TGFiZWw4NDUyNDc2ODY=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/usability","name":"usability","color":"ebf28c","default":false,"description":""},{"id":1507867504,"node_id":"MDU6TGFiZWwxNTA3ODY3NTA0","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/st-hold","name":"st-hold","color":"e5b890","default":false,"description":"We've paused the work on issue for some reason"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2021-04-21T15:53:27Z","updated_at":"2021-05-10T19:19:55Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"The [quantile functions](https://clickhouse.tech/docs/en/sql-reference/aggregate-functions/reference/quantile/) in ClickHouse supports `quantile(level)(expr)`, is it possible to support `quantile(level, expr)`? \r\nThe latter format is much easier to use with standard SQL libraries.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23448/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23448/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23444","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23444/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23444/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23444/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/23444","id":863924266,"node_id":"MDU6SXNzdWU4NjM5MjQyNjY=","number":23444,"title":"Major slowdown on queries with multiple subquery levels","user":{"login":"vpanfilov","id":11993879,"node_id":"MDQ6VXNlcjExOTkzODc5","avatar_url":"https://avatars.githubusercontent.com/u/11993879?v=4","gravatar_id":"","url":"https://api.github.com/users/vpanfilov","html_url":"https://github.com/vpanfilov","followers_url":"https://api.github.com/users/vpanfilov/followers","following_url":"https://api.github.com/users/vpanfilov/following{/other_user}","gists_url":"https://api.github.com/users/vpanfilov/gists{/gist_id}","starred_url":"https://api.github.com/users/vpanfilov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vpanfilov/subscriptions","organizations_url":"https://api.github.com/users/vpanfilov/orgs","repos_url":"https://api.github.com/users/vpanfilov/repos","events_url":"https://api.github.com/users/vpanfilov/events{/privacy}","received_events_url":"https://api.github.com/users/vpanfilov/received_events","type":"User","site_admin":false},"labels":[{"id":756395244,"node_id":"MDU6TGFiZWw3NTYzOTUyNDQ=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/performance","name":"performance","color":"c2e0c6","default":false,"description":null},{"id":2788693937,"node_id":"MDU6TGFiZWwyNzg4NjkzOTM3","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-cte","name":"comp-cte","color":"b5bcff","default":false,"description":"common table expression (WITH ... SELECT)"}],"state":"open","locked":false,"assignee":{"login":"kitaisreal","id":22458333,"node_id":"MDQ6VXNlcjIyNDU4MzMz","avatar_url":"https://avatars.githubusercontent.com/u/22458333?v=4","gravatar_id":"","url":"https://api.github.com/users/kitaisreal","html_url":"https://github.com/kitaisreal","followers_url":"https://api.github.com/users/kitaisreal/followers","following_url":"https://api.github.com/users/kitaisreal/following{/other_user}","gists_url":"https://api.github.com/users/kitaisreal/gists{/gist_id}","starred_url":"https://api.github.com/users/kitaisreal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kitaisreal/subscriptions","organizations_url":"https://api.github.com/users/kitaisreal/orgs","repos_url":"https://api.github.com/users/kitaisreal/repos","events_url":"https://api.github.com/users/kitaisreal/events{/privacy}","received_events_url":"https://api.github.com/users/kitaisreal/received_events","type":"User","site_admin":false},"assignees":[{"login":"kitaisreal","id":22458333,"node_id":"MDQ6VXNlcjIyNDU4MzMz","avatar_url":"https://avatars.githubusercontent.com/u/22458333?v=4","gravatar_id":"","url":"https://api.github.com/users/kitaisreal","html_url":"https://github.com/kitaisreal","followers_url":"https://api.github.com/users/kitaisreal/followers","following_url":"https://api.github.com/users/kitaisreal/following{/other_user}","gists_url":"https://api.github.com/users/kitaisreal/gists{/gist_id}","starred_url":"https://api.github.com/users/kitaisreal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kitaisreal/subscriptions","organizations_url":"https://api.github.com/users/kitaisreal/orgs","repos_url":"https://api.github.com/users/kitaisreal/repos","events_url":"https://api.github.com/users/kitaisreal/events{/privacy}","received_events_url":"https://api.github.com/users/kitaisreal/received_events","type":"User","site_admin":false}],"milestone":null,"comments":5,"created_at":"2021-04-21T13:59:36Z","updated_at":"2021-11-11T07:05:50Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Hello. We use fairly complicated dynamically-generated nested queries in our project and discovered strange performance issues on queries with multiple levels of filtering.\r\n\r\n**How to reproduce**\r\n* Tested on version 21.3.6.55\r\n* Minimal reproducible example that leads to terrible performance:\r\n```sql\r\nWITH\r\n  initial_query AS (\r\n    SELECT 1 AS number\r\n  ),\r\n  query1 AS (\r\n    SELECT *, number1 AS number FROM (\r\n      SELECT *, number AS number1\r\n      FROM initial_query\r\n      WHERE number IN (SELECT number FROM initial_query)\r\n    )\r\n  ),\r\n  query2 AS (\r\n    SELECT *, number2 AS number FROM (\r\n      SELECT *, number AS number2\r\n      FROM query1\r\n      WHERE number IN (SELECT number FROM query1)\r\n    )\r\n  ),\r\n  query3 AS (\r\n    SELECT *, number3 AS number FROM (\r\n      SELECT *, number AS number3\r\n      FROM query2\r\n      WHERE number IN (SELECT number FROM query2)\r\n    )\r\n  ),\r\n  query4 AS (\r\n    SELECT *, number4 AS number FROM (\r\n      SELECT *, number AS number4 FROM query3\r\n      WHERE number IN (SELECT number FROM query3)\r\n    )\r\n  )\r\nSELECT * FROM query4\r\n```\r\n```\r\n1 rows in set. Elapsed: 78.911 sec.\r\n```\r\n\r\nThe more nesting levels are used, the slower is the performance: \r\n\r\n- query1 ~ 0.005 sec.\r\n- query2 ~ 0.05 sec.\r\n- query3 ~ 1.5 sec.\r\n- query4 ~ 80 sec.\r\n\r\n**Expected performance**\r\nThe query should execute almost immediately","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23444/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23444/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23416","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23416/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23416/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23416/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/23416","id":863495452,"node_id":"MDU6SXNzdWU4NjM0OTU0NTI=","number":23416,"title":"Join Engine - Cannot find column `xxx` in source stream","user":{"login":"maver1ck","id":4006010,"node_id":"MDQ6VXNlcjQwMDYwMTA=","avatar_url":"https://avatars.githubusercontent.com/u/4006010?v=4","gravatar_id":"","url":"https://api.github.com/users/maver1ck","html_url":"https://github.com/maver1ck","followers_url":"https://api.github.com/users/maver1ck/followers","following_url":"https://api.github.com/users/maver1ck/following{/other_user}","gists_url":"https://api.github.com/users/maver1ck/gists{/gist_id}","starred_url":"https://api.github.com/users/maver1ck/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/maver1ck/subscriptions","organizations_url":"https://api.github.com/users/maver1ck/orgs","repos_url":"https://api.github.com/users/maver1ck/repos","events_url":"https://api.github.com/users/maver1ck/events{/privacy}","received_events_url":"https://api.github.com/users/maver1ck/received_events","type":"User","site_admin":false},"labels":[{"id":386401505,"node_id":"MDU6TGFiZWwzODY0MDE1MDU=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/bug","name":"bug","color":"ee0701","default":true,"description":"Confirmed user-visible misbehaviour in official release"},{"id":1507867504,"node_id":"MDU6TGFiZWwxNTA3ODY3NTA0","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/st-hold","name":"st-hold","color":"e5b890","default":false,"description":"We've paused the work on issue for some reason"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2021-04-21T06:29:29Z","updated_at":"2021-06-18T17:48:56Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"**Describe the bug**\r\n\r\nI'm using Join Engine.\r\nI can use it with joinGet:\r\n```\r\nselect *, joinGet('kafka.umts_join', 'OFFSET', TOPIC, PARTITION)  from kafka.umts u limit 10;\r\n...\r\n10 rows in set. Elapsed: 0.082 sec.\r\n```\r\n\r\nBut when I'm trying \r\n\r\n```\r\nselect * from kafka.umts u any left join `kafka`.`umts_join` using (TOPIC, PARTITION) limit 10;\r\n```\r\nI'm getting exception:\r\n```\r\nCode: 8. DB::Exception: Received from localhost:9000. DB::Exception: Cannot find column `umts_join.OFFSET` in source stream.\r\n```\r\n\r\n**Does it reproduce on recent release?**\r\nYes. I'm using 21.4.4.30 with revision 54449\r\n\r\n**How to reproduce**\r\n* Which ClickHouse server version to use 21.4.4.30 with revision 54449\r\n* Which interface to use, if matters clickhouse-client\r\n* Non-default settings, if any: I'm using distrubuted env on K8s started with clickhouse-operator.\r\n* `CREATE TABLE` statements for all tables involved\r\n```\r\ncreate table test (TOPIC String, PARTITION UInt64, OFFSET UInt64, ID UInt64) ENGINE ReplicatedMergeTree('/clickhouse/tables/{shard}/{database}/test', '{replica}') ORDER BY (TOPIC, PARTITION, OFFSET)\r\n\r\ncreate table test_join (TOPIC String, PARTITION UInt64, OFFSET UInt64)  ENGINE = Join(ANY, LEFT, `TOPIC`, `PARTITION`) SETTINGS join_any_take_last_row = 1;\r\n\r\ninsert into test values('abc',0,0,0);\r\n\r\ninsert into test_join values('abc',0,1);\r\n\r\nselect *, joinGet('test_join', 'OFFSET', TOPIC, PARTITION) from test;\r\n┌─TOPIC─┬─PARTITION─┬─OFFSET─┬─ID─┬─joinGet('test_join', 'OFFSET', TOPIC, PARTITION)─┐\r\n│ abc   │         0 │      0 │  0 │                                                1 │\r\n└───────┴───────────┴────────┴────┴──────────────────────────────────────────────────┘\r\n\r\nselect * from test any left join test_join using (TOPIC, PARTITION);\r\n\r\nCode: 8. DB::Exception: Received from localhost:9000. DB::Exception: Cannot find column `test_join.OFFSET` in source stream.\r\n``` \r\n* Queries to run that lead to unexpected result\r\n\r\n**Expected behavior**\r\nJoin should work.\r\n\r\n**Error message and/or stacktrace**\r\n```\r\n2021.04.21 06:22:45.714913 [ 38 ] {490ff41b-6d1f-4502-ab11-45045e7cf1b1} <Error> executeQuery: Code: 8, e.displayText() = DB::Exception: Cannot find column `.inner.umts_join.OFFSET` in source stream (version 21.4.4.30 (official build)) (from [::ffff:127.0.0.1]:44682) (in query: select * from kafka.umts u any left join `kafka`.`umts_join` using (TOPIC, PARTITION) limit 10;), Stack trace (when copying this message, always include the lines below):\r\n\r\n0. DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, bool) @ 0x8914f0a in /usr/bin/clickhouse\r\n1. DB::ActionsDAG::makeConvertingActions(std::__1::vector<DB::ColumnWithTypeAndName, std::__1::allocator<DB::ColumnWithTypeAndName> > const&, std::__1::vector<DB::ColumnWithTypeAndName, std::__1::allocator<DB::ColumnWithTypeAndName> > const&, DB::ActionsDAG::MatchColumnsMode, bool, bool, std::__1::unordered_map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::hash<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::equal_to<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > >*) @ 0xf2bc3a4 in /usr/bin/clickhouse\r\n2. DB::InterpreterSelectQuery::buildQueryPlan(DB::QueryPlan&) @ 0xf4dac89 in /usr/bin/clickhouse\r\n3. ? @ 0xfb7db5e in /usr/bin/clickhouse\r\n4. DB::ClusterProxy::SelectStreamFactory::createForShard(DB::Cluster::ShardInfo const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::shared_ptr<DB::IAST> const&, std::__1::shared_ptr<DB::Context> const&, std::__1::shared_ptr<DB::Throttler> const&, DB::SelectQueryInfo const&, std::__1::vector<std::__1::unique_ptr<DB::QueryPlan, std::__1::default_delete<DB::QueryPlan> >, std::__1::allocator<std::__1::unique_ptr<DB::QueryPlan, std::__1::default_delete<DB::QueryPlan> > > >&, std::__1::vector<DB::Pipe, std::__1::allocator<DB::Pipe> >&, std::__1::vector<DB::Pipe, std::__1::allocator<DB::Pipe> >&, Poco::Logger*) @ 0xfb7aa61 in /usr/bin/clickhouse\r\n5. DB::ClusterProxy::executeQuery(DB::QueryPlan&, DB::ClusterProxy::IStreamFactory&, Poco::Logger*, std::__1::shared_ptr<DB::IAST> const&, DB::Context const&, DB::SelectQueryInfo const&) @ 0xfb8348f in /usr/bin/clickhouse\r\n6. DB::StorageDistributed::read(DB::QueryPlan&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&, std::__1::shared_ptr<DB::StorageInMemoryMetadata const> const&, DB::SelectQueryInfo&, DB::Context const&, DB::QueryProcessingStage::Enum, unsigned long, unsigned int) @ 0xfb6aee8 in /usr/bin/clickhouse\r\n7. DB::StorageMaterializedView::read(DB::QueryPlan&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&, std::__1::shared_ptr<DB::StorageInMemoryMetadata const> const&, DB::SelectQueryInfo&, DB::Context const&, DB::QueryProcessingStage::Enum, unsigned long, unsigned int) @ 0xfbf3314 in /usr/bin/clickhouse\r\n8. DB::InterpreterSelectQuery::executeFetchColumns(DB::QueryProcessingStage::Enum, DB::QueryPlan&) @ 0xf4e669e in /usr/bin/clickhouse\r\n9. DB::InterpreterSelectQuery::executeImpl(DB::QueryPlan&, std::__1::shared_ptr<DB::IBlockInputStream> const&, std::__1::optional<DB::Pipe>) @ 0xf4dbdf1 in /usr/bin/clickhouse\r\n10. DB::InterpreterSelectQuery::buildQueryPlan(DB::QueryPlan&) @ 0xf4dac0b in /usr/bin/clickhouse\r\n11. DB::InterpreterSelectWithUnionQuery::buildQueryPlan(DB::QueryPlan&) @ 0xf801db3 in /usr/bin/clickhouse\r\n12. DB::InterpreterSelectWithUnionQuery::execute() @ 0xf802f3e in /usr/bin/clickhouse\r\n13. ? @ 0xf9a4ec2 in /usr/bin/clickhouse\r\n14. DB::executeQuery(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, DB::Context&, bool, DB::QueryProcessingStage::Enum, bool) @ 0xf9a3803 in /usr/bin/clickhouse\r\n15. DB::TCPHandler::runImpl() @ 0x1015b04d in /usr/bin/clickhouse\r\n16. DB::TCPHandler::run() @ 0x1016d5c9 in /usr/bin/clickhouse\r\n17. Poco::Net::TCPServerConnection::start() @ 0x1282790f in /usr/bin/clickhouse\r\n18. Poco::Net::TCPServerDispatcher::run() @ 0x12829321 in /usr/bin/clickhouse\r\n19. Poco::PooledThread::run() @ 0x1295fa49 in /usr/bin/clickhouse\r\n20. Poco::ThreadImpl::runnableEntry(void*) @ 0x1295b8aa in /usr/bin/clickhouse\r\n21. start_thread @ 0x9609 in /usr/lib/x86_64-linux-gnu/libpthread-2.31.so\r\n22. clone @ 0x122293 in /usr/lib/x86_64-linux-gnu/libc-2.31.so\r\n\r\n2021.04.21 06:22:45.715339 [ 38 ] {490ff41b-6d1f-4502-ab11-45045e7cf1b1} <Error> TCPHandler: Code: 8, e.displayText() = DB::Exception: Cannot find column `umts_join.OFFSET` in source stream, Stack trace:\r\n```\r\n\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23416/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23416/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23376","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23376/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23376/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23376/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/23376","id":863118797,"node_id":"MDU6SXNzdWU4NjMxMTg3OTc=","number":23376,"title":"`clickhouse-client --multiquery`: allow to specify queries in the value of the `--multiquery` parameter.","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":845247686,"node_id":"MDU6TGFiZWw4NDUyNDc2ODY=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/usability","name":"usability","color":"ebf28c","default":false,"description":""},{"id":1365579236,"node_id":"MDU6TGFiZWwxMzY1NTc5MjM2","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/minor","name":"minor","color":"FFF8F8","default":false,"description":"Priority: minor"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-04-20T18:40:15Z","updated_at":"2021-04-20T18:40:21Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"**Use case**\r\n\r\nCurrently query is accepted in `--query` parameter or in stdin.\r\nThere is also `--multiquery` (or `-n`) parameter that is a switch to allow multiple queries.\r\n\r\nExample:\r\n```\r\nclickhouse-client --query \"SELECT 1\"\r\nclickhouse-client --multiquery --query \"SELECT 1; SELECT 2;\"\r\n```\r\n\r\nIt will be very intuitive if one will be able to write:\r\n\r\n```\r\nclickhouse-client --multiquery \"SELECT 1; SELECT 2;\"\r\n```\r\n\r\nSo, the `--multiquery` will act not only as a switch but also as a parameter with value,\r\nif there is no `--query` parameter and the `--multiquery` parameter is presented in its full form (not `-n`).","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23376/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23376/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23344","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23344/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23344/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23344/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/23344","id":862332718,"node_id":"MDU6SXNzdWU4NjIzMzI3MTg=","number":23344,"title":"The following obscure query does not succeed.","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":1507867504,"node_id":"MDU6TGFiZWwxNTA3ODY3NTA0","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/st-hold","name":"st-hold","color":"e5b890","default":false,"description":"We've paused the work on issue for some reason"},{"id":1955634273,"node_id":"MDU6TGFiZWwxOTU1NjM0Mjcz","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/testing","name":"testing","color":"c9a224","default":false,"description":"Special issue with list of bugs found by CI"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-04-20T02:33:00Z","updated_at":"2021-08-16T08:51:36Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"**Describe the bug**\r\n`\r\nSELECT logTrace(repeat('Hello', 100)), ignore(*) FROM (SELECT ignore((SELECT groupArrayState(([number], [number])) FROM numbers(19000000))))\r\n`\r\n\r\n```\r\nMissing columns: 'ignore(_subquery10)' while processing query: 'SELECT logTrace(repeat('Hello', 100)), ignore(`ignore(_subquery10)`) FROM (SELECT ignore((SELECT groupArrayState(([number], [number])) FROM numbers(19000000))))', required columns: 'ignore(_subquery10)' 'ignore(_subquery10)'.\r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23344/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23344/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23320","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23320/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23320/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23320/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/23320","id":861896292,"node_id":"MDU6SXNzdWU4NjE4OTYyOTI=","number":23320,"title":"Syntax highlighting in clickhouse-client may not work correctly in multiline queries.","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":845247686,"node_id":"MDU6TGFiZWw4NDUyNDc2ODY=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/usability","name":"usability","color":"ebf28c","default":false,"description":""}],"state":"open","locked":false,"assignee":{"login":"amosbird","id":5085485,"node_id":"MDQ6VXNlcjUwODU0ODU=","avatar_url":"https://avatars.githubusercontent.com/u/5085485?v=4","gravatar_id":"","url":"https://api.github.com/users/amosbird","html_url":"https://github.com/amosbird","followers_url":"https://api.github.com/users/amosbird/followers","following_url":"https://api.github.com/users/amosbird/following{/other_user}","gists_url":"https://api.github.com/users/amosbird/gists{/gist_id}","starred_url":"https://api.github.com/users/amosbird/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/amosbird/subscriptions","organizations_url":"https://api.github.com/users/amosbird/orgs","repos_url":"https://api.github.com/users/amosbird/repos","events_url":"https://api.github.com/users/amosbird/events{/privacy}","received_events_url":"https://api.github.com/users/amosbird/received_events","type":"User","site_admin":false},"assignees":[{"login":"amosbird","id":5085485,"node_id":"MDQ6VXNlcjUwODU0ODU=","avatar_url":"https://avatars.githubusercontent.com/u/5085485?v=4","gravatar_id":"","url":"https://api.github.com/users/amosbird","html_url":"https://github.com/amosbird","followers_url":"https://api.github.com/users/amosbird/followers","following_url":"https://api.github.com/users/amosbird/following{/other_user}","gists_url":"https://api.github.com/users/amosbird/gists{/gist_id}","starred_url":"https://api.github.com/users/amosbird/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/amosbird/subscriptions","organizations_url":"https://api.github.com/users/amosbird/orgs","repos_url":"https://api.github.com/users/amosbird/repos","events_url":"https://api.github.com/users/amosbird/events{/privacy}","received_events_url":"https://api.github.com/users/amosbird/received_events","type":"User","site_admin":false}],"milestone":null,"comments":1,"created_at":"2021-04-19T20:57:16Z","updated_at":"2022-01-28T14:28:43Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"https://github.com/AmokHuginnsson/replxx/issues/106","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23320/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23320/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23297","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23297/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23297/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23297/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/23297","id":861074074,"node_id":"MDU6SXNzdWU4NjEwNzQwNzQ=","number":23297,"title":"Parquet filter pushdown ","user":{"login":"filimonov","id":1549571,"node_id":"MDQ6VXNlcjE1NDk1NzE=","avatar_url":"https://avatars.githubusercontent.com/u/1549571?v=4","gravatar_id":"","url":"https://api.github.com/users/filimonov","html_url":"https://github.com/filimonov","followers_url":"https://api.github.com/users/filimonov/followers","following_url":"https://api.github.com/users/filimonov/following{/other_user}","gists_url":"https://api.github.com/users/filimonov/gists{/gist_id}","starred_url":"https://api.github.com/users/filimonov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/filimonov/subscriptions","organizations_url":"https://api.github.com/users/filimonov/orgs","repos_url":"https://api.github.com/users/filimonov/repos","events_url":"https://api.github.com/users/filimonov/events{/privacy}","received_events_url":"https://api.github.com/users/filimonov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-04-19T08:58:19Z","updated_at":"2021-06-22T23:09:06Z","closed_at":null,"author_association":"COLLABORATOR","active_lock_reason":null,"body":"Limit reads from parquet file, when filters exist:  similar https://drill.apache.org/docs/parquet-filter-pushdown/","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23297/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23297/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23245","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23245/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23245/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23245/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/23245","id":860504506,"node_id":"MDU6SXNzdWU4NjA1MDQ1MDY=","number":23245,"title":"A query with large amount of UNION ALL may have larger memory usage than someone may expect.","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":1532016596,"node_id":"MDU6TGFiZWwxNTMyMDE2NTk2","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/memory","name":"memory","color":"e99695","default":false,"description":"When memory usage is higher than expected"}],"state":"open","locked":false,"assignee":{"login":"KochetovNicolai","id":4092911,"node_id":"MDQ6VXNlcjQwOTI5MTE=","avatar_url":"https://avatars.githubusercontent.com/u/4092911?v=4","gravatar_id":"","url":"https://api.github.com/users/KochetovNicolai","html_url":"https://github.com/KochetovNicolai","followers_url":"https://api.github.com/users/KochetovNicolai/followers","following_url":"https://api.github.com/users/KochetovNicolai/following{/other_user}","gists_url":"https://api.github.com/users/KochetovNicolai/gists{/gist_id}","starred_url":"https://api.github.com/users/KochetovNicolai/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/KochetovNicolai/subscriptions","organizations_url":"https://api.github.com/users/KochetovNicolai/orgs","repos_url":"https://api.github.com/users/KochetovNicolai/repos","events_url":"https://api.github.com/users/KochetovNicolai/events{/privacy}","received_events_url":"https://api.github.com/users/KochetovNicolai/received_events","type":"User","site_admin":false},"assignees":[{"login":"KochetovNicolai","id":4092911,"node_id":"MDQ6VXNlcjQwOTI5MTE=","avatar_url":"https://avatars.githubusercontent.com/u/4092911?v=4","gravatar_id":"","url":"https://api.github.com/users/KochetovNicolai","html_url":"https://github.com/KochetovNicolai","followers_url":"https://api.github.com/users/KochetovNicolai/followers","following_url":"https://api.github.com/users/KochetovNicolai/following{/other_user}","gists_url":"https://api.github.com/users/KochetovNicolai/gists{/gist_id}","starred_url":"https://api.github.com/users/KochetovNicolai/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/KochetovNicolai/subscriptions","organizations_url":"https://api.github.com/users/KochetovNicolai/orgs","repos_url":"https://api.github.com/users/KochetovNicolai/repos","events_url":"https://api.github.com/users/KochetovNicolai/events{/privacy}","received_events_url":"https://api.github.com/users/KochetovNicolai/received_events","type":"User","site_admin":false}],"milestone":null,"comments":4,"created_at":"2021-04-17T20:05:27Z","updated_at":"2021-06-22T21:42:28Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"The query:\r\n\r\n`SELECT sum(cityHash64(*)) FROM (SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1 UNION ALL SELECT * FROM test.hits LIMIT 1)`\r\n\r\neats slightly more than 10 GB for no reason.\r\nThe value of `max_threads` does not matter.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23245/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23245/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23240","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23240/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23240/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23240/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/23240","id":860502099,"node_id":"MDU6SXNzdWU4NjA1MDIwOTk=","number":23240,"title":"If query contains ridiculous amount of UNION ALL, the pipeline can be suboptimal.","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":756395244,"node_id":"MDU6TGFiZWw3NTYzOTUyNDQ=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/performance","name":"performance","color":"c2e0c6","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-04-17T19:52:20Z","updated_at":"2021-04-17T19:52:20Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"Example with a chain of 1000 UNION ALL statements:\r\n\r\n`clickhouse-client --send_logs_level debug --query \"$(echo 'EXPLAIN PIPELINE SELECT sum(*) FROM (SELECT 1'; yes 'UNION ALL SELECT count() FROM numbers_mt(1000000000)' | head -n1000; echo ')')\"`\r\n\r\nEvery UNION ALL element will use 16 (max_threads) streams to process. Although we can lower the amount of streams in pipeline to save memory.\r\n\r\nProposed solution: add a setting `max_streams_per_union_all_query_to_max_threads_ratio`, default 10.\r\nIf the number of streams in total will be larger than `max_threads` * `max_streams_per_union_all_query_to_max_threads_ratio`, e.g. 160 - lower the number of streams per UNION ALL element accordingly.\r\n\r\nE.g. if I have ridiculous amount of UNION ALL elements, each of them will be processed with one stream.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23240/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23240/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23239","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23239/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23239/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23239/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/23239","id":860499025,"node_id":"MDU6SXNzdWU4NjA0OTkwMjU=","number":23239,"title":"LIMIT pushdown to UNION ALL queries","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":756395244,"node_id":"MDU6TGFiZWw3NTYzOTUyNDQ=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/performance","name":"performance","color":"c2e0c6","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-04-17T19:35:52Z","updated_at":"2021-04-17T19:36:14Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"The first two queries below are slow due to missing optimization.\r\nThe last query is fast - this is how them are supposed to be optimized.\r\n\r\n```\r\nmilovidov-desktop :) SELECT * FROM (SELECT * FROM numbers(1000000000) ORDER BY number UNION ALL SELECT * FROM numbers(1000000000) ORDER BY number) ORDER BY number LIMIT 10\r\n\r\nSELECT *\r\nFROM \r\n(\r\n    SELECT *\r\n    FROM numbers(1000000000)\r\n    ORDER BY number ASC\r\n    UNION ALL\r\n    SELECT *\r\n    FROM numbers(1000000000)\r\n    ORDER BY number ASC\r\n)\r\nORDER BY number ASC\r\nLIMIT 10\r\n\r\nQuery id: ad5e3c17-6840-480a-ae12-27fe90d60e71\r\n\r\nCancelling query.\r\nOk.\r\nQuery was cancelled.\r\n\r\n0 rows in set. Elapsed: 2.809 sec. Processed 203.20 million rows, 1.63 GB (72.34 million rows/s., 578.76 MB/s.) \r\n\r\nmilovidov-desktop :) SELECT * FROM (SELECT * FROM numbers(1000000000) ORDER BY number UNION ALL SELECT * FROM numbers(1000000000) ORDER BY number) LIMIT 10\r\n\r\nSELECT *\r\nFROM \r\n(\r\n    SELECT *\r\n    FROM numbers(1000000000)\r\n    ORDER BY number ASC\r\n    UNION ALL\r\n    SELECT *\r\n    FROM numbers(1000000000)\r\n    ORDER BY number ASC\r\n)\r\nLIMIT 10\r\n\r\nQuery id: 98d7340d-4efb-4c13-aa4a-2dddb3aa0602\r\n\r\n→ Progress: 241.58 million rows, 1.93 GB (73.05 million rows/s., 584.37 MB/s.) ███████████████████▌                                                                                                                                               11%^Cancelling query.\r\nOk.\r\nQuery was cancelled.\r\n\r\n0 rows in set. Elapsed: 3.509 sec. Processed 256.45 million rows, 2.05 GB (73.09 million rows/s., 584.70 MB/s.) \r\n\r\nmilovidov-desktop :) SELECT * FROM (SELECT * FROM numbers(1000000000) ORDER BY number LIMIT 10 UNION ALL SELECT * FROM numbers(1000000000) ORDER BY number LIMIT 10) ORDER BY number LIMIT 10\r\n\r\nSELECT *\r\nFROM \r\n(\r\n    SELECT *\r\n    FROM numbers(1000000000)\r\n    ORDER BY number ASC\r\n    LIMIT 10\r\n    UNION ALL\r\n    SELECT *\r\n    FROM numbers(1000000000)\r\n    ORDER BY number ASC\r\n    LIMIT 10\r\n)\r\nORDER BY number ASC\r\nLIMIT 10\r\n\r\nQuery id: a550a49f-a792-4084-8294-e6e6304281ce\r\n\r\n┌─number─┐\r\n│      0 │\r\n│      0 │\r\n│      1 │\r\n│      1 │\r\n│      2 │\r\n│      2 │\r\n│      3 │\r\n│      3 │\r\n│      4 │\r\n│      4 │\r\n└────────┘\r\n\r\n10 rows in set. Elapsed: 0.794 sec. Processed 2.00 billion rows, 16.00 GB (2.52 billion rows/s., 20.16 GB/s.)\r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23239/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23239/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23214","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23214/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23214/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23214/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/23214","id":860348700,"node_id":"MDU6SXNzdWU4NjAzNDg3MDA=","number":23214,"title":"which version support field=value in JOIN ON clause","user":{"login":"SE2AI","id":21308534,"node_id":"MDQ6VXNlcjIxMzA4NTM0","avatar_url":"https://avatars.githubusercontent.com/u/21308534?v=4","gravatar_id":"","url":"https://api.github.com/users/SE2AI","html_url":"https://github.com/SE2AI","followers_url":"https://api.github.com/users/SE2AI/followers","following_url":"https://api.github.com/users/SE2AI/following{/other_user}","gists_url":"https://api.github.com/users/SE2AI/gists{/gist_id}","starred_url":"https://api.github.com/users/SE2AI/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/SE2AI/subscriptions","organizations_url":"https://api.github.com/users/SE2AI/orgs","repos_url":"https://api.github.com/users/SE2AI/repos","events_url":"https://api.github.com/users/SE2AI/events{/privacy}","received_events_url":"https://api.github.com/users/SE2AI/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-04-17T07:32:16Z","updated_at":"2021-04-17T14:40:00Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"my test case is:\r\n\r\n`select A.country, B.area from city A inner join city B on A.city=B.city and B.area='south'`\r\n\r\nException shows: No columns in one of equality side.: While processing B.area = 'south'\r\n\r\nI search for the exception in issues and find the same question asked before #18720 and #19685.\r\n\r\nIndeed, by using  `select A.country, B.area from city A inner join city B on A.city=B.city where B.area='south'` could solve it, but maybe the performance would be better if putting `B.area='south'` before `where`.\r\n\r\nThe question is\r\n1. will `on B.area='south'` improve performance for Clickhouse?\r\n2. I test it on V21.1.2.15. do you have any roadmap for supporting this feature? or which version has already implemented the feature?\r\n\r\n\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23214/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23214/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23206","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23206/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23206/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23206/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/23206","id":860182971,"node_id":"MDU6SXNzdWU4NjAxODI5NzE=","number":23206,"title":"Clickhouse Bouncer.","user":{"login":"den-crane","id":19737682,"node_id":"MDQ6VXNlcjE5NzM3Njgy","avatar_url":"https://avatars.githubusercontent.com/u/19737682?v=4","gravatar_id":"","url":"https://api.github.com/users/den-crane","html_url":"https://github.com/den-crane","followers_url":"https://api.github.com/users/den-crane/followers","following_url":"https://api.github.com/users/den-crane/following{/other_user}","gists_url":"https://api.github.com/users/den-crane/gists{/gist_id}","starred_url":"https://api.github.com/users/den-crane/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/den-crane/subscriptions","organizations_url":"https://api.github.com/users/den-crane/orgs","repos_url":"https://api.github.com/users/den-crane/repos","events_url":"https://api.github.com/users/den-crane/events{/privacy}","received_events_url":"https://api.github.com/users/den-crane/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2021-04-16T21:28:13Z","updated_at":"2021-04-18T17:18:32Z","closed_at":null,"author_association":"COLLABORATOR","active_lock_reason":null,"body":"Clickhouse Bouncer - lightweight connection gateway/reverse-proxy.\r\n\r\nSupport both HTTP (HTTPS?) / TCP Clickhouse protocols.\r\n\r\nAbility to connect to live nodes.\r\nAbility to connect to replica-sets depending on user profile. (Imagine we have 20 shards * 3 replica. 10 Super fast replica & 10+10 slow. And we want to route real-time queries from USER1 to the fast replicas and slow analytical queries from USER2, USER3 route to the slow replica-sets).\r\n\r\nBasically https://github.com/Vertamedia/chproxy can do it but only for HTTP/HTTPS.\r\n(https://github.com/Vertamedia/chproxy  _May proxy requests to multiple distinct ClickHouse clusters depending on the input user. For instance, requests from appserver user may go to stats-raw cluster, while requests from reportserver user may go to stats-aggregate cluster._)","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23206/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23206/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23203","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23203/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23203/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23203/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/23203","id":860058391,"node_id":"MDU6SXNzdWU4NjAwNTgzOTE=","number":23203,"title":"Should TTL Delete merges be limited by the size of the merge pool?","user":{"login":"genzgd","id":625882,"node_id":"MDQ6VXNlcjYyNTg4Mg==","avatar_url":"https://avatars.githubusercontent.com/u/625882?v=4","gravatar_id":"","url":"https://api.github.com/users/genzgd","html_url":"https://github.com/genzgd","followers_url":"https://api.github.com/users/genzgd/followers","following_url":"https://api.github.com/users/genzgd/following{/other_user}","gists_url":"https://api.github.com/users/genzgd/gists{/gist_id}","starred_url":"https://api.github.com/users/genzgd/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/genzgd/subscriptions","organizations_url":"https://api.github.com/users/genzgd/orgs","repos_url":"https://api.github.com/users/genzgd/repos","events_url":"https://api.github.com/users/genzgd/events{/privacy}","received_events_url":"https://api.github.com/users/genzgd/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-04-16T18:08:23Z","updated_at":"2021-04-16T18:08:40Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"ClickHouse version 21.3.2\r\n\r\nSince TTL_DELETE merges can only make parts smaller, I'm sure why they are limited by the current size of the merge pool.\r\n \r\n```TTL_DELETE │ Not executing log entry queue-0011769928 of type MERGE_PARTS for part 20210408_35571_40560_6 because source parts size (36.47 GiB) is greater than the current maximum (4.00 GiB).``` \r\n\r\nIt seems like, as with mutations, the merge pool size should be ignored for these?\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23203/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23203/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23194","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23194/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23194/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23194/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/23194","id":859856898,"node_id":"MDU6SXNzdWU4NTk4NTY4OTg=","number":23194,"title":"Describe how identifiers in SELECT queries are resolved","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":1546440057,"node_id":"MDU6TGFiZWwxNTQ2NDQwMDU3","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/development","name":"development","color":"fc80df","default":false,"description":"Developement process & source code & implementation details"},{"id":3130891542,"node_id":"MDU6TGFiZWwzMTMwODkxNTQy","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/nightmare","name":"nightmare","color":"000000","default":false,"description":"Difficulty level"}],"state":"open","locked":false,"assignee":{"login":"kitaisreal","id":22458333,"node_id":"MDQ6VXNlcjIyNDU4MzMz","avatar_url":"https://avatars.githubusercontent.com/u/22458333?v=4","gravatar_id":"","url":"https://api.github.com/users/kitaisreal","html_url":"https://github.com/kitaisreal","followers_url":"https://api.github.com/users/kitaisreal/followers","following_url":"https://api.github.com/users/kitaisreal/following{/other_user}","gists_url":"https://api.github.com/users/kitaisreal/gists{/gist_id}","starred_url":"https://api.github.com/users/kitaisreal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kitaisreal/subscriptions","organizations_url":"https://api.github.com/users/kitaisreal/orgs","repos_url":"https://api.github.com/users/kitaisreal/repos","events_url":"https://api.github.com/users/kitaisreal/events{/privacy}","received_events_url":"https://api.github.com/users/kitaisreal/received_events","type":"User","site_admin":false},"assignees":[{"login":"kitaisreal","id":22458333,"node_id":"MDQ6VXNlcjIyNDU4MzMz","avatar_url":"https://avatars.githubusercontent.com/u/22458333?v=4","gravatar_id":"","url":"https://api.github.com/users/kitaisreal","html_url":"https://github.com/kitaisreal","followers_url":"https://api.github.com/users/kitaisreal/followers","following_url":"https://api.github.com/users/kitaisreal/following{/other_user}","gists_url":"https://api.github.com/users/kitaisreal/gists{/gist_id}","starred_url":"https://api.github.com/users/kitaisreal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kitaisreal/subscriptions","organizations_url":"https://api.github.com/users/kitaisreal/orgs","repos_url":"https://api.github.com/users/kitaisreal/repos","events_url":"https://api.github.com/users/kitaisreal/events{/privacy}","received_events_url":"https://api.github.com/users/kitaisreal/received_events","type":"User","site_admin":false}],"milestone":null,"comments":11,"created_at":"2021-04-16T14:16:25Z","updated_at":"2021-11-25T13:25:04Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"Query analysis in ClickHouse is more complicated than it is in standard SQL due to the following extensions:\r\n- aliases can be defined and used in any part of the query;\r\n- expressions can be used in any part of the query;\r\n- there is support for complex columns with subcolumns (although standard SQL also has some sort of it);\r\n- there is ARRAY JOIN;\r\n- lambda functions and higher order functions.\r\n\r\nThese extensions are very convenient for writing SQL queries we don't regret of them :)\r\n\r\nBut it is not convenient from implementation standpoint - many things are in different places in code and are underspecified. It makes further development difficult.\r\n\r\nLet's try to describe how identifiers in SELECT queries are resolved.\r\nThen we will have a chance to implement it in more consistent, easy to maintain fashion.\r\n\r\nI will try to describe how it works right now and how it is supposed to work after upcoming extensions.\r\nThe text below is only for ClickHouse experts.\r\n\r\n---\r\n\r\n1. Identifier can correspond to a column in a table in section FROM:\r\n\r\n```\r\nSELECT column FROM table\r\n```\r\n\r\n\r\n2. Identifier can be unqualified, qualified by table or table alias:\r\n\r\n```\r\nSELECT table.column FROM table\r\n```\r\n\r\n```\r\nSELECT t.column FROM table AS t\r\n```\r\n\r\n\r\n3. A table can be qualified with database name:\r\n\r\n```\r\nSELECT database.table.column FROM database.table\r\n```\r\n\r\n\r\n4. A question: should we allow to qualify column identifier with default database if it's not qualified in table identifier?\r\n\r\n```\r\nSELECT database.table.column FROM table\r\n```\r\n\r\n\r\n5. In case of multiple tables in a query, unqualified identifer will be searched in every table. If it is found in only one table, it will be resolved to this table. In case of ambiguity, exception should be thrown.\r\n\r\n```\r\nSELECT t1.x, t2.x, y FROM (SELECT x, y) AS t1, (SELECT x, z) AS t2\r\n```\r\n\r\n\r\n6. If query does not contain FROM section, it behaves the same way as if `FROM system.one` is present.\r\n\r\n```\r\nSELECT 1;\r\nSELECT dummy;\r\nSELECT one.dummy;\r\nSELECT system.one.dummy;\r\n```\r\n\r\nThis query also works:\r\n```\r\nSELECT *\r\n```\r\nBut we may remove the support for asterisk expansion in case if section FROM is omitted.\r\n\r\nThis query works in current version of ClickHouse, but we are not proud of this fact:\r\n```\r\nSELECT ***\r\n```\r\n\r\n\r\n7. Identifier can consist of multiple components and can be resolved to a column or a subcolumn of arbitrarily nested path or a table.\r\n\r\n```\r\nSELECT * FROM t WHERE x IN table;\r\nSELECT * FROM t WHERE x IN db.table;\r\nSELECT * FROM t WHERE dictHas(table, x);\r\nSELECT * FROM t WHERE joinGet(db.table, x);\r\n```\r\n\r\nIn this example, `x` is resolved to a column in table `t`, and `table`, `db.table` and `t` are resolved to tables.\r\n\r\n```\r\nSELECT nest.key.subkey FROM t\r\n```\r\n\r\nIn this example, `nest.key.subkey` is subcolumn of complex column `nest`. Ambiguity is possible. In case of ambiguity, exception should be thrown.\r\n\r\n\r\n8. Table expression in FROM section can contain arbitrary number of ARRAY JOIN or LEFT ARRAY JOIN expressions.\r\nOn the left is a table and on the right is a column of Array type.\r\n\r\n```\r\nSELECT * FROM (SELECT [1, 2, 3] AS arr) ARRAY JOIN arr\r\n```\r\n\r\nA column to array join can be specified by identifier (`arr` in the example above) or as immediate array (literal):\r\n\r\n```\r\nSELECT * FROM table ARRAY JOIN [1, 2, 3] AS arr\r\n```\r\n\r\nIf it is specified as literal, alias is required. A question: we may not require alias.\r\n\r\n\r\nA column to array join can be resolved to complex column (nested data structure) as well:\r\n\r\n```\r\nCREATE TEMPORARY TABLE test1 (a String, nest Nested(x String, y String));\r\n\r\nSELECT a, nest.* FROM test1 ARRAY JOIN nest;\r\nSELECT a, n.* FROM test1 ARRAY JOIN nest AS n;\r\n```\r\n\r\nNested data type is a syntactic sugar for `Array(Tuple(...))`:\r\n\r\n```\r\nCREATE TEMPORARY TABLE test1 (a String, nest Array(Tuple(x String, y String)));\r\n\r\nSELECT a, nest.* FROM test1 ARRAY JOIN nest;\r\nSELECT a, n.* FROM test1 ARRAY JOIN nest AS n;\r\n```\r\n\r\nIf alias is specified for the right hand side of array join: `ARRAY JOIN arr AS joined`, the `joined` alias will reference to array elements and the original name `arr` will reference to the original value.\r\n\r\nIf alias is not specified for the right hand side of array join: `ARRAY JOIN arr`, the original name `arr` (can be qualified or not) will reference to the array elements and the original arrays cannot be referenced.\r\n\r\n```\r\nSELECT table.nest FROM table ARRAY JOIN nest\r\n```\r\n\r\n\r\n9. Aliases can be specified for every expression in a query. Within the boundaries of one SELECT query/subquery, alias is globally visible, even before it's declaration.\r\n\r\n```\r\nSELECT 1 AS x, x, x + 1;\r\nSELECT x, x + 1, 1 AS x;\r\nSELECT x, 1 + (2 + (3 AS x));\r\n```\r\n\r\n\r\n10. Aliases defined outside of subquery are not visible in subqueries (but see below).\r\n\r\nUnless they are specified in WITH clause and `enable_global_with_statement` is set.\r\n\r\n```\r\nSELECT 123 AS x FROM (SELECT a, x FROM (SELECT 1 AS a, 2 AS b)); -- invalid query, identifier `x` in subquery is not found.\r\n```\r\n\r\n```\r\nSELECT 123 AS x, (SELECT x) AS y; -- does not work even for scalar subqueries.\r\nSELECT 123 AS x, 123 IN (SELECT x); -- does not work even for IN subquery either.\r\n```\r\n\r\n```\r\nSET enable_global_with_statement = 1; -- this is by default, BTW.\r\n\r\nWITH 123 AS x SELECT 1 FROM (SELECT a, x FROM (SELECT 1 AS a, 2 AS b)); -- ok, identifier `x` in subquery is defined in WITH section.\r\n\r\n-- here we refer to table `t` (defined as subquery) three times, one of them inside another scalar subquery.\r\nWITH t AS (SELECT 1) SELECT t, (SELECT * FROM t) FROM t;\r\n```\r\n\r\nWe want to change it in the following way:\r\n- aliases *and columns* from the outside will be visible inside subqueries;\r\n- ambiguity will be resolved by scoping - the nearest name to the current scope is selected;\r\n- columns in current scope are preferred for disambiguation to aliases from the outer scope;\r\n- this is needed to allow correlated subqueries;\r\n- the visibility of outer aliases inside FROM subqueries is mostly pointless but still usable for scalar values;\r\n\r\n\r\n11. Aliases defined in subquery are not visible outside of subquery (but see clarification below).\r\n\r\n```\r\nSELECT x FROM (SELECT y FROM table WHERE (1 AS x) = y) AS t; -- throws, because x is not visible outside.\r\n```\r\n\r\n```\r\nSELECT t.x FROM (SELECT * FROM (SELECT 1 AS x) AS t); -- throws, because the table name `t` is not visible outside.\r\nSELECT x FROM (SELECT * FROM (SELECT 1 AS x) AS t); -- ok.\r\n```\r\n\r\nA question: should we allow to refer to aliases from subqueries by the names qualified by subquery name?\r\n```\r\nSELECT t.x FROM (SELECT a, a + (1 AS x) AS b) t\r\n```\r\n\r\n\r\n12. Only the names of SELECT expression (a.k.a projection names, correlation names) are \"exported\" outside as table columns:\r\n\r\n```\r\nSELECT t.x FROM (SELECT 1 AS x) AS t;\r\nSELECT t.x FROM (SELECT x FROM tbl) AS t;\r\nSELECT x FROM (SELECT x FROM tbl) AS t;\r\n```\r\n\r\n```\r\nSELECT tbl.x FROM (SELECT x FROM tbl) AS t; -- this is wrong, the `tbl` name is not exported\r\nSELECT t2.x FROM (SELECT x FROM tbl AS t2) AS t; -- this is also wrong, the `t2` alias is not exported\r\n```\r\n\r\nNothing is \"exported\" from scalar subqueries or IN subqueries, subquery expressions:\r\n\r\n```\r\nSELECT x, (SELECT 1 AS x); -- does not work, `x` is not visible;\r\nSELECT x IN (SELECT 1 AS x); -- does not work either;\r\nSELECT x IN (SELECT 1 AS x) FROM (SELECT 1 AS x); -- this will work, but keep in mind that there are two different `x`.\r\n```\r\n\r\n\r\n13. Aliases can be ambiguous with column names. In case of ambiguity inside the boundaries of one query/subquery, it is resolved according to the value of setting `prefer_column_name_to_alias`.\r\n\r\n```\r\nSELECT x + 1 AS x, x FROM (SELECT 1 AS x);\r\n```\r\n\r\nThis query will return either `2, 1` or `2, 2` depending on the value of `prefer_column_name_to_alias`.\r\n\r\n```\r\nSELECT x, x + 1 AS x FROM (SELECT 1 AS x);\r\n```\r\n\r\nThe order of alias usage and alias definition does not matter (this may be a subject to change).\r\n\r\n\r\n14. If more than one alias with the same name are defined inside the boundaries of one query/subquery and these aliases refers to semantically different expressions, exception should be thrown.\r\n\r\n```\r\nSELECT 1 AS x, 2 AS x; -- throws exception.\r\n```\r\n\r\n\r\n15. Identifier can appear as a formal parameter in a lambda function:\r\n\r\n```\r\nSELECT arrayMap(x -> x + 1, arr)\r\n```\r\n\r\nHere `x` is a formal parameter.\r\n\r\nParameters to lambda functions are scoped. Their names can be ambiguous to other identifiers. In case of ambiguity, parameter of lambda function is preferred. The nearest to the current scope parameter is preferred.\r\n\r\n```\r\nSELECT x, arrayMap((x, y) -> x[1] + y + arrayFirst(x -> x != y, x), arr) FROM (SELECT 1 AS x, [([1, 2], 3), ([4, 5], 6)] AS arr);\r\n```\r\n\r\nThis query disambiguated as follows:\r\n```\r\nSELECT x1, arrayMap((x2, y2) -> x2[1] + y2 + arrayFirst(x3 -> x3 != y2, x2), arr) FROM (SELECT 1 AS x1, [([1, 2], 3), ([4, 5], 6)] AS arr);\r\n```\r\n\r\nIn expression `x -> expr(x)` the scope of `x` is `expr(x)`. So, the expression `arrayMap(x -> x, x)` should be read as `arrayMap(x1 -> x1, x2)`.\r\n\r\n\r\n16. Aliases should refer to identifiers by their semantical meaning, not by the name or syntactic construction.\r\n\r\nIf alias referes to an expression that is using a name that is unavailable in the place where alias is substituted, exception should be thrown.\r\n\r\n```\r\nSELECT arrayMap(x -> [y * 2, (x + 1) AS y, 1 AS z], arr), y;\r\n```\r\nThe last `y` refers to an expression that depends on `x` that is formal parameter of lambda function and is not available out of its scope.\r\n\r\n```\r\nSELECT arrayMap(x -> [y * 2, (x + 1) AS y, 1 AS z], arr), z;\r\n```\r\nThis will work as alias `z` is not scoped.\r\n\r\n```\r\nSELECT arrayMap(x -> (x + 1) AS y, arr1), arrayMap(x -> (x || 'hello') AS y, arr);\r\n```\r\nThis should throw exception as aliases `y` refers to different expressions.\r\nThe scope of formal parameter `x` is not related to any aliases that are using `x`.\r\n\r\n\r\n17. If identifier can be resolved to a table or a column in a table, ambiguity is resolved in the following way:\r\n\r\nIn right hand side of ARRAY JOIN it is resolved to a column.\r\nIn other parts of FROM it is resolved to a table.\r\nIn all other places it is resolved to a column. This includes right hand side of IN operator, dictGet, joinGet.\r\n\r\n```\r\nSELECT x FROM x ARRAY JOIN x WHERE x IN x\r\n```\r\n\r\nThis is disambiguated as follows:\r\n\r\n```\r\nSELECT col FROM table ARRAY JOIN col WHERE col IN col\r\n```\r\n\r\nNote: we can make more cases when we simply throw exception in case of ambiguity.\r\n\r\n\r\n18. In case of ambiguity with subcolumns of complex columns, exception should be thrown.\r\n\r\nThe previous rule can be theoretically applied to subcolumns of complex columns as well:\r\n\r\n```\r\nCREATE TABLE db.tbl\r\n(\r\n    col String,\r\n    db Nested\r\n    (\r\n        tbl Nested\r\n        (\r\n            col String\r\n        )\r\n    )\r\n)\r\nENGINE = Memory;\r\n\r\nSELECT db.tbl.col FROM db.tbl\r\n```\r\n\r\nIn this example, `db.tbl.col` can be resolved to the name of subcolumn of the Nested column.\r\nBut it will be much better to simply throw exception in all cases of ambiguity with subcolumns.\r\n\r\n\r\n19. Asterisk or qualified asterisk can be specified in any place where a list of expressions is possible.\r\n\r\n```\r\nSELECT * FROM table; -- ok\r\nSELECT f(*) FROM table; -- ok\r\nSELECT * + * FROM table; -- ok, though looks weird\r\n```\r\n\r\n```\r\nSELECT * GROUP BY *; -- ok\r\nSELECT * ORDER BY *; -- not ok as every component of ORDER BY may contain ASC/DESC and COLLATE; though can be supported in some sense\r\nSELECT * WHERE *; -- not ok as WHERE contains single expression, not a list\r\n```\r\n\r\n20. Unqualified asterisk is expanded to all the columns from all tables in section FROM in current scope; without virtual (hidden) columns; without ALIAS and MATERIALIZED columns unless it's changed by the setting `asterisk_include_materialized_columns`, `asterisk_include_alias_columns`.\r\n\r\nIn case of ambiguous column names in tables, asterisk is expanded to an identifier qualified by table name (and if table name is ambiguous, also by database name). In case of no ambiguity, unqualified name is used.\r\n\r\n```\r\nSELECT * FROM (SELECT a) AS t, (SELECT b) AS u;\r\n-- equivalent to:\r\nSELECT a, b FROM (SELECT a) AS t, (SELECT b) AS u;\r\n```\r\n\r\n```\r\nSELECT * FROM (SELECT a) AS t, (SELECT a) AS u;\r\n-- equivalent to:\r\nSELECT t.a, u.a FROM (SELECT a) AS t, (SELECT a) AS u;\r\n```\r\n\r\n```\r\nSELECT * FROM (SELECT a) AS db1.t, (SELECT a) AS db2.t;\r\n-- equivalent to:\r\nSELECT db1.t.a, db2.t.a FROM (SELECT a) AS db1.t, (SELECT a) AS db2.t;\r\n```\r\n\r\n\r\n21. Qualified asterisk is expanded to all the columns from a table (with the same exceptions as for unqualified asterisk) or all subcolumns of a complex column or subcolumn of a table.\r\n\r\nA question. Should we allow asterisk qualified by database only?\r\n\r\n```\r\nSELECT db.* FROM db.t1, db.t2; -- it's in question whether this should work.\r\n```\r\n\r\n```\r\nSELECT nest.* FROM table; -- expansion of complex column.\r\nSELECT nest FROM table; -- you can select all complex column at once as a single tuple / array of tuples.\r\n```\r\n\r\nFor compatibility reasons, asterisk expansion also expands all complex columns recursively, so they are flattened into multiple columns. This maybe a subject for adjustment by settings.\r\n\r\n```\r\nCREATE TABLE t\r\n(\r\n    x String,\r\n    nest Nested\r\n    (\r\n        a String,\r\n        b String\r\n    )\r\n) ENGINE = Memory;\r\n\r\nSELECT * FROM t;\r\n\r\n-- equivalent to:\r\nSELECT x, nest.* FROM t;\r\n\r\n-- equivalent to:\r\nSELECT x, nest.a, nest.b FROM t;\r\n```\r\n\r\n\r\n22. Qualified asterisk as well as named tuple access operator can be applied to expressions.\r\n\r\n```\r\nSELECT generateTuple().1; -- simple tuple access operator\r\nSELECT generateTuple().hello; -- named tuple or complex column access operator - can be applied to Nested type as well as Array of named Tuple\r\nSELECT generateTuple().*; -- expansion of a tuple or complex column with asterisk\r\n\r\nSELECT CAST(('hello', 1) AS Tuple(name String, count UInt32)).*\r\n```\r\n\r\n\r\n23. Untuple expression is an alternative way to write asterisk expansion.\r\n\r\n```\r\nSELECT untuple(CAST(('hello', 1) AS Tuple(name String, count UInt32))); -- will give two columns `name` and `count`.\r\n```\r\n\r\n\r\n24. Asterisk expansion can be modified by column transformers expressions.\r\n\r\n```\r\nSELECT * EXCEPT('hello|world');\r\nSELECT t.* EXCEPT(hello, world);\r\nSELECT db.t.* REPLACE(x + 1 AS x);\r\n```\r\n\r\nColumn transformers can be chained:\r\n```\r\nSELECT * EXCEPT(hello) REPLACE(x + 1 AS x);\r\n```\r\n\r\n\r\n25. `COLUMNS` expression or qualified `COLUMNS` expression can be used in place of asterisk or qualified asterisk. It is processed similarly but with the specified filter.\r\n\r\n```\r\nSELECT COLUMNS('^test_') FROM table;\r\nSELECT t.COLUMNS('^test_') FROM t, u;\r\nSELECT t.COLUMNS('^test_') EXCEPT (test_hello, test_world) FROM t, u;\r\n```\r\n\r\nThe filter in form of regular expression is applied to unqualified names from the corresponding tables.\r\n\r\n\r\n26. Expressions with identical \"correlation names\" inside subqueries are not allowed.\r\n\r\n```\r\nSELECT * FROM (SELECT x, x FROM (SELECT 1 AS x)); -- will throw;\r\nSELECT x FROM (SELECT x, x FROM (SELECT 1 AS x)); -- will throw;\r\nSELECT 1 FROM (SELECT x, x FROM (SELECT 1 AS x)); -- will throw;\r\n```\r\n\r\n\r\n27. Unnamed expressions inside subqueries are automatically named in implementation specific way.\r\n\r\n```\r\nSELECT `plus(1, 2)` FROM (SELECT 1 + 2); -- this works for now but not guaranteed.\r\n```\r\n\r\nA question. We can leave this automatic names only for outermost query and simply not allow to refer unnamed expressions from subqueries.\r\n\r\n\r\n28. Identifiers can be resolved to functions. Lambda expressions can be aliased. (proposal)\r\n\r\n```\r\nSELECT arrayMap(plus, arr1, arr2);\r\nSELECT x -> x + 1 AS fun, arrayMap(fun, arr);\r\n```\r\n\r\nThis is needed to allow SQL UDFs.\r\n\r\nAggregate functions can be found as well:\r\n\r\n```\r\nSELECT arrayReduce(sum, arr);\r\n-- currently works only this way:\r\nSELECT arrayReduce('sum', arr);\r\n```\r\n\r\nIn case of ambiguity, function is less preferred than alias or column name or table name.\r\n\r\n\r\n29. Aliases specified inside table function expression are not visible outside of table function expression.\r\n\r\n```\r\nSELECT x FROM mysql(('host' AS x) || '123', port, db, table); -- does not work as `x` is not visible outside.\r\n```\r\n\r\n\r\n30. Table may have ALIAS columns.\r\n\r\nThese columns can be referred as usual columns, but they are expanded during query analysis (for better possibilities of optimization).\r\n\r\n```\r\nCREATE TEMPORARY TABLE t\r\n(\r\n    x UInt8, \r\n    y ALIAS x + 1\r\n);\r\n\r\nSELECT y FROM t;\r\n```\r\n\r\nIf an expression of ALIAS column defines other aliases, these aliases are only visible inside this expression.\r\n\r\n```\r\nCREATE TEMPORARY TABLE t\r\n(\r\n    x UInt8, \r\n    y ALIAS ((x + 1) AS z) + 1\r\n);\r\n\r\nSELECT x, y, z FROM t; -- does not work, because `z` is not visible.\r\n\r\n-- this is correct:\r\nCREATE TEMPORARY TABLE t\r\n(\r\n    x UInt8, \r\n    y ALIAS z + 1,\r\n    z ALIAS x + 1\r\n);\r\n```\r\n\r\nALIAS columns may refer other ALIAS columns in the same table. The order of ALIAS columns does not matter for that.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23194/reactions","total_count":16,"+1":0,"-1":0,"laugh":0,"hooray":12,"confused":0,"heart":0,"rocket":0,"eyes":4},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23194/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23193","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23193/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23193/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23193/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/23193","id":859843090,"node_id":"MDU6SXNzdWU4NTk4NDMwOTA=","number":23193,"title":"How to efficiently integrate offline + real-time data to de-compute?","user":{"login":"lxswbr","id":49576261,"node_id":"MDQ6VXNlcjQ5NTc2MjYx","avatar_url":"https://avatars.githubusercontent.com/u/49576261?v=4","gravatar_id":"","url":"https://api.github.com/users/lxswbr","html_url":"https://github.com/lxswbr","followers_url":"https://api.github.com/users/lxswbr/followers","following_url":"https://api.github.com/users/lxswbr/following{/other_user}","gists_url":"https://api.github.com/users/lxswbr/gists{/gist_id}","starred_url":"https://api.github.com/users/lxswbr/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/lxswbr/subscriptions","organizations_url":"https://api.github.com/users/lxswbr/orgs","repos_url":"https://api.github.com/users/lxswbr/repos","events_url":"https://api.github.com/users/lxswbr/events{/privacy}","received_events_url":"https://api.github.com/users/lxswbr/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-04-16T14:00:25Z","updated_at":"2021-04-16T14:00:25Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Now there is the following scenario: it is necessary to integrate the offline table and the real-time table into a full data calculation, then there is a problem, how to get the latest record of id? The current method is to use the ReplicatedReplacingMergeTree engine table, first perform offline and real-time union all initialization data, and then insert the last two hours of real-time data into the table every hour, and then execute the optimize operation on each node to trigger deduplication, so This leads to a lot of pressure on the cluster. Is there any other good way?","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23193/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23193/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23188","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23188/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23188/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23188/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/23188","id":859761447,"node_id":"MDU6SXNzdWU4NTk3NjE0NDc=","number":23188,"title":"Confusing message about `multiple CROSS/COMMA JOIN` despite no CROSS JOINs","user":{"login":"adrian17","id":4729533,"node_id":"MDQ6VXNlcjQ3Mjk1MzM=","avatar_url":"https://avatars.githubusercontent.com/u/4729533?v=4","gravatar_id":"","url":"https://api.github.com/users/adrian17","html_url":"https://github.com/adrian17","followers_url":"https://api.github.com/users/adrian17/followers","following_url":"https://api.github.com/users/adrian17/following{/other_user}","gists_url":"https://api.github.com/users/adrian17/gists{/gist_id}","starred_url":"https://api.github.com/users/adrian17/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/adrian17/subscriptions","organizations_url":"https://api.github.com/users/adrian17/orgs","repos_url":"https://api.github.com/users/adrian17/repos","events_url":"https://api.github.com/users/adrian17/events{/privacy}","received_events_url":"https://api.github.com/users/adrian17/received_events","type":"User","site_admin":false},"labels":[{"id":845247686,"node_id":"MDU6TGFiZWw4NDUyNDc2ODY=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/usability","name":"usability","color":"ebf28c","default":false,"description":""}],"state":"open","locked":false,"assignee":{"login":"vdimir","id":7023786,"node_id":"MDQ6VXNlcjcwMjM3ODY=","avatar_url":"https://avatars.githubusercontent.com/u/7023786?v=4","gravatar_id":"","url":"https://api.github.com/users/vdimir","html_url":"https://github.com/vdimir","followers_url":"https://api.github.com/users/vdimir/followers","following_url":"https://api.github.com/users/vdimir/following{/other_user}","gists_url":"https://api.github.com/users/vdimir/gists{/gist_id}","starred_url":"https://api.github.com/users/vdimir/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vdimir/subscriptions","organizations_url":"https://api.github.com/users/vdimir/orgs","repos_url":"https://api.github.com/users/vdimir/repos","events_url":"https://api.github.com/users/vdimir/events{/privacy}","received_events_url":"https://api.github.com/users/vdimir/received_events","type":"User","site_admin":false},"assignees":[{"login":"vdimir","id":7023786,"node_id":"MDQ6VXNlcjcwMjM3ODY=","avatar_url":"https://avatars.githubusercontent.com/u/7023786?v=4","gravatar_id":"","url":"https://api.github.com/users/vdimir","html_url":"https://github.com/vdimir","followers_url":"https://api.github.com/users/vdimir/followers","following_url":"https://api.github.com/users/vdimir/following{/other_user}","gists_url":"https://api.github.com/users/vdimir/gists{/gist_id}","starred_url":"https://api.github.com/users/vdimir/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vdimir/subscriptions","organizations_url":"https://api.github.com/users/vdimir/orgs","repos_url":"https://api.github.com/users/vdimir/repos","events_url":"https://api.github.com/users/vdimir/events{/privacy}","received_events_url":"https://api.github.com/users/vdimir/received_events","type":"User","site_admin":false}],"milestone":null,"comments":1,"created_at":"2021-04-16T12:17:44Z","updated_at":"2021-06-18T10:47:22Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Reproduced on server 21.3.4.\r\n\r\n```\r\nWITH example as (select 'date' as date) # not needed for repro, just for a single-query repro\r\nSELECT date\r\nFROM example\r\nLEFT JOIN \r\n(\r\n    SELECT 'date' as date\r\n) AS users ON example.date = users.date\r\nLEFT JOIN \r\n(\r\n    SELECT 'date' as date\r\n) AS map USING date\r\n```\r\n\r\nProduces an error message \r\n\r\n> DB::Exception: Multiple CROSS/COMMA JOIN do not support USING\r\n\r\nI'm okay with it being not supported with several JOINs, but the error message here makes no sense, as none of these are cross joins :)","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23188/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23188/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23178","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23178/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23178/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23178/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/23178","id":859514116,"node_id":"MDU6SXNzdWU4NTk1MTQxMTY=","number":23178,"title":"Code: 252, e.displayText() = DB::Exception: Too many parts (300). Parts cleaning are processing significantly slower than inserts: while write prefix to view src.xxxxx, Stack trace (when copying this message, always include the lines below)","user":{"login":"trollhe","id":41068725,"node_id":"MDQ6VXNlcjQxMDY4NzI1","avatar_url":"https://avatars.githubusercontent.com/u/41068725?v=4","gravatar_id":"","url":"https://api.github.com/users/trollhe","html_url":"https://github.com/trollhe","followers_url":"https://api.github.com/users/trollhe/followers","following_url":"https://api.github.com/users/trollhe/following{/other_user}","gists_url":"https://api.github.com/users/trollhe/gists{/gist_id}","starred_url":"https://api.github.com/users/trollhe/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/trollhe/subscriptions","organizations_url":"https://api.github.com/users/trollhe/orgs","repos_url":"https://api.github.com/users/trollhe/repos","events_url":"https://api.github.com/users/trollhe/events{/privacy}","received_events_url":"https://api.github.com/users/trollhe/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-04-16T06:45:55Z","updated_at":"2021-04-16T07:05:49Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"hi，\r\n\r\nhere`s the error messages:\r\n```\r\n0. DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, bool) @ 0x88b64ca in /usr/bin/clickhouse\r\n1. DB::Exception::Exception<unsigned long&>(int, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, unsigned long&) @ 0x8902322 in /usr/bin/clickhouse\r\n2. DB::MergeTreeData::delayInsertOrThrowIfNeeded(Poco::Event*) const @ 0xfd8f51e in /usr/bin/clickhouse\r\n3. DB::PushingToViewsBlockOutputStream::writePrefix() @ 0xf3d044b in /usr/bin/clickhouse\r\n4. DB::PushingToViewsBlockOutputStream::writePrefix() @ 0xf3d046a in /usr/bin/clickhouse\r\n5. DB::copyData(DB::IBlockInputStream&, DB::IBlockOutputStream&, std::__1::atomic<bool>*) @ 0xf035534 in /usr/bin/clickhouse\r\n6. DB::StorageKafka::streamToViews() @ 0xfc71821 in /usr/bin/clickhouse\r\n7. DB::StorageKafka::threadFunc(unsigned long) @ 0xfc70618 in /usr/bin/clickhouse\r\n8. DB::BackgroundSchedulePoolTaskInfo::execute() @ 0xf250840 in /usr/bin/clickhouse\r\n9. DB::BackgroundSchedulePool::threadFunction() @ 0xf252837 in /usr/bin/clickhouse\r\n10. ? @ 0xf253602 in /usr/bin/clickhouse\r\n11. ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) @ 0x88f65af in /usr/bin/clickhouse\r\n12. ? @ 0x88fa043 in /usr/bin/clickhouse\r\n13. start_thread @ 0x82de in /usr/lib64/libpthread-2.28.so\r\n14. __clone @ 0xfbe83 in /usr/lib64/libc-2.28.so\r\n (version 21.4.3.21 (official build))\r\n2021.04.16 14:40:06.118138 [ 3239175 ] {} <Error> void DB::StorageKafka::threadFunc(size_t): Code: 252, e.displayText() = DB::Exception: Too many parts (300). Parts cleaning are processing significantly slower than inserts: while write prefix to view src.src_xxxx, Stack trace (when copying this message, always include the lines below):\r\n```\r\n\r\nmy config.xml\r\n```\r\n<max_partitions_per_insert_block>0</max_partitions_per_insert_block>\r\n<inactive_parts_to_throw_insert>0</inactive_parts_to_throw_insert>\r\n```\r\n\r\ni each insert / drop partition to one partitions,but client cancel query ,is still show in system.progress , and is_cancel=0. \r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23178/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23178/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23176","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23176/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23176/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23176/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/23176","id":859507077,"node_id":"MDU6SXNzdWU4NTk1MDcwNzc=","number":23176,"title":"Documentation for REPLACE TABLE ... SELECT does not match reality","user":{"login":"cyberhuman","id":979624,"node_id":"MDQ6VXNlcjk3OTYyNA==","avatar_url":"https://avatars.githubusercontent.com/u/979624?v=4","gravatar_id":"","url":"https://api.github.com/users/cyberhuman","html_url":"https://github.com/cyberhuman","followers_url":"https://api.github.com/users/cyberhuman/followers","following_url":"https://api.github.com/users/cyberhuman/following{/other_user}","gists_url":"https://api.github.com/users/cyberhuman/gists{/gist_id}","starred_url":"https://api.github.com/users/cyberhuman/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/cyberhuman/subscriptions","organizations_url":"https://api.github.com/users/cyberhuman/orgs","repos_url":"https://api.github.com/users/cyberhuman/repos","events_url":"https://api.github.com/users/cyberhuman/events{/privacy}","received_events_url":"https://api.github.com/users/cyberhuman/received_events","type":"User","site_admin":false},"labels":[{"id":785082162,"node_id":"MDU6TGFiZWw3ODUwODIxNjI=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-documentation","name":"comp-documentation","color":"b5bcff","default":false,"description":"Used to run automatic builds of the documentation"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-04-16T06:35:11Z","updated_at":"2021-04-16T06:35:11Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"**Describe the issue**\r\nThe documentation at https://clickhouse.tech/docs/en/sql-reference/statements/create/table/#replace-table-query says:\r\n> Instead of above, you can use the following:\r\n>\r\n> ```\r\n> REPLACE TABLE myOldTable SELECT * FROM myOldTable WHERE CounterID <12345;\r\n> ```\r\n\r\nHowever, when trying to use this syntax, a syntax error is reported:\r\n```\r\nSyntax error: failed at position 26 ('SELECT'):\r\n\r\nREPLACE TABLE myOldTable SELECT * FROM myOldTable WHERE CounterID <12345;\r\n\r\nExpected one of: storage definition, ENGINE, AS, UUID, OpeningRoundBracket, ON, Dot, token\r\n```\r\n\r\nA working syntax:\r\n```\r\nREPLACE TABLE myOldTable ENGINE ... AS SELECT * FROM myOldTable WHERE CounterID <12345;\r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23176/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23176/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23162","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23162/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23162/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23162/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/23162","id":859189926,"node_id":"MDU6SXNzdWU4NTkxODk5MjY=","number":23162,"title":"Multi-JOIN allows to use a column with a wrong table specifier.","user":{"login":"den-crane","id":19737682,"node_id":"MDQ6VXNlcjE5NzM3Njgy","avatar_url":"https://avatars.githubusercontent.com/u/19737682?v=4","gravatar_id":"","url":"https://api.github.com/users/den-crane","html_url":"https://github.com/den-crane","followers_url":"https://api.github.com/users/den-crane/followers","following_url":"https://api.github.com/users/den-crane/following{/other_user}","gists_url":"https://api.github.com/users/den-crane/gists{/gist_id}","starred_url":"https://api.github.com/users/den-crane/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/den-crane/subscriptions","organizations_url":"https://api.github.com/users/den-crane/orgs","repos_url":"https://api.github.com/users/den-crane/repos","events_url":"https://api.github.com/users/den-crane/events{/privacy}","received_events_url":"https://api.github.com/users/den-crane/received_events","type":"User","site_admin":false},"labels":[{"id":386401505,"node_id":"MDU6TGFiZWwzODY0MDE1MDU=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/bug","name":"bug","color":"ee0701","default":true,"description":"Confirmed user-visible misbehaviour in official release"},{"id":1357578153,"node_id":"MDU6TGFiZWwxMzU3NTc4MTUz","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-joins","name":"comp-joins","color":"b5bcff","default":false,"description":"JOINs"},{"id":1507871495,"node_id":"MDU6TGFiZWwxNTA3ODcxNDk1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/st-community-taken","name":"st-community-taken","color":"e5b890","default":false,"description":"External developer is working on that"},{"id":2825253639,"node_id":"MDU6TGFiZWwyODI1MjUzNjM5","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/v21.3-affected","name":"v21.3-affected","color":"c2bfff","default":false,"description":""}],"state":"open","locked":false,"assignee":{"login":"hexiaoting","id":7898329,"node_id":"MDQ6VXNlcjc4OTgzMjk=","avatar_url":"https://avatars.githubusercontent.com/u/7898329?v=4","gravatar_id":"","url":"https://api.github.com/users/hexiaoting","html_url":"https://github.com/hexiaoting","followers_url":"https://api.github.com/users/hexiaoting/followers","following_url":"https://api.github.com/users/hexiaoting/following{/other_user}","gists_url":"https://api.github.com/users/hexiaoting/gists{/gist_id}","starred_url":"https://api.github.com/users/hexiaoting/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/hexiaoting/subscriptions","organizations_url":"https://api.github.com/users/hexiaoting/orgs","repos_url":"https://api.github.com/users/hexiaoting/repos","events_url":"https://api.github.com/users/hexiaoting/events{/privacy}","received_events_url":"https://api.github.com/users/hexiaoting/received_events","type":"User","site_admin":false},"assignees":[{"login":"hexiaoting","id":7898329,"node_id":"MDQ6VXNlcjc4OTgzMjk=","avatar_url":"https://avatars.githubusercontent.com/u/7898329?v=4","gravatar_id":"","url":"https://api.github.com/users/hexiaoting","html_url":"https://github.com/hexiaoting","followers_url":"https://api.github.com/users/hexiaoting/followers","following_url":"https://api.github.com/users/hexiaoting/following{/other_user}","gists_url":"https://api.github.com/users/hexiaoting/gists{/gist_id}","starred_url":"https://api.github.com/users/hexiaoting/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/hexiaoting/subscriptions","organizations_url":"https://api.github.com/users/hexiaoting/orgs","repos_url":"https://api.github.com/users/hexiaoting/repos","events_url":"https://api.github.com/users/hexiaoting/events{/privacy}","received_events_url":"https://api.github.com/users/hexiaoting/received_events","type":"User","site_admin":false}],"milestone":null,"comments":2,"created_at":"2021-04-15T19:35:21Z","updated_at":"2021-10-04T14:35:47Z","closed_at":null,"author_association":"COLLABORATOR","active_lock_reason":null,"body":"21.5.1.6434\r\n\r\n```sql\r\nCREATE TABLE t1 ( k Int64, x Int64) ENGINE = Memory;\r\n\r\nCREATE TABLE t2( x Int64 ) ENGINE = Memory;\r\n\r\ncreate table s (k Int64, d DateTime)  Engine=Memory;\r\n\r\nSELECT * FROM t1\r\nINNER JOIN s ON t1.k = s.k\r\nINNER JOIN t2 ON t2.x = t1.x\r\nWHERE (t1.d >= now());\r\n\r\nOk.\r\n```\r\nBut `t1` does not have `d` column.\r\nExpected behavior : `DB::Exception: There's no column 't1.d' in table 't1'`\r\n\r\nLets join only 2 tables:\r\n```sql\r\nSELECT * FROM t1\r\nINNER JOIN s ON t1.k = s.k\r\nWHERE (t1.d >= now());\r\n\r\nDB::Exception: There's no column 't1.d' in table 't1'\r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23162/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23162/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23157","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23157/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23157/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23157/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/23157","id":859021789,"node_id":"MDU6SXNzdWU4NTkwMjE3ODk=","number":23157,"title":"Live view doesn't exist during insertion","user":{"login":"loyd","id":952180,"node_id":"MDQ6VXNlcjk1MjE4MA==","avatar_url":"https://avatars.githubusercontent.com/u/952180?v=4","gravatar_id":"","url":"https://api.github.com/users/loyd","html_url":"https://github.com/loyd","followers_url":"https://api.github.com/users/loyd/followers","following_url":"https://api.github.com/users/loyd/following{/other_user}","gists_url":"https://api.github.com/users/loyd/gists{/gist_id}","starred_url":"https://api.github.com/users/loyd/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/loyd/subscriptions","organizations_url":"https://api.github.com/users/loyd/orgs","repos_url":"https://api.github.com/users/loyd/repos","events_url":"https://api.github.com/users/loyd/events{/privacy}","received_events_url":"https://api.github.com/users/loyd/received_events","type":"User","site_admin":false},"labels":[{"id":2020006233,"node_id":"MDU6TGFiZWwyMDIwMDA2MjMz","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-liveview","name":"comp-liveview","color":"b5bcff","default":false,"description":""},{"id":2673090580,"node_id":"MDU6TGFiZWwyNjczMDkwNTgw","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/bug%20experimental","name":"bug experimental","color":"E99695","default":false,"description":"Bug in the feature that should not be used in production"}],"state":"open","locked":false,"assignee":{"login":"vzakaznikov","id":41681088,"node_id":"MDQ6VXNlcjQxNjgxMDg4","avatar_url":"https://avatars.githubusercontent.com/u/41681088?v=4","gravatar_id":"","url":"https://api.github.com/users/vzakaznikov","html_url":"https://github.com/vzakaznikov","followers_url":"https://api.github.com/users/vzakaznikov/followers","following_url":"https://api.github.com/users/vzakaznikov/following{/other_user}","gists_url":"https://api.github.com/users/vzakaznikov/gists{/gist_id}","starred_url":"https://api.github.com/users/vzakaznikov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vzakaznikov/subscriptions","organizations_url":"https://api.github.com/users/vzakaznikov/orgs","repos_url":"https://api.github.com/users/vzakaznikov/repos","events_url":"https://api.github.com/users/vzakaznikov/events{/privacy}","received_events_url":"https://api.github.com/users/vzakaznikov/received_events","type":"User","site_admin":false},"assignees":[{"login":"vzakaznikov","id":41681088,"node_id":"MDQ6VXNlcjQxNjgxMDg4","avatar_url":"https://avatars.githubusercontent.com/u/41681088?v=4","gravatar_id":"","url":"https://api.github.com/users/vzakaznikov","html_url":"https://github.com/vzakaznikov","followers_url":"https://api.github.com/users/vzakaznikov/followers","following_url":"https://api.github.com/users/vzakaznikov/following{/other_user}","gists_url":"https://api.github.com/users/vzakaznikov/gists{/gist_id}","starred_url":"https://api.github.com/users/vzakaznikov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vzakaznikov/subscriptions","organizations_url":"https://api.github.com/users/vzakaznikov/orgs","repos_url":"https://api.github.com/users/vzakaznikov/repos","events_url":"https://api.github.com/users/vzakaznikov/events{/privacy}","received_events_url":"https://api.github.com/users/vzakaznikov/received_events","type":"User","site_admin":false}],"milestone":null,"comments":10,"created_at":"2021-04-15T15:55:29Z","updated_at":"2022-01-21T23:28:44Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"**Description**\r\n\r\nI play with streaming via CH and actively use live tables to detect when new rows arrived. I've written a benchmark, where some tasks insert data while others receive them. The last ones create live views before working dynamically.\r\n\r\nAt startup, it's possible to get the following error during _insertion_:\r\n```\r\nCode: 60, e.displayText() = DB::Exception: Table test.lv_7e751480f348c64bd21d3b413b319c4a86f9d7b0 (54b2e1f8-c553-4a29-9370-7afefa70575d) doesn't exist (version 21.4.3.21 (official build)) (from 127.0.0.1:33756) (in query: INSERT INTO indicator_log_buffer(trace_id,name,timestamp,value,source) FORMAT RowBinary )\r\n```\r\n\r\nAccording to logs, the pattern looks like\r\n```\r\nThread A accepts a request with `INSERT` query\r\nThread B accepts a request with `CREATE LIVE TABLE` query\r\nThread B starts executing its query  \r\nThread A starts executing its query... and fails\r\nThread B finished\r\n```\r\n\r\nRace condition?\r\n\r\n**Logs**\r\nThreads:\r\n`760991` — a thread running `INSERT INTO indicator_log_buffer`\r\n`761063` — a thread running `CREATE LIVE VIEW ... SELECT ... FROM indicator_log_buffer`\r\n\r\n```\r\n2021.04.15 15:06:43.977415 [ 760991 ] {} <Trace> HTTPHandler-factory: HTTP Request for HTTPHandler-factory. Method: POST, Address: 127.0.0.1:33756, User-Agent: (none), Content Type: , Transfer Encoding: chunked, X-Forwarded-For: (none)\r\n2021.04.15 15:06:43.977447 [ 221742 ] {} <Trace> HTTPHandler-factory: HTTP Request for HTTPHandler-factory. Method: POST, Address: 127.0.0.1:33754, User-Agent: (none), Content Type: , Transfer Encoding: chunked, X-Forwarded-For: (none)\r\n2021.04.15 15:06:43.977455 [ 761063 ] {b2dc5bb7-d564-42bc-9f9b-d23eb07ab458} <Debug> executeQuery: (from 127.0.0.1:33748, using production parser) INSERT INTO name_filter_1(name) FORMAT RowBinary\r\n2021.04.15 15:06:43.977495 [ 760991 ] {} <Trace> DynamicQueryHandler: Request URI: /?database=test&query=INSERT+INTO+indicator_log_buffer%28trace_id%2Cname%2Ctimestamp%2Cvalue%2Csource%29+FORMAT+RowBinary\r\n2021.04.15 15:06:43.977504 [ 761063 ] {b2dc5bb7-d564-42bc-9f9b-d23eb07ab458} <Trace> ContextAccess (default): Access granted: INSERT(name) ON test.name_filter_1\r\n2021.04.15 15:06:43.977531 [ 221742 ] {} <Trace> DynamicQueryHandler: Request URI: /?database=test&query=INSERT+INTO+indicator_log_buffer%28trace_id%2Cname%2Ctimestamp%2Cvalue%2Csource%29+FORMAT+RowBinary\r\n2021.04.15 15:06:43.977623 [ 673014 ] {} <Trace> HTTPHandler-factory: HTTP Request for HTTPHandler-factory. Method: POST, Address: 127.0.0.1:33758, User-Agent: (none), Content Type: , Transfer Encoding: chunked, X-Forwarded-For: (none)\r\n2021.04.15 15:06:43.977660 [ 761063 ] {b2dc5bb7-d564-42bc-9f9b-d23eb07ab458} <Debug> executeQuery: Query pipeline:\r\nNullAndDoCopy\r\n InputStreamFromASTInsertQuery\r\n\r\n2021.04.15 15:06:43.977670 [ 736865 ] {acf17888-4e1c-4ad3-ab9a-5fe45e9b1eae} <Debug> executeQuery: (from 127.0.0.1:33746, using production parser) INSERT INTO name_filter_0(name) FORMAT RowBinary\r\n2021.04.15 15:06:43.977683 [ 761063 ] {b2dc5bb7-d564-42bc-9f9b-d23eb07ab458} <Trace> ParallelFormattingOutputFormat: Parallel formatting is being used\r\n2021.04.15 15:06:43.977679 [ 673014 ] {} <Trace> DynamicQueryHandler: Request URI: /?database=test&query=INSERT+INTO+indicator_log_buffer%28trace_id%2Cname%2Ctimestamp%2Cvalue%2Csource%29+FORMAT+RowBinary\r\n2021.04.15 15:06:43.977748 [ 738487 ] {} <Trace> HTTPHandler-factory: HTTP Request for HTTPHandler-factory. Method: POST, Address: 127.0.0.1:33762, User-Agent: (none), Content Type: , Transfer Encoding: chunked, X-Forwarded-For: (none)\r\n2021.04.15 15:06:43.977776 [ 736865 ] {acf17888-4e1c-4ad3-ab9a-5fe45e9b1eae} <Trace> ContextAccess (default): Access granted: INSERT(name) ON test.name_filter_0\r\n2021.04.15 15:06:43.977808 [ 741098 ] {} <Trace> HTTPHandler-factory: HTTP Request for HTTPHandler-factory. Method: POST, Address: 127.0.0.1:33760, User-Agent: (none), Content Type: , Transfer Encoding: chunked, X-Forwarded-For: (none)\r\n2021.04.15 15:06:43.977836 [ 738487 ] {} <Trace> DynamicQueryHandler: Request URI: /?database=test&query=INSERT+INTO+indicator_log_buffer%28trace_id%2Cname%2Ctimestamp%2Cvalue%2Csource%29+FORMAT+RowBinary\r\n2021.04.15 15:06:43.977886 [ 741098 ] {} <Trace> DynamicQueryHandler: Request URI: /?database=test&query=INSERT+INTO+indicator_log_buffer%28trace_id%2Cname%2Ctimestamp%2Cvalue%2Csource%29+FORMAT+RowBinary\r\n2021.04.15 15:06:43.977905 [ 736865 ] {acf17888-4e1c-4ad3-ab9a-5fe45e9b1eae} <Debug> executeQuery: Query pipeline:\r\nNullAndDoCopy\r\n InputStreamFromASTInsertQuery\r\n\r\n2021.04.15 15:06:43.977933 [ 736865 ] {acf17888-4e1c-4ad3-ab9a-5fe45e9b1eae} <Trace> ParallelFormattingOutputFormat: Parallel formatting is being used\r\n2021.04.15 15:06:43.977970 [ 761063 ] {b2dc5bb7-d564-42bc-9f9b-d23eb07ab458} <Information> executeQuery: Read 100 rows, 3.36 KiB in 0.000481427 sec., 207715 rows/sec., 6.81 MiB/sec.\r\n2021.04.15 15:06:43.978137 [ 761063 ] {b2dc5bb7-d564-42bc-9f9b-d23eb07ab458} <Debug> DynamicQueryHandler: Done processing query\r\n2021.04.15 15:06:43.978146 [ 761063 ] {b2dc5bb7-d564-42bc-9f9b-d23eb07ab458} <Debug> MemoryTracker: Peak memory usage (for query): 2.00 MiB.\r\n2021.04.15 15:06:43.978153 [ 761063 ] {} <Debug> MemoryTracker: Peak memory usage (for query): 2.00 MiB.\r\n2021.04.15 15:06:43.978182 [ 736865 ] {acf17888-4e1c-4ad3-ab9a-5fe45e9b1eae} <Information> executeQuery: Read 100 rows, 3.34 KiB in 0.000476332 sec., 209937 rows/sec., 6.85 MiB/sec.\r\n2021.04.15 15:06:43.978325 [ 736865 ] {acf17888-4e1c-4ad3-ab9a-5fe45e9b1eae} <Debug> DynamicQueryHandler: Done processing query\r\n2021.04.15 15:06:43.978338 [ 736865 ] {acf17888-4e1c-4ad3-ab9a-5fe45e9b1eae} <Debug> MemoryTracker: Peak memory usage (for query): 2.00 MiB.\r\n2021.04.15 15:06:43.978348 [ 736865 ] {} <Debug> MemoryTracker: Peak memory usage (for query): 2.00 MiB.\r\n2021.04.15 15:06:43.978729 [ 761063 ] {} <Trace> HTTPHandler-factory: HTTP Request for HTTPHandler-factory. Method: POST, Address: 127.0.0.1:33748, User-Agent: (none), Length: 0, Content Type: , Transfer Encoding: identity, X-Forwarded-For: (none)\r\n2021.04.15 15:06:43.978763 [ 761063 ] {} <Trace> DynamicQueryHandler: Request URI: /?database=test&query=CREATE+LIVE+VIEW+IF+NOT+EXISTS+lv_7e751480f348c64bd21d3b413b319c4a86f9d7b0+WITH+TIMEOUT+AS+SELECT+max%28timestamp%29%0A++++++++++++++FROM+indicator_log_buffer%0A+++++++++++++WHERE+name+IN+name_filter_1&allow_experimental_live_view=1\r\n2021.04.15 15:06:43.978799 [ 736865 ] {} <Trace> HTTPHandler-factory: HTTP Request for HTTPHandler-factory. Method: POST, Address: 127.0.0.1:33746, User-Agent: (none), Length: 0, Content Type: , Transfer Encoding: identity, X-Forwarded-For: (none)\r\n2021.04.15 15:06:43.978834 [ 736865 ] {} <Trace> DynamicQueryHandler: Request URI: /?database=test&query=CREATE+LIVE+VIEW+IF+NOT+EXISTS+lv_02cc8c78cbf1c1fd00cbb8fc1f6e01e7c395efec+WITH+TIMEOUT+AS+SELECT+max%28timestamp%29%0A++++++++++++++FROM+indicator_log_buffer%0A+++++++++++++WHERE+name+IN+name_filter_0&allow_experimental_live_view=1\r\n2021.04.15 15:06:43.978974 [ 761063 ] {2dcc8baf-07e6-452e-b74f-a50fe2b09917} <Debug> executeQuery: (from 127.0.0.1:33748, using production parser) CREATE LIVE VIEW IF NOT EXISTS lv_7e751480f348c64bd21d3b413b319c4a86f9d7b0 WITH TIMEOUT AS SELECT max(timestamp) FROM indicator_log_buffer WHERE name IN name_filter_1\r\n2021.04.15 15:06:43.978994 [ 761063 ] {2dcc8baf-07e6-452e-b74f-a50fe2b09917} <Trace> ContextAccess (default): Access granted: CREATE VIEW ON test.lv_7e751480f348c64bd21d3b413b319c4a86f9d7b0\r\n2021.04.15 15:06:43.979091 [ 736865 ] {b288da25-4aa8-480f-b7d3-19ffe9f28247} <Debug> executeQuery: (from 127.0.0.1:33746, using production parser) CREATE LIVE VIEW IF NOT EXISTS lv_02cc8c78cbf1c1fd00cbb8fc1f6e01e7c395efec WITH TIMEOUT AS SELECT max(timestamp) FROM indicator_log_buffer WHERE name IN name_filter_0\r\n2021.04.15 15:06:43.979117 [ 736865 ] {b288da25-4aa8-480f-b7d3-19ffe9f28247} <Trace> ContextAccess (default): Access granted: CREATE VIEW ON test.lv_02cc8c78cbf1c1fd00cbb8fc1f6e01e7c395efec\r\n2021.04.15 15:06:43.979171 [ 761063 ] {2dcc8baf-07e6-452e-b74f-a50fe2b09917} <Trace> ContextAccess (default): Access granted: SELECT(name) ON test.name_filter_1\r\n2021.04.15 15:06:43.979382 [ 736865 ] {b288da25-4aa8-480f-b7d3-19ffe9f28247} <Trace> ContextAccess (default): Access granted: SELECT(name) ON test.name_filter_0\r\n2021.04.15 15:06:43.979454 [ 761063 ] {2dcc8baf-07e6-452e-b74f-a50fe2b09917} <Trace> ContextAccess (default): Access granted: SELECT(name, timestamp) ON test.indicator_log_buffer\r\n2021.04.15 15:06:43.979622 [ 760991 ] {fd68e918-22f5-4cf0-b332-a57cd89b0c08} <Debug> executeQuery: (from 127.0.0.1:33756, using production parser) INSERT INTO indicator_log_buffer(trace_id,name,timestamp,value,source) FORMAT RowBinary\r\n2021.04.15 15:06:43.979691 [ 736865 ] {b288da25-4aa8-480f-b7d3-19ffe9f28247} <Trace> ContextAccess (default): Access granted: SELECT(name, timestamp) ON test.indicator_log_buffer\r\n2021.04.15 15:06:43.979709 [ 760991 ] {fd68e918-22f5-4cf0-b332-a57cd89b0c08} <Trace> ContextAccess (default): Access granted: INSERT(trace_id, name, timestamp, value, source) ON test.indicator_log_buffer\r\n2021.04.15 15:06:43.979977 [ 760991 ] {fd68e918-22f5-4cf0-b332-a57cd89b0c08} <Error> executeQuery: Code: 60, e.displayText() = DB::Exception: Table test.lv_7e751480f348c64bd21d3b413b319c4a86f9d7b0 (54b2e1f8-c553-4a29-9370-7afefa70575d) doesn't exist (version 21.4.3.21 (official build)) (from 127.0.0.1:33756) (in query: INSERT INTO indicator_log_buffer(trace_id,name,timestamp,value,source) FORMAT RowBinary ), Stack trace (when copying this message, always include the lines below):\r\n\r\n0. DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, bool) @ 0x88b64ca in /usr/bin/clickhouse\r\n1. DB::Exception::Exception<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >(int, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >&&) @ 0x89c4d13 in /usr/bin/clickhouse\r\n2. void std::__1::__optional_storage_base<DB::Exception, false>::__construct<int const&, char const (&) [23], std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >(int const&, char const (&) [23], std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >&&) @ 0xf289b01 in /usr/bin/clickhouse\r\n3. DB::DatabaseCatalog::getTableImpl(DB::StorageID const&, DB::Context const&, std::__1::optional<DB::Exception>*) const @ 0xf27c486 in /usr/bin/clickhouse\r\n4. DB::DatabaseCatalog::getTable(DB::StorageID const&, DB::Context const&) const @ 0xf281d9f in /usr/bin/clickhouse\r\n5. DB::PushingToViewsBlockOutputStream::PushingToViewsBlockOutputStream(std::__1::shared_ptr<DB::IStorage> const&, std::__1::shared_ptr<DB::StorageInMemoryMetadata const> const&, DB::Context const&, std::__1::shared_ptr<DB::IAST> const&, bool) @ 0xf3cc92d in /usr/bin/clickhouse\r\n6. DB::InterpreterInsertQuery::execute() @ 0xf3c56d4 in /usr/bin/clickhouse\r\n7. ? @ 0xf8b98c2 in /usr/bin/clickhouse\r\n8. DB::executeQuery(DB::ReadBuffer&, DB::WriteBuffer&, bool, DB::Context&, std::__1::function<void (std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)>) @ 0xf8bcf75 in /usr/bin/clickhouse\r\n9. DB::HTTPHandler::processQuery(DB::Context&, DB::HTTPServerRequest&, DB::HTMLForm&, DB::HTTPServerResponse&, DB::HTTPHandler::Output&, std::__1::optional<DB::CurrentThread::QueryScope>&) @ 0xfffeac2 in /usr/bin/clickhouse\r\n10. DB::HTTPHandler::handleRequest(DB::HTTPServerRequest&, DB::HTTPServerResponse&) @ 0x1000212d in /usr/bin/clickhouse\r\n11. DB::HTTPServerConnection::run() @ 0x100887cf in /usr/bin/clickhouse\r\n12. Poco::Net::TCPServerConnection::start() @ 0x12739e8f in /usr/bin/clickhouse\r\n13. Poco::Net::TCPServerDispatcher::run() @ 0x1273b8a1 in /usr/bin/clickhouse\r\n14. Poco::PooledThread::run() @ 0x12871fc9 in /usr/bin/clickhouse\r\n15. Poco::ThreadImpl::runnableEntry(void*) @ 0x1286de2a in /usr/bin/clickhouse\r\n16. start_thread @ 0x9609 in /usr/lib/x86_64-linux-gnu/libpthread-2.31.so\r\n17. clone @ 0x122293 in /usr/lib/x86_64-linux-gnu/libc-2.31.so\r\n\r\n2021.04.15 15:06:43.980076 [ 761063 ] {2dcc8baf-07e6-452e-b74f-a50fe2b09917} <Debug> DynamicQueryHandler: Done processing query\r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23157/reactions","total_count":7,"+1":7,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23157/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23125","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23125/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23125/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23125/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/23125","id":858809713,"node_id":"MDU6SXNzdWU4NTg4MDk3MTM=","number":23125,"title":"Window function being applied after LIMIT.","user":{"login":"wol-e","id":52048829,"node_id":"MDQ6VXNlcjUyMDQ4ODI5","avatar_url":"https://avatars.githubusercontent.com/u/52048829?v=4","gravatar_id":"","url":"https://api.github.com/users/wol-e","html_url":"https://github.com/wol-e","followers_url":"https://api.github.com/users/wol-e/followers","following_url":"https://api.github.com/users/wol-e/following{/other_user}","gists_url":"https://api.github.com/users/wol-e/gists{/gist_id}","starred_url":"https://api.github.com/users/wol-e/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/wol-e/subscriptions","organizations_url":"https://api.github.com/users/wol-e/orgs","repos_url":"https://api.github.com/users/wol-e/repos","events_url":"https://api.github.com/users/wol-e/events{/privacy}","received_events_url":"https://api.github.com/users/wol-e/received_events","type":"User","site_admin":false},"labels":[{"id":386401505,"node_id":"MDU6TGFiZWwzODY0MDE1MDU=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/bug","name":"bug","color":"ee0701","default":true,"description":"Confirmed user-visible misbehaviour in official release"},{"id":2607635731,"node_id":"MDU6TGFiZWwyNjA3NjM1NzMx","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-window-functions","name":"comp-window-functions","color":"b5bcff","default":false,"description":""}],"state":"open","locked":false,"assignee":{"login":"KochetovNicolai","id":4092911,"node_id":"MDQ6VXNlcjQwOTI5MTE=","avatar_url":"https://avatars.githubusercontent.com/u/4092911?v=4","gravatar_id":"","url":"https://api.github.com/users/KochetovNicolai","html_url":"https://github.com/KochetovNicolai","followers_url":"https://api.github.com/users/KochetovNicolai/followers","following_url":"https://api.github.com/users/KochetovNicolai/following{/other_user}","gists_url":"https://api.github.com/users/KochetovNicolai/gists{/gist_id}","starred_url":"https://api.github.com/users/KochetovNicolai/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/KochetovNicolai/subscriptions","organizations_url":"https://api.github.com/users/KochetovNicolai/orgs","repos_url":"https://api.github.com/users/KochetovNicolai/repos","events_url":"https://api.github.com/users/KochetovNicolai/events{/privacy}","received_events_url":"https://api.github.com/users/KochetovNicolai/received_events","type":"User","site_admin":false},"assignees":[{"login":"KochetovNicolai","id":4092911,"node_id":"MDQ6VXNlcjQwOTI5MTE=","avatar_url":"https://avatars.githubusercontent.com/u/4092911?v=4","gravatar_id":"","url":"https://api.github.com/users/KochetovNicolai","html_url":"https://github.com/KochetovNicolai","followers_url":"https://api.github.com/users/KochetovNicolai/followers","following_url":"https://api.github.com/users/KochetovNicolai/following{/other_user}","gists_url":"https://api.github.com/users/KochetovNicolai/gists{/gist_id}","starred_url":"https://api.github.com/users/KochetovNicolai/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/KochetovNicolai/subscriptions","organizations_url":"https://api.github.com/users/KochetovNicolai/orgs","repos_url":"https://api.github.com/users/KochetovNicolai/repos","events_url":"https://api.github.com/users/KochetovNicolai/events{/privacy}","received_events_url":"https://api.github.com/users/KochetovNicolai/received_events","type":"User","site_admin":false},{"login":"novikd","id":10158699,"node_id":"MDQ6VXNlcjEwMTU4Njk5","avatar_url":"https://avatars.githubusercontent.com/u/10158699?v=4","gravatar_id":"","url":"https://api.github.com/users/novikd","html_url":"https://github.com/novikd","followers_url":"https://api.github.com/users/novikd/followers","following_url":"https://api.github.com/users/novikd/following{/other_user}","gists_url":"https://api.github.com/users/novikd/gists{/gist_id}","starred_url":"https://api.github.com/users/novikd/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/novikd/subscriptions","organizations_url":"https://api.github.com/users/novikd/orgs","repos_url":"https://api.github.com/users/novikd/repos","events_url":"https://api.github.com/users/novikd/events{/privacy}","received_events_url":"https://api.github.com/users/novikd/received_events","type":"User","site_admin":false}],"milestone":null,"comments":5,"created_at":"2021-04-15T12:00:32Z","updated_at":"2022-01-27T12:04:37Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Hi. I noticed that when using window functions with a LIMIT clause, the window function appears to be applied to the result _after_ applying the limit. To me this is rather unintuitive and different from the way I am used to it from other applications. \r\nIs this intended behaviour or should I raise an issue for this? \r\n\r\nExample (clickhouse version 21.3.5.42):\r\n\r\n````\r\nCREATE TABLE test.window_test ENGINE = MergeTree()\r\nPARTITION BY field\r\nORDER BY field\r\nSETTINGS index_granularity = 8192\r\nAS\r\nSELECT\r\n    'a' AS field\r\nUNION ALL\r\nSELECT\r\n    'a' AS field\r\nUNION ALL\r\nSELECT\r\n    'b' AS field\r\nUNION ALL\r\nSELECT\r\n    'b' AS field\r\n    ;\r\n\r\nset allow_experimental_window_functions = 1;\r\n\r\n-- Example query with expected output:\r\nSELECT\r\n    field,\r\n    count() over (partition by field) AS window_count\r\nFROM\r\n    test.window_test;\r\n\r\n-- Output \r\n--| field | window_count | \r\n--| a      | 2      | \r\n--| a      | 2      | \r\n--| b      | 2      | \r\n--| b      | 2      |\r\n\r\n-- Query with LIMIT giving unexpected output:\r\nSELECT\r\n    field,\r\n    count() over (partition by field) AS window_count\r\nFROM\r\n    test.window_test\r\nLIMIT 1;\r\n\r\n-- Output\r\n--| field | window_count | \r\n--| a      | 1       | \r\n\r\n-- Expected Output:\r\n--| field | window_count | \r\n--| a      | 2      | \r\n````\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23125/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23125/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23110","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23110/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23110/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23110/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/23110","id":858606262,"node_id":"MDU6SXNzdWU4NTg2MDYyNjI=","number":23110,"title":"if move_factor is set to large，the data from the first volume will be mostly moved to the next volume","user":{"login":"FoolishWall","id":30719147,"node_id":"MDQ6VXNlcjMwNzE5MTQ3","avatar_url":"https://avatars.githubusercontent.com/u/30719147?v=4","gravatar_id":"","url":"https://api.github.com/users/FoolishWall","html_url":"https://github.com/FoolishWall","followers_url":"https://api.github.com/users/FoolishWall/followers","following_url":"https://api.github.com/users/FoolishWall/following{/other_user}","gists_url":"https://api.github.com/users/FoolishWall/gists{/gist_id}","starred_url":"https://api.github.com/users/FoolishWall/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/FoolishWall/subscriptions","organizations_url":"https://api.github.com/users/FoolishWall/orgs","repos_url":"https://api.github.com/users/FoolishWall/repos","events_url":"https://api.github.com/users/FoolishWall/events{/privacy}","received_events_url":"https://api.github.com/users/FoolishWall/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""},{"id":1634815111,"node_id":"MDU6TGFiZWwxNjM0ODE1MTEx","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-multidisk","name":"comp-multidisk","color":"b5bcff","default":false,"description":"Storages & policies"},{"id":1669010018,"node_id":"MDU6TGFiZWwxNjY5MDEwMDE4","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question-answered","name":"question-answered","color":"bfdadc","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":5,"created_at":"2021-04-15T07:56:51Z","updated_at":"2021-11-30T06:39:41Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"the storage.xml is as follows\r\n```\r\n<yandex>\r\n  <storage_configuration>\r\n    <disks>\r\n      <default>\r\n         <!--\r\n             You can reserve some amount of free space\r\n             on any disk (including default) by adding\r\n             keep_free_space_bytes tag\r\n         -->\r\n         <keep_free_space_bytes>1024</keep_free_space_bytes>\r\n      </default>\r\n      <default1>\r\n        <path>/data2/clickhouse/</path>\r\n        <keep_free_space_bytes>1024</keep_free_space_bytes>\r\n      </default1>\r\n    </disks>\r\n    <policies>\r\n      <default> <!-- name for new storage policy -->\r\n        <volumes>\r\n          <default> <!-- name of volume -->\r\n            <disk>default</disk>\r\n          </default>\r\n          <default1_vol>\r\n            <disk>default1</disk>\r\n          </default1_vol>\r\n        </volumes>\r\n        <move_factor>0.8</move_factor>\r\n      </default>\r\n    </policies>\r\n  </storage_configuration>\r\n</yandex>\r\n```\r\n\r\nbefore data migration，the storage space information is as follows\r\ndisk | size | used | use%\r\n-- | -- | -- | --\r\n/data1 | 1T | 250G | 27%\r\n/data2 | 1T | 3.2G | 1%\r\n\r\n\r\n\r\nafter data migration，the storage space information is as follows\r\ndisk | size | used | use%\r\n-- | -- | -- | --\r\n/data1 | 1T | 1.9G | 1%\r\n/data2 | 1T | 221G | 24%\r\n\r\n\r\n**And, what is the max_data_part_size_bytes default value?**\r\n\r\n\r\nif move_factor is set to small，the data from the first volume will be little moved to the next volume\r\nthe storage.xml is as follows\r\n```\r\n<yandex>\r\n  <storage_configuration>\r\n    <disks>\r\n      <default>\r\n         <!--\r\n             You can reserve some amount of free space\r\n             on any disk (including default) by adding\r\n             keep_free_space_bytes tag\r\n         -->\r\n         <keep_free_space_bytes>1024</keep_free_space_bytes>\r\n      </default>\r\n      <default1>\r\n        <path>/data2/clickhouse/</path>\r\n        <keep_free_space_bytes>1024</keep_free_space_bytes>\r\n      </default1>\r\n    </disks>\r\n    <policies>\r\n      <default> <!-- name for new storage policy -->\r\n        <volumes>\r\n          <default1_vol>\r\n            <disk>default1</disk>\r\n          </default1_vol>\r\n          <default> <!-- name of volume -->\r\n            <disk>default</disk>\r\n          </default>\r\n        </volumes>\r\n        <move_factor>0.2</move_factor>\r\n      </default>\r\n    </policies>\r\n  </storage_configuration>\r\n</yandex>\r\n```\r\n\r\nbefore data migration，the storage space information is as follows\r\ndisk | size | used | use%\r\n-- | -- | -- | --\r\n/data1 | 1T | 132M | 27%\r\n/data2 | 1T | 214G | 1%\r\n\r\n\r\n\r\nafter data migration，the storage space information is as follows\r\ndisk | size | used | use%\r\n-- | -- | -- | --\r\n/data1 | 1T | 419M | 1%\r\n/data2 | 1T | 214G | 24%\r\n\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23110/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23110/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23105","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23105/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23105/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23105/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/23105","id":858567577,"node_id":"MDU6SXNzdWU4NTg1Njc1Nzc=","number":23105,"title":"Is the combination of pipeline reasonable in the join scenario?","user":{"login":"744570676","id":29849109,"node_id":"MDQ6VXNlcjI5ODQ5MTA5","avatar_url":"https://avatars.githubusercontent.com/u/29849109?v=4","gravatar_id":"","url":"https://api.github.com/users/744570676","html_url":"https://github.com/744570676","followers_url":"https://api.github.com/users/744570676/followers","following_url":"https://api.github.com/users/744570676/following{/other_user}","gists_url":"https://api.github.com/users/744570676/gists{/gist_id}","starred_url":"https://api.github.com/users/744570676/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/744570676/subscriptions","organizations_url":"https://api.github.com/users/744570676/orgs","repos_url":"https://api.github.com/users/744570676/repos","events_url":"https://api.github.com/users/744570676/events{/privacy}","received_events_url":"https://api.github.com/users/744570676/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""},{"id":1357578153,"node_id":"MDU6TGFiZWwxMzU3NTc4MTUz","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-joins","name":"comp-joins","color":"b5bcff","default":false,"description":"JOINs"},{"id":1948647732,"node_id":"MDU6TGFiZWwxOTQ4NjQ3NzMy","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-processors","name":"comp-processors","color":"b5bcff","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2021-04-15T07:10:49Z","updated_at":"2021-04-17T03:07:07Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"When i execute 'explain plan' command to find the combination of pipeline in the multiple join scenario, the following result is shown : \r\n\r\n```\r\nExpression (Projection)                                                          \r\n  Expression (Before ORDER BY and SELECT)                                        \r\n    CreatingSets (Create sets for subqueries and joins)                          \r\n      Aggregating                                                                \r\n        Expression (Before GROUP BY)                                             \r\n          Filter (WHERE)                                                         \r\n            InflatingExpression (JOIN)                                           \r\n              Expression (Before JOIN)                                           \r\n                Expression (Projection)                                          \r\n                  CreatingSets (Create sets for subqueries and joins)            \r\n                    Expression (Before ORDER BY and SELECT)                      \r\n                      Filter (WHERE)                                             \r\n                        InflatingExpression (JOIN)                               \r\n                          Expression (Before JOIN)                               \r\n                            Expression (Projection)                              \r\n                              CreatingSets (Create sets for subqueries and joins)\r\n                                Expression (Before ORDER BY and SELECT)          \r\n                                  Filter (WHERE)                                 \r\n                                    InflatingExpression (JOIN)                   \r\n                                      Expression (Before JOIN)                   \r\n                                        ReadFromStorage (Read from MergeTree)\r\n```\r\n1. Isn't it more reasonable to put `InfaltingExpression (JOIN)` after `Fliter (where)`, so that the amount of data will be reduced a lot when joining？\r\n2. CreatingSets read right table data using a LazyBlockInputStream to build the hash table，and InflatingExpression perform prebo operation. So, it's not easy to understand why put InfaltExpression before CreatingSets, i want to know how the pipeline is scheduled？\r\n3. CreatingSets will resize the parallelism of current pipe to 1, which result in the poor join performance. What is the purpose of this?\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23105/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23105/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23104","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23104/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23104/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23104/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/23104","id":858555720,"node_id":"MDU6SXNzdWU4NTg1NTU3MjA=","number":23104,"title":"Cannot rewrite JOINs when alias in right on is the same as select alias","user":{"login":"Zhile","id":8524923,"node_id":"MDQ6VXNlcjg1MjQ5MjM=","avatar_url":"https://avatars.githubusercontent.com/u/8524923?v=4","gravatar_id":"","url":"https://api.github.com/users/Zhile","html_url":"https://github.com/Zhile","followers_url":"https://api.github.com/users/Zhile/followers","following_url":"https://api.github.com/users/Zhile/following{/other_user}","gists_url":"https://api.github.com/users/Zhile/gists{/gist_id}","starred_url":"https://api.github.com/users/Zhile/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Zhile/subscriptions","organizations_url":"https://api.github.com/users/Zhile/orgs","repos_url":"https://api.github.com/users/Zhile/repos","events_url":"https://api.github.com/users/Zhile/events{/privacy}","received_events_url":"https://api.github.com/users/Zhile/received_events","type":"User","site_admin":false},"labels":[{"id":386401505,"node_id":"MDU6TGFiZWwzODY0MDE1MDU=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/bug","name":"bug","color":"ee0701","default":true,"description":"Confirmed user-visible misbehaviour in official release"},{"id":1357578153,"node_id":"MDU6TGFiZWwxMzU3NTc4MTUz","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-joins","name":"comp-joins","color":"b5bcff","default":false,"description":"JOINs"},{"id":1365579236,"node_id":"MDU6TGFiZWwxMzY1NTc5MjM2","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/minor","name":"minor","color":"FFF8F8","default":false,"description":"Priority: minor"},{"id":2266396286,"node_id":"MDU6TGFiZWwyMjY2Mzk2Mjg2","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/v20.8-affected","name":"v20.8-affected","color":"c2bfff","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-04-15T06:54:37Z","updated_at":"2021-04-19T20:30:56Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Reproduced in 20.12, 21.3\r\nHow to reproduce? \r\n```\r\ndrop database if exists test_01600;\r\ncreate database test_01600;\r\n\r\nCREATE TABLE test_01600.base\r\n(\r\n`id` UInt64,\r\n`id2` UInt64,\r\n`d` UInt64,\r\n`value` UInt64\r\n)\r\nENGINE=MergeTree()\r\nPARTITION BY d\r\nORDER BY (id,id2,d);\r\n\r\nCREATE TABLE test_01600.derived1\r\n(\r\n    `id1` UInt64,\r\n    `d1` UInt64,\r\n    `value1` UInt64\r\n)\r\nENGINE = MergeTree()\r\nPARTITION BY d1\r\nORDER BY (id1, d1)\r\n;\r\n\r\nCREATE TABLE test_01600.derived2\r\n(\r\n    `id2` UInt64,\r\n    `d2` UInt64,\r\n    `value2` UInt64\r\n)\r\nENGINE = MergeTree()\r\nPARTITION BY d2\r\nORDER BY (id2, d2)\r\n;\r\n\r\nSELECT\r\n    base.id AS `base.id`,\r\n    derived2.id2 AS `derived2.id2`,\r\n    derived2.value2 AS `derived2.value2`,\r\n    derived1.value1 AS `derived1.value1`\r\nFROM test_01600.base AS base\r\nLEFT JOIN test_01600.derived2 AS derived2 ON base.id2 = derived2.id2\r\nLEFT JOIN test_01600.derived1 AS derived1 ON base.id = derived1.id1\r\n```\r\nError message: \r\n```\r\nCode: 48. DB::Exception: Received from localhost:9000. DB::Exception: Cannot rewrite JOINs. Alias 'derived2.id2' used in ON section depends on another alias 'derived2.id2': While processing SELECT base.id AS `base.id`, derived2.id2 AS `derived2.id2`, derived2.value2 AS `derived2.value2`, derived1.value1 AS `derived1.value1` FROM test_01600.base AS base LEFT JOIN test_01600.derived2 AS derived2 ON base.id2 = derived2.id2 LEFT JOIN test_01600.derived1 AS derived1 ON base.id = derived1.id1.\r\n```\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23104/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23104/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23060","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23060/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23060/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23060/events","html_url":"https://github.com/ClickHouse/ClickHouse/pull/23060","id":857726868,"node_id":"MDExOlB1bGxSZXF1ZXN0NjE1MDk4NDM2","number":23060,"title":"Updated mysqlxx pool implementation","user":{"login":"kitaisreal","id":22458333,"node_id":"MDQ6VXNlcjIyNDU4MzMz","avatar_url":"https://avatars.githubusercontent.com/u/22458333?v=4","gravatar_id":"","url":"https://api.github.com/users/kitaisreal","html_url":"https://github.com/kitaisreal","followers_url":"https://api.github.com/users/kitaisreal/followers","following_url":"https://api.github.com/users/kitaisreal/following{/other_user}","gists_url":"https://api.github.com/users/kitaisreal/gists{/gist_id}","starred_url":"https://api.github.com/users/kitaisreal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kitaisreal/subscriptions","organizations_url":"https://api.github.com/users/kitaisreal/orgs","repos_url":"https://api.github.com/users/kitaisreal/repos","events_url":"https://api.github.com/users/kitaisreal/events{/privacy}","received_events_url":"https://api.github.com/users/kitaisreal/received_events","type":"User","site_admin":false},"labels":[{"id":1309674771,"node_id":"MDU6TGFiZWwxMzA5Njc0Nzcx","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/pr-feature","name":"pr-feature","color":"007700","default":false,"description":"Pull request with new product feature"},{"id":1807683251,"node_id":"MDU6TGFiZWwxODA3NjgzMjUx","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/doc-alert","name":"doc-alert","color":"e51068","default":false,"description":"PR where any documentation work is needed or proceeded"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2021-04-14T09:50:53Z","updated_at":"2021-09-28T20:20:02Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"draft":true,"pull_request":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/pulls/23060","html_url":"https://github.com/ClickHouse/ClickHouse/pull/23060","diff_url":"https://github.com/ClickHouse/ClickHouse/pull/23060.diff","patch_url":"https://github.com/ClickHouse/ClickHouse/pull/23060.patch","merged_at":null},"body":"I hereby agree to the terms of the CLA available at: https://yandex.ru/legal/cla/?lang=en\r\n\r\nChangelog category (leave one):\r\n- New Feature\r\n\r\nChangelog entry (a user-readable short description of the changes that goes to CHANGELOG.md):\r\nAdded options `max_connections_size`, `connection_idle_timeout` to MySQLDictionarySource.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23060/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23060/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23053","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23053/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23053/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23053/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/23053","id":857336152,"node_id":"MDU6SXNzdWU4NTczMzYxNTI=","number":23053,"title":" Unknown identifier with alias substitution ","user":{"login":"UnamedRus","id":9449405,"node_id":"MDQ6VXNlcjk0NDk0MDU=","avatar_url":"https://avatars.githubusercontent.com/u/9449405?v=4","gravatar_id":"","url":"https://api.github.com/users/UnamedRus","html_url":"https://github.com/UnamedRus","followers_url":"https://api.github.com/users/UnamedRus/followers","following_url":"https://api.github.com/users/UnamedRus/following{/other_user}","gists_url":"https://api.github.com/users/UnamedRus/gists{/gist_id}","starred_url":"https://api.github.com/users/UnamedRus/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/UnamedRus/subscriptions","organizations_url":"https://api.github.com/users/UnamedRus/orgs","repos_url":"https://api.github.com/users/UnamedRus/repos","events_url":"https://api.github.com/users/UnamedRus/events{/privacy}","received_events_url":"https://api.github.com/users/UnamedRus/received_events","type":"User","site_admin":false},"labels":[{"id":845247686,"node_id":"MDU6TGFiZWw4NDUyNDc2ODY=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/usability","name":"usability","color":"ebf28c","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-04-13T21:27:10Z","updated_at":"2021-04-13T21:27:10Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**How to reproduce**\r\nClickhouse version 21.5\r\n\r\n```\r\nCREATE TABLE repl_tbl\r\n(\r\n    `key` UInt32,\r\n    `val_1` UInt32,\r\n    `val_2` String,\r\n    `val_3` String,\r\n    `val_4` String,\r\n    `val_5` UUID,\r\n    `ts` DateTime\r\n)\r\nENGINE = ReplacingMergeTree(ts)\r\nORDER BY key\r\n\r\nset prefer_column_name_to_alias=1;\r\n\r\nWITH 10 as k SELECT k as key, * FROM repl_tbl WHERE key = k;\r\n \r\nReceived exception from server (version 21.5.1):\r\nCode: 47. DB::Exception: Received from localhost:9000. DB::Exception: Unknown identifier: key there are columns: val_1, val_2, val_3, val_4, val_5, ts: While processing key = (10 AS k).\r\n```\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23053/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23053/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23042","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23042/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23042/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23042/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/23042","id":856952819,"node_id":"MDU6SXNzdWU4NTY5NTI4MTk=","number":23042,"title":"If LTS version has released more than one year ago, print a message that \"support period has ended\"","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-04-13T13:17:18Z","updated_at":"2021-04-13T13:19:19Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"**Use case**\r\nKindly encourage people to upgrade to stable versions.\r\n\r\n**Additional details**\r\nAlso print similar message for non-LTS releases.\r\n\r\nThis logic does not require any internet access (it is simple calculation on release time) and it should not disrupt any use-cases.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23042/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23042/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23039","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23039/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23039/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23039/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/23039","id":856894357,"node_id":"MDU6SXNzdWU4NTY4OTQzNTc=","number":23039,"title":"CSV support for zero padded arrays of integers.","user":{"login":"UnamedRus","id":9449405,"node_id":"MDQ6VXNlcjk0NDk0MDU=","avatar_url":"https://avatars.githubusercontent.com/u/9449405?v=4","gravatar_id":"","url":"https://api.github.com/users/UnamedRus","html_url":"https://github.com/UnamedRus","followers_url":"https://api.github.com/users/UnamedRus/followers","following_url":"https://api.github.com/users/UnamedRus/following{/other_user}","gists_url":"https://api.github.com/users/UnamedRus/gists{/gist_id}","starred_url":"https://api.github.com/users/UnamedRus/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/UnamedRus/subscriptions","organizations_url":"https://api.github.com/users/UnamedRus/orgs","repos_url":"https://api.github.com/users/UnamedRus/repos","events_url":"https://api.github.com/users/UnamedRus/events{/privacy}","received_events_url":"https://api.github.com/users/UnamedRus/received_events","type":"User","site_admin":false},"labels":[{"id":1365579236,"node_id":"MDU6TGFiZWwxMzY1NTc5MjM2","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/minor","name":"minor","color":"FFF8F8","default":false,"description":"Priority: minor"},{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-04-13T12:04:57Z","updated_at":"2021-04-13T12:34:18Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Describe the unexpected behaviour**\r\nCSV support zero padded integers, but doesn't support Arrays of zero padded integers.\r\n\r\n**How to reproduce**\r\n\r\n```\r\nprintf \"0123,01234\\n\" | clickhouse-local --input-format CSV --structure 'x UInt32, y UInt32' --query='SELECT * FROM table' --stacktrace\r\n123     1234\r\n\r\n\r\n\r\nprintf \"0123,01234,\\\"[1,094]\\\"\\n\" | clickhouse-local --input-format CSV --structure 'x UInt32, y UInt32, z Array(UInt32)' --query='SELECT * FROM table'\r\nCode: 130, e.displayText() = DB::ParsingException: Cannot read array from text, expected comma or end of array, found '9':\r\nRow 1:\r\nColumn 0,   name: x, type: UInt32,        parsed text: \"0123\"\r\nColumn 1,   name: y, type: UInt32,        parsed text: \"01234\"\r\nColumn 2,   name: z, type: Array(UInt32), parsed text: \"<DOUBLE QUOTE>[1,094]<DOUBLE QUOTE>\"ERROR\r\nCode: 130, e.displayText() = DB::ParsingException: Cannot read array from text, expected comma or end of array, found '9' (version 21.5.1.6436 (official build))\r\n\r\n: While executing File: (at row 1)\r\n (version 21.5.1.6436 (official build))\r\n ```\r\n\r\nRelated https://github.com/ClickHouse/ClickHouse/issues/5999 https://github.com/ClickHouse/ClickHouse/issues/20225","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23039/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23039/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23019","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23019/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23019/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23019/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/23019","id":856502210,"node_id":"MDU6SXNzdWU4NTY1MDIyMTA=","number":23019,"title":"Exception: Conversion from AggregateFunction(sum, Nullable(Int64)) to AggregateFunction(sum, Int64) is not supported: While executing Remote.","user":{"login":"Sammion","id":33392372,"node_id":"MDQ6VXNlcjMzMzkyMzcy","avatar_url":"https://avatars.githubusercontent.com/u/33392372?v=4","gravatar_id":"","url":"https://api.github.com/users/Sammion","html_url":"https://github.com/Sammion","followers_url":"https://api.github.com/users/Sammion/followers","following_url":"https://api.github.com/users/Sammion/following{/other_user}","gists_url":"https://api.github.com/users/Sammion/gists{/gist_id}","starred_url":"https://api.github.com/users/Sammion/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Sammion/subscriptions","organizations_url":"https://api.github.com/users/Sammion/orgs","repos_url":"https://api.github.com/users/Sammion/repos","events_url":"https://api.github.com/users/Sammion/events{/privacy}","received_events_url":"https://api.github.com/users/Sammion/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-04-13T02:13:07Z","updated_at":"2021-04-15T20:13:16Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Hi team,\r\nI meet an error when try to query a distribute table:\r\nHere is query and error:\r\n`select  clsfd_trffc_chnl_name,page_type_txt,sum(clsfd_pv_cnt) as pv from my_db.all_PI_TRAFFIC  where 1=1 group by  clsfd_trffc_chnl_name,page_type_txt order by  clsfd_trffc_chnl_name,page_type_txt;`\r\n\r\nException: Conversion from AggregateFunction(sum, Nullable(Int64)) to AggregateFunction(sum, Int64) is not supported: While executing Remote.\r\n\r\nbut I try the same column on the local server, it works well. Here is query \r\n`0be97fd088ac :) select  clsfd_trffc_chnl_name,page_type_txt,sum(clsfd_pv_cnt) as pv from my_db.PI_TRAFFIC  where 1=1 group by  clsfd_trffc_chnl_name,page_type_txt order by  clsfd_trffc_chnl_name,page_type_txt;`\r\n\r\nI am not sure if it is a bug. Anyone know why?\r\nHow can I do to avoid it happens?","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23019/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/23019/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22980","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22980/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22980/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22980/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/22980","id":855412193,"node_id":"MDU6SXNzdWU4NTU0MTIxOTM=","number":22980,"title":"Memory limit may not work as expected if query has very large number of UNION ALL","user":{"login":"gituser","id":104405,"node_id":"MDQ6VXNlcjEwNDQwNQ==","avatar_url":"https://avatars.githubusercontent.com/u/104405?v=4","gravatar_id":"","url":"https://api.github.com/users/gituser","html_url":"https://github.com/gituser","followers_url":"https://api.github.com/users/gituser/followers","following_url":"https://api.github.com/users/gituser/following{/other_user}","gists_url":"https://api.github.com/users/gituser/gists{/gist_id}","starred_url":"https://api.github.com/users/gituser/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/gituser/subscriptions","organizations_url":"https://api.github.com/users/gituser/orgs","repos_url":"https://api.github.com/users/gituser/repos","events_url":"https://api.github.com/users/gituser/events{/privacy}","received_events_url":"https://api.github.com/users/gituser/received_events","type":"User","site_admin":false},"labels":[{"id":1532016596,"node_id":"MDU6TGFiZWwxNTMyMDE2NTk2","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/memory","name":"memory","color":"e99695","default":false,"description":"When memory usage is higher than expected"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":16,"created_at":"2021-04-11T21:30:06Z","updated_at":"2021-10-17T03:30:39Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"**Describe the bug**\r\nI was using clickhouse `v20.5.2.7` on VM with 4GB memory without any issues on dataset approximately ~5.2 GB (total) and decided to upgrade it to the latest version which is  `v21.3.5.42`.\r\n\r\nI'm using default configuration supplied with debian packages, only slightly adjusting default user in `users.d/default.xml` and listen port in `config.d/my.xml` all other values are default set by clickhouse.\r\n\r\nSo after upgrade I noticed lots of OOMs happening, so I've played around with the versions and noticed that the last stable version I can use is:\r\n`v20.6.11.1`\r\n\r\nIf I update to any version after the `v20.6.11.1` clickhouse-server starts to OOM, e.g. to:  ` v20.7.2.30` \r\n\r\n**Does it reproduce on recent release?**\r\nYes\r\n\r\n**How to reproduce**\r\nI'm not quite sure how to reproduce the issue, most likely OOM happens due to big query I have with lots of UNIONs.\r\n\r\nTry this on version: `v20.7.2.30` or on more recent one `v21.3.5.42`. For me reproduces on all version after the `v20.6.11.1`\r\n\r\nThe table itself is about 134M rows:\r\n\r\n```\r\n┌───count()─┐\r\n│ 134659659 │\r\n└───────────┘\r\n```\r\n\r\n* CREATE TABLE:\r\n```\r\nCREATE TABLE rates_clickhouse_prod.good_rates\r\n(\r\n    `event_date` Date DEFAULT toDate(event_time),\r\n    `event_time` DateTime,\r\n    `from` String,\r\n    `to` String,\r\n    `amount` String,\r\n    `source` String\r\n)\r\nENGINE = MergeTree(event_date, (event_time, event_date), 8192)\r\n```\r\n\r\n* Sample data for all these tables:\r\n```\r\n┌─event_date─┬──────────event_time─┬─from─┬─to──┬─amount───┬─source────────────────────┐\r\n│ 2021-04-12 │ 2021-04-12 00:06:13 │ USD  │ EUR │ 0.840904 │ openexchangerates@USD/EUR │\r\n│ 2021-04-12 │ 2021-04-12 00:12:15 │ USD  │ EUR │ 0.840904 │ openexchangerates@USD/EUR │\r\n│ 2021-04-12 │ 2021-04-12 00:02:12 │ USD  │ EUR │ 0.840904 │ openexchangerates@USD/EUR │\r\n│ 2021-04-12 │ 2021-04-12 00:16:13 │ USD  │ EUR │ 0.840904 │ openexchangerates@USD/EUR │\r\n│ 2021-04-12 │ 2021-04-12 00:04:12 │ USD  │ EUR │ 0.840904 │ openexchangerates@USD/EUR │\r\n└────────────┴─────────────────────┴──────┴─────┴──────────┴───────────────────────────┘\r\n```\r\n\r\n* Queries to run that lead to unexpected result\r\nThe query looks like this:\r\n\r\n```\r\n SELECT `from`, `to`, `amount`, `event_time`, toUnixTimestamp(good_rates.event_time, 'Europe/London') as unix_timestamp FROM \r\n`good_rates` LIMIT 0 UNION ALL SELECT `from`, `to`, `amount`, `event_time`, toUnixTimestamp(good_rates.event_time, 'Europe/London') as \r\nunix_timestamp FROM `good_rates` WHERE `from` = 'YYY' AND `to` = 'XXX' AND `event_time` <= '2021-04-11 06:23:07' AND `event_time` >= \r\n'2021-04-11 06:19:07' LIMIT 1 UNION ALL SELECT `from`, `to`, `amount`, `event_time`, toUnixTimestamp(good_rates.event_time, \r\n'Europe/London') as unix_timestamp FROM `good_rates` WHERE `from` = 'YYY' AND `to` = 'XXX' AND `event_time` <= '2021-04-11 07:23:07' \r\nAND `event_time` >= '2021-04-11 07:19:07' LIMIT 1 UNION ALL SELECT `from`, `to`, `amount`, `event_time`, \r\ntoUnixTimestamp(good_rates.event_time, 'Europe/London') as unix_timestamp FROM `good_rates` WHERE `from` = 'YYY' AND `to` = 'XXX' AND \r\n`event_time` <= '2021-04-11 08:23:07' AND `event_time` >= '2021-04-11 08:19:07' LIMIT 1 UNION ALL SELECT `from`, `to`, `amount`, \r\n`event_time`, toUnixTimestamp(good_rates.event_time, 'Europe/London') as unix_timestamp FROM `good_rates` WHERE `from` = 'YYY' AND `to` \r\n= 'XXX' AND `event_time` <= '2021-04-11 09:23:07' AND `event_time` >= '2021-04-11 09:19:07' LIMIT 1 UNION ALL SELECT `from`, `to`, \r\n`amount`, `event_time`, toUnixTimestamp(good_rates.event_time, 'Europe/London') as unix_timestamp FROM `good_rates` WHERE `from` = \r\n'YYY' AND `to` = 'XXX' AND `event_time` <= '2021-04-11 10:23:07' AND `event_time` >= '2021-04-11 10:19:07' LIMIT 1 UNION ALL SELECT \r\n`from`, `to`, `amount`, `event_time`, toUnixTimestamp(good_rates.event_time, 'Europe/London') as unix_timestamp FROM `good_rates` WHERE \r\n`from` = 'YYY' AND `to` = 'XXX' AND `event_time` <= '2021-04-11 11:23:07' AND `event_time` >= '2021-04-11 11:19:07' LIMIT 1 UNION ALL \r\nSELECT `from`, `to`, `amount`, `event_time`, toUnixTimestamp(good_rates.event_time, 'Europe/London') as unix_timestamp FROM \r\n`good_rates` WHERE `from` = 'YYY' AND `to` = 'XXX' AND `event_time` <= '2021-04-11 12:23:07' AND `event_time` >= '2021-04-11 12:19:07' \r\nLIMIT 1 UNION ALL SELECT `from`, `to`, `amount`, `event_time`, toUnixTimestamp(good_rates.event_time, 'Europe/London') as \r\nunix_timestamp FROM `good_rates` WHERE `from` = 'YYY' AND `to` = 'XXX' AND `event_time` <= '2021-04-11 13:23:07' AND `event_time` >= \r\n'2021-04-11 13:19:07' LIMIT 1 UNION ALL SELECT `from`, `to`, `amount`, `event_time`, toUnixTimestamp(good_rates.event_time, \r\n'Europe/London') as unix_timestamp FROM `good_rates` WHERE `from` = 'YYY' AND `to` = 'XXX' AND `event_time` <= '2021-04-11 14:23:07' \r\nAND `event_time` >= '2021-04-11 14:19:07' LIMIT 1 UNION ALL SELECT `from`, `to`, `amount`, `event_time`, \r\ntoUnixTimestamp(good_rates.event_time, 'Europe/London') as unix_timestamp FROM `good_rates` WHERE `from` = 'YYY' AND `to` = 'XXX' AND \r\n`event_time` <= '2021-04-11 15:23:07' AND `event_time` >= '2021-04-11 15:19:07' LIMIT 1 UNION ALL SELECT `from`, `to`, `amount`, \r\n`event_time`, toUnixTimestamp(good_rates.event_time, 'Europe/London') as unix_timestamp FROM `good_rates` WHERE `from` = 'YYY' AND `to` \r\n= 'XXX' AND `event_time` <= '2021-04-11 16:23:07' AND `event_time` >= '2021-04-11 16:19:07' LIMIT 1 UNION ALL SELECT `from`, `to`, \r\n`amount`, `event_time`, toUnixTimestamp(good_rates.event_time, 'Europe/London') as unix_timestamp FROM `good_rates` WHERE `from` = \r\n'YYY' AND `to` = 'XXX' AND `event_time` <= '2021-04-11 17:23:07' AND `event_time` >= '2021-04-11 17:19:07' LIMIT 1 UNION ALL SELECT \r\n`from`, `to`, `amount`, `event_time`, toUnixTimestamp(good_rates.event_time, 'Europe/London') as unix_timestamp FROM `good_rates` WHERE \r\n`from` = 'YYY' AND `to` = 'XXX' AND `event_time` <= '2021-04-11 18:23:07' AND `event_time` >= '2021-04-11 18:19:07' LIMIT 1 UNION ALL \r\nSELECT `from`, `to`, `amount`, `event_time`, toUnixTimestamp(good_rates.event_time, 'Europe/London') as unix_timestamp FROM \r\n`good_rates` WHERE `from` = 'YYY' AND `to` = 'ZZZ' AND `event_time` <= '2021-04-11 06:23:07' AND `event_time` >= '2021-04-11 06:19:07' \r\nLIMIT 1 UNION ALL SELECT `from`, `to`, `amount`, `event_time`, toUnixTimestamp(good_rates.event_time, 'Europe/London') as \r\nunix_timestamp FROM `good_rates` WHERE `from` = 'YYY' AND `to` = 'ZZZ' AND `event_time` <= '2021-04-11 07:23:07' AND ...\r\n```\r\nI know it's a bad query but the thing is on `v20.6.11.1` it works fine whilst on `v20.7.2.30` and above clickhouse-server OOMs.\r\n\r\n**Expected behavior**\r\nclickhouse-server shouldn't OOM.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22980/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22980/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22970","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22970/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22970/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22970/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/22970","id":855213545,"node_id":"MDU6SXNzdWU4NTUyMTM1NDU=","number":22970,"title":"Not to allow create different table with same zookeeper replica path","user":{"login":"yx91490","id":8814185,"node_id":"MDQ6VXNlcjg4MTQxODU=","avatar_url":"https://avatars.githubusercontent.com/u/8814185?v=4","gravatar_id":"","url":"https://api.github.com/users/yx91490","html_url":"https://github.com/yx91490","followers_url":"https://api.github.com/users/yx91490/followers","following_url":"https://api.github.com/users/yx91490/following{/other_user}","gists_url":"https://api.github.com/users/yx91490/gists{/gist_id}","starred_url":"https://api.github.com/users/yx91490/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yx91490/subscriptions","organizations_url":"https://api.github.com/users/yx91490/orgs","repos_url":"https://api.github.com/users/yx91490/repos","events_url":"https://api.github.com/users/yx91490/events{/privacy}","received_events_url":"https://api.github.com/users/yx91490/received_events","type":"User","site_admin":false},"labels":[{"id":845247686,"node_id":"MDU6TGFiZWw4NDUyNDc2ODY=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/usability","name":"usability","color":"ebf28c","default":false,"description":""},{"id":1365579236,"node_id":"MDU6TGFiZWwxMzY1NTc5MjM2","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/minor","name":"minor","color":"FFF8F8","default":false,"description":"Priority: minor"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":6,"created_at":"2021-04-11T04:11:36Z","updated_at":"2021-04-21T08:20:11Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"**Use case**\r\n\r\nI using version 20.8.11.17.lts. One day I created a table db2.tab1 with same zookeeper replica path as table db1.tab1, then I found some errors in log:\r\n\r\n```\r\n<Error> executeQuery: Code: 220, e.displayText() = DB::Exception: Duplicate interserver IO endpoint: DataPartsExchange:/clickhouse/tables/01/db2.tab1/replicas/xxxx (version 20.8.11.17 (official build)) (from 0.0.0.0:0)\r\n```\r\n\r\nthen I restart clickhouse instance but cannot start successfully, Similar error as above :\r\n\r\n```\r\n2021.04.08 03:10:11.605796 [ 4093 ] {} <Error> Application: Caught exception while loading metadata: Code: 231, e.displayText() = DB::Exception: The local set of parts of table db1.tab1 doesn't look like the set of parts in ZooKeeper: 244.00 rows of 244.00 total rows in filesystem are suspicious. There are 6 unexpected parts with 244 rows (0 of them is not just-written with 244 rows), 0 missing parts (with 0 blocks).: Cannot attach table `db1`.`tab1` from metadata file /apps/data/clickhouse-1/metadata/db1/tab1.sql from query ATTACH TABLE db1.tab1 (`department` String, `city` String, `begin_month` String , `transfer_ratio` Decimal(18, 2) COMMENT, `pre_ratio` Decimal(18, 2), `city_transfer_ratio` Decimal(18, 2), `city_pre_ratio` Decimal(18, 2), `dt` String) ENGINE = ReplicatedMergeTree('/clickhouse/tables/{shard}/db2.tab1', '{replica}') PARTITION BY dt ORDER BY (department, city) SETTINGS index_granularity = 8192: while loading database `db1` from path /apps/data/clickhouse-1/metadata/db1, Stack trace (when copying this message, always include the lines below)\r\n...\r\n2021.04.08 03:11:50.741636 [ 4508 ] {} <Error> Application: Caught exception while loading metadata: Code: 220, e.displayText() = DB::Exception: Duplicate interserver IO endpoint: DataPartsExchange:/clickhouse/tables/01/db2.tab1/replicas/xxx: while loading database `db2` from path /apps/data/clickhouse-1/metadata/db2, Stack trace (when copying this message, always include the lines below):\r\n```\r\n\r\nuntil I delete db1.tab1 metadata in disk I can start clickhouse instance successfully.\r\n\r\n**Describe the solution you'd like**\r\n\r\nSo I suggest Not to allow create different table with same zookeeper replica path to avoid this mistake error.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nNo\r\n\r\n**Additional context**\r\n\r\nNo\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22970/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22970/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22963","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22963/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22963/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22963/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/22963","id":855142857,"node_id":"MDU6SXNzdWU4NTUxNDI4NTc=","number":22963,"title":"Build debian packages manually without the help of `dh-*`, `dpkg-*`, `debuild`, `deb-*` tools.","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":521113272,"node_id":"MDU6TGFiZWw1MjExMTMyNzI=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/build","name":"build","color":"800000","default":false,"description":""},{"id":1529343116,"node_id":"MDU6TGFiZWwxNTI5MzQzMTE2","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/make%20it%20worse","name":"make it worse","color":"ffaaff","default":false,"description":""}],"state":"open","locked":false,"assignee":{"login":"Felixoid","id":3025537,"node_id":"MDQ6VXNlcjMwMjU1Mzc=","avatar_url":"https://avatars.githubusercontent.com/u/3025537?v=4","gravatar_id":"","url":"https://api.github.com/users/Felixoid","html_url":"https://github.com/Felixoid","followers_url":"https://api.github.com/users/Felixoid/followers","following_url":"https://api.github.com/users/Felixoid/following{/other_user}","gists_url":"https://api.github.com/users/Felixoid/gists{/gist_id}","starred_url":"https://api.github.com/users/Felixoid/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Felixoid/subscriptions","organizations_url":"https://api.github.com/users/Felixoid/orgs","repos_url":"https://api.github.com/users/Felixoid/repos","events_url":"https://api.github.com/users/Felixoid/events{/privacy}","received_events_url":"https://api.github.com/users/Felixoid/received_events","type":"User","site_admin":false},"assignees":[{"login":"Felixoid","id":3025537,"node_id":"MDQ6VXNlcjMwMjU1Mzc=","avatar_url":"https://avatars.githubusercontent.com/u/3025537?v=4","gravatar_id":"","url":"https://api.github.com/users/Felixoid","html_url":"https://github.com/Felixoid","followers_url":"https://api.github.com/users/Felixoid/followers","following_url":"https://api.github.com/users/Felixoid/following{/other_user}","gists_url":"https://api.github.com/users/Felixoid/gists{/gist_id}","starred_url":"https://api.github.com/users/Felixoid/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Felixoid/subscriptions","organizations_url":"https://api.github.com/users/Felixoid/orgs","repos_url":"https://api.github.com/users/Felixoid/repos","events_url":"https://api.github.com/users/Felixoid/events{/privacy}","received_events_url":"https://api.github.com/users/Felixoid/received_events","type":"User","site_admin":false}],"milestone":null,"comments":8,"created_at":"2021-04-10T19:48:52Z","updated_at":"2022-01-21T08:54:54Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"There is too much infrastructure in Debian tools.\r\nFor example, they set many build flags that require significant efforts from us to remove.\r\nWe already have portable single binary build without dependencies and we don't need debian tools at all.\r\n\r\nTo build Debian package we only need to place some files accordingly, run `tar`, `gzip` and `ar`.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22963/reactions","total_count":4,"+1":3,"-1":1,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22963/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22959","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22959/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22959/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22959/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/22959","id":855107556,"node_id":"MDU6SXNzdWU4NTUxMDc1NTY=","number":22959,"title":"toUnixTimestamp64* wrong value with negative timestamps","user":{"login":"zvonand","id":32552679,"node_id":"MDQ6VXNlcjMyNTUyNjc5","avatar_url":"https://avatars.githubusercontent.com/u/32552679?v=4","gravatar_id":"","url":"https://api.github.com/users/zvonand","html_url":"https://github.com/zvonand","followers_url":"https://api.github.com/users/zvonand/followers","following_url":"https://api.github.com/users/zvonand/following{/other_user}","gists_url":"https://api.github.com/users/zvonand/gists{/gist_id}","starred_url":"https://api.github.com/users/zvonand/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/zvonand/subscriptions","organizations_url":"https://api.github.com/users/zvonand/orgs","repos_url":"https://api.github.com/users/zvonand/repos","events_url":"https://api.github.com/users/zvonand/events{/privacy}","received_events_url":"https://api.github.com/users/zvonand/received_events","type":"User","site_admin":false},"labels":[{"id":1019683656,"node_id":"MDU6TGFiZWwxMDE5NjgzNjU2","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/altinity","name":"altinity","color":"c0f5f9","default":false,"description":""},{"id":1397894054,"node_id":"MDU6TGFiZWwxMzk3ODk0MDU0","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unfinished%20code","name":"unfinished code","color":"ff8800","default":false,"description":""},{"id":1481221764,"node_id":"MDU6TGFiZWwxNDgxMjIxNzY0","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-datetime","name":"comp-datetime","color":"b5bcff","default":false,"description":"date & time & timezone related"}],"state":"open","locked":false,"assignee":{"login":"Enmk","id":1110183,"node_id":"MDQ6VXNlcjExMTAxODM=","avatar_url":"https://avatars.githubusercontent.com/u/1110183?v=4","gravatar_id":"","url":"https://api.github.com/users/Enmk","html_url":"https://github.com/Enmk","followers_url":"https://api.github.com/users/Enmk/followers","following_url":"https://api.github.com/users/Enmk/following{/other_user}","gists_url":"https://api.github.com/users/Enmk/gists{/gist_id}","starred_url":"https://api.github.com/users/Enmk/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Enmk/subscriptions","organizations_url":"https://api.github.com/users/Enmk/orgs","repos_url":"https://api.github.com/users/Enmk/repos","events_url":"https://api.github.com/users/Enmk/events{/privacy}","received_events_url":"https://api.github.com/users/Enmk/received_events","type":"User","site_admin":false},"assignees":[{"login":"Enmk","id":1110183,"node_id":"MDQ6VXNlcjExMTAxODM=","avatar_url":"https://avatars.githubusercontent.com/u/1110183?v=4","gravatar_id":"","url":"https://api.github.com/users/Enmk","html_url":"https://github.com/Enmk","followers_url":"https://api.github.com/users/Enmk/followers","following_url":"https://api.github.com/users/Enmk/following{/other_user}","gists_url":"https://api.github.com/users/Enmk/gists{/gist_id}","starred_url":"https://api.github.com/users/Enmk/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Enmk/subscriptions","organizations_url":"https://api.github.com/users/Enmk/orgs","repos_url":"https://api.github.com/users/Enmk/repos","events_url":"https://api.github.com/users/Enmk/events{/privacy}","received_events_url":"https://api.github.com/users/Enmk/received_events","type":"User","site_admin":false}],"milestone":null,"comments":0,"created_at":"2021-04-10T16:40:35Z","updated_at":"2021-04-11T18:40:26Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"`toUnixTimestamp64*()` functions treat milli-, micro- and nanoseconds in a wrong way when timestamp is negative, for example:\r\n```\r\nSELECT toUnixTimestamp64Milli(toDateTime64('1927-01-01 00:00:00', 0, 'Europe/Zurich'))\r\n\r\n┌─toUnixTimestamp64Milli(toDateTime64('1927-01-01 00:00:00', 0, 'Europe/Zurich'))─┐\r\n│                                                                  -1357002000000 │\r\n└─────────────────────────────────────────────────────────────────────────────────┘\r\n\r\n\r\nSELECT toUnixTimestamp64Milli(toDateTime64('1927-01-01 00:00:00.123', 3, 'Europe/Zurich'))\r\n\r\n┌─toUnixTimestamp64Milli(toDateTime64('1927-01-01 00:00:00.123', 3, 'Europe/Zurich'))─┐\r\n│                                                                      -1357002000123 │\r\n└─────────────────────────────────────────────────────────────────────────────────────┘\r\n```\r\n(In the case above, the first timestamp must be less than the second)\r\n\r\nClickHouse version 21.5.1.6463","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22959/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22959/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22949","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22949/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22949/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22949/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/22949","id":855060206,"node_id":"MDU6SXNzdWU4NTUwNjAyMDY=","number":22949,"title":"Update Sign Field in CollapsingMeregTree Engine in Clickhouse","user":{"login":"IVRAMA","id":40890530,"node_id":"MDQ6VXNlcjQwODkwNTMw","avatar_url":"https://avatars.githubusercontent.com/u/40890530?v=4","gravatar_id":"","url":"https://api.github.com/users/IVRAMA","html_url":"https://github.com/IVRAMA","followers_url":"https://api.github.com/users/IVRAMA/followers","following_url":"https://api.github.com/users/IVRAMA/following{/other_user}","gists_url":"https://api.github.com/users/IVRAMA/gists{/gist_id}","starred_url":"https://api.github.com/users/IVRAMA/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/IVRAMA/subscriptions","organizations_url":"https://api.github.com/users/IVRAMA/orgs","repos_url":"https://api.github.com/users/IVRAMA/repos","events_url":"https://api.github.com/users/IVRAMA/events{/privacy}","received_events_url":"https://api.github.com/users/IVRAMA/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-04-10T12:46:56Z","updated_at":"2021-04-10T12:46:56Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Hi All, \r\nI am new to the **CollapsingMergeTree** Engine. \r\n\r\nI have a scenario where the data is ingested into a table for eg: Table named Events with fields \r\nEventid (PRimary KEy), \r\nUpdated_At (Date Field) \r\nSign (sign field for engine).\r\n\r\nThe first record could be inserted into Events with values(1,'2021-04-09 09:09:15', 1) \r\n\r\nAfter Soemtime a new record is inserted with values (1,'2021-04-09 16:22:23', 1)\r\n\r\nI would now like to change the sign as -1 for the first record but getting an error message cannot update key field (sign).\r\n\r\nCan someone help me in this usecase where i need to keep only the latest records and previous records need to be deleted. \r\nSimilar to **ReplacingMergeTree**. \r\nClickhouse documentation tells that we cannto garuntee **_Complete Deduplication of records_** in ReplacingMergeTree Engine.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22949/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22949/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22948","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22948/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22948/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22948/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/22948","id":855050355,"node_id":"MDU6SXNzdWU4NTUwNTAzNTU=","number":22948,"title":"toYearWeek() wrong value","user":{"login":"zvonand","id":32552679,"node_id":"MDQ6VXNlcjMyNTUyNjc5","avatar_url":"https://avatars.githubusercontent.com/u/32552679?v=4","gravatar_id":"","url":"https://api.github.com/users/zvonand","html_url":"https://github.com/zvonand","followers_url":"https://api.github.com/users/zvonand/followers","following_url":"https://api.github.com/users/zvonand/following{/other_user}","gists_url":"https://api.github.com/users/zvonand/gists{/gist_id}","starred_url":"https://api.github.com/users/zvonand/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/zvonand/subscriptions","organizations_url":"https://api.github.com/users/zvonand/orgs","repos_url":"https://api.github.com/users/zvonand/repos","events_url":"https://api.github.com/users/zvonand/events{/privacy}","received_events_url":"https://api.github.com/users/zvonand/received_events","type":"User","site_admin":false},"labels":[{"id":1019683656,"node_id":"MDU6TGFiZWwxMDE5NjgzNjU2","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/altinity","name":"altinity","color":"c0f5f9","default":false,"description":""},{"id":1397894054,"node_id":"MDU6TGFiZWwxMzk3ODk0MDU0","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unfinished%20code","name":"unfinished code","color":"ff8800","default":false,"description":""},{"id":1481221764,"node_id":"MDU6TGFiZWwxNDgxMjIxNzY0","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-datetime","name":"comp-datetime","color":"b5bcff","default":false,"description":"date & time & timezone related"}],"state":"open","locked":false,"assignee":{"login":"Enmk","id":1110183,"node_id":"MDQ6VXNlcjExMTAxODM=","avatar_url":"https://avatars.githubusercontent.com/u/1110183?v=4","gravatar_id":"","url":"https://api.github.com/users/Enmk","html_url":"https://github.com/Enmk","followers_url":"https://api.github.com/users/Enmk/followers","following_url":"https://api.github.com/users/Enmk/following{/other_user}","gists_url":"https://api.github.com/users/Enmk/gists{/gist_id}","starred_url":"https://api.github.com/users/Enmk/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Enmk/subscriptions","organizations_url":"https://api.github.com/users/Enmk/orgs","repos_url":"https://api.github.com/users/Enmk/repos","events_url":"https://api.github.com/users/Enmk/events{/privacy}","received_events_url":"https://api.github.com/users/Enmk/received_events","type":"User","site_admin":false},"assignees":[{"login":"Enmk","id":1110183,"node_id":"MDQ6VXNlcjExMTAxODM=","avatar_url":"https://avatars.githubusercontent.com/u/1110183?v=4","gravatar_id":"","url":"https://api.github.com/users/Enmk","html_url":"https://github.com/Enmk","followers_url":"https://api.github.com/users/Enmk/followers","following_url":"https://api.github.com/users/Enmk/following{/other_user}","gists_url":"https://api.github.com/users/Enmk/gists{/gist_id}","starred_url":"https://api.github.com/users/Enmk/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Enmk/subscriptions","organizations_url":"https://api.github.com/users/Enmk/orgs","repos_url":"https://api.github.com/users/Enmk/repos","events_url":"https://api.github.com/users/Enmk/events{/privacy}","received_events_url":"https://api.github.com/users/Enmk/received_events","type":"User","site_admin":false}],"milestone":null,"comments":0,"created_at":"2021-04-10T11:52:39Z","updated_at":"2021-04-11T10:07:49Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"According to [CH docs](https://clickhouse.tech/docs/en/sql-reference/functions/date-time-functions/#toweekdatemode), `toYearWeek` mode `0` has return years range 0 - 53, but instead of returning `*year*00` for the corresponding queries, it returns `*year-1*52`:\r\n\r\n```\r\nSELECT toYearWeek(toDateTime64('1930-01-01 00:00:00', 0, 'UTC'))\r\n\r\n┌─toYearWeek(toDateTime64('1930-01-01 00:00:00', 0, 'UTC'))─┐\r\n│                                                    192952 │\r\n└───────────────────────────────────────────────────────────┘\r\n\r\n\r\nSELECT toYearWeek(toDateTime64('1942-01-01 00:00:00', 0, 'UTC'))\r\n\r\n┌─toYearWeek(toDateTime64('1942-01-01 00:00:00', 0, 'UTC'))─┐\r\n│                                                    194152 │\r\n└───────────────────────────────────────────────────────────┘\r\n\r\n\r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22948/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22948/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22940","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22940/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22940/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22940/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/22940","id":854744539,"node_id":"MDU6SXNzdWU4NTQ3NDQ1Mzk=","number":22940,"title":"primary index by equality condition not always used","user":{"login":"akuzm","id":36882414,"node_id":"MDQ6VXNlcjM2ODgyNDE0","avatar_url":"https://avatars.githubusercontent.com/u/36882414?v=4","gravatar_id":"","url":"https://api.github.com/users/akuzm","html_url":"https://github.com/akuzm","followers_url":"https://api.github.com/users/akuzm/followers","following_url":"https://api.github.com/users/akuzm/following{/other_user}","gists_url":"https://api.github.com/users/akuzm/gists{/gist_id}","starred_url":"https://api.github.com/users/akuzm/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/akuzm/subscriptions","organizations_url":"https://api.github.com/users/akuzm/orgs","repos_url":"https://api.github.com/users/akuzm/repos","events_url":"https://api.github.com/users/akuzm/events{/privacy}","received_events_url":"https://api.github.com/users/akuzm/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-04-09T18:03:37Z","updated_at":"2021-04-09T18:03:37Z","closed_at":null,"author_association":"COLLABORATOR","active_lock_reason":null,"body":"```\r\n*2* :) create table ttt engine MergeTree order by str = '1' as select number, toString(number % 10) str from numbers_mt(100000);\r\n\r\n\r\n*2* :) select * from ttt where str = '1' format Null\r\n\r\n0 rows in set. Elapsed: 0.024 sec. Processed 100.00 thousand rows, 1.28 MB (4.13 million rows/s., 52.70 MB/s.) \r\n\r\n*2* :) select * from ttt where (str = '1') = 1 format Null\r\n\r\n0 rows in set. Elapsed: 0.037 sec. Processed 18.08 thousand rows, 325.44 KB (484.22 thousand rows/s., 8.72 MB/s.) \r\n```\r\n\r\nCompare the number of read rows.\r\n\r\nFound this when working with the CI checks database, where I often need to handle pull request #0 meaning master, and empty test name meaning the whole check, so I tried creating an index like this.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22940/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22940/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22933","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22933/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22933/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22933/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/22933","id":854491947,"node_id":"MDU6SXNzdWU4NTQ0OTE5NDc=","number":22933,"title":"support exchange partition between a partition of a table and a non parttion table","user":{"login":"l1t1","id":23301704,"node_id":"MDQ6VXNlcjIzMzAxNzA0","avatar_url":"https://avatars.githubusercontent.com/u/23301704?v=4","gravatar_id":"","url":"https://api.github.com/users/l1t1","html_url":"https://github.com/l1t1","followers_url":"https://api.github.com/users/l1t1/followers","following_url":"https://api.github.com/users/l1t1/following{/other_user}","gists_url":"https://api.github.com/users/l1t1/gists{/gist_id}","starred_url":"https://api.github.com/users/l1t1/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/l1t1/subscriptions","organizations_url":"https://api.github.com/users/l1t1/orgs","repos_url":"https://api.github.com/users/l1t1/repos","events_url":"https://api.github.com/users/l1t1/events{/privacy}","received_events_url":"https://api.github.com/users/l1t1/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-04-09T12:46:12Z","updated_at":"2021-04-09T19:31:04Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"ref:\r\n\r\nhttps://docs.oracle.com/cd/B19306_01/server.102/b14200/statements_3001.htm#i2132971\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22933/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22933/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22932","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22932/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22932/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22932/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/22932","id":854486029,"node_id":"MDU6SXNzdWU4NTQ0ODYwMjk=","number":22932,"title":"cte supports column names list in table name","user":{"login":"l1t1","id":23301704,"node_id":"MDQ6VXNlcjIzMzAxNzA0","avatar_url":"https://avatars.githubusercontent.com/u/23301704?v=4","gravatar_id":"","url":"https://api.github.com/users/l1t1","html_url":"https://github.com/l1t1","followers_url":"https://api.github.com/users/l1t1/followers","following_url":"https://api.github.com/users/l1t1/following{/other_user}","gists_url":"https://api.github.com/users/l1t1/gists{/gist_id}","starred_url":"https://api.github.com/users/l1t1/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/l1t1/subscriptions","organizations_url":"https://api.github.com/users/l1t1/orgs","repos_url":"https://api.github.com/users/l1t1/repos","events_url":"https://api.github.com/users/l1t1/events{/privacy}","received_events_url":"https://api.github.com/users/l1t1/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":2788693937,"node_id":"MDU6TGFiZWwyNzg4NjkzOTM3","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-cte","name":"comp-cte","color":"b5bcff","default":false,"description":"common table expression (WITH ... SELECT)"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-04-09T12:37:58Z","updated_at":"2021-04-09T19:31:48Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"we must write as following now\r\n```sql\r\nwith tmp \r\nas\r\n(select 'a'c1,'b'c2,'b'c3,'c'c4  union all\r\nselect 'b','b','a','d'  union all\r\nselect 'a','b','e','c'  union all\r\nselect 'e','b','a','d' \r\n)\r\n```\r\nI want to write \r\n```sql\r\nwith tmp (c1,c2,c3,c4)\r\nas\r\n(select 'a','b','b','c'  union all\r\nselect 'b','b','a','d'  union all\r\nselect 'a','b','e','c'  union all\r\nselect 'e','b','a','d' \r\n)\r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22932/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22932/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22930","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22930/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22930/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22930/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/22930","id":854440149,"node_id":"MDU6SXNzdWU4NTQ0NDAxNDk=","number":22930,"title":"toWeek() returning wrong result for some dates","user":{"login":"zvonand","id":32552679,"node_id":"MDQ6VXNlcjMyNTUyNjc5","avatar_url":"https://avatars.githubusercontent.com/u/32552679?v=4","gravatar_id":"","url":"https://api.github.com/users/zvonand","html_url":"https://github.com/zvonand","followers_url":"https://api.github.com/users/zvonand/followers","following_url":"https://api.github.com/users/zvonand/following{/other_user}","gists_url":"https://api.github.com/users/zvonand/gists{/gist_id}","starred_url":"https://api.github.com/users/zvonand/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/zvonand/subscriptions","organizations_url":"https://api.github.com/users/zvonand/orgs","repos_url":"https://api.github.com/users/zvonand/repos","events_url":"https://api.github.com/users/zvonand/events{/privacy}","received_events_url":"https://api.github.com/users/zvonand/received_events","type":"User","site_admin":false},"labels":[{"id":1019683656,"node_id":"MDU6TGFiZWwxMDE5NjgzNjU2","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/altinity","name":"altinity","color":"c0f5f9","default":false,"description":""},{"id":1397894054,"node_id":"MDU6TGFiZWwxMzk3ODk0MDU0","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unfinished%20code","name":"unfinished code","color":"ff8800","default":false,"description":""},{"id":1481221764,"node_id":"MDU6TGFiZWwxNDgxMjIxNzY0","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-datetime","name":"comp-datetime","color":"b5bcff","default":false,"description":"date & time & timezone related"}],"state":"open","locked":false,"assignee":{"login":"Enmk","id":1110183,"node_id":"MDQ6VXNlcjExMTAxODM=","avatar_url":"https://avatars.githubusercontent.com/u/1110183?v=4","gravatar_id":"","url":"https://api.github.com/users/Enmk","html_url":"https://github.com/Enmk","followers_url":"https://api.github.com/users/Enmk/followers","following_url":"https://api.github.com/users/Enmk/following{/other_user}","gists_url":"https://api.github.com/users/Enmk/gists{/gist_id}","starred_url":"https://api.github.com/users/Enmk/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Enmk/subscriptions","organizations_url":"https://api.github.com/users/Enmk/orgs","repos_url":"https://api.github.com/users/Enmk/repos","events_url":"https://api.github.com/users/Enmk/events{/privacy}","received_events_url":"https://api.github.com/users/Enmk/received_events","type":"User","site_admin":false},"assignees":[{"login":"Enmk","id":1110183,"node_id":"MDQ6VXNlcjExMTAxODM=","avatar_url":"https://avatars.githubusercontent.com/u/1110183?v=4","gravatar_id":"","url":"https://api.github.com/users/Enmk","html_url":"https://github.com/Enmk","followers_url":"https://api.github.com/users/Enmk/followers","following_url":"https://api.github.com/users/Enmk/following{/other_user}","gists_url":"https://api.github.com/users/Enmk/gists{/gist_id}","starred_url":"https://api.github.com/users/Enmk/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Enmk/subscriptions","organizations_url":"https://api.github.com/users/Enmk/orgs","repos_url":"https://api.github.com/users/Enmk/repos","events_url":"https://api.github.com/users/Enmk/events{/privacy}","received_events_url":"https://api.github.com/users/Enmk/received_events","type":"User","site_admin":false}],"milestone":null,"comments":0,"created_at":"2021-04-09T11:34:26Z","updated_at":"2021-04-10T13:06:44Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"As I understand from [docs](https://clickhouse.tech/docs/en/sql-reference/functions/date-time-functions/#toweekdatemode), the week number for the last days of year must be counted starting from the beginning of THE SAME year (52 or 53). Either this behavior should be fixed or docs should be made more clear.\r\n```\r\nSELECT toWeek(toDateTime64('1971-12-31 23:59:59', 3, 'UTC'), 9)\r\n\r\n┌─toWeek(toDateTime64('1971-12-31 23:59:59', 3, 'UTC'), 9)─┐\r\n│                                                        1 │\r\n└──────────────────────────────────────────────────────────┘\r\n\r\nSELECT toWeek(toDateTime64('1969-12-31 23:59:59', 3, 'UTC'), 9)\r\n\r\n┌─toWeek(toDateTime64('1969-12-31 23:59:59', 3, 'UTC'), 9)─┐\r\n│                                                        1 │\r\n└──────────────────────────────────────────────────────────┘\r\n```\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22930/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22930/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22929","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22929/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22929/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22929/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/22929","id":854397777,"node_id":"MDU6SXNzdWU4NTQzOTc3Nzc=","number":22929,"title":"toUnixTimestamp() throws exception when DateTime64 out of normal range","user":{"login":"zvonand","id":32552679,"node_id":"MDQ6VXNlcjMyNTUyNjc5","avatar_url":"https://avatars.githubusercontent.com/u/32552679?v=4","gravatar_id":"","url":"https://api.github.com/users/zvonand","html_url":"https://github.com/zvonand","followers_url":"https://api.github.com/users/zvonand/followers","following_url":"https://api.github.com/users/zvonand/following{/other_user}","gists_url":"https://api.github.com/users/zvonand/gists{/gist_id}","starred_url":"https://api.github.com/users/zvonand/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/zvonand/subscriptions","organizations_url":"https://api.github.com/users/zvonand/orgs","repos_url":"https://api.github.com/users/zvonand/repos","events_url":"https://api.github.com/users/zvonand/events{/privacy}","received_events_url":"https://api.github.com/users/zvonand/received_events","type":"User","site_admin":false},"labels":[{"id":1019683656,"node_id":"MDU6TGFiZWwxMDE5NjgzNjU2","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/altinity","name":"altinity","color":"c0f5f9","default":false,"description":""},{"id":1397894054,"node_id":"MDU6TGFiZWwxMzk3ODk0MDU0","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unfinished%20code","name":"unfinished code","color":"ff8800","default":false,"description":""},{"id":1481221764,"node_id":"MDU6TGFiZWwxNDgxMjIxNzY0","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-datetime","name":"comp-datetime","color":"b5bcff","default":false,"description":"date & time & timezone related"}],"state":"open","locked":false,"assignee":{"login":"Enmk","id":1110183,"node_id":"MDQ6VXNlcjExMTAxODM=","avatar_url":"https://avatars.githubusercontent.com/u/1110183?v=4","gravatar_id":"","url":"https://api.github.com/users/Enmk","html_url":"https://github.com/Enmk","followers_url":"https://api.github.com/users/Enmk/followers","following_url":"https://api.github.com/users/Enmk/following{/other_user}","gists_url":"https://api.github.com/users/Enmk/gists{/gist_id}","starred_url":"https://api.github.com/users/Enmk/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Enmk/subscriptions","organizations_url":"https://api.github.com/users/Enmk/orgs","repos_url":"https://api.github.com/users/Enmk/repos","events_url":"https://api.github.com/users/Enmk/events{/privacy}","received_events_url":"https://api.github.com/users/Enmk/received_events","type":"User","site_admin":false},"assignees":[{"login":"Enmk","id":1110183,"node_id":"MDQ6VXNlcjExMTAxODM=","avatar_url":"https://avatars.githubusercontent.com/u/1110183?v=4","gravatar_id":"","url":"https://api.github.com/users/Enmk","html_url":"https://github.com/Enmk","followers_url":"https://api.github.com/users/Enmk/followers","following_url":"https://api.github.com/users/Enmk/following{/other_user}","gists_url":"https://api.github.com/users/Enmk/gists{/gist_id}","starred_url":"https://api.github.com/users/Enmk/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Enmk/subscriptions","organizations_url":"https://api.github.com/users/Enmk/orgs","repos_url":"https://api.github.com/users/Enmk/repos","events_url":"https://api.github.com/users/Enmk/events{/privacy}","received_events_url":"https://api.github.com/users/Enmk/received_events","type":"User","site_admin":false}],"milestone":null,"comments":0,"created_at":"2021-04-09T10:32:43Z","updated_at":"2021-04-09T10:36:35Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"toUnixTimestamp() throws exception when DateTime64 out of normal range:\r\n```\r\nSELECT toUnixTimestamp(toDateTime64('1928-12-31 12:12:12.123', 3, 'UTC'))\r\n\r\nReceived exception from server (version 21.5.1):\r\nCode: 407. DB::Exception: Received from localhost:9000. DB::Exception: Convert overflow: While processing toUnixTimestamp(toDateTime64('1928-12-31 12:12:12.123', 3, 'UTC')). \r\n```\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22929/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22929/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22923","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22923/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22923/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22923/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/22923","id":854345197,"node_id":"MDU6SXNzdWU4NTQzNDUxOTc=","number":22923,"title":"WITH statement can be missed in distributed query processing","user":{"login":"DimasKovas","id":34828390,"node_id":"MDQ6VXNlcjM0ODI4Mzkw","avatar_url":"https://avatars.githubusercontent.com/u/34828390?v=4","gravatar_id":"","url":"https://api.github.com/users/DimasKovas","html_url":"https://github.com/DimasKovas","followers_url":"https://api.github.com/users/DimasKovas/followers","following_url":"https://api.github.com/users/DimasKovas/following{/other_user}","gists_url":"https://api.github.com/users/DimasKovas/gists{/gist_id}","starred_url":"https://api.github.com/users/DimasKovas/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/DimasKovas/subscriptions","organizations_url":"https://api.github.com/users/DimasKovas/orgs","repos_url":"https://api.github.com/users/DimasKovas/repos","events_url":"https://api.github.com/users/DimasKovas/events{/privacy}","received_events_url":"https://api.github.com/users/DimasKovas/received_events","type":"User","site_admin":false},"labels":[{"id":386401505,"node_id":"MDU6TGFiZWwzODY0MDE1MDU=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/bug","name":"bug","color":"ee0701","default":true,"description":"Confirmed user-visible misbehaviour in official release"},{"id":1634829961,"node_id":"MDU6TGFiZWwxNjM0ODI5OTYx","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-distributed","name":"comp-distributed","color":"b5bcff","default":false,"description":"Distributed tables"},{"id":2788693937,"node_id":"MDU6TGFiZWwyNzg4NjkzOTM3","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-cte","name":"comp-cte","color":"b5bcff","default":false,"description":"common table expression (WITH ... SELECT)"},{"id":3679617212,"node_id":"LA_kwDOA5dJV87bUoC8","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/yandex","name":"yandex","color":"ffcc00","default":false,"description":""}],"state":"open","locked":false,"assignee":{"login":"kitaisreal","id":22458333,"node_id":"MDQ6VXNlcjIyNDU4MzMz","avatar_url":"https://avatars.githubusercontent.com/u/22458333?v=4","gravatar_id":"","url":"https://api.github.com/users/kitaisreal","html_url":"https://github.com/kitaisreal","followers_url":"https://api.github.com/users/kitaisreal/followers","following_url":"https://api.github.com/users/kitaisreal/following{/other_user}","gists_url":"https://api.github.com/users/kitaisreal/gists{/gist_id}","starred_url":"https://api.github.com/users/kitaisreal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kitaisreal/subscriptions","organizations_url":"https://api.github.com/users/kitaisreal/orgs","repos_url":"https://api.github.com/users/kitaisreal/repos","events_url":"https://api.github.com/users/kitaisreal/events{/privacy}","received_events_url":"https://api.github.com/users/kitaisreal/received_events","type":"User","site_admin":false},"assignees":[{"login":"kitaisreal","id":22458333,"node_id":"MDQ6VXNlcjIyNDU4MzMz","avatar_url":"https://avatars.githubusercontent.com/u/22458333?v=4","gravatar_id":"","url":"https://api.github.com/users/kitaisreal","html_url":"https://github.com/kitaisreal","followers_url":"https://api.github.com/users/kitaisreal/followers","following_url":"https://api.github.com/users/kitaisreal/following{/other_user}","gists_url":"https://api.github.com/users/kitaisreal/gists{/gist_id}","starred_url":"https://api.github.com/users/kitaisreal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kitaisreal/subscriptions","organizations_url":"https://api.github.com/users/kitaisreal/orgs","repos_url":"https://api.github.com/users/kitaisreal/repos","events_url":"https://api.github.com/users/kitaisreal/events{/privacy}","received_events_url":"https://api.github.com/users/kitaisreal/received_events","type":"User","site_admin":false}],"milestone":null,"comments":1,"created_at":"2021-04-09T09:23:41Z","updated_at":"2022-01-05T16:13:19Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**How to reproduce**\r\n* Which ClickHouse server version to use\r\nlatest master/arcadia\r\n* Non-default settings, if any\r\n```sql\r\nSET prefer_localhost_replica=0\r\n```\r\n(Without it a local stream is created instead of a remote one. The query works fine with the local stream)\r\n* `CREATE TABLE` statements for all tables involved\r\n```sql\r\ncreate table \"t0\" (a Int64, b Int64) engine = MergeTree() partition by a order by a;\r\ncreate table \"dist_t0\" (a Int64, b Int64) engine = Distributed(test_shard_localhost, default, t0);\r\n```\r\n* Sample data for all these tables\r\n```sql\r\ninsert into t0 values (0, 0);\r\n```\r\n* Queries to run that lead to unexpected result\r\n\r\n```sql\r\ndi.man.yp-c.yandex.net :) with b as (select toInt64(number) as a from numbers(10)), c as (select toInt64(number) as a from numbers(10)) select * from \"dist_t0\" as a left join b as b on a.a = b.a left join c as c on a.a = c.a\r\n\r\nWITH\r\n    b AS \r\n    (\r\n        SELECT toInt64(number) AS a\r\n        FROM numbers(10)\r\n    ),\r\n    c AS \r\n    (\r\n        SELECT toInt64(number) AS a\r\n        FROM numbers(10)\r\n    )\r\nSELECT *\r\nFROM dist_t0 AS a\r\nLEFT JOIN b AS b ON a.a = b.a\r\nLEFT JOIN c AS c ON a.a = c.a\r\n\r\nQuery id: 612b615a-fe30-4582-be2e-2d017558a21b\r\n\r\n0 rows in set. Elapsed: 0.029 sec. \r\n\r\nReceived exception from server (version 21.5.1):\r\nCode: 60. DB::Exception: Received from localhost:9000. DB::Exception: Received from localhost:9000. DB::Exception: Table default.b doesn't exist.\r\n```\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22923/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22923/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22859","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22859/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22859/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22859/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/22859","id":853489344,"node_id":"MDU6SXNzdWU4NTM0ODkzNDQ=","number":22859,"title":"ALTER ... DROP PARTITION KEY","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-04-08T13:43:40Z","updated_at":"2021-04-08T14:13:20Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"**Use case**\r\nUser created wrong partition key by mistake.\r\n\r\n**Describe the solution you'd like**\r\nAllow to remove partition key. It will be almost free - all the existing parts will belong to the same partition.\r\nSome twiddling of metadata in ZooKeeper may be required.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22859/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22859/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22840","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22840/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22840/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22840/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/22840","id":853277919,"node_id":"MDU6SXNzdWU4NTMyNzc5MTk=","number":22840,"title":"\"Unknown column name\" in a query with multiple joins and enable_optimize_predicate_expression=1 ","user":{"login":"DimasKovas","id":34828390,"node_id":"MDQ6VXNlcjM0ODI4Mzkw","avatar_url":"https://avatars.githubusercontent.com/u/34828390?v=4","gravatar_id":"","url":"https://api.github.com/users/DimasKovas","html_url":"https://github.com/DimasKovas","followers_url":"https://api.github.com/users/DimasKovas/followers","following_url":"https://api.github.com/users/DimasKovas/following{/other_user}","gists_url":"https://api.github.com/users/DimasKovas/gists{/gist_id}","starred_url":"https://api.github.com/users/DimasKovas/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/DimasKovas/subscriptions","organizations_url":"https://api.github.com/users/DimasKovas/orgs","repos_url":"https://api.github.com/users/DimasKovas/repos","events_url":"https://api.github.com/users/DimasKovas/events{/privacy}","received_events_url":"https://api.github.com/users/DimasKovas/received_events","type":"User","site_admin":false},"labels":[{"id":386401505,"node_id":"MDU6TGFiZWwzODY0MDE1MDU=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/bug","name":"bug","color":"ee0701","default":true,"description":"Confirmed user-visible misbehaviour in official release"}],"state":"open","locked":false,"assignee":{"login":"kitaisreal","id":22458333,"node_id":"MDQ6VXNlcjIyNDU4MzMz","avatar_url":"https://avatars.githubusercontent.com/u/22458333?v=4","gravatar_id":"","url":"https://api.github.com/users/kitaisreal","html_url":"https://github.com/kitaisreal","followers_url":"https://api.github.com/users/kitaisreal/followers","following_url":"https://api.github.com/users/kitaisreal/following{/other_user}","gists_url":"https://api.github.com/users/kitaisreal/gists{/gist_id}","starred_url":"https://api.github.com/users/kitaisreal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kitaisreal/subscriptions","organizations_url":"https://api.github.com/users/kitaisreal/orgs","repos_url":"https://api.github.com/users/kitaisreal/repos","events_url":"https://api.github.com/users/kitaisreal/events{/privacy}","received_events_url":"https://api.github.com/users/kitaisreal/received_events","type":"User","site_admin":false},"assignees":[{"login":"kitaisreal","id":22458333,"node_id":"MDQ6VXNlcjIyNDU4MzMz","avatar_url":"https://avatars.githubusercontent.com/u/22458333?v=4","gravatar_id":"","url":"https://api.github.com/users/kitaisreal","html_url":"https://github.com/kitaisreal","followers_url":"https://api.github.com/users/kitaisreal/followers","following_url":"https://api.github.com/users/kitaisreal/following{/other_user}","gists_url":"https://api.github.com/users/kitaisreal/gists{/gist_id}","starred_url":"https://api.github.com/users/kitaisreal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kitaisreal/subscriptions","organizations_url":"https://api.github.com/users/kitaisreal/orgs","repos_url":"https://api.github.com/users/kitaisreal/repos","events_url":"https://api.github.com/users/kitaisreal/events{/privacy}","received_events_url":"https://api.github.com/users/kitaisreal/received_events","type":"User","site_admin":false}],"milestone":null,"comments":1,"created_at":"2021-04-08T09:38:44Z","updated_at":"2021-08-16T08:56:00Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"\r\n* Which ClickHouse server version to use\r\nlatest master/trunk version\r\n\r\n* Queries to run that lead to unexpected result\r\n```sql\r\ndi.man.yp-c.yandex.net :) select * from (select * from (select * from numbers(10)) as a join (select * from numbers(10)) as b on a.number = b.number join (select * from numbers(10)) as c on b.number = c.number) where a.number = 0\r\n\r\nSELECT *\r\nFROM \r\n(\r\n    SELECT *\r\n    FROM \r\n    (\r\n        SELECT *\r\n        FROM numbers(10)\r\n    ) AS a\r\n    INNER JOIN \r\n    (\r\n        SELECT *\r\n        FROM numbers(10)\r\n    ) AS b ON a.number = b.number\r\n    INNER JOIN \r\n    (\r\n        SELECT *\r\n        FROM numbers(10)\r\n    ) AS c ON b.number = c.number\r\n)\r\nWHERE a.number = 0\r\n```\r\n\r\n**Error message and/or stacktrace**\r\n```\r\nReceived exception from server (version 21.5.1):\r\nCode: 47. DB::Exception: Received from localhost:9000. DB::Exception: Unknown column name 'a.number': While processing SELECT `--a.number` AS `a.number`, `--b.number` AS `b.number`, c.number AS `c.number` FROM (SELECT * FROM numbers(10)) AS a INNER JOIN (SELECT * FROM numbers(10)) AS b ON a.number = b.number INNER JOIN (SELECT * FROM numbers(10)) AS c ON b.number = c.number HAVING `a.number` = 0. \r\n```\r\n\r\n**Additional context**\r\nWith `enable_optimize_predicate_expression=0` this query works fine.\r\nFix for #20497 does not help.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22840/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22840/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22830","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22830/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22830/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22830/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/22830","id":853158413,"node_id":"MDU6SXNzdWU4NTMxNTg0MTM=","number":22830,"title":"How to Stop Merges for Replicated Merge Tree Tables Even After ClickHouse Restarts?","user":{"login":"jlazdw","id":70690935,"node_id":"MDQ6VXNlcjcwNjkwOTM1","avatar_url":"https://avatars.githubusercontent.com/u/70690935?v=4","gravatar_id":"","url":"https://api.github.com/users/jlazdw","html_url":"https://github.com/jlazdw","followers_url":"https://api.github.com/users/jlazdw/followers","following_url":"https://api.github.com/users/jlazdw/following{/other_user}","gists_url":"https://api.github.com/users/jlazdw/gists{/gist_id}","starred_url":"https://api.github.com/users/jlazdw/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jlazdw/subscriptions","organizations_url":"https://api.github.com/users/jlazdw/orgs","repos_url":"https://api.github.com/users/jlazdw/repos","events_url":"https://api.github.com/users/jlazdw/events{/privacy}","received_events_url":"https://api.github.com/users/jlazdw/received_events","type":"User","site_admin":false},"labels":[{"id":845247686,"node_id":"MDU6TGFiZWw4NDUyNDc2ODY=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/usability","name":"usability","color":"ebf28c","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-04-08T07:27:08Z","updated_at":"2021-04-08T07:29:48Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"The ClickHouse System command: START/STOP MERGES only works within the same ClickHouse server process. Since the action locks are held by the ActionLocksManager only in memory, without being persisted, if the ClickHouse server gets restarted, the action locks will disappear and thus the background merges will resume.\r\n\r\nIn order to support ZooKeeper metadata migration for Replicated Merge Tree tables, I have a need to keep merges being stopped after the command being issued, even after the server process gets restarted.  By having a cluster with complete merges being stopped, the ZooKeeper metadata will not be changed,  and thus I can have the consistent ZK tree during the  migration. If even one server process out of hundreds of the processes gets accidentally restarted for some reason, the ZK tree consistency during migration can not be guaranteed.\r\n\r\nI examined the code and found that if I have the merge tree setting parameter:\r\n  \r\nmax_replicated_merges_in_queue = 0\r\n\r\nthen from StorageReplicatedMergeTree.cpp, https://github.com/ClickHouse/ClickHouse/blob/20.7/src/Storages/StorageReplicatedMergeTree.cpp#L2611, the background merge thread that selects the merge parts candidates will be stopped. \r\n\r\nFurther, if I set:\r\n\r\nalways_fetch_merged_part = 0,\r\n\r\nthen from https://github.com/ClickHouse/ClickHouse/blob/20.7/src/Storages/StorageReplicatedMergeTree.cpp#L1314, the method of “tryExecuteMerge” will always return false, and thus does not proceed to perform the actual merging function “merger_mutator.mergePartsToTemporaryPart”.\r\n\r\nIn summary, to stop merges for replicated merge tree related tables, even after the ClickHouse server gets restarted, I would need to provide the following merge-tree settings:\r\n\r\n<merge_tree>\r\n    <max_replicated_merges_in_queue>0</max_replicated_merges_in_queue>\r\n    <always_fetch_merged_part>1</always_fetch_merged_part>\r\n</merge_tree>\r\n\r\nThe first parameter stops the merge parts candidates submission, and the second parameter stops the actual merge parts processing.  I tested it in a multi-shard ClickHouse cluster and it seems that it works as what I expect, by checking the Profile Event count of “ReplicatedPartMerges” during the experiment.\r\n \r\nI like to seek the expert opinion on whether the above described solution is correct or not for the Replicated Merge Tree tables, as I am aware that the merge-tree parameters that I identified above only work for the replicated merge trees. \r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22830/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22830/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22825","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22825/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22825/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22825/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/22825","id":852729675,"node_id":"MDU6SXNzdWU4NTI3Mjk2NzU=","number":22825,"title":"IPv4OrZero or toIPv4OrNull does not exist.","user":{"login":"UnamedRus","id":9449405,"node_id":"MDQ6VXNlcjk0NDk0MDU=","avatar_url":"https://avatars.githubusercontent.com/u/9449405?v=4","gravatar_id":"","url":"https://api.github.com/users/UnamedRus","html_url":"https://github.com/UnamedRus","followers_url":"https://api.github.com/users/UnamedRus/followers","following_url":"https://api.github.com/users/UnamedRus/following{/other_user}","gists_url":"https://api.github.com/users/UnamedRus/gists{/gist_id}","starred_url":"https://api.github.com/users/UnamedRus/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/UnamedRus/subscriptions","organizations_url":"https://api.github.com/users/UnamedRus/orgs","repos_url":"https://api.github.com/users/UnamedRus/repos","events_url":"https://api.github.com/users/UnamedRus/events{/privacy}","received_events_url":"https://api.github.com/users/UnamedRus/received_events","type":"User","site_admin":false},"labels":[{"id":845247686,"node_id":"MDU6TGFiZWw4NDUyNDc2ODY=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/usability","name":"usability","color":"ebf28c","default":false,"description":""}],"state":"open","locked":false,"assignee":{"login":"kitaisreal","id":22458333,"node_id":"MDQ6VXNlcjIyNDU4MzMz","avatar_url":"https://avatars.githubusercontent.com/u/22458333?v=4","gravatar_id":"","url":"https://api.github.com/users/kitaisreal","html_url":"https://github.com/kitaisreal","followers_url":"https://api.github.com/users/kitaisreal/followers","following_url":"https://api.github.com/users/kitaisreal/following{/other_user}","gists_url":"https://api.github.com/users/kitaisreal/gists{/gist_id}","starred_url":"https://api.github.com/users/kitaisreal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kitaisreal/subscriptions","organizations_url":"https://api.github.com/users/kitaisreal/orgs","repos_url":"https://api.github.com/users/kitaisreal/repos","events_url":"https://api.github.com/users/kitaisreal/events{/privacy}","received_events_url":"https://api.github.com/users/kitaisreal/received_events","type":"User","site_admin":false},"assignees":[{"login":"kitaisreal","id":22458333,"node_id":"MDQ6VXNlcjIyNDU4MzMz","avatar_url":"https://avatars.githubusercontent.com/u/22458333?v=4","gravatar_id":"","url":"https://api.github.com/users/kitaisreal","html_url":"https://github.com/kitaisreal","followers_url":"https://api.github.com/users/kitaisreal/followers","following_url":"https://api.github.com/users/kitaisreal/following{/other_user}","gists_url":"https://api.github.com/users/kitaisreal/gists{/gist_id}","starred_url":"https://api.github.com/users/kitaisreal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kitaisreal/subscriptions","organizations_url":"https://api.github.com/users/kitaisreal/orgs","repos_url":"https://api.github.com/users/kitaisreal/repos","events_url":"https://api.github.com/users/kitaisreal/events{/privacy}","received_events_url":"https://api.github.com/users/kitaisreal/received_events","type":"User","site_admin":false}],"milestone":null,"comments":2,"created_at":"2021-04-07T19:15:07Z","updated_at":"2021-04-19T20:12:06Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"Clickhouse recommend to use IPv4OrZero or toIPv4OrNull functions in error message, but they do not actually exist.\r\n\r\n\r\n**How to reproduce**\r\nClickhouse version 21.5\r\n\r\n```\r\nSELECT CAST('127.0.0.1', 'IPv4')\r\n\r\nQuery id: f7ce4a55-0e57-41a8-b771-8fd6be54d41b\r\n\r\n\r\n0 rows in set. Elapsed: 0.002 sec.\r\n\r\nReceived exception from server (version 21.5.1):\r\nCode: 6. DB::Exception: Received from localhost:9000. DB::Exception: Cannot parse string '127.0.0.1' as IPv4: syntax error at position 3 (parsed just '127'). Note: there are toIPv4OrZero and toIPv4OrNull functions, which returns zero/NULL instead of throwing exception.: While processing CAST('127.0.0.1', 'IPv4').\r\n\r\n\r\nlocaldomain  :) SELECT toIPv4OrZero('127.0.0.1')　;\r\n\r\nSELECT toIPv4OrZero('127.0.0.1')\r\n\r\n0 rows in set. Elapsed: 0.002 sec.\r\n\r\nReceived exception from server (version 21.5.1):\r\nCode: 46. DB::Exception: Received from localhost:9000. DB::Exception: Unknown function toIPv4OrZero. Maybe you meant: ['toInt8OrZero','toInt64OrZero']: While processing toIPv4OrZero('127.0.0.1').\r\n\r\nlocaldomain  :) SELECT toIPv4OrNull('127.0.0.1')　;\r\n\r\nSELECT toIPv4OrNull('127.0.0.1')\r\n\r\n0 rows in set. Elapsed: 0.002 sec.\r\n\r\nReceived exception from server (version 21.5.1):\r\nCode: 46. DB::Exception: Received from localhost:9000. DB::Exception: Unknown function toIPv4OrNull. Maybe you meant: ['toInt8OrNull','toInt64OrNull']: While processing toIPv4OrNull('127.0.0.1').\r\n\r\nlocaldomain  :) SELECT toIPv4('127.0.0.1')　;\r\n\r\nSELECT toIPv4('127.0.0.1')\r\n\r\n\r\n┌─toIPv4('127.0.0.1')─┐\r\n│ 127.0.0.1           │\r\n└─────────────────────┘\r\n\r\n1 rows in set. Elapsed: 0.003 sec.\r\n\r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22825/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22825/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22660","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22660/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22660/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22660/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/22660","id":850243895,"node_id":"MDU6SXNzdWU4NTAyNDM4OTU=","number":22660,"title":"Does ClickHouse support multiple round trips in an aggregation pipeline?","user":{"login":"achimbab","id":36371084,"node_id":"MDQ6VXNlcjM2MzcxMDg0","avatar_url":"https://avatars.githubusercontent.com/u/36371084?v=4","gravatar_id":"","url":"https://api.github.com/users/achimbab","html_url":"https://github.com/achimbab","followers_url":"https://api.github.com/users/achimbab/followers","following_url":"https://api.github.com/users/achimbab/following{/other_user}","gists_url":"https://api.github.com/users/achimbab/gists{/gist_id}","starred_url":"https://api.github.com/users/achimbab/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/achimbab/subscriptions","organizations_url":"https://api.github.com/users/achimbab/orgs","repos_url":"https://api.github.com/users/achimbab/repos","events_url":"https://api.github.com/users/achimbab/events{/privacy}","received_events_url":"https://api.github.com/users/achimbab/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-04-05T09:44:29Z","updated_at":"2021-04-08T08:07:34Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"Sometimes it is required to support multiple roundtrips in an aggregation pipeline in order to implement efficient ML functionalities.\r\n\r\nAn example that supports multiple roundtrips is the Map/Reduce of Hadoop.\r\n\r\n```\r\n        <First round-trip>               <Second round-trip>               <N round-trip>\r\n                                \r\nShard 1 --Map--+           +--Reduce-->  --Map--+           +--Reduce-->\r\n               |           |                    |           |\r\n               +--Shuffle--+                    +--Shuffle--+              ...\r\n               |           |                    |           |\r\nShard N --Map--+           +--Reduce-->  --Map--+           +--Reduce-->\r\n```\r\n\r\nBut, There are some disadvantages to use Hadoop's Map/Reduce.\r\n- It is not that fast for ad-hoc queries.\r\n- Most of the data are in ClickHouse, so data-transfer-cost is too big to move from ClickHouse to Hadoop.\r\n\r\nIn my opinion, if ClickHouse can support multiple round-trips for Aggregation Functions, it is able to implement various ML functionalities. Additionally, the ML functionalities built upon the ClickHouse will be faster than the other databases are.\r\n\r\nDoes ClickHouse support multiple round trips? Otherwise, do you have a plan to support multiple round trips in an aggregation pipeline?\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22660/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22660/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22627","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22627/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22627/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22627/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/22627","id":849947152,"node_id":"MDU6SXNzdWU4NDk5NDcxNTI=","number":22627,"title":"Missing columns: 'a' while processing query with more than 2 tables in cross join","user":{"login":"UnamedRus","id":9449405,"node_id":"MDQ6VXNlcjk0NDk0MDU=","avatar_url":"https://avatars.githubusercontent.com/u/9449405?v=4","gravatar_id":"","url":"https://api.github.com/users/UnamedRus","html_url":"https://github.com/UnamedRus","followers_url":"https://api.github.com/users/UnamedRus/followers","following_url":"https://api.github.com/users/UnamedRus/following{/other_user}","gists_url":"https://api.github.com/users/UnamedRus/gists{/gist_id}","starred_url":"https://api.github.com/users/UnamedRus/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/UnamedRus/subscriptions","organizations_url":"https://api.github.com/users/UnamedRus/orgs","repos_url":"https://api.github.com/users/UnamedRus/repos","events_url":"https://api.github.com/users/UnamedRus/events{/privacy}","received_events_url":"https://api.github.com/users/UnamedRus/received_events","type":"User","site_admin":false},"labels":[{"id":386401505,"node_id":"MDU6TGFiZWwzODY0MDE1MDU=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/bug","name":"bug","color":"ee0701","default":true,"description":"Confirmed user-visible misbehaviour in official release"},{"id":1357578153,"node_id":"MDU6TGFiZWwxMzU3NTc4MTUz","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-joins","name":"comp-joins","color":"b5bcff","default":false,"description":"JOINs"},{"id":1507867504,"node_id":"MDU6TGFiZWwxNTA3ODY3NTA0","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/st-hold","name":"st-hold","color":"e5b890","default":false,"description":"We've paused the work on issue for some reason"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-04-04T19:43:01Z","updated_at":"2021-06-17T03:18:34Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**How to reproduce**\r\nClickhouse 21.5\r\n\r\n```\r\nWITH\r\n    x AS\r\n    (\r\n        SELECT 1 AS a\r\n    ),\r\n    xx AS\r\n    (\r\n        SELECT *\r\n        FROM x\r\n        , x AS x1\r\n    )\r\nSELECT *\r\nFROM xx\r\nWHERE a = 1\r\n\r\nQuery id: f4fc159a-a136-4191-a0f0-c11c5ecdea74\r\n\r\n┌─a─┬─x1.a─┐\r\n│ 1 │    1 │\r\n└───┴──────┘\r\n\r\nWITH\r\n    x AS\r\n    (\r\n        SELECT 1 AS a\r\n    ),\r\n    xx AS\r\n    (\r\n        SELECT *\r\n        FROM x\r\n        , x AS x1\r\n        , x AS x2\r\n    )\r\nSELECT *\r\nFROM xx\r\nWHERE a = 1\r\n\r\nQuery id: bee7bab0-1f6a-4f29-bab5-f3b845e7095d\r\n\r\n\r\n0 rows in set. Elapsed: 0.004 sec.\r\n\r\nReceived exception from server (version 21.5.1):\r\nCode: 47. DB::Exception: Received from localhost:9000. DB::Exception: Missing columns: 'a' while processing query: 'WITH x AS (SELECT 1 AS a), xx AS (SELECT * FROM x , x AS x1 , x AS x2) SELECT `x.a`, `x1.a`, `x2.a` FROM xx WHERE a = 1', required columns: 'x.a' 'x1.a' 'x2.a' 'a' 'x.a' 'x1.a' 'x2.a' 'a'.\r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22627/reactions","total_count":2,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":2},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22627/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22581","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22581/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22581/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22581/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/22581","id":849779567,"node_id":"MDU6SXNzdWU4NDk3Nzk1Njc=","number":22581,"title":"Don't allow distributed queries across servers with different CPU architecture.","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":2402913184,"node_id":"MDU6TGFiZWwyNDAyOTEzMTg0","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-aarch64","name":"comp-aarch64","color":"b5bcff","default":false,"description":"arm / aarch platform specific"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-04-04T02:11:19Z","updated_at":"2021-11-21T11:43:32Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"**Use case**\r\n\r\nIf some of cluster nodes are x86_64 and some are aarch64, the result of distributed query may be incorrect due to different hash functions used to split data into buckets.\r\n\r\n**Describe the solution you'd like**\r\n\r\nAdd architecture identifier to ClientInfo. Throw exception if client has different architecture than the server and query processing is requested up to WithMergeableState.\r\n\r\nNormal client requests should be allowed to work.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22581/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22581/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22574","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22574/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22574/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22574/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/22574","id":849754886,"node_id":"MDU6SXNzdWU4NDk3NTQ4ODY=","number":22574,"title":"CSV parsing setting: format_csv_not_trim_spaces","user":{"login":"UnamedRus","id":9449405,"node_id":"MDQ6VXNlcjk0NDk0MDU=","avatar_url":"https://avatars.githubusercontent.com/u/9449405?v=4","gravatar_id":"","url":"https://api.github.com/users/UnamedRus","html_url":"https://github.com/UnamedRus","followers_url":"https://api.github.com/users/UnamedRus/followers","following_url":"https://api.github.com/users/UnamedRus/following{/other_user}","gists_url":"https://api.github.com/users/UnamedRus/gists{/gist_id}","starred_url":"https://api.github.com/users/UnamedRus/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/UnamedRus/subscriptions","organizations_url":"https://api.github.com/users/UnamedRus/orgs","repos_url":"https://api.github.com/users/UnamedRus/repos","events_url":"https://api.github.com/users/UnamedRus/events{/privacy}","received_events_url":"https://api.github.com/users/UnamedRus/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":1401255404,"node_id":"MDU6TGFiZWwxNDAxMjU1NDA0","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-formats","name":"comp-formats","color":"b5bcff","default":false,"description":"Input / output formats"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-04-03T22:49:29Z","updated_at":"2021-04-04T18:11:41Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Use case**\r\nCSV file with unquoted strings and spaces at start and end of strings which needs to be preserved.\r\n\r\n>  In violation of the RFC, when parsing rows without quotes, the leading and trailing spaces and tabs are ignored. \r\n\r\n```\r\necho \"aa ,2\" | clickhouse-local -S \"a String, b int\" --input-format=\"CustomSeparated\" --format_custom_escaping_rule=CSV --format_custom_field_delimiter=',' --format_csv_delimiter=',' -q \"select * from table FORMAT CSV\"\r\n\"aa\",2\r\n```\r\n\r\n\r\n**Describe the solution you'd like**\r\nSetting\r\n\r\nhttps://github.com/ClickHouse/ClickHouse/issues/6742#issuecomment-526567265\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22574/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22574/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22564","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22564/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22564/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22564/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/22564","id":849723842,"node_id":"MDU6SXNzdWU4NDk3MjM4NDI=","number":22564,"title":"NOAA weather dataset","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":785082162,"node_id":"MDU6TGFiZWw3ODUwODIxNjI=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-documentation","name":"comp-documentation","color":"b5bcff","default":false,"description":"Used to run automatic builds of the documentation"},{"id":3360106261,"node_id":"MDU6TGFiZWwzMzYwMTA2MjYx","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/dataset","name":"dataset","color":"00CCCC","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":6,"created_at":"2021-04-03T19:23:39Z","updated_at":"2021-10-30T18:11:06Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"Something interesting here:\r\n\r\nhttps://www.ncei.noaa.gov/data/global-hourly/archive/csv/","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22564/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22564/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22520","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22520/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22520/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22520/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/22520","id":849447798,"node_id":"MDU6SXNzdWU4NDk0NDc3OTg=","number":22520,"title":"Function sipHash{64,128} not usable as MAC (not seedable)","user":{"login":"stergiotis","id":8849541,"node_id":"MDQ6VXNlcjg4NDk1NDE=","avatar_url":"https://avatars.githubusercontent.com/u/8849541?v=4","gravatar_id":"","url":"https://api.github.com/users/stergiotis","html_url":"https://github.com/stergiotis","followers_url":"https://api.github.com/users/stergiotis/followers","following_url":"https://api.github.com/users/stergiotis/following{/other_user}","gists_url":"https://api.github.com/users/stergiotis/gists{/gist_id}","starred_url":"https://api.github.com/users/stergiotis/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/stergiotis/subscriptions","organizations_url":"https://api.github.com/users/stergiotis/orgs","repos_url":"https://api.github.com/users/stergiotis/repos","events_url":"https://api.github.com/users/stergiotis/events{/privacy}","received_events_url":"https://api.github.com/users/stergiotis/received_events","type":"User","site_admin":false},"labels":[{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":4,"created_at":"2021-04-02T20:11:47Z","updated_at":"2021-12-23T08:58:33Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"**Describe the unexpected behaviour**\r\nSipHash is designed to be used as MAC (message authentication code) crypto primitive. To be able to do so it takes two arguments: `calcSipHash(msg, key)`. The ClickHouse™ functions `sipHash64` and `sipHash128` function do only expose the first argument `msg` (see [sipHash64 Doc](https://clickhouse.tech/docs/en/sql-reference/functions/hash-functions/#hash_functions-siphash64)).\r\n\r\n**How to reproduce**\r\n* See documentation of function sipHash64 and compare with [Wikipedia - SipHash](https://en.wikipedia.org/wiki/SipHash).\r\n* Review implementation in https://github.com/ClickHouse/ClickHouse/blob/c3a9cbe01c1c07d21cd1f89b31291a194fc21b25/src/Functions/FunctionsHashing.h#L204\r\n\r\n**Expected behavior**\r\nAdd two new functions which allow for user-defined keys/seeds:\r\n* `sipHash64Keyed(key,par1,...)` \r\n* `sipHash128Keyed(key,par1,...)`","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22520/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22520/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22516","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22516/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22516/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22516/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/22516","id":849337001,"node_id":"MDU6SXNzdWU4NDkzMzcwMDE=","number":22516,"title":"Data duplication with ALTER commands, using ReplicatedMergeTree with S3 storage","user":{"login":"taiwhite","id":26258789,"node_id":"MDQ6VXNlcjI2MjU4Nzg5","avatar_url":"https://avatars.githubusercontent.com/u/26258789?v=4","gravatar_id":"","url":"https://api.github.com/users/taiwhite","html_url":"https://github.com/taiwhite","followers_url":"https://api.github.com/users/taiwhite/followers","following_url":"https://api.github.com/users/taiwhite/following{/other_user}","gists_url":"https://api.github.com/users/taiwhite/gists{/gist_id}","starred_url":"https://api.github.com/users/taiwhite/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/taiwhite/subscriptions","organizations_url":"https://api.github.com/users/taiwhite/orgs","repos_url":"https://api.github.com/users/taiwhite/repos","events_url":"https://api.github.com/users/taiwhite/events{/privacy}","received_events_url":"https://api.github.com/users/taiwhite/received_events","type":"User","site_admin":false},"labels":[{"id":2673090580,"node_id":"MDU6TGFiZWwyNjczMDkwNTgw","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/bug%20experimental","name":"bug experimental","color":"E99695","default":false,"description":"Bug in the feature that should not be used in production"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":4,"created_at":"2021-04-02T16:56:25Z","updated_at":"2021-09-15T15:07:07Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Describe the bug**\r\nWhen a ReplicatedMergeTree table on S3 storage with multiple replicas is modified using ALTER commands, the data on S3 is duplicated every time ALTER is used.\r\n\r\n**Does it reproduce on recent release?**\r\n[The list of releases](https://github.com/ClickHouse/ClickHouse/blob/master/utils/list-versions/version_date.tsv)\r\n* 21.2.2.8 revision 54447\r\n* 21.4.1 revision 54447\r\n\r\n**How to reproduce**\r\n* Version: 21.4.1 revision 54447 or 21.2.2.8 revision 54447\r\n* Storage configuration:\r\n```\r\n<storage_configuration>\r\n    <disks>\r\n      <external>\r\n        <type>s3</type>\r\n        <endpoint>[AWS S3 endpoint]</endpoint>\r\n        <access_key_id>[access_key_id]</access_key_id>\r\n        <secret_access_key>[secret_access_key]</secret_access_key>\r\n      </external>\r\n    </disks>\r\n    <policies>\r\n      <external>\r\n        <volumes>\r\n          <external>\r\n            <disk>external</disk>\r\n          </external>\r\n        </volumes>\r\n      </external>\r\n    </policies>\r\n  </storage_configuration>\r\n```\r\n* Statements to reproduce error:\r\nCreate replicated table on two instances of ClickHouse:\r\n```\r\nCREATE TABLE zero_copy_replication ( d UInt64, sign Int8 ) ENGINE = ReplicatedMergeTree('/clickhouse/zero_copy_replication', '1') ORDER BY d \r\nSETTINGS storage_policy='external';\r\nCREATE TABLE zero_copy_replication ( d UInt64, sign Int8 ) ENGINE = ReplicatedMergeTree('/clickhouse/zero_copy_replication', '2') ORDER BY d \r\nSETTINGS storage_policy='external';\r\n```\r\nInsert data into the table, then alter the table on either instance using a command similar to this:\r\n`ALTER TABLE zero_copy_replication UPDATE sign = 1 WHERE 1;`\r\nThen SYNC on both instances:\r\n`SYSTEM SYNC REPLICA zero_copy_replication;`\r\nEach time the table is altered using similar commands, data will be duplicated in the AWS S3 bucket.\r\n\r\n**Expected behavior**\r\nNo increase in the amount of data in the S3 bucket when the replicated table is altered.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22516/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22516/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22495","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22495/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22495/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22495/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/22495","id":849142981,"node_id":"MDU6SXNzdWU4NDkxNDI5ODE=","number":22495,"title":"select table has a big different query_duration_ms result","user":{"login":"haiertashu","id":5144734,"node_id":"MDQ6VXNlcjUxNDQ3MzQ=","avatar_url":"https://avatars.githubusercontent.com/u/5144734?v=4","gravatar_id":"","url":"https://api.github.com/users/haiertashu","html_url":"https://github.com/haiertashu","followers_url":"https://api.github.com/users/haiertashu/followers","following_url":"https://api.github.com/users/haiertashu/following{/other_user}","gists_url":"https://api.github.com/users/haiertashu/gists{/gist_id}","starred_url":"https://api.github.com/users/haiertashu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/haiertashu/subscriptions","organizations_url":"https://api.github.com/users/haiertashu/orgs","repos_url":"https://api.github.com/users/haiertashu/repos","events_url":"https://api.github.com/users/haiertashu/events{/privacy}","received_events_url":"https://api.github.com/users/haiertashu/received_events","type":"User","site_admin":false},"labels":[{"id":756395244,"node_id":"MDU6TGFiZWw3NTYzOTUyNDQ=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/performance","name":"performance","color":"c2e0c6","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":5,"created_at":"2021-04-02T10:39:21Z","updated_at":"2021-04-02T19:48:17Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"hi\r\nI use a simple scripts to select * from a 11 million rows distribute mergetree table, by sending two http requests: 1) send a request to one ch node directly. 2) send a request to VIP(virtual IP). \r\nHere is the scripts:\r\n```\r\nquery(){\r\n  echo \"run at `date`\"\r\n  _start=`date +%s`\r\n  case $1 in\r\n    \"vip\")\r\n    curl -o log -sS 'http://uname:passwd@10.110.119.120:5566' -d 'select * from mydb.my_distribute_table'\r\n    ;;\r\n    \"host\")\r\n    curl -o log -sS 'http://uname:passwd@10.996.996.996:8123' -d 'select * from mydb.my_distribute_table'\r\n    ;;\r\n    *)\r\n    echo \"input query host\"\r\n    ;;\r\n  esac\r\n  echo -e \"end at `date`, query duration $[ `date +%s` - $_start ]s, log count: `wc -l log`. \\n\"\r\n}\r\nquery host\r\nsleep 15\r\nquery vip\r\n```\r\nMy ch cluster has 4 ch instances, 2shard 2replica, CH version is 20.12.3.3.\r\nthe question is 'query vip' is 2~4 times slower than 'query host', and it can reappear stably！And, all the slow query happen on the another shard, when the initial query in shard 1, one replica of shard 2 always query slowly.\r\n```\r\nrun at Fri Apr  2 18:22:01 CST 2021\r\nend at Fri Apr  2 18:22:33 CST 2021, query duration 32s, log count: 11189667 log.\r\n\r\nrun at Fri Apr  2 18:22:49 CST 2021\r\nend at Fri Apr  2 18:23:48 CST 2021, query duration 59s, log count: 11189667 log.\r\n```\r\nHere is the slow query's system.query_log info and log\r\n```\r\nquery_duration_ms:    58414\r\nquery_id:             188be671-a1cf-4e18-a373-d8fe9508d72a\r\ninitial_query_id:     68d11186-0c5c-45f5-86e5-eb4ccdfa09ed\r\nhttp_user_agent:      curl/7.29.0\r\nthread_ids:           [220258,13057,13043,13110,13430,13161,13391,13301,13210,13554,13052,13520,13365,13391,13430,13424,13043,13057,12943,13430,13442,13554,13365,12960,13161,13336,13043,13424,13161,13430,13336,13554,12960,13043,13391,13210,13052,13110,13160,13372,13102,13279,13202,13516,13373,13147,13217,13224,13208,13207,13030,13040,13292,12984,13268,13195,13411,13137,13267,13545,12955,13406,13332,13231,13181,13154,13412,13380]\r\nProfileEvents.Names:  ['Query','SelectQuery','FileOpen','ReadBufferFromFileDescriptorRead','ReadBufferFromFileDescriptorReadBytes','ReadCompressedBytes','CompressedReadBufferBlocks','CompressedReadBufferBytes','IOBufferAllocs','IOBufferAllocBytes','MarkCacheHits','CreatedReadBufferOrdinary','DiskReadElapsedMicroseconds','NetworkSendElapsedMicroseconds','SelectedParts','SelectedRanges','SelectedMarks','SelectedRows','SelectedBytes','ContextLock','RWLockAcquiredReadLocks','RealTimeMicroseconds','UserTimeMicroseconds','SystemTimeMicroseconds','SoftPageFaults','OSCPUWaitMicroseconds','OSCPUVirtualTimeMicroseconds','OSWriteBytes','OSReadChars','OSWriteChars']\r\nProfileEvents.Values: [1,1,852,1973,465583205,465583241,9215,1025886558,1706,327414590,852,852,379000,54591309,38,38,701,5596502,1787010820,182,1,1750202466,6060574,1328192,400046,147521,7389416,8192,465582080,215040]\r\nSettings.Names:       ['use_uncompressed_cache','load_balancing','log_queries','max_bytes_before_external_group_by','max_memory_usage']\r\nSettings.Values:      ['0','random','1','22442450944','53687091200']\r\n```\r\n\r\n```\r\n2021.04.02 18:22:49.348497 [ 220258 ] {188be671-a1cf-4e18-a373-d8fe9508d72a} <Debug> executeQuery: (from 10.147.46.16:22048, initial_query_id: 68d11186-0c5c-45f5-86e5-eb4ccdfa09ed) SELECT my_distribute_table_local.cuid, my_distribute_table_local.os, my_distribute_table_local.soft_version, my_distribute_table_local.channel, my_distribute_table_local.brand, my_distribute_table_local.device, my_distribute_table_local.resh, my_distribute_table_local.resv, my_distribute_table_local.net_type, my_distribute_table_local.net_provider, my_distribute_table_local.country, my_distribute_table_local.province, my_distribute_table_local.city, my_distribute_table_local.exp_map, my_distribute_table_local.is_spam, my_distribute_table_local.oaid, my_distribute_table_local.idfa, my_distribute_table_local.bhv_ts, my_distribute_table_local.ip, my_distribute_table_local.is_wall, my_distribute_table_local.event_day, my_distribute_table_local.event_action, my_distribute_table_local.event_appid FROM mydb.my_distribute_table_local\r\n2021.04.02 18:22:49.349259 [ 220258 ] {188be671-a1cf-4e18-a373-d8fe9508d72a} <Trace> ContextAccess (default): Access granted: SELECT(cuid, os, soft_version, channel, brand, device, resh, resv, net_type, net_provider, country, province, city, exp_map, is_spam, oaid, idfa, bhv_ts, ip, is_wall, event_day, event_action, event_appid) ON mydb.my_distribute_table_local\r\n2021.04.02 18:22:49.350518 [ 220258 ] {188be671-a1cf-4e18-a373-d8fe9508d72a} <Debug> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Key condition: unknown\r\n2021.04.02 18:22:49.350529 [ 220258 ] {188be671-a1cf-4e18-a373-d8fe9508d72a} <Debug> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): MinMax index condition: unknown\r\n2021.04.02 18:22:49.350634 [ 13057 ] {188be671-a1cf-4e18-a373-d8fe9508d72a} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210315_1_1_0\r\n2021.04.02 18:22:49.350676 [ 13110 ] {188be671-a1cf-4e18-a373-d8fe9508d72a} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210319_2_2_0\r\n2021.04.02 18:22:49.350692 [ 13391 ] {188be671-a1cf-4e18-a373-d8fe9508d72a} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210320_10_10_0\r\n2021.04.02 18:22:49.350701 [ 13430 ] {188be671-a1cf-4e18-a373-d8fe9508d72a} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210319_7_7_0\r\n2021.04.02 18:22:49.350704 [ 13043 ] {188be671-a1cf-4e18-a373-d8fe9508d72a} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210315_4_4_0\r\n2021.04.02 18:22:49.350695 [ 13301 ] {188be671-a1cf-4e18-a373-d8fe9508d72a} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210320_6_6_0\r\n2021.04.02 18:22:49.350766 [ 13554 ] {188be671-a1cf-4e18-a373-d8fe9508d72a} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210319_3_3_0\r\n2021.04.02 18:22:49.350771 [ 13430 ] {188be671-a1cf-4e18-a373-d8fe9508d72a} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210322_13_13_0\r\n2021.04.02 18:22:49.350768 [ 13052 ] {188be671-a1cf-4e18-a373-d8fe9508d72a} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210321_9_9_0\r\n2021.04.02 18:22:49.350800 [ 13365 ] {188be671-a1cf-4e18-a373-d8fe9508d72a} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210322_11_11_0\r\n2021.04.02 18:22:49.350778 [ 13391 ] {188be671-a1cf-4e18-a373-d8fe9508d72a} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210323_14_14_0\r\n2021.04.02 18:22:49.350813 [ 13043 ] {188be671-a1cf-4e18-a373-d8fe9508d72a} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210321_12_12_0\r\n2021.04.02 18:22:49.350706 [ 13161 ] {188be671-a1cf-4e18-a373-d8fe9508d72a} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210321_8_8_0\r\n2021.04.02 18:22:49.350799 [ 13520 ] {188be671-a1cf-4e18-a373-d8fe9508d72a} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210323_16_16_0\r\n2021.04.02 18:22:49.350832 [ 13057 ] {188be671-a1cf-4e18-a373-d8fe9508d72a} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210324_17_17_0\r\n2021.04.02 18:22:49.350867 [ 13442 ] {188be671-a1cf-4e18-a373-d8fe9508d72a} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210324_18_18_0\r\n2021.04.02 18:22:49.350866 [ 13424 ] {188be671-a1cf-4e18-a373-d8fe9508d72a} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210322_15_15_0\r\n2021.04.02 18:22:49.350837 [ 13430 ] {188be671-a1cf-4e18-a373-d8fe9508d72a} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210324_22_22_0\r\n2021.04.02 18:22:49.350910 [ 13043 ] {188be671-a1cf-4e18-a373-d8fe9508d72a} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210326_27_27_0\r\n2021.04.02 18:22:49.350917 [ 13336 ] {188be671-a1cf-4e18-a373-d8fe9508d72a} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210325_20_20_0\r\n2021.04.02 18:22:49.350923 [ 12960 ] {188be671-a1cf-4e18-a373-d8fe9508d72a} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210325_25_25_0\r\n2021.04.02 18:22:49.350897 [ 13161 ] {188be671-a1cf-4e18-a373-d8fe9508d72a} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210326_23_23_0\r\n2021.04.02 18:22:49.350877 [ 13554 ] {188be671-a1cf-4e18-a373-d8fe9508d72a} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210325_21_21_0\r\n2021.04.02 18:22:49.350882 [ 12943 ] {188be671-a1cf-4e18-a373-d8fe9508d72a} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210323_19_19_0\r\n2021.04.02 18:22:49.350709 [ 13210 ] {188be671-a1cf-4e18-a373-d8fe9508d72a} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210320_5_5_0\r\n2021.04.02 18:22:49.350888 [ 13365 ] {188be671-a1cf-4e18-a373-d8fe9508d72a} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210326_30_30_0\r\n2021.04.02 18:22:49.350996 [ 13430 ] {188be671-a1cf-4e18-a373-d8fe9508d72a} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210327_31_31_0\r\n2021.04.02 18:22:49.350999 [ 13336 ] {188be671-a1cf-4e18-a373-d8fe9508d72a} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210327_34_34_0\r\n2021.04.02 18:22:49.351003 [ 13554 ] {188be671-a1cf-4e18-a373-d8fe9508d72a} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210328_28_28_0\r\n2021.04.02 18:22:49.351026 [ 13424 ] {188be671-a1cf-4e18-a373-d8fe9508d72a} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210327_24_24_0\r\n2021.04.02 18:22:49.351020 [ 13043 ] {188be671-a1cf-4e18-a373-d8fe9508d72a} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210328_35_35_0\r\n2021.04.02 18:22:49.351046 [ 13210 ] {188be671-a1cf-4e18-a373-d8fe9508d72a} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210330_37_37_0\r\n2021.04.02 18:22:49.351027 [ 12960 ] {188be671-a1cf-4e18-a373-d8fe9508d72a} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210328_29_29_0\r\n2021.04.02 18:22:49.351031 [ 13391 ] {188be671-a1cf-4e18-a373-d8fe9508d72a} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210329_32_32_0\r\n2021.04.02 18:22:49.351044 [ 13052 ] {188be671-a1cf-4e18-a373-d8fe9508d72a} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210331_38_38_0\r\n2021.04.02 18:22:49.351073 [ 13160 ] {188be671-a1cf-4e18-a373-d8fe9508d72a} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210329_36_36_0\r\n2021.04.02 18:22:49.351059 [ 13110 ] {188be671-a1cf-4e18-a373-d8fe9508d72a} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210329_33_33_0\r\n2021.04.02 18:22:49.351013 [ 13161 ] {188be671-a1cf-4e18-a373-d8fe9508d72a} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210327_26_26_0\r\n2021.04.02 18:22:49.351241 [ 220258 ] {188be671-a1cf-4e18-a373-d8fe9508d72a} <Debug> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Selected 38 parts by partition key, 38 parts by primary key, 701 marks by primary key, 701 marks to read from 38 ranges\r\n2021.04.02 18:22:49.353433 [ 220258 ] {188be671-a1cf-4e18-a373-d8fe9508d72a} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Reading approx. 5742771 rows with 28 streams\r\n2021.04.02 18:22:49.354352 [ 220258 ] {188be671-a1cf-4e18-a373-d8fe9508d72a} <Trace> InterpreterSelectQuery: FetchColumns -> WithMergeableState\r\n2021.04.02 18:23:47.762754 [ 220258 ] {188be671-a1cf-4e18-a373-d8fe9508d72a} <Information> executeQuery: Read 5596502 rows, 1.66 GiB in 58.414195782 sec., 95807 rows/sec., 29.17 MiB/sec.\r\n2021.04.02 18:23:47.762784 [ 220258 ] {188be671-a1cf-4e18-a373-d8fe9508d72a} <Debug> MemoryTracker: Peak memory usage (for query): 378.99 MiB.\r\n```\r\nHere is the fast query's system.query_log info and log\r\n```\r\nquery_duration_ms:    31364\r\nquery_id:             ebffd6b9-666c-48a8-9081-c5fc86fee1d4\r\ninitial_query_id:     d78a3277-fca1-40f0-a032-07fc2cc59887\r\nhttp_user_agent:      curl/7.29.0\r\nthread_ids:           [220258,13069,13477,13155,13126,13215,13383,13149,13213,13496,13395,12992,13060,13126,13069,13523,13108,13496,13108,13149,13126,12992,13215,13155,13383,12941,13069,13060,13395,13523,13496,13304,13206,13453,13060,13477,13108,13149,13213,13569,13382,13375,13469,13465,13128,13084,13049,13041,13068,13309,13151,12947,13468,13470,13499,13107,13227,12962,13190,13129,13337,13374,13276,13568,12980,13381,13123,13258]\r\nProfileEvents.Names:  ['Query','SelectQuery','FileOpen','ReadBufferFromFileDescriptorRead','ReadBufferFromFileDescriptorReadBytes','ReadCompressedBytes','CompressedReadBufferBlocks','CompressedReadBufferBytes','IOBufferAllocs','IOBufferAllocBytes','MarkCacheHits','CreatedReadBufferOrdinary','DiskReadElapsedMicroseconds','NetworkSendElapsedMicroseconds','SelectedParts','SelectedRanges','SelectedMarks','SelectedRows','SelectedBytes','ContextLock','RWLockAcquiredReadLocks','RealTimeMicroseconds','UserTimeMicroseconds','SystemTimeMicroseconds','SoftPageFaults','OSIOWaitMicroseconds','OSCPUWaitMicroseconds','OSCPUVirtualTimeMicroseconds','OSReadBytes','OSWriteBytes','OSReadChars','OSWriteChars']\r\nProfileEvents.Values: [1,1,852,1973,465583205,465583241,9215,1025886558,1706,327414590,852,852,385000,27606539,38,38,701,5596502,1787010820,182,1,939213003,5953611,1200827,232051,941016,110882,7120761,155648,20480,465582080,119808]\r\nSettings.Names:       ['use_uncompressed_cache','load_balancing','log_queries','max_bytes_before_external_group_by','max_memory_usage']\r\nSettings.Values:      ['0','random','1','22442450944','53687091200']\r\n```\r\n\r\n```\r\n2021.04.02 18:22:01.146652 [ 220258 ] {ebffd6b9-666c-48a8-9081-c5fc86fee1d4} <Debug> executeQuery: (from 10.147.46.16:22048, initial_query_id: d78a3277-fca1-40f0-a032-07fc2cc59887) SELECT my_distribute_table_local.cuid, my_distribute_table_local.os, my_distribute_table_local.soft_version, my_distribute_table_local.channel, my_distribute_table_local.brand, my_distribute_table_local.device, my_distribute_table_local.resh, my_distribute_table_local.resv, my_distribute_table_local.net_type, my_distribute_table_local.net_provider, my_distribute_table_local.country, my_distribute_table_local.province, my_distribute_table_local.city, my_distribute_table_local.exp_map, my_distribute_table_local.is_spam, my_distribute_table_local.oaid, my_distribute_table_local.idfa, my_distribute_table_local.bhv_ts, my_distribute_table_local.ip, my_distribute_table_local.is_wall, my_distribute_table_local.event_day, my_distribute_table_local.event_action, my_distribute_table_local.event_appid FROM mydb.my_distribute_table_local\r\n2021.04.02 18:22:01.147120 [ 220258 ] {ebffd6b9-666c-48a8-9081-c5fc86fee1d4} <Trace> ContextAccess (default): Access granted: SELECT(cuid, os, soft_version, channel, brand, device, resh, resv, net_type, net_provider, country, province, city, exp_map, is_spam, oaid, idfa, bhv_ts, ip, is_wall, event_day, event_action, event_appid) ON mydb.my_distribute_table_local\r\n2021.04.02 18:22:01.147314 [ 220258 ] {ebffd6b9-666c-48a8-9081-c5fc86fee1d4} <Debug> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Key condition: unknown\r\n2021.04.02 18:22:01.147320 [ 220258 ] {ebffd6b9-666c-48a8-9081-c5fc86fee1d4} <Debug> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): MinMax index condition: unknown\r\n2021.04.02 18:22:01.147396 [ 13069 ] {ebffd6b9-666c-48a8-9081-c5fc86fee1d4} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210315_1_1_0\r\n2021.04.02 18:22:01.147424 [ 13477 ] {ebffd6b9-666c-48a8-9081-c5fc86fee1d4} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210315_4_4_0\r\n2021.04.02 18:22:01.147460 [ 13126 ] {ebffd6b9-666c-48a8-9081-c5fc86fee1d4} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210319_7_7_0\r\n2021.04.02 18:22:01.147473 [ 13149 ] {ebffd6b9-666c-48a8-9081-c5fc86fee1d4} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210320_10_10_0\r\n2021.04.02 18:22:01.147481 [ 13215 ] {ebffd6b9-666c-48a8-9081-c5fc86fee1d4} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210319_3_3_0\r\n2021.04.02 18:22:01.147495 [ 13383 ] {ebffd6b9-666c-48a8-9081-c5fc86fee1d4} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210320_5_5_0\r\n2021.04.02 18:22:01.147514 [ 13126 ] {ebffd6b9-666c-48a8-9081-c5fc86fee1d4} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210323_14_14_0\r\n2021.04.02 18:22:01.147429 [ 13155 ] {ebffd6b9-666c-48a8-9081-c5fc86fee1d4} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210319_2_2_0\r\n2021.04.02 18:22:01.147526 [ 12992 ] {ebffd6b9-666c-48a8-9081-c5fc86fee1d4} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210323_16_16_0\r\n2021.04.02 18:22:01.147506 [ 13213 ] {ebffd6b9-666c-48a8-9081-c5fc86fee1d4} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210321_12_12_0\r\n2021.04.02 18:22:01.147537 [ 13395 ] {ebffd6b9-666c-48a8-9081-c5fc86fee1d4} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210322_13_13_0\r\n2021.04.02 18:22:01.147544 [ 13060 ] {ebffd6b9-666c-48a8-9081-c5fc86fee1d4} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210321_8_8_0\r\n2021.04.02 18:22:01.147553 [ 13523 ] {ebffd6b9-666c-48a8-9081-c5fc86fee1d4} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210322_11_11_0\r\n2021.04.02 18:22:01.147545 [ 13496 ] {ebffd6b9-666c-48a8-9081-c5fc86fee1d4} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210321_9_9_0\r\n2021.04.02 18:22:01.147568 [ 13108 ] {ebffd6b9-666c-48a8-9081-c5fc86fee1d4} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210320_6_6_0\r\n2021.04.02 18:22:01.147516 [ 13069 ] {ebffd6b9-666c-48a8-9081-c5fc86fee1d4} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210322_15_15_0\r\n2021.04.02 18:22:01.147620 [ 13108 ] {ebffd6b9-666c-48a8-9081-c5fc86fee1d4} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210324_18_18_0\r\n2021.04.02 18:22:01.147630 [ 13149 ] {ebffd6b9-666c-48a8-9081-c5fc86fee1d4} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210324_17_17_0\r\n2021.04.02 18:22:01.147622 [ 13496 ] {ebffd6b9-666c-48a8-9081-c5fc86fee1d4} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210323_19_19_0\r\n2021.04.02 18:22:01.147648 [ 13126 ] {ebffd6b9-666c-48a8-9081-c5fc86fee1d4} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210325_20_20_0\r\n2021.04.02 18:22:01.147660 [ 13069 ] {ebffd6b9-666c-48a8-9081-c5fc86fee1d4} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210326_30_30_0\r\n2021.04.02 18:22:01.147652 [ 13060 ] {ebffd6b9-666c-48a8-9081-c5fc86fee1d4} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210327_24_24_0\r\n2021.04.02 18:22:01.147643 [ 13215 ] {ebffd6b9-666c-48a8-9081-c5fc86fee1d4} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210324_22_22_0\r\n2021.04.02 18:22:01.147655 [ 12992 ] {ebffd6b9-666c-48a8-9081-c5fc86fee1d4} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210325_21_21_0\r\n2021.04.02 18:22:01.147722 [ 13060 ] {ebffd6b9-666c-48a8-9081-c5fc86fee1d4} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210329_36_36_0\r\n2021.04.02 18:22:01.147727 [ 13108 ] {ebffd6b9-666c-48a8-9081-c5fc86fee1d4} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210329_32_32_0\r\n2021.04.02 18:22:01.147730 [ 13477 ] {ebffd6b9-666c-48a8-9081-c5fc86fee1d4} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210329_33_33_0\r\n2021.04.02 18:22:01.147735 [ 13453 ] {ebffd6b9-666c-48a8-9081-c5fc86fee1d4} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210328_28_28_0\r\n2021.04.02 18:22:01.147739 [ 13496 ] {ebffd6b9-666c-48a8-9081-c5fc86fee1d4} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210328_35_35_0\r\n2021.04.02 18:22:01.147743 [ 13206 ] {ebffd6b9-666c-48a8-9081-c5fc86fee1d4} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210330_37_37_0\r\n2021.04.02 18:22:01.147673 [ 12941 ] {ebffd6b9-666c-48a8-9081-c5fc86fee1d4} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210326_27_27_0\r\n2021.04.02 18:22:01.147761 [ 13213 ] {ebffd6b9-666c-48a8-9081-c5fc86fee1d4} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210331_38_38_0\r\n2021.04.02 18:22:01.147741 [ 13304 ] {ebffd6b9-666c-48a8-9081-c5fc86fee1d4} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210327_34_34_0\r\n2021.04.02 18:22:01.147742 [ 13149 ] {ebffd6b9-666c-48a8-9081-c5fc86fee1d4} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210328_29_29_0\r\n2021.04.02 18:22:01.147646 [ 13155 ] {ebffd6b9-666c-48a8-9081-c5fc86fee1d4} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210325_25_25_0\r\n2021.04.02 18:22:01.147660 [ 13383 ] {ebffd6b9-666c-48a8-9081-c5fc86fee1d4} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210326_23_23_0\r\n2021.04.02 18:22:01.147678 [ 13395 ] {ebffd6b9-666c-48a8-9081-c5fc86fee1d4} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210327_26_26_0\r\n2021.04.02 18:22:01.147664 [ 13523 ] {ebffd6b9-666c-48a8-9081-c5fc86fee1d4} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Not using primary index on part 20210327_31_31_0\r\n2021.04.02 18:22:01.148009 [ 220258 ] {ebffd6b9-666c-48a8-9081-c5fc86fee1d4} <Debug> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Selected 38 parts by partition key, 38 parts by primary key, 701 marks by primary key, 701 marks to read from 38 ranges\r\n2021.04.02 18:22:01.150129 [ 220258 ] {ebffd6b9-666c-48a8-9081-c5fc86fee1d4} <Trace> mydb.my_distribute_table_local (b4da65e4-f513-4007-ba69-0556a07ae064) (SelectExecutor): Reading approx. 5742771 rows with 28 streams\r\n2021.04.02 18:22:01.150949 [ 220258 ] {ebffd6b9-666c-48a8-9081-c5fc86fee1d4} <Trace> InterpreterSelectQuery: FetchColumns -> WithMergeableState\r\n2021.04.02 18:22:32.511282 [ 220258 ] {ebffd6b9-666c-48a8-9081-c5fc86fee1d4} <Information> executeQuery: Read 5596502 rows, 1.66 GiB in 31.364582323 sec., 178433 rows/sec., 54.34 MiB/sec.\r\n2021.04.02 18:22:32.511318 [ 220258 ] {ebffd6b9-666c-48a8-9081-c5fc86fee1d4} <Debug> MemoryTracker: Peak memory usage (for query): 386.73 MiB.\r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22495/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22495/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22486","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22486/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22486/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22486/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/22486","id":848927304,"node_id":"MDU6SXNzdWU4NDg5MjczMDQ=","number":22486,"title":"improve EXPLAIN PLAN \\ PIPELINE to show which data skip indexes will use to execute query","user":{"login":"Slach","id":105560,"node_id":"MDQ6VXNlcjEwNTU2MA==","avatar_url":"https://avatars.githubusercontent.com/u/105560?v=4","gravatar_id":"","url":"https://api.github.com/users/Slach","html_url":"https://github.com/Slach","followers_url":"https://api.github.com/users/Slach/followers","following_url":"https://api.github.com/users/Slach/following{/other_user}","gists_url":"https://api.github.com/users/Slach/gists{/gist_id}","starred_url":"https://api.github.com/users/Slach/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Slach/subscriptions","organizations_url":"https://api.github.com/users/Slach/orgs","repos_url":"https://api.github.com/users/Slach/repos","events_url":"https://api.github.com/users/Slach/events{/privacy}","received_events_url":"https://api.github.com/users/Slach/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-04-02T03:16:09Z","updated_at":"2021-04-02T03:16:09Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Use case**\r\nI need to know which data skip indexes can be applied to the queries before run their\r\n\r\n**Describe the solution you'd like**\r\nimprove EXPLAIN PLAN \\ PIPELINE to show which data skip indexes will use to execute query\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22486/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22486/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22482","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22482/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22482/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22482/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/22482","id":848888929,"node_id":"MDU6SXNzdWU4NDg4ODg5Mjk=","number":22482,"title":"Reddit comments dataset","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":785082162,"node_id":"MDU6TGFiZWw3ODUwODIxNjI=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-documentation","name":"comp-documentation","color":"b5bcff","default":false,"description":"Used to run automatic builds of the documentation"},{"id":3360106261,"node_id":"MDU6TGFiZWwzMzYwMTA2MjYx","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/dataset","name":"dataset","color":"00CCCC","default":false,"description":""}],"state":"open","locked":false,"assignee":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"assignees":[{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false}],"milestone":null,"comments":12,"created_at":"2021-04-02T01:13:19Z","updated_at":"2021-09-16T12:43:45Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"Needed for #1158.\r\n\r\nThis is a follow-up to\r\nhttps://www.percona.com/blog/2017/10/02/big-data-set-reddit-comments-analyzing-clickhouse/","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22482/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22482/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22481","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22481/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22481/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22481/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/22481","id":848853585,"node_id":"MDU6SXNzdWU4NDg4NTM1ODU=","number":22481,"title":"2 almost identical queries but one takes much longer.","user":{"login":"ramazanpolat","id":3527695,"node_id":"MDQ6VXNlcjM1Mjc2OTU=","avatar_url":"https://avatars.githubusercontent.com/u/3527695?v=4","gravatar_id":"","url":"https://api.github.com/users/ramazanpolat","html_url":"https://github.com/ramazanpolat","followers_url":"https://api.github.com/users/ramazanpolat/followers","following_url":"https://api.github.com/users/ramazanpolat/following{/other_user}","gists_url":"https://api.github.com/users/ramazanpolat/gists{/gist_id}","starred_url":"https://api.github.com/users/ramazanpolat/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ramazanpolat/subscriptions","organizations_url":"https://api.github.com/users/ramazanpolat/orgs","repos_url":"https://api.github.com/users/ramazanpolat/repos","events_url":"https://api.github.com/users/ramazanpolat/events{/privacy}","received_events_url":"https://api.github.com/users/ramazanpolat/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-04-01T23:33:13Z","updated_at":"2021-04-02T10:40:23Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"These are 2 almost identical queries but query1 takes much longer.\r\n\r\nAny idea about why this happens?\r\n\r\n(*Clickhouse version: 21.3.4.25*)\r\n\r\n**Query1**\r\n\r\n```sql\r\nSELECT count()\r\nFROM\r\n(\r\n    SELECT num1.number\r\n    FROM numbers(5000000000) AS num1\r\n    ,\r\n    (\r\n        SELECT number\r\n        FROM numbers(1000)\r\n    ) AS num2\r\n    WHERE num1.number = num2.number\r\n)\r\n\r\nQuery id: 26c01eeb-d56d-42ba-871e-c2bf71570c7e\r\n\r\n┌─count()─┐\r\n│    1000 │\r\n└─────────┘\r\n\r\n1 rows in set. Elapsed: 36.661 sec. Processed 5.00 billion rows, 40.00 GB (136.39 million rows/s., 1.09 GB/s.)\r\n```\r\n\r\n**Query2**\r\n```sql\r\nSELECT count()\r\nFROM\r\n(\r\n    SELECT num1.number\r\n    FROM numbers(5000000000) AS num1\r\n    INNER JOIN numbers(1000) AS num2 ON num1.number = num2.number\r\n)\r\n\r\nQuery id: b5d00081-f5e4-413c-b91b-8e68ecdd1beb\r\n\r\n┌─count()─┐\r\n│    1000 │\r\n└─────────┘\r\n\r\n1 rows in set. Elapsed: 22.304 sec. Processed 5.00 billion rows, 40.00 GB (224.18 million rows/s., 1.79 GB/s.)\r\n```\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22481/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22481/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22471","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22471/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22471/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22471/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/22471","id":848648823,"node_id":"MDU6SXNzdWU4NDg2NDg4MjM=","number":22471,"title":"Explicit secret management in ClickHouse","user":{"login":"Enmk","id":1110183,"node_id":"MDQ6VXNlcjExMTAxODM=","avatar_url":"https://avatars.githubusercontent.com/u/1110183?v=4","gravatar_id":"","url":"https://api.github.com/users/Enmk","html_url":"https://github.com/Enmk","followers_url":"https://api.github.com/users/Enmk/followers","following_url":"https://api.github.com/users/Enmk/following{/other_user}","gists_url":"https://api.github.com/users/Enmk/gists{/gist_id}","starred_url":"https://api.github.com/users/Enmk/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Enmk/subscriptions","organizations_url":"https://api.github.com/users/Enmk/orgs","repos_url":"https://api.github.com/users/Enmk/repos","events_url":"https://api.github.com/users/Enmk/events{/privacy}","received_events_url":"https://api.github.com/users/Enmk/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2021-04-01T17:19:42Z","updated_at":"2021-04-02T08:53:20Z","closed_at":null,"author_association":"COLLABORATOR","active_lock_reason":null,"body":"**Use case**\r\nPasswords/connection data scattered in different parts of the system is difficult/impossible to reuse in other contexts, which is why the same connection data can appear repeatedly in different places.\r\n\r\nE.g. if the MySQL server connection password ever changes, you will have to recreate tables with the MySQL engine, rewrite selections using the MySQL table function, dictionaries using the same connection, etc. \r\n\r\nAnd it is extremely hard to avoid leaking such secrets to just about any database user.\r\n\r\n**Describe the solution you'd like**\r\nDevelop a secret management API in clickhouse, so the secrets can be provided\\managed from outside of CH and don't have to be explicitly typed in.\r\n\r\nE.g. add a new function in ClickHouse's SQL dialect:\r\n```\r\nsecret('secret_name')\r\n```\r\nThis way the secret itself doesn't leak to the query log or doesn't even need to be known by the client. It is easy to reuse and change if required.\r\n\r\nEach secret is managed by some backend, with controls secret acquisition from external (or internal source), its lifetime, refresh rate, etc.\r\n\r\n### Examples:\r\n```sql\r\nSELECT encrypt('aes-256-cfb128',  'plaintext to encrypt', secret('mysecret'));\r\nSELECT * FROM mysql('localhost:3306', 'test', 'test', secret('mysql_localhost_user'), secret('mysql_localhost_password'));\r\n```\r\n\r\nWhere `mysecret` is a name that is resolved to a secret value at run-time.\r\n\r\nThere could be many backends that manage the secrets: in-memory plaintext, server-key based (just like in #22423), (Hashicorp vault)[https://www.vaultproject.io/] or anything else that provides a reasonable API.\r\n\r\nOf course, all of those backends have to be developed separately or used via some generic HTTP-API.\r\n\r\n### Configuration example\r\nGiven that we have implemented 3 backends: plaintext, server-key-derivation based backend and hashicorp-vault-based one, we may have the following configuration:\r\n```\r\n<secrets>\r\n    <!-- plaintext secret, accessible by name `literal_password` -->\r\n    <literal_password>this is the password</literal_password>\r\n\r\n    <!-- server-key-derivation-based secret, accessible by name `server_key_32` -->\r\n    <server_key_32>\r\n        <secret_backend>server_key_provider</secret_backend>\r\n        <server_key_provider>\r\n            <key_bytes>32</key_bytes>\r\n        </server_key_provider>\r\n    </server_key_32>\r\n\r\n    <!-- hashicorp-vault-managed secret, accessible by name `external_secret` -->\r\n    <external_secret>\r\n        <secret_backend>hashicorp_vault</secret_backend>\r\n        <hashicorp_vault>\r\n            <token>blah-blah</token>\r\n            <namespace>blah-blah</namespace>\r\n            <vault_host>some url</vault_host>\r\n            <secret_name>some secret name</secret_name>\r\n        </hashicorp_vault>\r\n        <!-- generic options, like lifetime or renewing period -->\r\n    </external_secret>\r\n</secrets>\r\n```\r\n\r\nWhere `<secret_backend>backend_name</secret_backend>` section controls which backed is going to be used, and the corresponding config section describes particular settings of the backend.\r\n\r\n**Additional context**\r\nPossible future extension points:\r\n* `SYSTEM RESET SECRET 'secret_name';`\r\n* `SYSTEM RESET ALL SECRETS;`\r\n* Access management for the secrets: `GRANT / REVOKE SECRET`\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22471/reactions","total_count":4,"+1":4,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22471/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22431","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22431/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22431/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22431/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/22431","id":848181333,"node_id":"MDU6SXNzdWU4NDgxODEzMzM=","number":22431,"title":"Support inserting data when a partitioned column is specified","user":{"login":"mdianjun","id":12122541,"node_id":"MDQ6VXNlcjEyMTIyNTQx","avatar_url":"https://avatars.githubusercontent.com/u/12122541?v=4","gravatar_id":"","url":"https://api.github.com/users/mdianjun","html_url":"https://github.com/mdianjun","followers_url":"https://api.github.com/users/mdianjun/followers","following_url":"https://api.github.com/users/mdianjun/following{/other_user}","gists_url":"https://api.github.com/users/mdianjun/gists{/gist_id}","starred_url":"https://api.github.com/users/mdianjun/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mdianjun/subscriptions","organizations_url":"https://api.github.com/users/mdianjun/orgs","repos_url":"https://api.github.com/users/mdianjun/repos","events_url":"https://api.github.com/users/mdianjun/events{/privacy}","received_events_url":"https://api.github.com/users/mdianjun/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":4,"created_at":"2021-04-01T08:07:06Z","updated_at":"2021-04-01T16:19:48Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"\r\n\r\n**Use case**\r\nWhen Insert hive data file into clickhouse table, if the hive table is a partitioned table, the hive data file doesn't contain partitioned column, so clickhouse couldn't recognize `partition by` filed.\r\n\r\n**Describe the solution you'd like**\r\n\r\nSupport an insert statement like `INSERT INTO table_name PARTITION(partition_column=xxxx)`.\r\n\r\n```\r\n centos1.local :) CREATE TABLE default.demo\r\n(\r\n    `id` Int32,\r\n    `name` String,\r\n    `dt` String\r\n)\r\nENGINE = MergeTree\r\nPARTITION BY `dt`\r\nORDER BY `id`\r\nSETTINGS index_granularity = 8192;\r\n\r\ncentos1.local :) INSERT INTO demo PARTITION(dt='20200310') (id,name) FORMAT < format_name> <data_set>;\r\n```\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22431/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22431/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22426","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22426/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22426/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22426/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/22426","id":847833374,"node_id":"MDU6SXNzdWU4NDc4MzMzNzQ=","number":22426,"title":"Pressing Ctrl+C in client should terminate the output of resultset.","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":845247686,"node_id":"MDU6TGFiZWw4NDUyNDc2ODY=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/usability","name":"usability","color":"ebf28c","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-04-01T03:39:44Z","updated_at":"2021-04-01T03:40:13Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22426/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22426/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22405","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22405/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22405/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22405/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/22405","id":846080592,"node_id":"MDU6SXNzdWU4NDYwODA1OTI=","number":22405,"title":"TTL GROUP BY / DB::Exception: Not found column toStartOfHour(Timeslot) in block.","user":{"login":"Jirennor","id":16560991,"node_id":"MDQ6VXNlcjE2NTYwOTkx","avatar_url":"https://avatars.githubusercontent.com/u/16560991?v=4","gravatar_id":"","url":"https://api.github.com/users/Jirennor","html_url":"https://github.com/Jirennor","followers_url":"https://api.github.com/users/Jirennor/followers","following_url":"https://api.github.com/users/Jirennor/following{/other_user}","gists_url":"https://api.github.com/users/Jirennor/gists{/gist_id}","starred_url":"https://api.github.com/users/Jirennor/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Jirennor/subscriptions","organizations_url":"https://api.github.com/users/Jirennor/orgs","repos_url":"https://api.github.com/users/Jirennor/repos","events_url":"https://api.github.com/users/Jirennor/events{/privacy}","received_events_url":"https://api.github.com/users/Jirennor/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""}],"state":"open","locked":false,"assignee":{"login":"CurtizJ","id":20361854,"node_id":"MDQ6VXNlcjIwMzYxODU0","avatar_url":"https://avatars.githubusercontent.com/u/20361854?v=4","gravatar_id":"","url":"https://api.github.com/users/CurtizJ","html_url":"https://github.com/CurtizJ","followers_url":"https://api.github.com/users/CurtizJ/followers","following_url":"https://api.github.com/users/CurtizJ/following{/other_user}","gists_url":"https://api.github.com/users/CurtizJ/gists{/gist_id}","starred_url":"https://api.github.com/users/CurtizJ/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/CurtizJ/subscriptions","organizations_url":"https://api.github.com/users/CurtizJ/orgs","repos_url":"https://api.github.com/users/CurtizJ/repos","events_url":"https://api.github.com/users/CurtizJ/events{/privacy}","received_events_url":"https://api.github.com/users/CurtizJ/received_events","type":"User","site_admin":false},"assignees":[{"login":"CurtizJ","id":20361854,"node_id":"MDQ6VXNlcjIwMzYxODU0","avatar_url":"https://avatars.githubusercontent.com/u/20361854?v=4","gravatar_id":"","url":"https://api.github.com/users/CurtizJ","html_url":"https://github.com/CurtizJ","followers_url":"https://api.github.com/users/CurtizJ/followers","following_url":"https://api.github.com/users/CurtizJ/following{/other_user}","gists_url":"https://api.github.com/users/CurtizJ/gists{/gist_id}","starred_url":"https://api.github.com/users/CurtizJ/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/CurtizJ/subscriptions","organizations_url":"https://api.github.com/users/CurtizJ/orgs","repos_url":"https://api.github.com/users/CurtizJ/repos","events_url":"https://api.github.com/users/CurtizJ/events{/privacy}","received_events_url":"https://api.github.com/users/CurtizJ/received_events","type":"User","site_admin":false}],"milestone":null,"comments":6,"created_at":"2021-03-31T07:27:16Z","updated_at":"2021-04-13T15:08:28Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"I have a SummingMergeTree table that receives data with a minute interval (inserted with toStartOfMinute()).\r\nAfter 24 hours I would like to regroup that data with an interval of a hour.\r\nI created the following table:\r\n```\r\nCREATE TABLE IF NOT EXISTS ttl_test\r\n(\r\n  Timeslot DateTime,\r\n  Device String,\r\n  EType String,\r\n  Proto String,\r\n  Bytes UInt64,\r\n  Packets UInt64\r\n) ENGINE = SummingMergeTree()\r\nPARTITION BY toYYYYMMDD(Timeslot)\r\nORDER BY (Timeslot,Device,EType,Proto)\r\nTTL Timeslot + INTERVAL 24 HOUR GROUP BY Timeslot,Device,EType,Proto SET Timeslot=min(toStartOfHour(Timeslot)),Bytes=sum(Bytes),Packets=sum(Packets);\r\n```\r\nFor testing purpose I set the interval to 5 minutes and after some time I receive the following exception.\r\n```\r\n2021.03.31 08:43:00.268102 [ 119181 ] {} <Error> auto DB::IBackgroundJobExecutor::jobExecutingTask()::(anonymous class)::operator()() const: Code: 10, e.displayText() = DB::Exception: Not found column toStartOfHour(Timeslot) in block. There are only columns: Timeslot, Device, EType, Proto, Bytes, Packets, Stack trace (when copying this message, always include the lines below):\r\n\r\n0. DB::Block::getPositionByName(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) const @ 0xe70a774 in /usr/bin/clickhouse\r\n1. DB::TTLAggregationAlgorithm::TTLAggregationAlgorithm(DB::TTLDescription const&, DB::MergeTreeDataPartTTLInfo const&, long, bool, DB::Block const&, DB::MergeTreeData const&) @ 0xf653527 in /usr/bin/clickhouse\r\n2. DB::TTLBlockInputStream::TTLBlockInputStream(std::__1::shared_ptr<DB::IBlockInputStream> const&, DB::MergeTreeData const&, std::__1::shared_ptr<DB::StorageInMemoryMetadata const> const&, std::__1::shared_ptr<DB::IMergeTreeDataPart> const&, long, bool) @ 0xf64e7b5 in /usr/bin/clickhouse\r\n3. DB::MergeTreeDataMergerMutator::mergePartsToTemporaryPart(DB::FutureMergedMutatedPart const&, std::__1::shared_ptr<DB::StorageInMemoryMetadata const> const&, DB::BackgroundProcessListEntry<DB::MergeListElement, DB::MergeInfo>&, std::__1::shared_ptr<DB::RWLockImpl::LockHolderImpl>&, long, DB::Context const&, std::__1::unique_ptr<DB::IReservation, std::__1::default_delete<DB::IReservation> > const&, bool, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&) @ 0xf627a1f in /usr/bin/clickhouse\r\n4. DB::StorageMergeTree::mergeSelectedParts(std::__1::shared_ptr<DB::StorageInMemoryMetadata const> const&, bool, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&, DB::StorageMergeTree::MergeMutateSelectedEntry&, std::__1::shared_ptr<DB::RWLockImpl::LockHolderImpl>&) @ 0xf3a76b8 in /usr/bin/clickhouse\r\n5. ? @ 0xf3b9b0c in /usr/bin/clickhouse\r\n6. ? @ 0xf57b687 in /usr/bin/clickhouse\r\n7. ThreadPoolImpl<ThreadFromGlobalPool>::worker(std::__1::__list_iterator<ThreadFromGlobalPool, void*>) @ 0x8654088 in /usr/bin/clickhouse\r\n8. ThreadFromGlobalPool::ThreadFromGlobalPool<void ThreadPoolImpl<ThreadFromGlobalPool>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda1'()>(void&&, void ThreadPoolImpl<ThreadFromGlobalPool>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda1'()&&...)::'lambda'()::operator()() @ 0x865603f in /usr/bin/clickhouse\r\n9. ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) @ 0x865165f in /usr/bin/clickhouse\r\n10. ? @ 0x86550f3 in /usr/bin/clickhouse\r\n11. start_thread @ 0x7ea5 in /usr/lib64/libpthread-2.17.so\r\n12. clone @ 0xfe9fd in /usr/lib64/libc-2.17.so\r\n (version 21.3.4.25 (official build))\r\n```\r\nSo the main question is: Can I use the ttl group by for this kind of action or do I need to come up with something different?\r\n\r\n\r\nI did saw this issues: https://github.com/ClickHouse/ClickHouse/issues/14345\r\nSo I adjusted the table configuration to:\r\n```\r\nCREATE TABLE IF NOT EXISTS ttl_test\r\n(\r\n  Timeslot DateTime,\r\n  Device String,\r\n  EType String,\r\n  Proto String,\r\n  Bytes UInt64,\r\n  Packets UInt64\r\n) ENGINE = SummingMergeTree()\r\nPARTITION BY toYYYYMMDD(Timeslot)\r\nORDER BY (toStartOfHour(Timeslot),Timeslot,Device,EType,Proto)\r\nTTL toStartOfHour(Timeslot) + INTERVAL 24 HOUR GROUP BY toStartOfHour(Timeslot),Device,EType,Proto SET Timeslot=min(toStartOfHour(Timeslot)),Bytes=sum(Bytes),Packets=sum(Packets);\r\n\r\n```\r\nBut then I get the following error when creating the table:\r\n```\r\nReceived exception from server (version 21.3.4):\r\nCode: 450. DB::Exception: Received from 127.0.0.1:9000. DB::Exception: TTL Expression GROUP BY key should be a prefix of primary key.\r\n```\r\n\r\n\r\n\r\n\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22405/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22405/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22398","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22398/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22398/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22398/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/22398","id":845860612,"node_id":"MDU6SXNzdWU4NDU4NjA2MTI=","number":22398,"title":"A list of benchmarks","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":785082162,"node_id":"MDU6TGFiZWw3ODUwODIxNjI=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-documentation","name":"comp-documentation","color":"b5bcff","default":false,"description":"Used to run automatic builds of the documentation"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":37,"created_at":"2021-03-31T04:49:19Z","updated_at":"2022-01-22T14:28:46Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"Post every link to benchmark here.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22398/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22398/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22344","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22344/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22344/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22344/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/22344","id":844220967,"node_id":"MDU6SXNzdWU4NDQyMjA5Njc=","number":22344,"title":"CREATE AS SELECT performance downgrade in 20.8","user":{"login":"filimonov","id":1549571,"node_id":"MDQ6VXNlcjE1NDk1NzE=","avatar_url":"https://avatars.githubusercontent.com/u/1549571?v=4","gravatar_id":"","url":"https://api.github.com/users/filimonov","html_url":"https://github.com/filimonov","followers_url":"https://api.github.com/users/filimonov/followers","following_url":"https://api.github.com/users/filimonov/following{/other_user}","gists_url":"https://api.github.com/users/filimonov/gists{/gist_id}","starred_url":"https://api.github.com/users/filimonov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/filimonov/subscriptions","organizations_url":"https://api.github.com/users/filimonov/orgs","repos_url":"https://api.github.com/users/filimonov/repos","events_url":"https://api.github.com/users/filimonov/events{/privacy}","received_events_url":"https://api.github.com/users/filimonov/received_events","type":"User","site_admin":false},"labels":[{"id":756395244,"node_id":"MDU6TGFiZWw3NTYzOTUyNDQ=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/performance","name":"performance","color":"c2e0c6","default":false,"description":null},{"id":1365579236,"node_id":"MDU6TGFiZWwxMzY1NTc5MjM2","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/minor","name":"minor","color":"FFF8F8","default":false,"description":"Priority: minor"},{"id":2266396286,"node_id":"MDU6TGFiZWwyMjY2Mzk2Mjg2","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/v20.8-affected","name":"v20.8-affected","color":"c2bfff","default":false,"description":""},{"id":2825253639,"node_id":"MDU6TGFiZWwyODI1MjUzNjM5","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/v21.3-affected","name":"v21.3-affected","color":"c2bfff","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2021-03-30T08:25:37Z","updated_at":"2021-06-27T12:17:35Z","closed_at":null,"author_association":"COLLABORATOR","active_lock_reason":null,"body":"20.7 and earlier - query time is about 5.5 sec. \r\n\r\n```\r\nClickHouse client version 20.7.4.11 (official build).\r\nConnecting to localhost:9000 as user default.\r\nConnected to ClickHouse server version 20.7.4 revision 54437.\r\n\r\nbd215eb73ee1 :) create table test3 engine=MergeTree ORDER BY (toDate(eeid_time_ns), strategy, symbol)  AS  SELECT toString( rand() % 100) as strategy,  toString( rand() % 10000 ) as symbol, 1617036720967027485 + number*3600*100000000 + rand()%1000000000 eeid_time_ns from numbers(10000000);\r\n\r\nCREATE TABLE test3\r\nENGINE = MergeTree\r\nORDER BY (toDate(eeid_time_ns), strategy, symbol) AS\r\nSELECT \r\n    toString(rand() % 100) AS strategy,\r\n    toString(rand() % 10000) AS symbol,\r\n    (1617036720967027485 + ((number * 3600) * 100000000)) + (rand() % 1000000000) AS eeid_time_ns\r\nFROM numbers(10000000)\r\n\r\nOk.\r\n\r\n0 rows in set. Elapsed: 5.450 sec. Processed 10.02 million rows, 80.18 MB (1.84 million rows/s., 14.71 MB/s.) \r\n```\r\n\r\n20.8 and newer - query time is about 11 sec. \r\n\r\n```\r\nClickHouse client version 20.8.2.3 (official build).\r\nConnecting to localhost:9000 as user default.\r\nConnected to ClickHouse server version 20.8.2 revision 54438.\r\n\r\n62206255473b :) create table test3 engine=MergeTree ORDER BY (toDate(eeid_time_ns), strategy, symbol)  AS  SELECT toString( rand() % 100) as strategy,  toString( rand() % 10000 ) as symbol, 1617036720967027485 + number*3600*100000000 + rand()%1000000000 eeid_time_ns from numbers(10000000);\r\n\r\nCREATE TABLE test3\r\nENGINE = MergeTree\r\nORDER BY (toDate(eeid_time_ns), strategy, symbol) AS\r\nSELECT \r\n    toString(rand() % 100) AS strategy,\r\n    toString(rand() % 10000) AS symbol,\r\n    (1617036720967027485 + ((number * 3600) * 100000000)) + (rand() % 1000000000) AS eeid_time_ns\r\nFROM numbers(10000000)\r\n\r\nOk.\r\n\r\n0 rows in set. Elapsed: 11.296 sec. Processed 10.49 million rows, 83.88 MB (928.24 thousand rows/s., 7.43 MB/s.) \r\n```\r\n\r\n```\r\nClickHouse client version 21.3.4.25 (official build).\r\nConnecting to localhost:9000 as user default.\r\nConnected to ClickHouse server version 21.3.4 revision 54447.\r\n\r\nd2952c32db58 :) create table test3 engine=MergeTree ORDER BY (toDate(eeid_time_ns), strategy, symbol)  AS  SELECT toString( rand() % 100) as strategy,  toString( rand() % 10000 ) as symbol, 1617036720967027485 + number*3600*100000000 + rand()%1000000000 eeid_time_ns from numbers(10000000);\r\n\r\nCREATE TABLE test3\r\nENGINE = MergeTree\r\nORDER BY (toDate(eeid_time_ns), strategy, symbol) AS\r\nSELECT\r\n    toString(rand() % 100) AS strategy,\r\n    toString(rand() % 10000) AS symbol,\r\n    (1617036720967027485 + ((number * 3600) * 100000000)) + (rand() % 1000000000) AS eeid_time_ns\r\nFROM numbers(10000000)\r\n\r\nQuery id: 57ef0340-f31e-454d-a749-52bcfba3d8e3\r\n\r\nOk.\r\n\r\n0 rows in set. Elapsed: 11.525 sec. Processed 10.49 million rows, 83.88 MB (909.78 thousand rows/s., 7.28 MB/s.) \r\n```\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22344/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22344/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22327","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22327/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22327/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22327/events","html_url":"https://github.com/ClickHouse/ClickHouse/pull/22327","id":843851908,"node_id":"MDExOlB1bGxSZXF1ZXN0NjAzMTc5ODc1","number":22327,"title":"Added ConcurrentLRUHashMap","user":{"login":"kitaisreal","id":22458333,"node_id":"MDQ6VXNlcjIyNDU4MzMz","avatar_url":"https://avatars.githubusercontent.com/u/22458333?v=4","gravatar_id":"","url":"https://api.github.com/users/kitaisreal","html_url":"https://github.com/kitaisreal","followers_url":"https://api.github.com/users/kitaisreal/followers","following_url":"https://api.github.com/users/kitaisreal/following{/other_user}","gists_url":"https://api.github.com/users/kitaisreal/gists{/gist_id}","starred_url":"https://api.github.com/users/kitaisreal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kitaisreal/subscriptions","organizations_url":"https://api.github.com/users/kitaisreal/orgs","repos_url":"https://api.github.com/users/kitaisreal/repos","events_url":"https://api.github.com/users/kitaisreal/events{/privacy}","received_events_url":"https://api.github.com/users/kitaisreal/received_events","type":"User","site_admin":false},"labels":[{"id":1876999755,"node_id":"MDU6TGFiZWwxODc2OTk5NzU1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/pr-not-for-changelog","name":"pr-not-for-changelog","color":"007700","default":false,"description":"This PR should not be mentioned in the changelog"}],"state":"open","locked":false,"assignee":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"assignees":[{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false}],"milestone":null,"comments":2,"created_at":"2021-03-29T22:03:50Z","updated_at":"2021-06-04T07:23:09Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"draft":true,"pull_request":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/pulls/22327","html_url":"https://github.com/ClickHouse/ClickHouse/pull/22327","diff_url":"https://github.com/ClickHouse/ClickHouse/pull/22327.diff","patch_url":"https://github.com/ClickHouse/ClickHouse/pull/22327.patch","merged_at":null},"body":"I hereby agree to the terms of the CLA available at: https://yandex.ru/legal/cla/?lang=en\r\n\r\nChangelog category (leave one):\r\n- Not for changelog (changelog entry is not required)\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22327/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22327/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22236","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22236/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22236/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22236/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/22236","id":842884062,"node_id":"MDU6SXNzdWU4NDI4ODQwNjI=","number":22236,"title":"HDFS Storage support hadoop.rpc.protection=PRIVACY","user":{"login":"Qsimple","id":28128661,"node_id":"MDQ6VXNlcjI4MTI4NjYx","avatar_url":"https://avatars.githubusercontent.com/u/28128661?v=4","gravatar_id":"","url":"https://api.github.com/users/Qsimple","html_url":"https://github.com/Qsimple","followers_url":"https://api.github.com/users/Qsimple/followers","following_url":"https://api.github.com/users/Qsimple/following{/other_user}","gists_url":"https://api.github.com/users/Qsimple/gists{/gist_id}","starred_url":"https://api.github.com/users/Qsimple/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Qsimple/subscriptions","organizations_url":"https://api.github.com/users/Qsimple/orgs","repos_url":"https://api.github.com/users/Qsimple/repos","events_url":"https://api.github.com/users/Qsimple/events{/privacy}","received_events_url":"https://api.github.com/users/Qsimple/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-03-29T01:06:50Z","updated_at":"2021-10-07T12:03:33Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Some context can be found in https://github.com/ClickHouse/ClickHouse/pull/16621#issuecomment-808635139      \r\n\r\nHope to discuss the future plan about the intergration with HDFS.  \r\n\r\ntks\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22236/reactions","total_count":1,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":1},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22236/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22227","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22227/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22227/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22227/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/22227","id":842834662,"node_id":"MDU6SXNzdWU4NDI4MzQ2NjI=","number":22227,"title":"Distributed table Sharding not working properly","user":{"login":"samanway1996","id":10659497,"node_id":"MDQ6VXNlcjEwNjU5NDk3","avatar_url":"https://avatars.githubusercontent.com/u/10659497?v=4","gravatar_id":"","url":"https://api.github.com/users/samanway1996","html_url":"https://github.com/samanway1996","followers_url":"https://api.github.com/users/samanway1996/followers","following_url":"https://api.github.com/users/samanway1996/following{/other_user}","gists_url":"https://api.github.com/users/samanway1996/gists{/gist_id}","starred_url":"https://api.github.com/users/samanway1996/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/samanway1996/subscriptions","organizations_url":"https://api.github.com/users/samanway1996/orgs","repos_url":"https://api.github.com/users/samanway1996/repos","events_url":"https://api.github.com/users/samanway1996/events{/privacy}","received_events_url":"https://api.github.com/users/samanway1996/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":5,"created_at":"2021-03-28T21:23:50Z","updated_at":"2021-03-29T18:17:06Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"I am creating a distributed table over three underlying tables (or, shards created with engine ReplacingMergeTree). While inserting data into the distributed table, two of the shards getting filled appropriately, but one shard is having data records which should have been stored to the other ones.   \r\n\r\n**More about the Issue:**\r\nI am inserting duplicate data on different batch, so while querying I need my data to be deduplicated. And that's the reason I am using ReplacingMergeTree and OPTIMIZE statement. But to get the data deduplicated while querying, I need same records to be inserted to same shard (as OPTIMIZE does not work over distributed table). I am using an hashed Id (which is a String of 10 characters). But after investigating more I realised while inserting to the distributed table, the data is not going to proper shard where it should be. \r\n\r\n**How to reproduce**\r\nClickhouse version I am using: 21.2.5\r\n\r\n**Table schema**\r\n```\r\nCREATE TABLE db_name.shard_name\r\n(\r\n  `some_id` String,\r\n  `date_created` DateTime DEFAULT now() CODEC(T64, LZ4),\r\n  `some_column` Datatype\r\n)\r\nENGINE = ReplacingMergeTree()\r\nPARTITION BY toYYYYMMDD(date_created)\r\nORDER BY some_id\r\nSETTINGS index_granularity = 8192\r\n```\r\n\r\n```\r\nCREATE TABLE db_name.distributed_table_name ON CLUSTER `cluster-name` AS db_name.shard_name\r\nENGINE = Distributed(cluster-name, db_name, shard_name, xxHash32(some_id))\r\n```\r\n\r\n```\r\n#!/bin/bash\r\nclickhouse-client -h CLICKHOUSE_HOSTNAME -u CLICKHOUSE_USERNAME --password CLICKHOUSE_PASSWORD -d db_name --multiquery --query \\\r\n    \"SET max_memory_usage=60000000000;\r\n    INSERT INTO db_name.distributed_table_name FORMAT JSONEachRow\" --input_format_skip_unknown_fields=1  < filename.json\r\n```\r\n\r\n**Error message and/or stacktrace**\r\nSurprisingly when insertion was done in multiple batches, I issued the following query to each shard.\r\n```\r\nSELECT some_id, xxHash32(some_id ) AS hashed_id, xxHash32(some_id )%3  AS modulo\r\nFROM db_name.shard_name \r\nWHERE date_created >= '2021-03-29 00:00:00'\r\n```\r\nI am getting the following result.\r\n<img width=\"297\" alt=\"Screenshot 2021-03-29 at 2 39 58 AM\" src=\"https://user-images.githubusercontent.com/10659497/112768180-5abf8000-9038-11eb-904c-f62c1b8b05bb.png\">\r\n<img width=\"299\" alt=\"Screenshot 2021-03-29 at 2 36 52 AM\" src=\"https://user-images.githubusercontent.com/10659497/112768185-601cca80-9038-11eb-8309-de0f535ffa22.png\">\r\n<img width=\"299\" alt=\"Screenshot 2021-03-29 at 2 37 03 AM\" src=\"https://user-images.githubusercontent.com/10659497/112768191-63b05180-9038-11eb-9c4d-191ed4af8a1e.png\">\r\n\r\n**Expected behavior**\r\nClearly the third shard should store the records having `xxHash32(some_id )%3 = 0`. The record with ID as _2903312331_ should be stored in first shard. \r\n\r\n**Other workarounds tried**\r\nI have read that ReplacingMergeTree can suffer from race conditions if SELECT query is issued in between OPTIMIZE is processing, and data can be invalidated. But I made sure, I query from the table once OPTIMIZE is finished. Also have tried with other hash like `murmurHash3_64`.\r\n\r\n**More context**\r\nThe shard tables were created long ago, and first data was being inserted to individual shards randomly. Later the distributed table was created in purpose to deduplicate the data (by directing same records to be inserted to same shard, so that OPTIMIZE can deduplicate the whole data).","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22227/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22227/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22223","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22223/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22223/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22223/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/22223","id":842769748,"node_id":"MDU6SXNzdWU4NDI3Njk3NDg=","number":22223,"title":"Table doesn't exist exception when using `arrayExists`","user":{"login":"OmarBazaraa","id":6713329,"node_id":"MDQ6VXNlcjY3MTMzMjk=","avatar_url":"https://avatars.githubusercontent.com/u/6713329?v=4","gravatar_id":"","url":"https://api.github.com/users/OmarBazaraa","html_url":"https://github.com/OmarBazaraa","followers_url":"https://api.github.com/users/OmarBazaraa/followers","following_url":"https://api.github.com/users/OmarBazaraa/following{/other_user}","gists_url":"https://api.github.com/users/OmarBazaraa/gists{/gist_id}","starred_url":"https://api.github.com/users/OmarBazaraa/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/OmarBazaraa/subscriptions","organizations_url":"https://api.github.com/users/OmarBazaraa/orgs","repos_url":"https://api.github.com/users/OmarBazaraa/repos","events_url":"https://api.github.com/users/OmarBazaraa/events{/privacy}","received_events_url":"https://api.github.com/users/OmarBazaraa/received_events","type":"User","site_admin":false},"labels":[{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-03-28T16:06:48Z","updated_at":"2021-03-28T19:43:22Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"I have the following table:\r\n\r\n```sql\r\nCREATE TABLE test.table\r\n(\r\n    Id      UInt64,\r\n    Arr1    Array(String),\r\n    Arr2    Array(String)\r\n)\r\nENGINE = MergeTree()\r\nORDER BY (Id);\r\n```\r\n\r\nWhenever I run this simple query, I get that strange error that I'm not expecting ...\r\n\r\n```sql\r\nSELECT arrayExists(x -> (x NOT IN (Arr2)), Arr1)\r\nFROM test.table\r\n```\r\n```\r\nQuery id: 1407dc4e-1176-4bd3-9d93-e2706eeef12b\r\n\r\nReceived exception from server (version 21.1.2):\r\nCode: 60. DB::Exception: Received from localhost:9440. DB::Exception: Table default.Arr2 doesn't exist: While processing arrayExists(x -> (x NOT IN (Arr2)), Arr1).\r\n```\r\n\r\nWhy is ClickHouse considering `Arr2` as a table?!","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22223/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22223/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22222","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22222/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22222/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22222/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/22222","id":842760030,"node_id":"MDU6SXNzdWU4NDI3NjAwMzA=","number":22222,"title":"Official ARM image for Docker","user":{"login":"pablote","id":2463995,"node_id":"MDQ6VXNlcjI0NjM5OTU=","avatar_url":"https://avatars.githubusercontent.com/u/2463995?v=4","gravatar_id":"","url":"https://api.github.com/users/pablote","html_url":"https://github.com/pablote","followers_url":"https://api.github.com/users/pablote/followers","following_url":"https://api.github.com/users/pablote/following{/other_user}","gists_url":"https://api.github.com/users/pablote/gists{/gist_id}","starred_url":"https://api.github.com/users/pablote/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pablote/subscriptions","organizations_url":"https://api.github.com/users/pablote/orgs","repos_url":"https://api.github.com/users/pablote/repos","events_url":"https://api.github.com/users/pablote/events{/privacy}","received_events_url":"https://api.github.com/users/pablote/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":1010059902,"node_id":"MDU6TGFiZWwxMDEwMDU5OTAy","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/docker","name":"docker","color":"2c8bdd","default":false,"description":""},{"id":2402913184,"node_id":"MDU6TGFiZWwyNDAyOTEzMTg0","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-aarch64","name":"comp-aarch64","color":"b5bcff","default":false,"description":"arm / aarch platform specific"}],"state":"open","locked":false,"assignee":{"login":"Felixoid","id":3025537,"node_id":"MDQ6VXNlcjMwMjU1Mzc=","avatar_url":"https://avatars.githubusercontent.com/u/3025537?v=4","gravatar_id":"","url":"https://api.github.com/users/Felixoid","html_url":"https://github.com/Felixoid","followers_url":"https://api.github.com/users/Felixoid/followers","following_url":"https://api.github.com/users/Felixoid/following{/other_user}","gists_url":"https://api.github.com/users/Felixoid/gists{/gist_id}","starred_url":"https://api.github.com/users/Felixoid/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Felixoid/subscriptions","organizations_url":"https://api.github.com/users/Felixoid/orgs","repos_url":"https://api.github.com/users/Felixoid/repos","events_url":"https://api.github.com/users/Felixoid/events{/privacy}","received_events_url":"https://api.github.com/users/Felixoid/received_events","type":"User","site_admin":false},"assignees":[{"login":"Felixoid","id":3025537,"node_id":"MDQ6VXNlcjMwMjU1Mzc=","avatar_url":"https://avatars.githubusercontent.com/u/3025537?v=4","gravatar_id":"","url":"https://api.github.com/users/Felixoid","html_url":"https://github.com/Felixoid","followers_url":"https://api.github.com/users/Felixoid/followers","following_url":"https://api.github.com/users/Felixoid/following{/other_user}","gists_url":"https://api.github.com/users/Felixoid/gists{/gist_id}","starred_url":"https://api.github.com/users/Felixoid/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Felixoid/subscriptions","organizations_url":"https://api.github.com/users/Felixoid/orgs","repos_url":"https://api.github.com/users/Felixoid/repos","events_url":"https://api.github.com/users/Felixoid/events{/privacy}","received_events_url":"https://api.github.com/users/Felixoid/received_events","type":"User","site_admin":false}],"milestone":null,"comments":23,"created_at":"2021-03-28T15:18:24Z","updated_at":"2022-01-17T16:58:56Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Current official Docker images seem to be only built for amd64. It would be great to also have arm64 images. Lots of other databases or similar, like mongo/postgres/redis, already provide multi arch Docker images.\r\n\r\n**Use case**\r\nMy main use case would be to easily run Clickhouse on EC2 Graviton2 instances. Also it'd help local development on Apple M1 computers without having to emulate amd64 images.\r\n\r\n**Describe the solution you'd like**\r\nOfficial arm64 builds for Docker\r\n\r\n**Describe alternatives you've considered**\r\nI understand an alternative would be to build Clickhouse myself. This is considerably more difficult than just running a pre built container. Not sure if there's another alternative.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22222/reactions","total_count":35,"+1":35,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22222/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22169","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22169/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22169/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22169/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/22169","id":842001638,"node_id":"MDU6SXNzdWU4NDIwMDE2Mzg=","number":22169,"title":"Performance comparison with MySql HeatWave","user":{"login":"yahorsi","id":9819679,"node_id":"MDQ6VXNlcjk4MTk2Nzk=","avatar_url":"https://avatars.githubusercontent.com/u/9819679?v=4","gravatar_id":"","url":"https://api.github.com/users/yahorsi","html_url":"https://github.com/yahorsi","followers_url":"https://api.github.com/users/yahorsi/followers","following_url":"https://api.github.com/users/yahorsi/following{/other_user}","gists_url":"https://api.github.com/users/yahorsi/gists{/gist_id}","starred_url":"https://api.github.com/users/yahorsi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yahorsi/subscriptions","organizations_url":"https://api.github.com/users/yahorsi/orgs","repos_url":"https://api.github.com/users/yahorsi/repos","events_url":"https://api.github.com/users/yahorsi/events{/privacy}","received_events_url":"https://api.github.com/users/yahorsi/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-03-26T14:19:54Z","updated_at":"2021-03-26T14:19:54Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Hu Guys,\r\n\r\nRecently Oracle has developed a columnar engine called Heat Wave - https://www.oracle.com/mysql/heatwave/.\r\nIt is available only in the Oracle Cloud, works as a \"transparent\" engine, which means, the query can still be executed on the MySql server with no changes, but if the table is loaded in the HeatWave cluster, then it can be executed on the new columnar engine.\r\n\r\nThis is very fresh, new, vectorized, columnar, distributed, low price (cluster with 3 servers and 1.5 TB of memory costs less than 1k month). So, would be really cool to have a perf comparison, like ClickHouse on 2 nodes with 1TB memory vs ClickHouse cluster of 3 nodes (minimal configuration, where 1 node is just MySql node and 2 nodes are used as Heat Wave). \r\n\r\nAdditionally, would be great to have a similar comparison to the Microsoft SQL server that has support for the clustered column store index and, especially, to the **Sql Server Analysis Services**. With the last one, it's not sort of the apples to apples, but it still the columnar engine that **they claim** is the fastest (well, we know who's really the fastest but...)\r\n\r\nThanks\r\n\r\n\r\nPS:\r\nGuys under the ClickHouse, I love you :)","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22169/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22169/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22160","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22160/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22160/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22160/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/22160","id":841875178,"node_id":"MDU6SXNzdWU4NDE4NzUxNzg=","number":22160,"title":"Timezone: toDate() works different in different query clauses","user":{"login":"ilevd","id":5524072,"node_id":"MDQ6VXNlcjU1MjQwNzI=","avatar_url":"https://avatars.githubusercontent.com/u/5524072?v=4","gravatar_id":"","url":"https://api.github.com/users/ilevd","html_url":"https://github.com/ilevd","followers_url":"https://api.github.com/users/ilevd/followers","following_url":"https://api.github.com/users/ilevd/following{/other_user}","gists_url":"https://api.github.com/users/ilevd/gists{/gist_id}","starred_url":"https://api.github.com/users/ilevd/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ilevd/subscriptions","organizations_url":"https://api.github.com/users/ilevd/orgs","repos_url":"https://api.github.com/users/ilevd/repos","events_url":"https://api.github.com/users/ilevd/events{/privacy}","received_events_url":"https://api.github.com/users/ilevd/received_events","type":"User","site_admin":false},"labels":[{"id":1481221764,"node_id":"MDU6TGFiZWwxNDgxMjIxNzY0","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-datetime","name":"comp-datetime","color":"b5bcff","default":false,"description":"date & time & timezone related"},{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-03-26T11:55:08Z","updated_at":"2021-03-26T13:41:48Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"**Describe the bug**\r\nI have a table with column `date DateTime('Asia/Kamchatka')`, server/client timezone is `'Europe/Moscow'`. Two queries return different results:\r\n\r\n```\r\nlocal :) select uid, date, toDate(date) = toDate('2021-03-24') res FROM table WHERE res = 1\r\n\r\nSELECT \r\n    uid,\r\n    date,\r\n    toDate(date) = toDate('2021-03-24') AS res\r\nFROM table\r\nWHERE res = 1\r\n\r\n┌─uid──────────────────────────────────┬──────────date───────┬─res─┐\r\n│ 4c36abda-8bd8-11eb-8204-005056aa8bf6 │ 2021-03-24 01:04:27 │   1 │\r\n│ 4c408902-8bd8-11eb-8204-005056aa8bf6 │ 2021-03-24 01:04:27 │   1 │\r\n│ 4c5bf20a-8bd8-11eb-8204-005056aa8bf6 │ 2021-03-24 01:04:27 │   1 │\r\n│ 4c61623a-8bd8-11eb-8204-005056aa8bf6 │ 2021-03-24 01:04:27 │   1 │\r\n│ 4c6efab2-8bd8-11eb-a952-005056aa8bf6 │ 2021-03-24 01:04:27 │   1 │\r\n└──────────────────────────────────────┴─────────────────────┴─────┘\r\n```\r\nAND\r\n```\r\nlocal :) select uid, date, toDate(date) = toDate('2021-03-24') res FROM table WHERE toDate(date) = toDate('2021-03-24');\r\n\r\nSELECT \r\n    uid,\r\n    date,\r\n    toDate(date) = toDate('2021-03-24') AS res\r\nFROM table\r\nWHERE toDate(date) = toDate('2021-03-24')\r\n\r\nOk.\r\n\r\n0 rows in set. Elapsed: 0.252 sec. \r\n```\r\nIt seems like position for toDate in query matters - column timezone doesn't work in `where` clause.\r\n\r\n\r\n**How to reproduce**\r\n\r\nClickHouse client version 20.8.4.11 (official build).\r\nConnecting to localhost:9001 as user default.\r\nConnected to ClickHouse server version 20.8.4 revision 54438.\r\n\r\n\r\n**Expected behavior**\r\nSame results.\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22160/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22160/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22155","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22155/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22155/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22155/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/22155","id":841696542,"node_id":"MDU6SXNzdWU4NDE2OTY1NDI=","number":22155,"title":"Kafka Engine  exception: There is no checkpoint","user":{"login":"gj-zhang","id":21170229,"node_id":"MDQ6VXNlcjIxMTcwMjI5","avatar_url":"https://avatars.githubusercontent.com/u/21170229?v=4","gravatar_id":"","url":"https://api.github.com/users/gj-zhang","html_url":"https://github.com/gj-zhang","followers_url":"https://api.github.com/users/gj-zhang/followers","following_url":"https://api.github.com/users/gj-zhang/following{/other_user}","gists_url":"https://api.github.com/users/gj-zhang/gists{/gist_id}","starred_url":"https://api.github.com/users/gj-zhang/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/gj-zhang/subscriptions","organizations_url":"https://api.github.com/users/gj-zhang/orgs","repos_url":"https://api.github.com/users/gj-zhang/repos","events_url":"https://api.github.com/users/gj-zhang/events{/privacy}","received_events_url":"https://api.github.com/users/gj-zhang/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-03-26T08:01:44Z","updated_at":"2021-03-26T08:01:44Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"CH Version 20.9.3.45\r\nKafka Version 0.11.0.3\r\n```sql\r\ncreate table default.kafka_table_shard   \r\n(\r\n    id Int64,\r\n    name String,\r\n    age Int8,\r\n    score Float32,\r\n    coment String\r\n)\r\nengine = Kafka()\r\nsettings\r\n    kafka_broker_list = 'xxx',\r\n    kafka_topic_list = 'ck_kafka_engine_test_topic',\r\n    kafka_group_name = 'ck_kafka_engine_zgj_group1',\r\n    kafka_format = 'CustomSeparated',\r\n    format_custom_field_delimiter = '^',\r\n\r\n    kafka_num_consumers = 2,\r\n\r\n    kafka_skip_broken_messages = 0,\r\n    kafka_commit_every_batch = 0,\r\n    kafka_thread_per_consumer = 1;\r\n```\r\n```shell \r\ndata: 1^zhangsan^18^32.2^{\"key\":\"value\"}\r\n```\r\n```shell\r\n2021.03.26 15:36:09.706819 [ 300 ] {8ebce6d4-bb5c-4c99-ac8a-599fba7fcf30} <Error> executeQuery: Code: 49, e.displayText() = DB::Exception: There is no checkpoint: While executing SourceFromInputStream (version 20.9.3.45 (official build)) (from 10.177.12.18:55604) (in query: select * from default.kafka_table_shard;), Stack trace (when copying this message, always include the lines below):\r\n\r\n0. Poco::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int) @ 0x18e1b360 in /usr/bin/clickhouse\r\n1. DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int) @ 0xe736dad in /usr/bin/clickhouse\r\n2. ? @ 0x165fbb3e in /usr/bin/clickhouse\r\n3. DB::TemplateRowInputFormat::checkForSuffix() @ 0x166cbff9 in /usr/bin/clickhouse\r\n4. DB::TemplateRowInputFormat::readRow(std::__1::vector<COW<DB::IColumn>::mutable_ptr<DB::IColumn>, std::__1::allocator<COW<DB::IColumn>::mutable_ptr<DB::IColumn> > >&, DB::RowReadExtension&) @ 0x166cc7d1 in /usr/bin/clickhouse\r\n5. DB::IRowInputFormat::generate() @ 0x165aa161 in /usr/bin/clickhouse\r\n6. DB::ISource::work() @ 0x1651f65b in /usr/bin/clickhouse\r\n7. ? @ 0x16161e0d in /usr/bin/clickhouse\r\n8. DB::KafkaBlockInputStream::readImpl() @ 0x16162f74 in /usr/bin/clickhouse\r\n9. DB::IBlockInputStream::read() @ 0x156c6d3d in /usr/bin/clickhouse\r\n10. DB::SourceFromInputStream::generate() @ 0x1674dd34 in /usr/bin/clickhouse\r\n11. DB::ISource::work() @ 0x1651f65b in /usr/bin/clickhouse\r\n12. DB::SourceFromInputStream::work() @ 0x1674dc05 in /usr/bin/clickhouse\r\n13. ? @ 0x1655b260 in /usr/bin/clickhouse\r\n14. ? @ 0x1655f4bd in /usr/bin/clickhouse\r\n15. ? @ 0x1655fd86 in /usr/bin/clickhouse\r\n16. ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) @ 0xe7645b7 in /usr/bin/clickhouse\r\n17. ? @ 0xe762b03 in /usr/bin/clickhouse\r\n18. start_thread @ 0x9609 in /usr/lib/x86_64-linux-gnu/libpthread-2.31.so\r\n19. clone @ 0x122293 in /usr/lib/x86_64-linux-gnu/libc-2.31.so\r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22155/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22155/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22130","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22130/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22130/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22130/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/22130","id":841006855,"node_id":"MDU6SXNzdWU4NDEwMDY4NTU=","number":22130,"title":"Allow writes into system.zookeeper table","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":1006992822,"node_id":"MDU6TGFiZWwxMDA2OTkyODIy","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/operations","name":"operations","color":"7fe8ba","default":false,"description":""},{"id":3086255531,"node_id":"MDU6TGFiZWwzMDg2MjU1NTMx","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/warmup%20task","name":"warmup task","color":"FBCA04","default":false,"description":"The task for new ClickHouse team members. Low risk, moderate complexity, no urgency."}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-03-25T14:48:45Z","updated_at":"2021-06-23T15:46:22Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"**Use case**\r\nManually modify the contents of ZooKeeper.\r\nNot for normal usage scenarios... mostly for operations engineers.\r\n\r\n**Describe the solution you'd like**\r\n\r\nAllow INSERT. It should contain only subset of the columns, because some of the columns in `system.zookeeper` table (like numChildren, ctime, etc...) cannot be specified explicitly.\r\n\r\nINSERT will perform multiple create operations.\r\n\r\nAdd a setting to perform set operations (update existing nodes) instead of creating new nodes.\r\n\r\n**Additional context**\r\n\r\nAlso it will be nice to allow \"full scan\" queries to `system.zookeeper` table to quickly creating dumps.\r\nIt can be filtered by condition on prefix of path.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22130/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22130/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22128","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22128/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22128/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22128/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/22128","id":840985636,"node_id":"MDU6SXNzdWU4NDA5ODU2MzY=","number":22128,"title":"ssl_cert, ssl_key, ssl_ca options for MYSQL engine is not documented","user":{"login":"imdad","id":1075113,"node_id":"MDQ6VXNlcjEwNzUxMTM=","avatar_url":"https://avatars.githubusercontent.com/u/1075113?v=4","gravatar_id":"","url":"https://api.github.com/users/imdad","html_url":"https://github.com/imdad","followers_url":"https://api.github.com/users/imdad/followers","following_url":"https://api.github.com/users/imdad/following{/other_user}","gists_url":"https://api.github.com/users/imdad/gists{/gist_id}","starred_url":"https://api.github.com/users/imdad/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/imdad/subscriptions","organizations_url":"https://api.github.com/users/imdad/orgs","repos_url":"https://api.github.com/users/imdad/repos","events_url":"https://api.github.com/users/imdad/events{/privacy}","received_events_url":"https://api.github.com/users/imdad/received_events","type":"User","site_admin":false},"labels":[{"id":785082162,"node_id":"MDU6TGFiZWw3ODUwODIxNjI=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-documentation","name":"comp-documentation","color":"b5bcff","default":false,"description":"Used to run automatic builds of the documentation"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-03-25T14:26:28Z","updated_at":"2021-03-25T14:26:28Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"On https://clickhouse.tech/docs/en/engines/database-engines/mysql/ and https://clickhouse.tech/docs/en/engines/table-engines/integrations/mysql/ there are examples to create database and create table respectively using MYSQL engine. There is no mention of connecting to MySQL using SSL certificates. However, as per the comment on the issue https://github.com/ClickHouse/ClickHouse/issues/1217 it seems this has been done and merged in 2017. Because, it is not updated in the document I'm not sure how one could pass those parameters while creating table/database with MYSQL Engine.\r\n\r\n ","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22128/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22128/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22120","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22120/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22120/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22120/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/22120","id":840905766,"node_id":"MDU6SXNzdWU4NDA5MDU3NjY=","number":22120,"title":"only one quota works when creating multi-quotas to a user","user":{"login":"JackyWoo","id":3991709,"node_id":"MDQ6VXNlcjM5OTE3MDk=","avatar_url":"https://avatars.githubusercontent.com/u/3991709?v=4","gravatar_id":"","url":"https://api.github.com/users/JackyWoo","html_url":"https://github.com/JackyWoo","followers_url":"https://api.github.com/users/JackyWoo/followers","following_url":"https://api.github.com/users/JackyWoo/following{/other_user}","gists_url":"https://api.github.com/users/JackyWoo/gists{/gist_id}","starred_url":"https://api.github.com/users/JackyWoo/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/JackyWoo/subscriptions","organizations_url":"https://api.github.com/users/JackyWoo/orgs","repos_url":"https://api.github.com/users/JackyWoo/repos","events_url":"https://api.github.com/users/JackyWoo/events{/privacy}","received_events_url":"https://api.github.com/users/JackyWoo/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-03-25T13:02:40Z","updated_at":"2021-03-29T03:08:04Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"(you don't have to strictly follow this form)\r\n\r\n**Describe the unexpected behaviour**\r\n\r\nClickhouse allows to create multi-quotas to user, but only one works.\r\n\r\n**How to reproduce**\r\n* create a user and a table\r\n* create a `query_selects` quota to a user \r\n* create `query_inserts`  quota to a user \r\n* send requests \r\n* you can  find only one quota works\r\n\r\n**Expected behavior**\r\nall quota works, or reject creating another quota.\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22120/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/22120/timeline","performed_via_github_app":null}]

[{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27149","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27149/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27149/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27149/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/27149","id":959328361,"node_id":"MDU6SXNzdWU5NTkzMjgzNjE=","number":27149,"title":"Add arrayReplace()/arraySet() function to replace one or more values in an array","user":{"login":"vzakaznikov","id":41681088,"node_id":"MDQ6VXNlcjQxNjgxMDg4","avatar_url":"https://avatars.githubusercontent.com/u/41681088?v=4","gravatar_id":"","url":"https://api.github.com/users/vzakaznikov","html_url":"https://github.com/vzakaznikov","followers_url":"https://api.github.com/users/vzakaznikov/followers","following_url":"https://api.github.com/users/vzakaznikov/following{/other_user}","gists_url":"https://api.github.com/users/vzakaznikov/gists{/gist_id}","starred_url":"https://api.github.com/users/vzakaznikov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vzakaznikov/subscriptions","organizations_url":"https://api.github.com/users/vzakaznikov/orgs","repos_url":"https://api.github.com/users/vzakaznikov/repos","events_url":"https://api.github.com/users/vzakaznikov/events{/privacy}","received_events_url":"https://api.github.com/users/vzakaznikov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2021-08-03T17:17:47Z","updated_at":"2021-08-03T19:38:55Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Use case**\r\n\r\nFunction to quickly modify one or more elements of an array. Right now, one solution is to use `arrayMap`\r\nbut it comes at the cost of needing to scan the whole array and also needs another array for indexing which\r\nis very inefficient.\r\n\r\n**Proposed Solution**\r\n\r\nAdd `arrayReplace` function.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nCurrently the user has to do something like this\r\n\r\n```sql\r\nWITH\r\n    [1, 2, 3, 4] AS arr,\r\n    2 AS idx,\r\n    33 AS new_v\r\nSELECT arrayMap((v, i) -> If(i = idx, new_v, v), arr, arrayEnumerate(arr))\r\n```\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27149/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27149/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27140","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27140/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27140/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27140/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/27140","id":959112207,"node_id":"MDU6SXNzdWU5NTkxMTIyMDc=","number":27140,"title":"Sign aws specific headers `x-amz` ","user":{"login":"UnamedRus","id":9449405,"node_id":"MDQ6VXNlcjk0NDk0MDU=","avatar_url":"https://avatars.githubusercontent.com/u/9449405?v=4","gravatar_id":"","url":"https://api.github.com/users/UnamedRus","html_url":"https://github.com/UnamedRus","followers_url":"https://api.github.com/users/UnamedRus/followers","following_url":"https://api.github.com/users/UnamedRus/following{/other_user}","gists_url":"https://api.github.com/users/UnamedRus/gists{/gist_id}","starred_url":"https://api.github.com/users/UnamedRus/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/UnamedRus/subscriptions","organizations_url":"https://api.github.com/users/UnamedRus/orgs","repos_url":"https://api.github.com/users/UnamedRus/repos","events_url":"https://api.github.com/users/UnamedRus/events{/privacy}","received_events_url":"https://api.github.com/users/UnamedRus/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":2020016497,"node_id":"MDU6TGFiZWwyMDIwMDE2NDk3","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-s3","name":"comp-s3","color":"b5bcff","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-08-03T13:21:44Z","updated_at":"2021-08-04T09:24:22Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"In https://github.com/ClickHouse/ClickHouse/pull/11134 support for custom headers in s3 functions was added, but it's not working if you would try to pass some aws specific headers like `x-amz-request-payer` in it.\r\n\r\n```\r\n<header>x-amz-request-payer: requester</header>\r\n```\r\nError message:\r\n\r\n```\r\n`AccessDenied`, message: 'There were headers present in the request which were not signed'.\r\n```\r\n\r\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/ObjectsinRequesterPaysBuckets.html\r\n\r\nBecause clickhouse doesn't sign them properly\r\n\r\n\r\n**Expected behavior**\r\n\r\ncustom_headers working fine with aws s3.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27140/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27140/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27123","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27123/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27123/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27123/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/27123","id":958826431,"node_id":"MDU6SXNzdWU5NTg4MjY0MzE=","number":27123,"title":"Does ClickHouse now support Redis cluster as a dictionary source?","user":{"login":"fsgdgsdfgsgd","id":29115270,"node_id":"MDQ6VXNlcjI5MTE1Mjcw","avatar_url":"https://avatars.githubusercontent.com/u/29115270?v=4","gravatar_id":"","url":"https://api.github.com/users/fsgdgsdfgsgd","html_url":"https://github.com/fsgdgsdfgsgd","followers_url":"https://api.github.com/users/fsgdgsdfgsgd/followers","following_url":"https://api.github.com/users/fsgdgsdfgsgd/following{/other_user}","gists_url":"https://api.github.com/users/fsgdgsdfgsgd/gists{/gist_id}","starred_url":"https://api.github.com/users/fsgdgsdfgsgd/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/fsgdgsdfgsgd/subscriptions","organizations_url":"https://api.github.com/users/fsgdgsdfgsgd/orgs","repos_url":"https://api.github.com/users/fsgdgsdfgsgd/repos","events_url":"https://api.github.com/users/fsgdgsdfgsgd/events{/privacy}","received_events_url":"https://api.github.com/users/fsgdgsdfgsgd/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":1351463315,"node_id":"MDU6TGFiZWwxMzUxNDYzMzE1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-dictionary","name":"comp-dictionary","color":"b5bcff","default":false,"description":"Dictionaries"},{"id":1365689344,"node_id":"MDU6TGFiZWwxMzY1Njg5MzQ0","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-foreign-db","name":"comp-foreign-db","color":"b5bcff","default":false,"description":"Integrations with other databases"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2021-08-03T07:41:10Z","updated_at":"2021-08-03T13:08:19Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"I read the document on using Redis as a dictionary source: https://clickhouse.tech/docs/en/sql-reference/dictionaries/external-dictionaries/external-dicts-dict-sources/#dicts-external_dicts_dict_sources-redis\r\nBut I didn't find instructions on cluster connection. \r\nIs there a effective way to connect  to the Redis cluster?","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27123/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27123/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27115","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27115/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27115/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27115/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/27115","id":958639973,"node_id":"MDU6SXNzdWU5NTg2Mzk5NzM=","number":27115,"title":"groupArray result is not as expected","user":{"login":"peaksnail","id":1744607,"node_id":"MDQ6VXNlcjE3NDQ2MDc=","avatar_url":"https://avatars.githubusercontent.com/u/1744607?v=4","gravatar_id":"","url":"https://api.github.com/users/peaksnail","html_url":"https://github.com/peaksnail","followers_url":"https://api.github.com/users/peaksnail/followers","following_url":"https://api.github.com/users/peaksnail/following{/other_user}","gists_url":"https://api.github.com/users/peaksnail/gists{/gist_id}","starred_url":"https://api.github.com/users/peaksnail/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/peaksnail/subscriptions","organizations_url":"https://api.github.com/users/peaksnail/orgs","repos_url":"https://api.github.com/users/peaksnail/repos","events_url":"https://api.github.com/users/peaksnail/events{/privacy}","received_events_url":"https://api.github.com/users/peaksnail/received_events","type":"User","site_admin":false},"labels":[{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""},{"id":2532986061,"node_id":"MDU6TGFiZWwyNTMyOTg2MDYx","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-query-syntax","name":"comp-query-syntax","color":"b5bcff","default":false,"description":"Relates to query parse / aliases resolution etc."}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2021-08-03T01:49:09Z","updated_at":"2021-08-04T10:58:23Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"ch version  20.8.12.2\r\n\r\n```\r\nselect * from (\r\nselect *  from (\r\n  select eventDate from (\r\n    select \r\n      eventDate \r\n    from daily_business_report final where 1=1 and storeId = '882ff105-695b-4e6c-90be-b231bfbd7db5' and \r\n    eventDate>=toDate(1625090400000/1000) and eventDate<toDate(1627682400000/1000) order by eventDate\r\n  ) order by eventDate with fill from toDate(1625090400000/1000) to toDate(1627682400000/1000)-1 \r\n) order by  eventDate \r\n)\r\n```\r\n\r\nresult\r\n```\r\n2021-07-01\r\n2021-07-02\r\n2021-07-03\r\n2021-07-04\r\n2021-07-05\r\n2021-07-06\r\n2021-07-07\r\n2021-07-08\r\n2021-07-09\r\n2021-07-10\r\n2021-07-11\r\n2021-07-12\r\n2021-07-13\r\n2021-07-14\r\n2021-07-15\r\n2021-07-16\r\n2021-07-17\r\n2021-07-18\r\n2021-07-19\r\n2021-07-20\r\n2021-07-21\r\n2021-07-22\r\n2021-07-23\r\n2021-07-24\r\n2021-07-25\r\n2021-07-26\r\n2021-07-27\r\n2021-07-28\r\n2021-07-29\r\n```\r\nthere has 9 records is not in the ch, gived by the 'with fill'\r\n\r\nand then execute sql\r\n```\r\nselect  \r\n  groupArray(eventDate) as keys,\r\n  count() as c   \r\nfrom (\r\nselect * from (\r\n  select *  from (\r\n    select eventDate from (\r\n      select \r\n        eventDate \r\n      from daily_business_report final where 1=1 and storeId = '882ff105-695b-4e6c-90be-b231bfbd7db5' and \r\n      eventDate>=toDate(1625090400000/1000) and eventDate<toDate(1627682400000/1000) order by eventDate\r\n      ) order by eventDate with fill from toDate(1625090400000/1000) to toDate(1627682400000/1000)-1 \r\n    ) order by  eventDate \r\n  )\r\n)\r\n```\r\nresult \r\n```\r\nkeys    c\r\n['2021-07-06','2021-07-08','2021-07-09','2021-07-10','2021-07-11','2021-07-12','2021-07-14','2021-07-15','2021-07-16','2021-07-17','2021-07-18','2021-07-19','2021-07-20','2021-07-21','2021-07-22','2021-07-23','2021-07-24','2021-07-25','2021-07-26','2021-07-27']\t20\r\n```\r\n\r\nit just has 20 record and not inlcude the data gived by the 'with fill'\r\n\r\nthere expect to get the all data include the record gived by the 'with fill'\r\n\r\nthanks\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27115/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27115/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27090","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27090/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27090/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27090/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/27090","id":958131268,"node_id":"MDU6SXNzdWU5NTgxMzEyNjg=","number":27090,"title":"s2geometry: ERROR Invalid S2LatLng in S2LatLng::ToPoint","user":{"login":"qoega","id":2159081,"node_id":"MDQ6VXNlcjIxNTkwODE=","avatar_url":"https://avatars.githubusercontent.com/u/2159081?v=4","gravatar_id":"","url":"https://api.github.com/users/qoega","html_url":"https://github.com/qoega","followers_url":"https://api.github.com/users/qoega/followers","following_url":"https://api.github.com/users/qoega/following{/other_user}","gists_url":"https://api.github.com/users/qoega/gists{/gist_id}","starred_url":"https://api.github.com/users/qoega/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/qoega/subscriptions","organizations_url":"https://api.github.com/users/qoega/orgs","repos_url":"https://api.github.com/users/qoega/repos","events_url":"https://api.github.com/users/qoega/events{/privacy}","received_events_url":"https://api.github.com/users/qoega/received_events","type":"User","site_admin":false},"labels":[{"id":2104602822,"node_id":"MDU6TGFiZWwyMTA0NjAyODIy","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/fuzz","name":"fuzz","color":"abc4ea","default":false,"description":""}],"state":"open","locked":false,"assignee":{"login":"nikitamikhaylov","id":25705399,"node_id":"MDQ6VXNlcjI1NzA1Mzk5","avatar_url":"https://avatars.githubusercontent.com/u/25705399?v=4","gravatar_id":"","url":"https://api.github.com/users/nikitamikhaylov","html_url":"https://github.com/nikitamikhaylov","followers_url":"https://api.github.com/users/nikitamikhaylov/followers","following_url":"https://api.github.com/users/nikitamikhaylov/following{/other_user}","gists_url":"https://api.github.com/users/nikitamikhaylov/gists{/gist_id}","starred_url":"https://api.github.com/users/nikitamikhaylov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nikitamikhaylov/subscriptions","organizations_url":"https://api.github.com/users/nikitamikhaylov/orgs","repos_url":"https://api.github.com/users/nikitamikhaylov/repos","events_url":"https://api.github.com/users/nikitamikhaylov/events{/privacy}","received_events_url":"https://api.github.com/users/nikitamikhaylov/received_events","type":"User","site_admin":false},"assignees":[{"login":"nikitamikhaylov","id":25705399,"node_id":"MDQ6VXNlcjI1NzA1Mzk5","avatar_url":"https://avatars.githubusercontent.com/u/25705399?v=4","gravatar_id":"","url":"https://api.github.com/users/nikitamikhaylov","html_url":"https://github.com/nikitamikhaylov","followers_url":"https://api.github.com/users/nikitamikhaylov/followers","following_url":"https://api.github.com/users/nikitamikhaylov/following{/other_user}","gists_url":"https://api.github.com/users/nikitamikhaylov/gists{/gist_id}","starred_url":"https://api.github.com/users/nikitamikhaylov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nikitamikhaylov/subscriptions","organizations_url":"https://api.github.com/users/nikitamikhaylov/orgs","repos_url":"https://api.github.com/users/nikitamikhaylov/repos","events_url":"https://api.github.com/users/nikitamikhaylov/events{/privacy}","received_events_url":"https://api.github.com/users/nikitamikhaylov/received_events","type":"User","site_admin":false}],"milestone":null,"comments":1,"created_at":"2021-08-02T13:12:53Z","updated_at":"2021-08-02T22:22:22Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"https://clickhouse-test-reports.s3.yandex.net/0/6951e8147d7a25f7bb4f7d43738793cff239db6d/stress_test_(debug).html#fail1\r\n\r\n```\r\n:) SELECT geoToS2(toFloat64(toUInt64(-1)), toFloat64(toUInt64(-1)));\r\n\r\nSELECT geoToS2(toFloat64(toUInt64(-1)), toFloat64(toUInt64(-1)))\r\n\r\nQuery id: f1ef3f1d-b46d-4ef4-a5e5-869798d8379c\r\n\r\n┌─geoToS2(toFloat64(toUInt64(-1)), toFloat64(toUInt64(-1)))─┐\r\n│                                       4864204703484167331 │\r\n└───────────────────────────────────────────────────────────┘\r\n```\r\n\r\n```\r\n$ grep -Fa ERROR stderr.log \r\n../contrib/s2geometry/src/s2/s2latlng.cc:37 ERROR Invalid S2LatLng in S2LatLng::ToPoint: [1.84467e+19, 1.84467e+19]\r\n```\r\n\r\nMaybe it should throw exception if point is invalid. Also it should not print errors to `stderr`.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27090/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27090/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27071","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27071/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27071/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27071/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/27071","id":957869444,"node_id":"MDU6SXNzdWU5NTc4Njk0NDQ=","number":27071,"title":"system.settings_profiles.apply_to_list for profiles/users coming from users.xml ","user":{"login":"filimonov","id":1549571,"node_id":"MDQ6VXNlcjE1NDk1NzE=","avatar_url":"https://avatars.githubusercontent.com/u/1549571?v=4","gravatar_id":"","url":"https://api.github.com/users/filimonov","html_url":"https://github.com/filimonov","followers_url":"https://api.github.com/users/filimonov/followers","following_url":"https://api.github.com/users/filimonov/following{/other_user}","gists_url":"https://api.github.com/users/filimonov/gists{/gist_id}","starred_url":"https://api.github.com/users/filimonov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/filimonov/subscriptions","organizations_url":"https://api.github.com/users/filimonov/orgs","repos_url":"https://api.github.com/users/filimonov/repos","events_url":"https://api.github.com/users/filimonov/events{/privacy}","received_events_url":"https://api.github.com/users/filimonov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":2011606513,"node_id":"MDU6TGFiZWwyMDExNjA2NTEz","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-rbac","name":"comp-rbac","color":"b5bcff","default":false,"description":"Access control related"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-08-02T07:57:53Z","updated_at":"2021-08-02T07:57:53Z","closed_at":null,"author_association":"COLLABORATOR","active_lock_reason":null,"body":"```\r\n:) SELECT user()\r\n\r\n┌─currentUser()─┐\r\n│ default       │\r\n└───────────────┘\r\n\r\n:) SELECT * FROM system.settings_profiles\r\n\r\n┌─name─────┬─id───────────────────────────────────┬─storage───┬─num_elements─┬─apply_to_all─┬─apply_to_list─┬─apply_to_except─┐\r\n│ readonly │ d1659f3e-83fe-3845-f1be-5fada6046b67 │ users.xml │            1 │            0 │ []            │ []              │\r\n│ default  │ 4bfbe653-9137-0ea6-b97d-dc391ec9a919 │ users.xml │            8 │            0 │ []            │ []              │\r\n└──────────┴──────────────────────────────────────┴───────────┴──────────────┴──────────────┴───────────────┴─────────────────┘\r\n```\r\n\r\nDefault profile was applied to the user `default` (explicitly in XML config). Can we expose that information in the `system.settings_profiles` introspection table (via `apply_to_list` column)?","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27071/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27071/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27068","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27068/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27068/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27068/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/27068","id":957712159,"node_id":"MDU6SXNzdWU5NTc3MTIxNTk=","number":27068,"title":"Got \"Unknown identifier\" while quering","user":{"login":"assassinors","id":31181490,"node_id":"MDQ6VXNlcjMxMTgxNDkw","avatar_url":"https://avatars.githubusercontent.com/u/31181490?v=4","gravatar_id":"","url":"https://api.github.com/users/assassinors","html_url":"https://github.com/assassinors","followers_url":"https://api.github.com/users/assassinors/followers","following_url":"https://api.github.com/users/assassinors/following{/other_user}","gists_url":"https://api.github.com/users/assassinors/gists{/gist_id}","starred_url":"https://api.github.com/users/assassinors/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/assassinors/subscriptions","organizations_url":"https://api.github.com/users/assassinors/orgs","repos_url":"https://api.github.com/users/assassinors/repos","events_url":"https://api.github.com/users/assassinors/events{/privacy}","received_events_url":"https://api.github.com/users/assassinors/received_events","type":"User","site_admin":false},"labels":[{"id":386401505,"node_id":"MDU6TGFiZWwzODY0MDE1MDU=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/bug","name":"bug","color":"ee0701","default":true,"description":"Confirmed user-visible misbehaviour in official release"},{"id":1507867504,"node_id":"MDU6TGFiZWwxNTA3ODY3NTA0","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/st-hold","name":"st-hold","color":"e5b890","default":false,"description":"We've paused the work on issue for some reason"}],"state":"open","locked":false,"assignee":{"login":"kitaisreal","id":22458333,"node_id":"MDQ6VXNlcjIyNDU4MzMz","avatar_url":"https://avatars.githubusercontent.com/u/22458333?v=4","gravatar_id":"","url":"https://api.github.com/users/kitaisreal","html_url":"https://github.com/kitaisreal","followers_url":"https://api.github.com/users/kitaisreal/followers","following_url":"https://api.github.com/users/kitaisreal/following{/other_user}","gists_url":"https://api.github.com/users/kitaisreal/gists{/gist_id}","starred_url":"https://api.github.com/users/kitaisreal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kitaisreal/subscriptions","organizations_url":"https://api.github.com/users/kitaisreal/orgs","repos_url":"https://api.github.com/users/kitaisreal/repos","events_url":"https://api.github.com/users/kitaisreal/events{/privacy}","received_events_url":"https://api.github.com/users/kitaisreal/received_events","type":"User","site_admin":false},"assignees":[{"login":"kitaisreal","id":22458333,"node_id":"MDQ6VXNlcjIyNDU4MzMz","avatar_url":"https://avatars.githubusercontent.com/u/22458333?v=4","gravatar_id":"","url":"https://api.github.com/users/kitaisreal","html_url":"https://github.com/kitaisreal","followers_url":"https://api.github.com/users/kitaisreal/followers","following_url":"https://api.github.com/users/kitaisreal/following{/other_user}","gists_url":"https://api.github.com/users/kitaisreal/gists{/gist_id}","starred_url":"https://api.github.com/users/kitaisreal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kitaisreal/subscriptions","organizations_url":"https://api.github.com/users/kitaisreal/orgs","repos_url":"https://api.github.com/users/kitaisreal/repos","events_url":"https://api.github.com/users/kitaisreal/events{/privacy}","received_events_url":"https://api.github.com/users/kitaisreal/received_events","type":"User","site_admin":false}],"milestone":null,"comments":1,"created_at":"2021-08-02T03:51:07Z","updated_at":"2021-08-15T05:41:48Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"**Describe the bug**\r\nHello，recently I met a bug while using clickhouse to do some queries with tableau server，which is weird and I can not find any solutions after searching the internet.\r\n\r\n**How to reproduce**\r\nHere are the steps to reproduce the bug.\r\n\r\n1. ClickHouse Server version : 21.1.2.15\r\n\r\n2. Table DDL\r\n`CREATE TABLE test\r\n(\r\n    id String,\r\n    create_time DateTime\r\n)\r\nENGINE = MergeTree\r\nORDER BY id\r\n`\r\n3. insert some values into the table\r\n`insert into test values(1,'1970-02-01 00:00:00');`\r\n`insert into test values(2,'1970-02-01 00:00:00');`\r\n4. the query sql\r\n`select id,'1997-02-01' as create_time from test where test.create_time='1970-02-01 00:00:00'`\r\nonce you run the sql，you'll get an exception which is said \"_Unkown identifier create_time there are columns : id: while processing create_time='1997-02-01 00:00:00'(version 21.1.2.15 (official build))_\"\r\nI also try these steps in mysql，however，there is no problem in it. So，I think it is a bug in clickhouse.\r\n\r\nI know it's kind of strange that the column alias is the same as the column in the table，but  it is tableau's behaviour and I can hardly change it.\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27068/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27068/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27059","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27059/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27059/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27059/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/27059","id":957411377,"node_id":"MDU6SXNzdWU5NTc0MTEzNzc=","number":27059,"title":"Consider adding compressed marks","user":{"login":"vmihailenco","id":290976,"node_id":"MDQ6VXNlcjI5MDk3Ng==","avatar_url":"https://avatars.githubusercontent.com/u/290976?v=4","gravatar_id":"","url":"https://api.github.com/users/vmihailenco","html_url":"https://github.com/vmihailenco","followers_url":"https://api.github.com/users/vmihailenco/followers","following_url":"https://api.github.com/users/vmihailenco/following{/other_user}","gists_url":"https://api.github.com/users/vmihailenco/gists{/gist_id}","starred_url":"https://api.github.com/users/vmihailenco/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vmihailenco/subscriptions","organizations_url":"https://api.github.com/users/vmihailenco/orgs","repos_url":"https://api.github.com/users/vmihailenco/repos","events_url":"https://api.github.com/users/vmihailenco/events{/privacy}","received_events_url":"https://api.github.com/users/vmihailenco/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":1507888214,"node_id":"MDU6TGFiZWwxNTA3ODg4MjE0","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/st-accepted","name":"st-accepted","color":"e5b890","default":false,"description":"The issue is in our backlog, ready to take"},{"id":3086255531,"node_id":"MDU6TGFiZWwzMDg2MjU1NTMx","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/warmup%20task","name":"warmup task","color":"FBCA04","default":false,"description":"The task for new ClickHouse team members. Low risk, moderate complexity, no urgency."}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2021-08-01T06:52:26Z","updated_at":"2021-08-05T21:09:37Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"It looks like mark files can take large amount of space (relative to data size) if you have large number of mostly empty `LowCardinality(String)` columns. For example, in the following table marks account for ~25% of space (default index_granularity):\r\n\r\n```sql\r\nSELECT\r\n    sum(rows),\r\n    sum(bytes),\r\n    sum(marks),\r\n    sum(marks_bytes),\r\n    sum(primary_key_bytes_in_memory),\r\n    sum(marks_bytes) / sum(bytes) AS marks_to_data\r\nFROM system.parts\r\nWHERE (table = 'table') AND active\r\n\r\n┌──sum(rows)─┬──sum(bytes)─┬─sum(marks)─┬─sum(marks_bytes)─┬─sum(primary_key_bytes_in_memory)─┬───────marks_to_data─┐\r\n│ 2014937404 │ 55167121116 │    1959074 │      13399869552 │                         37466039 │ 0.24289593658193748 │\r\n└────────────┴─────────────┴────────────┴──────────────────┴──────────────────────────────────┴─────────────────────┘\r\n```\r\n\r\nThe same table using system.columns\r\n\r\n```sql\r\nSELECT\r\n    sum(data_uncompressed_bytes),\r\n    sum(data_compressed_bytes),\r\n    sum(marks_bytes),\r\n    sum(marks_bytes) / sum(data_compressed_bytes) AS marks_to_data\r\nFROM system.columns\r\nWHERE table = 'table'\r\n\r\n┌─sum(data_uncompressed_bytes)─┬─sum(data_compressed_bytes)─┬─sum(marks_bytes)─┬───────marks_to_data─┐\r\n│                1066273375281 │                41681307765 │      13422063600 │ 0.32201637423839596 │\r\n└──────────────────────────────┴────────────────────────────┴──────────────────┴─────────────────────┘\r\n```\r\n\r\nAdding `group by name, type` shows that `LowCardinality(String)` columns have \"bad\" `marks_to_data` ratio.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27059/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27059/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27056","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27056/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27056/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27056/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/27056","id":957396847,"node_id":"MDU6SXNzdWU5NTczOTY4NDc=","number":27056,"title":"Allow to pass query to MySQL as is.","user":{"login":"Junwen-Qiu","id":81570250,"node_id":"MDQ6VXNlcjgxNTcwMjUw","avatar_url":"https://avatars.githubusercontent.com/u/81570250?v=4","gravatar_id":"","url":"https://api.github.com/users/Junwen-Qiu","html_url":"https://github.com/Junwen-Qiu","followers_url":"https://api.github.com/users/Junwen-Qiu/followers","following_url":"https://api.github.com/users/Junwen-Qiu/following{/other_user}","gists_url":"https://api.github.com/users/Junwen-Qiu/gists{/gist_id}","starred_url":"https://api.github.com/users/Junwen-Qiu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Junwen-Qiu/subscriptions","organizations_url":"https://api.github.com/users/Junwen-Qiu/orgs","repos_url":"https://api.github.com/users/Junwen-Qiu/repos","events_url":"https://api.github.com/users/Junwen-Qiu/events{/privacy}","received_events_url":"https://api.github.com/users/Junwen-Qiu/received_events","type":"User","site_admin":false},"labels":[{"id":845247686,"node_id":"MDU6TGFiZWw4NDUyNDc2ODY=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/usability","name":"usability","color":"ebf28c","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-08-01T05:28:17Z","updated_at":"2021-09-15T13:16:06Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"(you don't have to strictly follow this form)\r\n\r\n**Describe the issue**\r\nQuery a certain mysql table through clickhouse, such as select count(*) from mysql.table; will be processed into select col from mysql.table; running and mysql, when the number of mysql tables is very large, this is a bad idea The processing method, including limit is also recommended, it is recommended to provide configuration support sql complete push down to mysql","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27056/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27056/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27039","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27039/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27039/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27039/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/27039","id":957304342,"node_id":"MDU6SXNzdWU5NTczMDQzNDI=","number":27039,"title":"Add a technique similar to GWP-ASan","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":1955634273,"node_id":"MDU6TGFiZWwxOTU1NjM0Mjcz","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/testing","name":"testing","color":"c9a224","default":false,"description":"Special issue with list of bugs found by CI"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2021-07-31T19:10:06Z","updated_at":"2021-08-01T17:20:28Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"**Describe the solution you'd like**\r\nSmall random subset of memory allocations should be protected by guard pages.\r\n\r\nGWP-ASan (is in fact almost unrelated to ASan) is not a specific tool but a technique that requires a small change in memory allocator. https://llvm.org/docs/GwpAsan.html\r\n\r\nThe only point is to enable it by default in production.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27039/reactions","total_count":2,"+1":2,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27039/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27035","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27035/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27035/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27035/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/27035","id":957015316,"node_id":"MDU6SXNzdWU5NTcwMTUzMTY=","number":27035,"title":"Config to specify arrow columns to be output as strings","user":{"login":"lejtmany","id":11560378,"node_id":"MDQ6VXNlcjExNTYwMzc4","avatar_url":"https://avatars.githubusercontent.com/u/11560378?v=4","gravatar_id":"","url":"https://api.github.com/users/lejtmany","html_url":"https://github.com/lejtmany","followers_url":"https://api.github.com/users/lejtmany/followers","following_url":"https://api.github.com/users/lejtmany/following{/other_user}","gists_url":"https://api.github.com/users/lejtmany/gists{/gist_id}","starred_url":"https://api.github.com/users/lejtmany/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/lejtmany/subscriptions","organizations_url":"https://api.github.com/users/lejtmany/orgs","repos_url":"https://api.github.com/users/lejtmany/repos","events_url":"https://api.github.com/users/lejtmany/events{/privacy}","received_events_url":"https://api.github.com/users/lejtmany/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":1401255404,"node_id":"MDU6TGFiZWwxNDAxMjU1NDA0","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-formats","name":"comp-formats","color":"b5bcff","default":false,"description":"Input / output formats"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-07-30T19:41:07Z","updated_at":"2021-08-03T08:39:30Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Currently `String` columns are typed as `Binary` when output in `Arrow` format. It would be great if the was an analog to the `output_format_avro_string_column_pattern` setting for avro called `output_format_arrow_string_column_pattern` that would allow the user to specify which columns should be output as Strings\r\n\r\nThank you!","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27035/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27035/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27027","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27027/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27027/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27027/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/27027","id":956744040,"node_id":"MDU6SXNzdWU5NTY3NDQwNDA=","number":27027,"title":"Improve OpenTelemetry","user":{"login":"qoega","id":2159081,"node_id":"MDQ6VXNlcjIxNTkwODE=","avatar_url":"https://avatars.githubusercontent.com/u/2159081?v=4","gravatar_id":"","url":"https://api.github.com/users/qoega","html_url":"https://github.com/qoega","followers_url":"https://api.github.com/users/qoega/followers","following_url":"https://api.github.com/users/qoega/following{/other_user}","gists_url":"https://api.github.com/users/qoega/gists{/gist_id}","starred_url":"https://api.github.com/users/qoega/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/qoega/subscriptions","organizations_url":"https://api.github.com/users/qoega/orgs","repos_url":"https://api.github.com/users/qoega/repos","events_url":"https://api.github.com/users/qoega/events{/privacy}","received_events_url":"https://api.github.com/users/qoega/received_events","type":"User","site_admin":false},"labels":[{"id":845247686,"node_id":"MDU6TGFiZWw4NDUyNDc2ODY=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/usability","name":"usability","color":"ebf28c","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2021-07-30T13:24:06Z","updated_at":"2021-07-30T15:13:47Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"- [ ] It is possible that parent_span_id is 0\r\nExample:\r\n```\r\nRow 9:\r\n───────\r\ntrace_id:         ba90165d-d8dd-f625-0a33-ec2af3ad4e7b\r\nspan_id:          5581180788918133289\r\nparent_span_id:   0\r\noperation_name:   query\r\nstart_time_us:    1627647625113335\r\nfinish_time_us:   1627647625118356\r\nfinish_date:      2021-07-30\r\nattribute.names:  ['clickhouse.query_status','db.statement','clickhouse.query_id']\r\nattribute.values: ['QueryFinish','select * from system.opentelemetry_span_log;','f85046be-f32e-4e56-89ef-8eb8bcd390ee']\r\n```\r\n\r\n- [ ] No easy way to output span ids in format with 16 chars. Workaround ```concat(repeat('0', CAST(16 - length(lower(hex(parent_span_id))), 'UInt8')), lower(hex(parent_span_id))) AS parentId```\r\n\r\n- [ ] use the Map data type for attributes\r\n\r\n- [ ] Jaeger returns an error when we push json via URL engine. Manually export json and load by curl was successful\r\n``` bash\r\ncurl -X POST -s localhost:9411/api/v2/spans -H'Content-Type: application/json' -d @3fd68ca2.json\r\n``` \r\n\r\n```\r\n2021.07.30 14:36:09.245701 [ 1788 ] {} <Error> void DB::SystemLog<DB::OpenTelemetrySpanLogElement>::flushImpl(const std::vector<LogElement> &, uint64_t) [LogE\r\nlement = DB::OpenTelemetrySpanLogElement]: Code: 86, e.displayText() = DB::Exception: Received error from remote server /api/v2/spans. HTTP status code: 400 B\r\nad Request, body: Cannot parse Content-Type: mime: no media type\r\n: while write prefix to view default.zipkin_spans (46ed4c07-c25d-4339-86ed-4c07c25de339), Stack trace (when copying this message, always include the lines bel\r\now):\r\n\r\n0. DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, bool) @ 0x8d2aa5a in /usr/bin/c\r\nlickhouse\r\n1. DB::assertResponseIsOk(Poco::Net::HTTPRequest const&, Poco::Net::HTTPResponse&, std::__1::basic_istream<char, std::__1::char_traits<char> >&, bool) @ 0xdc2\r\n17a3 in /usr/bin/clickhouse\r\n2. DB::PushingToViewsBlockOutputStream::writeSuffix() @ 0xfac1863 in /usr/bin/clickhouse\r\n3. DB::PushingToViewsBlockOutputStream::writeSuffix() @ 0xfac1cbf in /usr/bin/clickhouse\r\n4. DB::SystemLog<DB::OpenTelemetrySpanLogElement>::flushImpl(std::__1::vector<DB::OpenTelemetrySpanLogElement, std::__1::allocator<DB::OpenTelemetrySpanLogEle\r\nment> > const&, unsigned long) @ 0xfd6360e in /usr/bin/clickhouse\r\n5. DB::SystemLog<DB::OpenTelemetrySpanLogElement>::savingThreadFunction() @ 0xfd619e0 in /usr/bin/clickhouse\r\n6. ThreadFromGlobalPool::ThreadFromGlobalPool<DB::SystemLog<DB::OpenTelemetrySpanLogElement>::startup()::'lambda'()>(DB::OpenTelemetrySpanLogElement&&, DB::Sy\r\nstemLog<DB::OpenTelemetrySpanLogElement>::startup()::'lambda'()&&...)::'lambda'()::operator()() @ 0xfd61896 in /usr/bin/clickhouse\r\n7. ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) @ 0x8d6b91f in /usr/bin/clickhouse\r\n8. ? @ 0x8d6f203 in /usr/bin/clickhouse\r\n9. start_thread @ 0x9609 in /usr/lib/x86_64-linux-gnu/libpthread-2.31.so\r\n10. clone @ 0x122293 in /usr/lib/x86_64-linux-gnu/libc-2.31.so\r\n (version 21.7.4.18 (official build))\r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27027/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27027/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27025","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27025/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27025/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27025/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/27025","id":956707817,"node_id":"MDU6SXNzdWU5NTY3MDc4MTc=","number":27025,"title":"[enhancement][discussion] HasAllAny optimization using CPU vectorization","user":{"login":"youennL-cs","id":87176914,"node_id":"MDQ6VXNlcjg3MTc2OTE0","avatar_url":"https://avatars.githubusercontent.com/u/87176914?v=4","gravatar_id":"","url":"https://api.github.com/users/youennL-cs","html_url":"https://github.com/youennL-cs","followers_url":"https://api.github.com/users/youennL-cs/followers","following_url":"https://api.github.com/users/youennL-cs/following{/other_user}","gists_url":"https://api.github.com/users/youennL-cs/gists{/gist_id}","starred_url":"https://api.github.com/users/youennL-cs/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/youennL-cs/subscriptions","organizations_url":"https://api.github.com/users/youennL-cs/orgs","repos_url":"https://api.github.com/users/youennL-cs/repos","events_url":"https://api.github.com/users/youennL-cs/events{/privacy}","received_events_url":"https://api.github.com/users/youennL-cs/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":756395244,"node_id":"MDU6TGFiZWw3NTYzOTUyNDQ=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/performance","name":"performance","color":"c2e0c6","default":false,"description":null},{"id":1401233890,"node_id":"MDU6TGFiZWwxNDAxMjMzODkw","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-arrays","name":"comp-arrays","color":"b5bcff","default":false,"description":"Arrays / array joins / higher order"}],"state":"open","locked":false,"assignee":{"login":"youennL-cs","id":87176914,"node_id":"MDQ6VXNlcjg3MTc2OTE0","avatar_url":"https://avatars.githubusercontent.com/u/87176914?v=4","gravatar_id":"","url":"https://api.github.com/users/youennL-cs","html_url":"https://github.com/youennL-cs","followers_url":"https://api.github.com/users/youennL-cs/followers","following_url":"https://api.github.com/users/youennL-cs/following{/other_user}","gists_url":"https://api.github.com/users/youennL-cs/gists{/gist_id}","starred_url":"https://api.github.com/users/youennL-cs/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/youennL-cs/subscriptions","organizations_url":"https://api.github.com/users/youennL-cs/orgs","repos_url":"https://api.github.com/users/youennL-cs/repos","events_url":"https://api.github.com/users/youennL-cs/events{/privacy}","received_events_url":"https://api.github.com/users/youennL-cs/received_events","type":"User","site_admin":false},"assignees":[{"login":"youennL-cs","id":87176914,"node_id":"MDQ6VXNlcjg3MTc2OTE0","avatar_url":"https://avatars.githubusercontent.com/u/87176914?v=4","gravatar_id":"","url":"https://api.github.com/users/youennL-cs","html_url":"https://github.com/youennL-cs","followers_url":"https://api.github.com/users/youennL-cs/followers","following_url":"https://api.github.com/users/youennL-cs/following{/other_user}","gists_url":"https://api.github.com/users/youennL-cs/gists{/gist_id}","starred_url":"https://api.github.com/users/youennL-cs/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/youennL-cs/subscriptions","organizations_url":"https://api.github.com/users/youennL-cs/orgs","repos_url":"https://api.github.com/users/youennL-cs/repos","events_url":"https://api.github.com/users/youennL-cs/events{/privacy}","received_events_url":"https://api.github.com/users/youennL-cs/received_events","type":"User","site_admin":false}],"milestone":null,"comments":3,"created_at":"2021-07-30T12:36:51Z","updated_at":"2022-01-28T23:09:18Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"At ContentSquare we are relying a lot on _HasAny_ and _HasAll_ functions for our data models.\r\n\r\nIn an effort to improve speedup of those functions, we work on a proof of concept to determine how much could we gain (in term of speedup) if we vectorized the code explicitly.\r\n\r\nFor this POC, we focused on the **_HasAll_** function only. _HasAny_ could be managed in the same way. We also focus on **32-bits interger** arrays which may contains null elements. We are also focusing on **Intel SSE instructions**; using at most **SSE4.2**, to show the porwerfulness of this approach and to show that all actual computers can leverage from it.\r\n\r\nOur implementation works as follow (see code in the end of the issue).\r\nWe set a mask based on the subarray null_map to avoid to compare null elements. A vector of four element from the subarray is loaded; the main array is browsed by four elements too to be compared. The comparison use the mask and mix several instructions: logical or, equality comparison and shuffle. These operations update the mask. If one element is still set to 0 in the mask, we can stop the process because it means that not all elements of the subarray have matched. Otherwise, we continue with the next four elements of the subarray. Obviously, all arrays will not be divisible by four so there is a remainder loop that casually perform the last iterations.\r\n\r\nPlease find results here: [results.csv](https://gist.github.com/youennL-cs/de4c2dacbe20324014a444fea3be956f). \r\nThey have been obtained on an DELL XPS15  with an Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz.\r\nResults have been run using a large range of values for both main array and subarray:\r\n* Main array sizes: {8, 15, 16, 25, 32, 50, 64, 128, 150, 200, 250, 256, 300, 350, 400, 500, 512, 1024, 2048, 4096, 5120, 10240, 20480, 40960, 50000}\r\n* subarray Sizes: {2, 4, 6, 8, 10, 15, 16, 20, 25, 32, 50, 75, 100}\r\n\r\nWe use what we call the random strategy - the subarray is filled with random values from the main array - we believe this is the most relevant strategy. In addition, both arrays contain null elements.\r\nResults contains all parameters used, execution time (in nanoseconds) for each versions and sizes and the final speedup. CH correspond to the current version of Clickhouse; SSE correspond to our custom version using intel SSE instructions. The last lines of the results file present min, median and max speedup. \r\nAs we can see, in average, with SSE we obtain a **x3.5** speedup. \r\n\r\nIt may be even faster on very large arrays if it was implemented using AVX or even AVX512.\r\nThe function can also be implemented for short, long, float and/or double. An equivalent can also be done for string.\r\n\r\nThis opened issue is also a discussion. We would like to have your opinion on that optimization.\r\n- What do you think about providing optimized overloads using SSE4.2 or AVX in order to speed these functions ?\r\n- We are ready to implement it in clickhouse ourself, but we also want your opinion about if you want all SSE+AVX versions and in your opinion, which types must we manage ? \r\n- We are aware that this represents a lot of code duplication. However, would you mind to integrate it if we would raise a PR ?\r\n- Last question, to manage other kind of CPU (e.g ARM/Neon instructions), would you accept to add a new library that would help to factorize the code, instead of duplicating it again ?\r\n\r\nmany thanks for the attention,\r\n\r\nYouenn Lebras\r\nContentSquare\r\n\r\nFor reference, there is the function of the SSE version.\r\nP.S: A git repository can be opened for more details and to play with it.\r\n\r\n```cpp\r\nbool hasAll_sse(const int *set, size_t set_size, const int *subset, size_t subset_size, int8_t *set_null_map, int8_t *subset_null_map) {\r\n    if (subset_size == 0) return true;\r\n\r\n    bool has =  false;\r\n    unsigned j = 0;\r\n    const bool has_set_null_map    = set_null_map    != nullptr;\r\n    const bool has_subset_null_map = subset_null_map != nullptr;\r\n    // if both null map are differents then no need to compare anyother elements\r\n    if (has_set_null_map != has_subset_null_map && has_subset_null_map) return false;\r\n\r\n    if (subset_size > 2) {\r\n        int has_mask = NONE;\r\n        for (; j < subset_size-3 && !has; j += 4) {\r\n            const __m128i data = _mm_lddqu_si128((__m128i *)(subset+j));\r\n            // bitmask is filled with 0xFFFF for corresponding null map elements, 0x0 otherwise;\r\n            __m128i bitmask = has_subset_null_map ? _mm_set_epi32((subset_null_map[j+3])? FULL: NONE,\r\n                                                                  (subset_null_map[j+2])? FULL: NONE,\r\n                                                                  (subset_null_map[j+1])? FULL: NONE,\r\n                                                                  (subset_null_map[j])  ? FULL: NONE\r\n                                                                  )\r\n                                                    :_mm_setzero_si128();\r\n            unsigned i = 0;\r\n            //browse set array to find all subset elements.\r\n            for (; i < set_size-3 && _mm_movemask_epi8(bitmask) < FULL; i += 4) {\r\n                const __m128i r_set = _mm_lddqu_si128((__m128i*)(set+i));\r\n                bitmask =\r\n                    _mm_or_si128(\r\n                        _mm_or_si128(\r\n                            _mm_or_si128(\r\n                                _mm_cmpeq_epi32(data, _mm_shuffle_epi32(r_set, _MM_SHUFFLE(0,1,2,3))),\r\n                                _mm_cmpeq_epi32(data, _mm_shuffle_epi32(r_set, _MM_SHUFFLE(1,2,3,0)))),\r\n                            _mm_or_si128(\r\n                                _mm_cmpeq_epi32(data, _mm_shuffle_epi32(r_set, _MM_SHUFFLE(2,3,0,1))),\r\n                                _mm_cmpeq_epi32(data, _mm_shuffle_epi32(r_set, _MM_SHUFFLE(3,0,1,2))))\r\n                        ),\r\n                        bitmask);\r\n            } // end for i\r\n            has_mask = _mm_movemask_epi8(bitmask);\r\n\r\n            // [loop-jam] If the set size cannot be divided by 4\r\n            if (i < set_size) {\r\n                for (; i < set_size && has_mask < FULL; i++) {\r\n                    // use ternary operator to perform a logical or\r\n                    has_mask |= (set[i] == subset[j])? FIRST: NONE;\r\n                    has_mask |= (j+1 < subset_size)? ((set[i] == subset[j+1])? SECOND: NONE): NONE;\r\n                    has_mask |= (j+2 < subset_size)? ((set[i] == subset[j+2])? THIRD : NONE): NONE;\r\n                    has_mask |= (j+3 < subset_size)? ((set[i] == subset[j+3])? FOURTH: NONE): NONE;\r\n                }\r\n            }\r\n            has = (has_mask >= FULL);\r\n        } // end for j\r\n    } //end if\r\n\r\n    // [loop-jam] If the subset size cannot be divided by 4 or smaller than 3\r\n    bool found = false;\r\n    for (; j < subset_size; j++) {\r\n        // skip null elements since both have at least one\r\n        found = (subset_null_map[j])? true: false;\r\n        for (unsigned i = 0; i < set_size && !found; i ++)\r\n            found = (set[i] == subset[j]);\r\n        if (!found)\r\n            return false;\r\n    }\r\n    return has || found;\r\n}\r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27025/reactions","total_count":6,"+1":6,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27025/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27005","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27005/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27005/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27005/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/27005","id":956544041,"node_id":"MDU6SXNzdWU5NTY1NDQwNDE=","number":27005,"title":"Select with DateTime64 scan all table without partitioning","user":{"login":"ADovgalyuk","id":56922689,"node_id":"MDQ6VXNlcjU2OTIyNjg5","avatar_url":"https://avatars.githubusercontent.com/u/56922689?v=4","gravatar_id":"","url":"https://api.github.com/users/ADovgalyuk","html_url":"https://github.com/ADovgalyuk","followers_url":"https://api.github.com/users/ADovgalyuk/followers","following_url":"https://api.github.com/users/ADovgalyuk/following{/other_user}","gists_url":"https://api.github.com/users/ADovgalyuk/gists{/gist_id}","starred_url":"https://api.github.com/users/ADovgalyuk/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ADovgalyuk/subscriptions","organizations_url":"https://api.github.com/users/ADovgalyuk/orgs","repos_url":"https://api.github.com/users/ADovgalyuk/repos","events_url":"https://api.github.com/users/ADovgalyuk/events{/privacy}","received_events_url":"https://api.github.com/users/ADovgalyuk/received_events","type":"User","site_admin":false},"labels":[{"id":756395244,"node_id":"MDU6TGFiZWw3NTYzOTUyNDQ=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/performance","name":"performance","color":"c2e0c6","default":false,"description":null},{"id":1481221764,"node_id":"MDU6TGFiZWwxNDgxMjIxNzY0","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-datetime","name":"comp-datetime","color":"b5bcff","default":false,"description":"date & time & timezone related"},{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":{"login":"Enmk","id":1110183,"node_id":"MDQ6VXNlcjExMTAxODM=","avatar_url":"https://avatars.githubusercontent.com/u/1110183?v=4","gravatar_id":"","url":"https://api.github.com/users/Enmk","html_url":"https://github.com/Enmk","followers_url":"https://api.github.com/users/Enmk/followers","following_url":"https://api.github.com/users/Enmk/following{/other_user}","gists_url":"https://api.github.com/users/Enmk/gists{/gist_id}","starred_url":"https://api.github.com/users/Enmk/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Enmk/subscriptions","organizations_url":"https://api.github.com/users/Enmk/orgs","repos_url":"https://api.github.com/users/Enmk/repos","events_url":"https://api.github.com/users/Enmk/events{/privacy}","received_events_url":"https://api.github.com/users/Enmk/received_events","type":"User","site_admin":false},"assignees":[{"login":"Enmk","id":1110183,"node_id":"MDQ6VXNlcjExMTAxODM=","avatar_url":"https://avatars.githubusercontent.com/u/1110183?v=4","gravatar_id":"","url":"https://api.github.com/users/Enmk","html_url":"https://github.com/Enmk","followers_url":"https://api.github.com/users/Enmk/followers","following_url":"https://api.github.com/users/Enmk/following{/other_user}","gists_url":"https://api.github.com/users/Enmk/gists{/gist_id}","starred_url":"https://api.github.com/users/Enmk/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Enmk/subscriptions","organizations_url":"https://api.github.com/users/Enmk/orgs","repos_url":"https://api.github.com/users/Enmk/repos","events_url":"https://api.github.com/users/Enmk/events{/privacy}","received_events_url":"https://api.github.com/users/Enmk/received_events","type":"User","site_admin":false}],"milestone":null,"comments":3,"created_at":"2021-07-30T08:50:09Z","updated_at":"2021-12-27T08:44:00Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"I've got a table with DateTime64 column:\r\n```\r\n`date_time` DateTime64(3)\r\n```\r\nand following params:\r\n```\r\nENGINE = ReplacingMergeTree\r\nPARTITION BY toDate(date_time)\r\nORDER BY (date_time,  host, session_id)\r\n```\r\nWhen I'm using toDateTime in where clause only partitions whith appropriate date are being scanned\r\n```\r\nSELECT count()\r\nFROM grameen_http_cdr\r\nWHERE toDateTime(date_time) >= toDateTime(1627279320)\r\n\r\nQuery id: 2029a447-b8a9-4dd2-bd8e-b967ff3ec71b\r\n\r\n┌───count()─┐\r\n│ 603959607 │\r\n└───────────┘\r\n\r\n1 rows in set. Elapsed: 2.090 sec. Processed 603.96 million rows, 4.83 GB (288.97 million rows/s., 2.31 GB/s.) \r\n```\r\nBut when toDateTime64 filter is used, all table is scanned, not respecting toDate(date_time)  partitioning.\r\n```\r\nSELECT count()\r\nFROM http_cdr\r\nWHERE toDateTime64(date_time, 3) >= toDateTime64(1627279320, 3)\r\n\r\nQuery id: 2514d7ca-3679-47bc-87a8-6ff82f5b8278\r\n\r\n┌───count()─┐\r\n│ 603880825 │\r\n└───────────┘\r\n\r\n1 rows in set. Elapsed: 7.834 sec. Processed 2.40 billion rows, 19.20 GB (306.38 million rows/s., 2.45 GB/s.) \r\n```\r\nWhy toDateTime64 filter doesn't respect partitioning?\r\n\r\n\r\n**CH version** 21.4.6 revision 54447\r\n\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27005/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27005/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27004","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27004/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27004/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27004/events","html_url":"https://github.com/ClickHouse/ClickHouse/pull/27004","id":956464380,"node_id":"MDExOlB1bGxSZXF1ZXN0NzAwMDU1OTc2","number":27004,"title":"Add quorum mode to the distributed_ddl_output_mode when executing DDL…","user":{"login":"marising","id":8611398,"node_id":"MDQ6VXNlcjg2MTEzOTg=","avatar_url":"https://avatars.githubusercontent.com/u/8611398?v=4","gravatar_id":"","url":"https://api.github.com/users/marising","html_url":"https://github.com/marising","followers_url":"https://api.github.com/users/marising/followers","following_url":"https://api.github.com/users/marising/following{/other_user}","gists_url":"https://api.github.com/users/marising/gists{/gist_id}","starred_url":"https://api.github.com/users/marising/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/marising/subscriptions","organizations_url":"https://api.github.com/users/marising/orgs","repos_url":"https://api.github.com/users/marising/repos","events_url":"https://api.github.com/users/marising/events{/privacy}","received_events_url":"https://api.github.com/users/marising/received_events","type":"User","site_admin":false},"labels":[{"id":1304141686,"node_id":"MDU6TGFiZWwxMzA0MTQxNjg2","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/pr-improvement","name":"pr-improvement","color":"007700","default":false,"description":"Pull request with some product improvements"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-07-30T07:00:25Z","updated_at":"2021-12-09T14:59:33Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"draft":false,"pull_request":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/pulls/27004","html_url":"https://github.com/ClickHouse/ClickHouse/pull/27004","diff_url":"https://github.com/ClickHouse/ClickHouse/pull/27004.diff","patch_url":"https://github.com/ClickHouse/ClickHouse/pull/27004.patch","merged_at":null},"body":"… query, ignoring inactive nodes\r\n\r\nI hereby agree to the terms of the CLA available at: https://yandex.ru/legal/cla/?lang=en\r\n\r\nChangelog category (leave one):\r\n- Improvement\r\n\r\nChangelog entry (a user-readable short description of the changes that goes to CHANGELOG.md):\r\nAdd quorum mode to the distributed_ddl_output_mode when executing DDL query, ignoring inactive nodes.\r\n\r\nDetailed description / Documentation draft:\r\n#25412\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27004/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27004/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27003","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27003/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27003/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27003/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/27003","id":956463797,"node_id":"MDU6SXNzdWU5NTY0NjM3OTc=","number":27003,"title":"Node time-consuming long tail problem","user":{"login":"shadowDy","id":18388143,"node_id":"MDQ6VXNlcjE4Mzg4MTQz","avatar_url":"https://avatars.githubusercontent.com/u/18388143?v=4","gravatar_id":"","url":"https://api.github.com/users/shadowDy","html_url":"https://github.com/shadowDy","followers_url":"https://api.github.com/users/shadowDy/followers","following_url":"https://api.github.com/users/shadowDy/following{/other_user}","gists_url":"https://api.github.com/users/shadowDy/gists{/gist_id}","starred_url":"https://api.github.com/users/shadowDy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/shadowDy/subscriptions","organizations_url":"https://api.github.com/users/shadowDy/orgs","repos_url":"https://api.github.com/users/shadowDy/repos","events_url":"https://api.github.com/users/shadowDy/events{/privacy}","received_events_url":"https://api.github.com/users/shadowDy/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2021-07-30T06:59:23Z","updated_at":"2021-07-31T09:54:25Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"View system.query_log information:\r\n`Query id: f31110f6-123a-4b98-8cb8-0534789f1546\r\n\r\nRow 1:\r\n──────\r\ntype:                          QueryStart\r\nevent_date:                    2021-07-30\r\nevent_time:                    2021-07-30 14:29:14\r\nevent_time_microseconds:       2021-07-30 14:29:14.278350\r\nquery_start_time:              2021-07-30 14:29:14\r\nquery_start_time_microseconds: 2021-07-30 14:29:14.278350`\r\n\r\n`Row 2:\r\n──────\r\ntype:                          QueryFinish\r\nevent_date:                    2021-07-30\r\nevent_time:                    2021-07-30 14:29:27\r\nevent_time_microseconds:       2021-07-30 14:29:27.228829\r\nquery_start_time:              2021-07-30 14:29:14\r\nquery_start_time_microseconds: 2021-07-30 14:29:14.278350\r\nquery_duration_ms:             3867\r\nread_rows:                     1\r\nread_bytes:                    4104`\r\n\r\nAlthough query_ duration_ The MS value is not very high (actually it is also a long tail), but what is more prominent is the time-consuming from receiving SQL to starting execution, and there is no clue in the log. How to fix this problem.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27003/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/27003/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26993","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26993/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26993/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26993/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26993","id":956183969,"node_id":"MDU6SXNzdWU5NTYxODM5Njk=","number":26993,"title":"Print Byte Upload Amount On Insertion","user":{"login":"rlazimi-dev","id":47514208,"node_id":"MDQ6VXNlcjQ3NTE0MjA4","avatar_url":"https://avatars.githubusercontent.com/u/47514208?v=4","gravatar_id":"","url":"https://api.github.com/users/rlazimi-dev","html_url":"https://github.com/rlazimi-dev","followers_url":"https://api.github.com/users/rlazimi-dev/followers","following_url":"https://api.github.com/users/rlazimi-dev/following{/other_user}","gists_url":"https://api.github.com/users/rlazimi-dev/gists{/gist_id}","starred_url":"https://api.github.com/users/rlazimi-dev/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rlazimi-dev/subscriptions","organizations_url":"https://api.github.com/users/rlazimi-dev/orgs","repos_url":"https://api.github.com/users/rlazimi-dev/repos","events_url":"https://api.github.com/users/rlazimi-dev/events{/privacy}","received_events_url":"https://api.github.com/users/rlazimi-dev/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":5,"created_at":"2021-07-29T20:30:19Z","updated_at":"2021-08-10T12:57:27Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"**Use case**\r\nI would like to measure the amount of bytes uploaded by clickhouse-client when performing an upload of a large file that is being decompressed into clickhouse-client. This would prevent me from having to decompress the file more than once to obtain file size.\r\n\r\n**Describe the solution you'd like**\r\nPrint out the number of bytes uploaded to ClickHouse through clickhouse-client.\r\n\r\ne.g.:\r\n```\r\n➜ rlazimi ~/projects  Ω pigz -dc compressed.gz | clickhouse-client --query=\"insert into logs.test\"\r\n9743910234\r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26993/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26993/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26976","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26976/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26976/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26976/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26976","id":955991546,"node_id":"MDU6SXNzdWU5NTU5OTE1NDY=","number":26976,"title":"Implement four letter commands for `clickhouse-keeper`.","user":{"login":"alesapin","id":3684697,"node_id":"MDQ6VXNlcjM2ODQ2OTc=","avatar_url":"https://avatars.githubusercontent.com/u/3684697?v=4","gravatar_id":"","url":"https://api.github.com/users/alesapin","html_url":"https://github.com/alesapin","followers_url":"https://api.github.com/users/alesapin/followers","following_url":"https://api.github.com/users/alesapin/following{/other_user}","gists_url":"https://api.github.com/users/alesapin/gists{/gist_id}","starred_url":"https://api.github.com/users/alesapin/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alesapin/subscriptions","organizations_url":"https://api.github.com/users/alesapin/orgs","repos_url":"https://api.github.com/users/alesapin/repos","events_url":"https://api.github.com/users/alesapin/events{/privacy}","received_events_url":"https://api.github.com/users/alesapin/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":{"login":"JackyWoo","id":3991709,"node_id":"MDQ6VXNlcjM5OTE3MDk=","avatar_url":"https://avatars.githubusercontent.com/u/3991709?v=4","gravatar_id":"","url":"https://api.github.com/users/JackyWoo","html_url":"https://github.com/JackyWoo","followers_url":"https://api.github.com/users/JackyWoo/followers","following_url":"https://api.github.com/users/JackyWoo/following{/other_user}","gists_url":"https://api.github.com/users/JackyWoo/gists{/gist_id}","starred_url":"https://api.github.com/users/JackyWoo/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/JackyWoo/subscriptions","organizations_url":"https://api.github.com/users/JackyWoo/orgs","repos_url":"https://api.github.com/users/JackyWoo/repos","events_url":"https://api.github.com/users/JackyWoo/events{/privacy}","received_events_url":"https://api.github.com/users/JackyWoo/received_events","type":"User","site_admin":false},"assignees":[{"login":"JackyWoo","id":3991709,"node_id":"MDQ6VXNlcjM5OTE3MDk=","avatar_url":"https://avatars.githubusercontent.com/u/3991709?v=4","gravatar_id":"","url":"https://api.github.com/users/JackyWoo","html_url":"https://github.com/JackyWoo","followers_url":"https://api.github.com/users/JackyWoo/followers","following_url":"https://api.github.com/users/JackyWoo/following{/other_user}","gists_url":"https://api.github.com/users/JackyWoo/gists{/gist_id}","starred_url":"https://api.github.com/users/JackyWoo/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/JackyWoo/subscriptions","organizations_url":"https://api.github.com/users/JackyWoo/orgs","repos_url":"https://api.github.com/users/JackyWoo/repos","events_url":"https://api.github.com/users/JackyWoo/events{/privacy}","received_events_url":"https://api.github.com/users/JackyWoo/received_events","type":"User","site_admin":false}],"milestone":null,"comments":2,"created_at":"2021-07-29T16:04:08Z","updated_at":"2021-09-06T20:40:24Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"We need to implement similar commands in `clickhouse-keeper`: https://zookeeper.apache.org/doc/r3.4.8/zookeeperAdmin.html#sc_zkCommands. Not the best interface for system monitoring, but will be compatible with existing monitoring tools.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26976/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26976/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26965","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26965/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26965/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26965/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26965","id":955869672,"node_id":"MDU6SXNzdWU5NTU4Njk2NzI=","number":26965,"title":"Simple CTE disables index scan ","user":{"login":"javisantana","id":30147,"node_id":"MDQ6VXNlcjMwMTQ3","avatar_url":"https://avatars.githubusercontent.com/u/30147?v=4","gravatar_id":"","url":"https://api.github.com/users/javisantana","html_url":"https://github.com/javisantana","followers_url":"https://api.github.com/users/javisantana/followers","following_url":"https://api.github.com/users/javisantana/following{/other_user}","gists_url":"https://api.github.com/users/javisantana/gists{/gist_id}","starred_url":"https://api.github.com/users/javisantana/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/javisantana/subscriptions","organizations_url":"https://api.github.com/users/javisantana/orgs","repos_url":"https://api.github.com/users/javisantana/repos","events_url":"https://api.github.com/users/javisantana/events{/privacy}","received_events_url":"https://api.github.com/users/javisantana/received_events","type":"User","site_admin":false},"labels":[{"id":756395244,"node_id":"MDU6TGFiZWw3NTYzOTUyNDQ=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/performance","name":"performance","color":"c2e0c6","default":false,"description":null},{"id":2788693937,"node_id":"MDU6TGFiZWwyNzg4NjkzOTM3","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-cte","name":"comp-cte","color":"b5bcff","default":false,"description":"common table expression (WITH ... SELECT)"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-07-29T13:54:57Z","updated_at":"2021-07-29T14:16:30Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"Using a simple CTE makes the query slow because if diables index scan.\r\n\r\nExample:\r\n\r\nsetup \r\n\r\n``` \r\ndrop database if exists tt;\r\ncreate database tt;\r\nuse tt;\r\nselect version();\r\ncreate table tt.ev (a Int32, b Int32) Engine=MergeTree() order by a;\r\ncreate table tt.idx (a Int32) Engine=MergeTree() order by a;\r\ninsert into tt.ev select number, number from numbers(100000000);\r\ninsert into tt.idx select number*5 from numbers(1000);\r\n\r\n```\r\n\r\nhow to reproduce\r\n\r\n```\nSET enable_global_with_statement = 1\r\n\r\nOk.\r\n\r\n0 rows in set. Elapsed: 0.001 sec. \r\n\r\n\r\nWITH 'test' AS u\r\nSELECT count()\r\nFROM ev\r\nWHERE a IN \r\n(\r\n    SELECT a\r\n    FROM idx\r\n)\r\n\r\n┌─count()─┐\r\n│    1000 │\r\n└─────────┘\r\n\r\n1 rows in set. Elapsed: 0.261 sec. Processed 100.00 million rows, 400.00 MB (382.46 million rows/s., 1.53 GB/s.) \r\n\r\n\r\nSELECT count()\r\nFROM ev\r\nWHERE a IN \r\n(\r\n    SELECT a\r\n    FROM idx\r\n)\r\n\r\n┌─count()─┐\r\n│    1000 │\r\n└─────────┘\r\n\r\n1 rows in set. Elapsed: 0.002 sec. Processed 8.19 thousand rows, 32.77 KB (3.73 million rows/s., 14.93 MB/s.) \r\n\r\n\r\nSET enable_global_with_statement = 0\r\n\r\nOk.\r\n\r\n0 rows in set. Elapsed: 0.000 sec. \r\n\r\n\r\nSELECT count()\r\nFROM ev\r\nWHERE a IN \r\n(\r\n    SELECT a\r\n    FROM idx\r\n)\r\n\r\n┌─count()─┐\r\n│    1000 │\r\n└─────────┘\r\n\r\n1 rows in set. Elapsed: 0.002 sec. Processed 8.19 thousand rows, 32.77 KB (4.28 million rows/s., 17.12 MB/s.) \r\n``` \r\n\r\nFirst one scans 100M vs 8k rows when global with statement disabled.\r\n\r\nThis is big problem when using Distributed because `_table` is added as CTE. Checked in versions starting at 21.4 to 21.7\r\n\r\nLikely related to https://github.com/ClickHouse/ClickHouse/issues/26956\r\n\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26965/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26965/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26955","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26955/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26955/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26955/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26955","id":955704836,"node_id":"MDU6SXNzdWU5NTU3MDQ4MzY=","number":26955,"title":"TTL is not cleaning data despite setting small merge_with_ttl_timeout","user":{"login":"tshahmuratov","id":15175737,"node_id":"MDQ6VXNlcjE1MTc1NzM3","avatar_url":"https://avatars.githubusercontent.com/u/15175737?v=4","gravatar_id":"","url":"https://api.github.com/users/tshahmuratov","html_url":"https://github.com/tshahmuratov","followers_url":"https://api.github.com/users/tshahmuratov/followers","following_url":"https://api.github.com/users/tshahmuratov/following{/other_user}","gists_url":"https://api.github.com/users/tshahmuratov/gists{/gist_id}","starred_url":"https://api.github.com/users/tshahmuratov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tshahmuratov/subscriptions","organizations_url":"https://api.github.com/users/tshahmuratov/orgs","repos_url":"https://api.github.com/users/tshahmuratov/repos","events_url":"https://api.github.com/users/tshahmuratov/events{/privacy}","received_events_url":"https://api.github.com/users/tshahmuratov/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""},{"id":1401282669,"node_id":"MDU6TGFiZWwxNDAxMjgyNjY5","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-ttl","name":"comp-ttl","color":"b5bcff","default":false,"description":"TTL"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":5,"created_at":"2021-07-29T10:39:53Z","updated_at":"2021-08-07T18:04:44Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Maybe I'm getting this wrong but merge_with_ttl_timeout is not working as expected\r\n1. Created table with data https://clickhouse.tech/docs/ru/sql-reference/statements/alter/ttl/ and populateded it same way\r\n2. `alter table table_with_ttl modify setting merge_with_ttl_timeout=10;`\r\n3. wait for 5 min just in case. Data is still there\r\n4. Ran `optimize table table_with_ttl final;`\r\n5. Outdated data is dropped\r\n\r\nIs merge_with_ttl_timeout expected to run each 10 seconds and drop outdated data or we should periodically call  `optimize table table_with_ttl final` in order to do cleanup?\r\n\r\nClickhouse is latest version from docker image without additional settings.\r\nConnected to ClickHouse server version 21.6.4 revision 54448.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26955/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26955/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26952","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26952/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26952/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26952/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26952","id":955621924,"node_id":"MDU6SXNzdWU5NTU2MjE5MjQ=","number":26952,"title":"Clickhouse continuously generates error logs:\"PostgreSQLReaplicaConsumer: connection error: Lost connection to the database server\"","user":{"login":"ohhhYang","id":33926647,"node_id":"MDQ6VXNlcjMzOTI2NjQ3","avatar_url":"https://avatars.githubusercontent.com/u/33926647?v=4","gravatar_id":"","url":"https://api.github.com/users/ohhhYang","html_url":"https://github.com/ohhhYang","followers_url":"https://api.github.com/users/ohhhYang/followers","following_url":"https://api.github.com/users/ohhhYang/following{/other_user}","gists_url":"https://api.github.com/users/ohhhYang/gists{/gist_id}","starred_url":"https://api.github.com/users/ohhhYang/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ohhhYang/subscriptions","organizations_url":"https://api.github.com/users/ohhhYang/orgs","repos_url":"https://api.github.com/users/ohhhYang/repos","events_url":"https://api.github.com/users/ohhhYang/events{/privacy}","received_events_url":"https://api.github.com/users/ohhhYang/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""},{"id":2763098588,"node_id":"MDU6TGFiZWwyNzYzMDk4NTg4","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-postgresql","name":"comp-postgresql","color":"b5bcff","default":false,"description":""}],"state":"open","locked":false,"assignee":{"login":"kssenii","id":54203879,"node_id":"MDQ6VXNlcjU0MjAzODc5","avatar_url":"https://avatars.githubusercontent.com/u/54203879?v=4","gravatar_id":"","url":"https://api.github.com/users/kssenii","html_url":"https://github.com/kssenii","followers_url":"https://api.github.com/users/kssenii/followers","following_url":"https://api.github.com/users/kssenii/following{/other_user}","gists_url":"https://api.github.com/users/kssenii/gists{/gist_id}","starred_url":"https://api.github.com/users/kssenii/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kssenii/subscriptions","organizations_url":"https://api.github.com/users/kssenii/orgs","repos_url":"https://api.github.com/users/kssenii/repos","events_url":"https://api.github.com/users/kssenii/events{/privacy}","received_events_url":"https://api.github.com/users/kssenii/received_events","type":"User","site_admin":false},"assignees":[{"login":"kssenii","id":54203879,"node_id":"MDQ6VXNlcjU0MjAzODc5","avatar_url":"https://avatars.githubusercontent.com/u/54203879?v=4","gravatar_id":"","url":"https://api.github.com/users/kssenii","html_url":"https://github.com/kssenii","followers_url":"https://api.github.com/users/kssenii/followers","following_url":"https://api.github.com/users/kssenii/following{/other_user}","gists_url":"https://api.github.com/users/kssenii/gists{/gist_id}","starred_url":"https://api.github.com/users/kssenii/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kssenii/subscriptions","organizations_url":"https://api.github.com/users/kssenii/orgs","repos_url":"https://api.github.com/users/kssenii/repos","events_url":"https://api.github.com/users/kssenii/events{/privacy}","received_events_url":"https://api.github.com/users/kssenii/received_events","type":"User","site_admin":false}],"milestone":null,"comments":14,"created_at":"2021-07-29T09:02:14Z","updated_at":"2021-12-24T06:10:41Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Hi， I'm new to clickhouse , here I got a problom:\r\n\r\nclickhouse server version:  21.9.1.7503 (testing version)\r\nwhat did I do：\r\n1. install clickhouse server 21.9.1.7503 with rpm packages and configure the root password.\r\n2. start up clickhouse server\r\n3. create a database test\r\n4. use database test,  and then create table with MaterializedPostgreSQL table engine \r\n     CREATE TABLE test.tb1 (`id` Int32, ... ) ENGINE = MaterializedPostgreSQL('xxxx:5432', 'dbName', 'tableName', 'root', 'xxx')\r\nORDER BY id PARTITION by (id % 20) PRIMARY key id;\r\nSo far, everything is normal. \r\nbut after I created tbl2, errors log came:\r\n5.  CREATE TABLE test.tb2 (`id` Int32, ... ) ENGINE = MaterializedPostgreSQL('xxxx:5432', 'dbName', 'tableName2', 'root', 'xxx')\r\nORDER BY id PARTITION by (id % 20) PRIMARY key id;\r\nEven if I drop tbl2 now, the error log won't go away， Unless I drop tbl1 as well ( That is, all tables created using the MaterializedPostgreSQL table engine are deleted ).\r\nbtw, Synchronizing data from pg to clickhouse is ok.\r\nlogs (Keep outputting ) looks like :\r\n![ch_err_log](https://user-images.githubusercontent.com/33926647/127463313-c735b7be-d977-4e60-b0f3-2a40ba790fba.png)\r\n\r\nWhat's the problem? ","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26952/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26952/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26928","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26928/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26928/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26928/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26928","id":955250144,"node_id":"MDU6SXNzdWU5NTUyNTAxNDQ=","number":26928,"title":"JOIN condition optimization","user":{"login":"UnamedRus","id":9449405,"node_id":"MDQ6VXNlcjk0NDk0MDU=","avatar_url":"https://avatars.githubusercontent.com/u/9449405?v=4","gravatar_id":"","url":"https://api.github.com/users/UnamedRus","html_url":"https://github.com/UnamedRus","followers_url":"https://api.github.com/users/UnamedRus/followers","following_url":"https://api.github.com/users/UnamedRus/following{/other_user}","gists_url":"https://api.github.com/users/UnamedRus/gists{/gist_id}","starred_url":"https://api.github.com/users/UnamedRus/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/UnamedRus/subscriptions","organizations_url":"https://api.github.com/users/UnamedRus/orgs","repos_url":"https://api.github.com/users/UnamedRus/repos","events_url":"https://api.github.com/users/UnamedRus/events{/privacy}","received_events_url":"https://api.github.com/users/UnamedRus/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":1357578153,"node_id":"MDU6TGFiZWwxMzU3NTc4MTUz","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-joins","name":"comp-joins","color":"b5bcff","default":false,"description":"JOINs"},{"id":1401777979,"node_id":"MDU6TGFiZWwxNDAxNzc3OTc5","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-optimizers","name":"comp-optimizers","color":"b5bcff","default":false,"description":"Query optimizations"}],"state":"open","locked":false,"assignee":{"login":"vdimir","id":7023786,"node_id":"MDQ6VXNlcjcwMjM3ODY=","avatar_url":"https://avatars.githubusercontent.com/u/7023786?v=4","gravatar_id":"","url":"https://api.github.com/users/vdimir","html_url":"https://github.com/vdimir","followers_url":"https://api.github.com/users/vdimir/followers","following_url":"https://api.github.com/users/vdimir/following{/other_user}","gists_url":"https://api.github.com/users/vdimir/gists{/gist_id}","starred_url":"https://api.github.com/users/vdimir/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vdimir/subscriptions","organizations_url":"https://api.github.com/users/vdimir/orgs","repos_url":"https://api.github.com/users/vdimir/repos","events_url":"https://api.github.com/users/vdimir/events{/privacy}","received_events_url":"https://api.github.com/users/vdimir/received_events","type":"User","site_admin":false},"assignees":[{"login":"vdimir","id":7023786,"node_id":"MDQ6VXNlcjcwMjM3ODY=","avatar_url":"https://avatars.githubusercontent.com/u/7023786?v=4","gravatar_id":"","url":"https://api.github.com/users/vdimir","html_url":"https://github.com/vdimir","followers_url":"https://api.github.com/users/vdimir/followers","following_url":"https://api.github.com/users/vdimir/following{/other_user}","gists_url":"https://api.github.com/users/vdimir/gists{/gist_id}","starred_url":"https://api.github.com/users/vdimir/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vdimir/subscriptions","organizations_url":"https://api.github.com/users/vdimir/orgs","repos_url":"https://api.github.com/users/vdimir/repos","events_url":"https://api.github.com/users/vdimir/events{/privacy}","received_events_url":"https://api.github.com/users/vdimir/received_events","type":"User","site_admin":false}],"milestone":null,"comments":4,"created_at":"2021-07-28T21:31:27Z","updated_at":"2021-08-02T00:15:31Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Use case**\r\n\r\nSome BI tools really like to produce queries which has weird JOIN clauses.\r\nAs an example from power bi: \r\n\r\n```\r\n    ) AS ITBL ON (((toFloat64(OTBL.DestAirportID) = toFloat64(ITBL.C1)) AND isNotNull(OTBL.DestAirportID)) AND isNotNull(ITBL.C1)) OR (isNull(OTBL.DestAirportID) AND isNull(ITBL.C1))\r\n```\r\n\r\nIt's being done in such strange way to join by Null = Null condition also.\r\nBut in clickhouse it's quite common to avoid using Nullable datatypes at all.\r\nSo clickhouse could get rig of always true/false clauses and make join condition much simpler.\r\n\r\n```\r\n    ) AS ITBL ON (((toFloat64(OTBL.DestAirportID) = toFloat64(ITBL.C1))\r\n```\r\nIf both DestAirportID and C1 are non nullable datatypes it's possible to drop `AND isNotNull(OTBL.DestAirportID)) AND isNotNull(ITBL.C1))` because it's always true. And drop `OR (isNull(OTBL.DestAirportID) AND isNull(ITBL.C1))` because it's always false.\r\n\r\n**Describe the solution you'd like**\r\nClickhouse would simplify and remove all unnecessary conditions from join clause.\r\n\r\n**Additional context**\r\nRelated https://github.com/ClickHouse/ClickHouse/pull/24420\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26928/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26928/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26911","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26911/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26911/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26911/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26911","id":954895346,"node_id":"MDU6SXNzdWU5NTQ4OTUzNDY=","number":26911,"title":"unit test zstd_buffers, I do not get which code updates the pos in BufferBase.","user":{"login":"wangzhen11aaa","id":7311971,"node_id":"MDQ6VXNlcjczMTE5NzE=","avatar_url":"https://avatars.githubusercontent.com/u/7311971?v=4","gravatar_id":"","url":"https://api.github.com/users/wangzhen11aaa","html_url":"https://github.com/wangzhen11aaa","followers_url":"https://api.github.com/users/wangzhen11aaa/followers","following_url":"https://api.github.com/users/wangzhen11aaa/following{/other_user}","gists_url":"https://api.github.com/users/wangzhen11aaa/gists{/gist_id}","starred_url":"https://api.github.com/users/wangzhen11aaa/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/wangzhen11aaa/subscriptions","organizations_url":"https://api.github.com/users/wangzhen11aaa/orgs","repos_url":"https://api.github.com/users/wangzhen11aaa/repos","events_url":"https://api.github.com/users/wangzhen11aaa/events{/privacy}","received_events_url":"https://api.github.com/users/wangzhen11aaa/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-07-28T14:07:45Z","updated_at":"2021-07-28T14:08:15Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"In zstd_buffers.cpp \r\nline 28 - 31\r\n\r\n      for (size_t i = 0; i < n; ++i)\r\n        {\r\n            DB::writeIntText(i, zstd_buf); // I do not find the code which updates the pos in BufferBase, That is weird.\r\n            DB::writeChar('\\t', zstd_buf);\r\n        }\r\nThe template function is\r\n\r\n```\r\ntemplate <typename T>\r\nvoid writeIntText(T x, WriteBuffer & buf)\r\n{\r\n    if (likely(reinterpret_cast<intptr_t>(buf.position()) + WRITE_HELPERS_MAX_INT_WIDTH < reinterpret_cast<intptr_t>(buf.buffer().end())))\r\n        buf.position() = itoa(x, buf.position()); // After this assignment, the pos changed. Why?\r\n    else\r\n        detail::writeUIntTextFallback(x, buf);\r\n}\r\n```\r\n\r\nI debug the code, find nothing about the updation code. Please give an advice.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26911/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26911/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26872","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26872/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26872/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26872/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26872","id":954601705,"node_id":"MDU6SXNzdWU5NTQ2MDE3MDU=","number":26872,"title":"COPY table1 TO table2","user":{"login":"filimonov","id":1549571,"node_id":"MDQ6VXNlcjE1NDk1NzE=","avatar_url":"https://avatars.githubusercontent.com/u/1549571?v=4","gravatar_id":"","url":"https://api.github.com/users/filimonov","html_url":"https://github.com/filimonov","followers_url":"https://api.github.com/users/filimonov/followers","following_url":"https://api.github.com/users/filimonov/following{/other_user}","gists_url":"https://api.github.com/users/filimonov/gists{/gist_id}","starred_url":"https://api.github.com/users/filimonov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/filimonov/subscriptions","organizations_url":"https://api.github.com/users/filimonov/orgs","repos_url":"https://api.github.com/users/filimonov/repos","events_url":"https://api.github.com/users/filimonov/events{/privacy}","received_events_url":"https://api.github.com/users/filimonov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":1365579236,"node_id":"MDU6TGFiZWwxMzY1NTc5MjM2","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/minor","name":"minor","color":"FFF8F8","default":false,"description":"Priority: minor"},{"id":1507886722,"node_id":"MDU6TGFiZWwxNTA3ODg2NzIy","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/st-discussion","name":"st-discussion","color":"e5b890","default":false,"description":"The story requires discussion /research / expert help / design & decomposition before will be taken"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-07-28T08:18:15Z","updated_at":"2021-07-28T09:24:57Z","closed_at":null,"author_association":"COLLABORATOR","active_lock_reason":null,"body":"Copying tables is a very common use case. \r\n\r\nThat command should be:\r\n- deterministic (in terms of order of inserts, and block sizes) \r\n- IO optimal (not read too many files from a lot of source table partitions at once). \r\n- have retries (if one block fails it first retry it several times) - if target table support retries, \r\n- both table1 and table2 can be table functions (s3 / file / url etc).\r\n- (maybe) can be restarted from the middle in case of failures (may require storing the state in zookeeper)\r\n- (maybe) when both tables are distributed - do the work on shards.\r\n- (maybe) when tables are replicated - split the work for all replica\r\n\r\nAlternatives:\r\n- attach all partitions https://github.com/ClickHouse/ClickHouse/issues/25223 nice if both sides share the same schema (that can be a mode of copy table) \r\n- `insert ... select ... ` - may require some extra efforts to do retries, to preserve the deterministic order, also without WHERE select tends to collect data from many different partitions at once. See also #26870\r\n- clickhouse-copier - hard to set up, works only between clickhouse tables/clusters. \r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26872/reactions","total_count":2,"+1":2,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26872/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26846","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26846/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26846/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26846/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26846","id":954083135,"node_id":"MDU6SXNzdWU5NTQwODMxMzU=","number":26846,"title":"Website markup is unbearable.","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":2668414603,"node_id":"MDU6TGFiZWwyNjY4NDE0NjAz","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/bug%20on%20website","name":"bug on website","color":"EA39C8","default":false,"description":""}],"state":"open","locked":false,"assignee":{"login":"rfraposa","id":5323324,"node_id":"MDQ6VXNlcjUzMjMzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/5323324?v=4","gravatar_id":"","url":"https://api.github.com/users/rfraposa","html_url":"https://github.com/rfraposa","followers_url":"https://api.github.com/users/rfraposa/followers","following_url":"https://api.github.com/users/rfraposa/following{/other_user}","gists_url":"https://api.github.com/users/rfraposa/gists{/gist_id}","starred_url":"https://api.github.com/users/rfraposa/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rfraposa/subscriptions","organizations_url":"https://api.github.com/users/rfraposa/orgs","repos_url":"https://api.github.com/users/rfraposa/repos","events_url":"https://api.github.com/users/rfraposa/events{/privacy}","received_events_url":"https://api.github.com/users/rfraposa/received_events","type":"User","site_admin":false},"assignees":[{"login":"rfraposa","id":5323324,"node_id":"MDQ6VXNlcjUzMjMzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/5323324?v=4","gravatar_id":"","url":"https://api.github.com/users/rfraposa","html_url":"https://github.com/rfraposa","followers_url":"https://api.github.com/users/rfraposa/followers","following_url":"https://api.github.com/users/rfraposa/following{/other_user}","gists_url":"https://api.github.com/users/rfraposa/gists{/gist_id}","starred_url":"https://api.github.com/users/rfraposa/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rfraposa/subscriptions","organizations_url":"https://api.github.com/users/rfraposa/orgs","repos_url":"https://api.github.com/users/rfraposa/repos","events_url":"https://api.github.com/users/rfraposa/events{/privacy}","received_events_url":"https://api.github.com/users/rfraposa/received_events","type":"User","site_admin":false}],"milestone":null,"comments":2,"created_at":"2021-07-27T17:03:34Z","updated_at":"2022-01-16T03:23:34Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"1.\r\n![Screenshot_20210719_183057](https://user-images.githubusercontent.com/18581488/127196887-ec8bd3ca-b260-4964-b205-6a060ef40426.png)\r\n\r\n2.\r\n![Screenshot_20210630_024744](https://user-images.githubusercontent.com/18581488/127196964-afdf352d-e8a3-433e-a196-618cdae83ea3.png)\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26846/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26846/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26835","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26835/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26835/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26835/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26835","id":953896620,"node_id":"MDU6SXNzdWU5NTM4OTY2MjA=","number":26835,"title":"UNKNOWN_USER in system.errors for SQL created users","user":{"login":"den-crane","id":19737682,"node_id":"MDQ6VXNlcjE5NzM3Njgy","avatar_url":"https://avatars.githubusercontent.com/u/19737682?v=4","gravatar_id":"","url":"https://api.github.com/users/den-crane","html_url":"https://github.com/den-crane","followers_url":"https://api.github.com/users/den-crane/followers","following_url":"https://api.github.com/users/den-crane/following{/other_user}","gists_url":"https://api.github.com/users/den-crane/gists{/gist_id}","starred_url":"https://api.github.com/users/den-crane/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/den-crane/subscriptions","organizations_url":"https://api.github.com/users/den-crane/orgs","repos_url":"https://api.github.com/users/den-crane/repos","events_url":"https://api.github.com/users/den-crane/events{/privacy}","received_events_url":"https://api.github.com/users/den-crane/received_events","type":"User","site_admin":false},"labels":[{"id":845247686,"node_id":"MDU6TGFiZWw4NDUyNDc2ODY=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/usability","name":"usability","color":"ebf28c","default":false,"description":""},{"id":1365579236,"node_id":"MDU6TGFiZWwxMzY1NTc5MjM2","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/minor","name":"minor","color":"FFF8F8","default":false,"description":"Priority: minor"},{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""},{"id":2011606513,"node_id":"MDU6TGFiZWwyMDExNjA2NTEz","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-rbac","name":"comp-rbac","color":"b5bcff","default":false,"description":"Access control related"}],"state":"open","locked":false,"assignee":{"login":"vitlibar","id":45142681,"node_id":"MDQ6VXNlcjQ1MTQyNjgx","avatar_url":"https://avatars.githubusercontent.com/u/45142681?v=4","gravatar_id":"","url":"https://api.github.com/users/vitlibar","html_url":"https://github.com/vitlibar","followers_url":"https://api.github.com/users/vitlibar/followers","following_url":"https://api.github.com/users/vitlibar/following{/other_user}","gists_url":"https://api.github.com/users/vitlibar/gists{/gist_id}","starred_url":"https://api.github.com/users/vitlibar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vitlibar/subscriptions","organizations_url":"https://api.github.com/users/vitlibar/orgs","repos_url":"https://api.github.com/users/vitlibar/repos","events_url":"https://api.github.com/users/vitlibar/events{/privacy}","received_events_url":"https://api.github.com/users/vitlibar/received_events","type":"User","site_admin":false},"assignees":[{"login":"vitlibar","id":45142681,"node_id":"MDQ6VXNlcjQ1MTQyNjgx","avatar_url":"https://avatars.githubusercontent.com/u/45142681?v=4","gravatar_id":"","url":"https://api.github.com/users/vitlibar","html_url":"https://github.com/vitlibar","followers_url":"https://api.github.com/users/vitlibar/followers","following_url":"https://api.github.com/users/vitlibar/following{/other_user}","gists_url":"https://api.github.com/users/vitlibar/gists{/gist_id}","starred_url":"https://api.github.com/users/vitlibar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vitlibar/subscriptions","organizations_url":"https://api.github.com/users/vitlibar/orgs","repos_url":"https://api.github.com/users/vitlibar/repos","events_url":"https://api.github.com/users/vitlibar/events{/privacy}","received_events_url":"https://api.github.com/users/vitlibar/received_events","type":"User","site_admin":false}],"milestone":null,"comments":3,"created_at":"2021-07-27T13:40:08Z","updated_at":"2021-07-27T17:00:52Z","closed_at":null,"author_association":"COLLABORATOR","active_lock_reason":null,"body":"```\r\n21.8.1.7409\r\n\r\ncreate user foo identified by 'secret';\r\n\r\nclickhouse-client -u foo --password=secret\r\n\r\nSELECT\r\n    name,\r\n    value,\r\n    last_error_message\r\nFROM system.errors\r\nWHERE code = 192\r\n\r\n┌─name─────────┬─value─┬─last_error_message──────────────────┐\r\n│ UNKNOWN_USER │     1 │ There is no user `foo` in users.xml │\r\n└──────────────┴───────┴─────────────────────────────────────┘\r\n\r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26835/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26835/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26833","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26833/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26833/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26833/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26833","id":953755024,"node_id":"MDU6SXNzdWU5NTM3NTUwMjQ=","number":26833,"title":"In-memory part can be written only at INSERT ?","user":{"login":"etah000","id":7627204,"node_id":"MDQ6VXNlcjc2MjcyMDQ=","avatar_url":"https://avatars.githubusercontent.com/u/7627204?v=4","gravatar_id":"","url":"https://api.github.com/users/etah000","html_url":"https://github.com/etah000","followers_url":"https://api.github.com/users/etah000/followers","following_url":"https://api.github.com/users/etah000/following{/other_user}","gists_url":"https://api.github.com/users/etah000/gists{/gist_id}","starred_url":"https://api.github.com/users/etah000/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/etah000/subscriptions","organizations_url":"https://api.github.com/users/etah000/orgs","repos_url":"https://api.github.com/users/etah000/repos","events_url":"https://api.github.com/users/etah000/events{/privacy}","received_events_url":"https://api.github.com/users/etah000/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""},{"id":2557407378,"node_id":"MDU6TGFiZWwyNTU3NDA3Mzc4","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-inmemory-parts","name":"comp-inmemory-parts","color":"b5bcff","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":4,"created_at":"2021-07-27T10:50:56Z","updated_at":"2021-11-17T08:24:24Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"Now CH supports memory part. but strangely, those parts cannot be merged in memory.  \r\n\r\nIf users have a lot of small inserts in parallel, those small data parts could be saved and merged in memory  until the merged part's size meets \"min_rows_for_compact_part\". Then it is written to disks.\r\n\r\nActually, it throws exception \"DataPartWriterInMemory supports only one write\". Is there any special consideration to forbid those operations?\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26833/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26833/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26832","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26832/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26832/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26832/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26832","id":953753780,"node_id":"MDU6SXNzdWU5NTM3NTM3ODA=","number":26832,"title":"Code: 999. DB::Exception: Received from localhost:9000. DB::Exception: Connection loss.","user":{"login":"AngelLittleChaochao","id":12526278,"node_id":"MDQ6VXNlcjEyNTI2Mjc4","avatar_url":"https://avatars.githubusercontent.com/u/12526278?v=4","gravatar_id":"","url":"https://api.github.com/users/AngelLittleChaochao","html_url":"https://github.com/AngelLittleChaochao","followers_url":"https://api.github.com/users/AngelLittleChaochao/followers","following_url":"https://api.github.com/users/AngelLittleChaochao/following{/other_user}","gists_url":"https://api.github.com/users/AngelLittleChaochao/gists{/gist_id}","starred_url":"https://api.github.com/users/AngelLittleChaochao/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/AngelLittleChaochao/subscriptions","organizations_url":"https://api.github.com/users/AngelLittleChaochao/orgs","repos_url":"https://api.github.com/users/AngelLittleChaochao/repos","events_url":"https://api.github.com/users/AngelLittleChaochao/events{/privacy}","received_events_url":"https://api.github.com/users/AngelLittleChaochao/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""},{"id":1401894928,"node_id":"MDU6TGFiZWwxNDAxODk0OTI4","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-zookeeper","name":"comp-zookeeper","color":"b5bcff","default":false,"description":"Zookeeper"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2021-07-27T10:49:18Z","updated_at":"2021-07-27T15:21:46Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Recently when we did ingestion to ClickHouse, we often encountered 'Connection loss' error or 'Session expired' error. Since the connection to Zookeeper is lost, the table to read only state. Now the error is very often.  It has relationship with two many znodes in Zookeeper since it was running normally before.  (I got many connection loss error, the call stack maybe different for connection loss exception.)\r\nI only have one machine to do ingestion, other 99 machines' ingestion task has been stopped.\r\nHere is my zookeeper environment config:\r\n1. 11 machines in zookeeper cluster.\r\n2. For Zookeeper each machine, 38 cores, 113GB memory.\r\n3. Snapshot size: 3.2GB\r\n4. Snapshot and Txnlog dumpped to SSD disk.\r\n5. The znode count is about **11 million** \r\n\r\n2021.07.27 03:40:34.366333 [ 62894 ] {} <Error> prod.test: void DB::StorageReplicatedMergeTree::mergeSelectingTask(): Code: 999, e.displayText() = Coordination::Exception: /test/shard_6/block_numbers/20200711-20200711-20200711-0-0 (Connection loss), Stack trace (when copying this message, always include the lines below):\r\n\r\n0. DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, bool) @ 0x87f714a in /usr/bin/clickhouse\r\n1. Coordination::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, Coordination::Error, int) @ 0x1022f905 in /usr/bin/clickhouse\r\n2. Coordination::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, Coordination::Error) @ 0x1022fb72 in /usr/bin/clickhouse\r\n3. ? @ 0x1024781a in /usr/bin/clickhouse\r\n4. Coordination::ZooKeeper::finalize(bool, bool) @ 0x1026db25 in /usr/bin/clickhouse\r\n5. Coordination::ZooKeeper::receiveThread() @ 0x10273516 in /usr/bin/clickhouse\r\n6. ? @ 0x10278602 in /usr/bin/clickhouse\r\n7. ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) @ 0x88372bf in /usr/bin/clickhouse\r\n8. ? @ 0x883ade3 in /usr/bin/clickhouse\r\n9. start_thread @ 0x76db in /lib/x86_64-linux-gnu/libpthread-2.27.so\r\n10. __clone @ 0x12188f in /lib/x86_64-linux-gnu/libc-2.27.so\r\n (version 21.4.6.55 (official build))\r\n\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26832/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26832/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26831","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26831/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26831/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26831/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26831","id":953736320,"node_id":"MDU6SXNzdWU5NTM3MzYzMjA=","number":26831,"title":"Want to know why  Clickhouse/programs/server/Server.h file can use header file in src directory","user":{"login":"Yanbuc","id":28927682,"node_id":"MDQ6VXNlcjI4OTI3Njgy","avatar_url":"https://avatars.githubusercontent.com/u/28927682?v=4","gravatar_id":"","url":"https://api.github.com/users/Yanbuc","html_url":"https://github.com/Yanbuc","followers_url":"https://api.github.com/users/Yanbuc/followers","following_url":"https://api.github.com/users/Yanbuc/following{/other_user}","gists_url":"https://api.github.com/users/Yanbuc/gists{/gist_id}","starred_url":"https://api.github.com/users/Yanbuc/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Yanbuc/subscriptions","organizations_url":"https://api.github.com/users/Yanbuc/orgs","repos_url":"https://api.github.com/users/Yanbuc/repos","events_url":"https://api.github.com/users/Yanbuc/events{/privacy}","received_events_url":"https://api.github.com/users/Yanbuc/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-07-27T10:26:19Z","updated_at":"2021-07-27T10:26:19Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"I can't understand the code in  Clickhouse/programs/server/Server.h. \r\n![image](https://user-images.githubusercontent.com/28927682/127138480-fd32c87e-954c-4431-bd59-be61f51ddecd.png)\r\n\r\ndaemon/BaseDaemon.h is in src direcory, but Server.h can use it by #include<>. I search in CMakeLists.txt, but I can't find code like  \"target_include_directories(clickhouse-server-lib\". I want to know why Server.h can use the header file in src directory.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26831/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26831/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26825","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26825/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26825/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26825/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26825","id":953490291,"node_id":"MDU6SXNzdWU5NTM0OTAyOTE=","number":26825,"title":"when exec distributed ddl， got error： can not write to ostream at offet 14","user":{"login":"miaojianxin","id":31402330,"node_id":"MDQ6VXNlcjMxNDAyMzMw","avatar_url":"https://avatars.githubusercontent.com/u/31402330?v=4","gravatar_id":"","url":"https://api.github.com/users/miaojianxin","html_url":"https://github.com/miaojianxin","followers_url":"https://api.github.com/users/miaojianxin/followers","following_url":"https://api.github.com/users/miaojianxin/following{/other_user}","gists_url":"https://api.github.com/users/miaojianxin/gists{/gist_id}","starred_url":"https://api.github.com/users/miaojianxin/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/miaojianxin/subscriptions","organizations_url":"https://api.github.com/users/miaojianxin/orgs","repos_url":"https://api.github.com/users/miaojianxin/repos","events_url":"https://api.github.com/users/miaojianxin/events{/privacy}","received_events_url":"https://api.github.com/users/miaojianxin/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":4,"created_at":"2021-07-27T04:27:07Z","updated_at":"2021-07-28T05:50:13Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"sometimes， I run sql like this，use the client：CREATE TABLE replicaTest on cluster distable ( label_id UInt32,  label_name String,  insert_time Date) ENGINE = ReplicatedMergeTree('/clickhouse/tables/{shard_name}/replicaTest','{replica_name}',insert_time, (label_id, insert_time), 8192);\r\n\r\n\r\ngot error, the stacktrace is as follows, the ck version is  20.8.6,   thank you\r\nthe stack is not the same as  https://github.com/ClickHouse/ClickHouse/issues/3981,  I didn't use http client.\r\n\r\nReceived exception from server (version 20.8.6):\r\nCode: 24. DB::Exception: Received from localhost:7901. DB::Exception: Cannot write to ostream at offset 22. Stack trace:\r\n\r\n0. Poco::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int) @ 0x1a13f46f in /data2/clickhouse_ha_test/ha_1/clickhouse\r\n1. DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int) @ 0xea77199 in /data2/clickhouse_ha_test/ha_1/clickhouse\r\n2. DB::WriteBufferFromOStream::nextImpl() (.cold) @ 0x10688eea in /data2/clickhouse_ha_test/ha_1/clickhouse\r\n3. DB::IAST::FormatSettings::writeIdentifier(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) const @ 0x17cbb26e in /data2/clickhouse_ha_test/ha_1/clickhouse\r\n4. DB::ASTIdentifier::formatImplWithoutAlias(DB::IAST::FormatSettings const&, DB::IAST::FormatState&, DB::IAST::FormatStateStacked) const @ 0x17c090cd in /data2/clickhouse_ha_test/ha_1/clickhouse\r\n5. DB::ASTWithAlias::formatImpl(DB::IAST::FormatSettings const&, DB::IAST::FormatState&, DB::IAST::FormatStateStacked) const @ 0x17c9bd47 in /data2/clickhouse_ha_test/ha_1/clickhouse\r\n6. DB::ASTFunction::formatImplWithoutAlias(DB::IAST::FormatSettings const&, DB::IAST::FormatState&, DB::IAST::FormatStateStacked) const @ 0x17c01899 in /data2/clickhouse_ha_test/ha_1/clickhouse\r\n7. DB::ASTWithAlias::formatImpl(DB::IAST::FormatSettings const&, DB::IAST::FormatState&, DB::IAST::FormatStateStacked) const @ 0x17c9bd47 in /data2/clickhouse_ha_test/ha_1/clickhouse\r\n8. DB::ASTStorage::formatImpl(DB::IAST::FormatSettings const&, DB::IAST::FormatState&, DB::IAST::FormatStateStacked) const @ 0x17bdc936 in /data2/clickhouse_ha_test/ha_1/clickhouse\r\n9. DB::ASTCreateQuery::formatQueryImpl(DB::IAST::FormatSettings const&, DB::IAST::FormatState&, DB::IAST::FormatStateStacked) const @ 0x17bdddce in /data2/clickhouse_ha_test/ha_1/clickhouse\r\n10. DB::ASTQueryWithOutput::formatImpl(DB::IAST::FormatSettings const&, DB::IAST::FormatState&, DB::IAST::FormatStateStacked) const @ 0x17c43363 in /data2/clickhouse_ha_test/ha_1/clickhouse\r\n11. DB::formatAST(DB::IAST const&, std::__1::basic_ostream<char, std::__1::char_traits<char> >&, bool, bool) @ 0x17d3f37b in /data2/clickhouse_ha_test/ha_1/clickhouse\r\n12. DB::executeDDLQueryOnCluster(std::__1::shared_ptr<DB::IAST> const&, DB::Context const&, DB::AccessRightsElements&&, bool) @ 0x16ae5163 in /data2/clickhouse_ha_test/ha_1/clickhouse\r\n13. DB::InterpreterCreateQuery::execute() @ 0x16c50aa2 in /data2/clickhouse_ha_test/ha_1/clickhouse\r\n14. DB::executeQueryImpl(char const*, char const*, DB::Context&, bool, DB::QueryProcessingStage::Enum, bool, DB::ReadBuffer*) @ 0x17093ced in /data2/clickhouse_ha_test/ha_1/clickhouse\r\n15. DB::executeQuery(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, DB::Context&, bool, DB::QueryProcessingStage::Enum, bool) @ 0x1709573a in /data2/clickhouse_ha_test/ha_1/clickhouse\r\n16. DB::TCPHandler::runImpl() @ 0x177405d2 in /data2/clickhouse_ha_test/ha_1/clickhouse\r\n17. DB::TCPHandler::run() @ 0x177412ac in /data2/clickhouse_ha_test/ha_1/clickhouse\r\n18. Poco::Net::TCPServerConnection::start() @ 0x1a05d4a7 in /data2/clickhouse_ha_test/ha_1/clickhouse\r\n19. Poco::Net::TCPServerDispatcher::run() @ 0x1a05d91f in /data2/clickhouse_ha_test/ha_1/clickhouse\r\n20. Poco::PooledThread::run() @ 0x1a1dad4e in /data2/clickhouse_ha_test/ha_1/clickhouse\r\n21. Poco::ThreadImpl::runnableEntry(void*) @ 0x1a1d6257 in /data2/clickhouse_ha_test/ha_1/clickhouse\r\n22. start_thread @ 0x8347 in /data2/mjx/gentoo/lib64/libpthread-2.30.so\r\n23. __clone @ 0x107fdf in /data2/mjx/gentoo/lib64/libc-2.30.so\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26825/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26825/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26819","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26819/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26819/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26819/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26819","id":953091787,"node_id":"MDU6SXNzdWU5NTMwOTE3ODc=","number":26819,"title":"-if combinator index/prewhere optimization","user":{"login":"UnamedRus","id":9449405,"node_id":"MDQ6VXNlcjk0NDk0MDU=","avatar_url":"https://avatars.githubusercontent.com/u/9449405?v=4","gravatar_id":"","url":"https://api.github.com/users/UnamedRus","html_url":"https://github.com/UnamedRus","followers_url":"https://api.github.com/users/UnamedRus/followers","following_url":"https://api.github.com/users/UnamedRus/following{/other_user}","gists_url":"https://api.github.com/users/UnamedRus/gists{/gist_id}","starred_url":"https://api.github.com/users/UnamedRus/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/UnamedRus/subscriptions","organizations_url":"https://api.github.com/users/UnamedRus/orgs","repos_url":"https://api.github.com/users/UnamedRus/repos","events_url":"https://api.github.com/users/UnamedRus/events{/privacy}","received_events_url":"https://api.github.com/users/UnamedRus/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-07-26T16:45:07Z","updated_at":"2021-07-26T16:45:07Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Use case**\r\n\r\n```\r\nCREATE TABLE combinator\r\n(\r\n    `type` UInt8,\r\n    `key` UInt32,\r\n    `value` UInt32\r\n)\r\nENGINE = MergeTree\r\nORDER BY (type, key)\r\n\r\nINSERT INTO combinator SELECT\r\n    number % 10,\r\n    number,\r\n    rand()\r\nFROM numbers(1000000)\r\n\r\nSELECT sumIf(value, type = 1)\r\nFROM combinator\r\n\r\n┌─sumIf(value, equals(type, 1))─┐\r\n│               215530341743630 │\r\n└───────────────────────────────┘\r\n\r\n1 rows in set. Elapsed: 0.017 sec. Processed 1.00 million rows, 5.00 MB (59.91 million rows/s., 299.55 MB/s.)\r\n\r\nWHERE type = 1\r\n\r\n1 rows in set. Elapsed: 0.004 sec. Processed 106.50 thousand rows, 532.48 KB (27.21 million rows/s., 136.04 MB/s.)\r\n\r\nSELECT\r\n    sumIf(value, type = 1),\r\n    sumIf(value, type = 8)\r\nFROM combinator\r\n\r\n┌─sumIf(value, equals(type, 1))─┬─sumIf(value, equals(type, 8))─┐\r\n│               215530341743630 │               214411846766369 │\r\n└───────────────────────────────┴───────────────────────────────┘\r\n\r\n1 rows in set. Elapsed: 0.006 sec. Processed 1.00 million rows, 5.00 MB (156.68 million rows/s., 783.39 MB/s.)\r\n\r\n\r\nSELECT\r\n    sumIf(value, type = 1),\r\n    sumIf(key, type = 8)\r\nFROM combinator\r\n\r\n┌─sumIf(value, equals(type, 1))─┬─sumIf(key, equals(type, 8))─┐\r\n│               215530341743630 │                 50000300000 │\r\n└───────────────────────────────┴─────────────────────────────┘\r\n\r\n1 rows in set. Elapsed: 0.007 sec. Processed 1.00 million rows, 9.00 MB (150.67 million rows/s., 1.36 GB/s.)\r\n```\r\n\r\nsumIf(value, type = 1),\r\nsumIf(key, type = 8)\r\n    \r\nClickhouse would read `value` column marks range only where type=1.\r\nClickhouse would read `key` column marks range only where type=8.\r\nSo it's like WHERE condition would be applied at column level.\r\n\r\n\r\nRelated https://github.com/ClickHouse/ClickHouse/issues/15427 \r\nAnd probably https://github.com/ClickHouse/ClickHouse/issues/24779","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26819/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26819/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26811","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26811/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26811/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26811/events","html_url":"https://github.com/ClickHouse/ClickHouse/pull/26811","id":952904385,"node_id":"MDExOlB1bGxSZXF1ZXN0Njk3MDI5NDIx","number":26811,"title":"Split setting `allow_to_copy_alias_and_materialized_columns` for copier","user":{"login":"nikitamikhaylov","id":25705399,"node_id":"MDQ6VXNlcjI1NzA1Mzk5","avatar_url":"https://avatars.githubusercontent.com/u/25705399?v=4","gravatar_id":"","url":"https://api.github.com/users/nikitamikhaylov","html_url":"https://github.com/nikitamikhaylov","followers_url":"https://api.github.com/users/nikitamikhaylov/followers","following_url":"https://api.github.com/users/nikitamikhaylov/following{/other_user}","gists_url":"https://api.github.com/users/nikitamikhaylov/gists{/gist_id}","starred_url":"https://api.github.com/users/nikitamikhaylov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nikitamikhaylov/subscriptions","organizations_url":"https://api.github.com/users/nikitamikhaylov/orgs","repos_url":"https://api.github.com/users/nikitamikhaylov/repos","events_url":"https://api.github.com/users/nikitamikhaylov/events{/privacy}","received_events_url":"https://api.github.com/users/nikitamikhaylov/received_events","type":"User","site_admin":false},"labels":[{"id":1304141686,"node_id":"MDU6TGFiZWwxMzA0MTQxNjg2","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/pr-improvement","name":"pr-improvement","color":"007700","default":false,"description":"Pull request with some product improvements"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":6,"created_at":"2021-07-26T13:26:36Z","updated_at":"2021-12-02T12:17:58Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"draft":false,"pull_request":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/pulls/26811","html_url":"https://github.com/ClickHouse/ClickHouse/pull/26811","diff_url":"https://github.com/ClickHouse/ClickHouse/pull/26811.diff","patch_url":"https://github.com/ClickHouse/ClickHouse/pull/26811.patch","merged_at":null},"body":"I hereby agree to the terms of the CLA available at: https://yandex.ru/legal/cla/?lang=en\r\n\r\nChangelog category (leave one):\r\n\r\n- Improvement\r\n\r\n\r\nChangelog entry (a user-readable short description of the changes that goes to CHANGELOG.md):\r\nSplit setting `allow_to_copy_alias_and_materialized_columns` into `allow_to_copy_materialized_columns` and `allow_to_copy_aliases`.\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26811/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26811/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26810","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26810/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26810/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26810/events","html_url":"https://github.com/ClickHouse/ClickHouse/pull/26810","id":952891977,"node_id":"MDExOlB1bGxSZXF1ZXN0Njk3MDE4NzQy","number":26810,"title":"Add generate-documentation tool and simple documentation as a first example","user":{"login":"FArthur-cmd","id":58165623,"node_id":"MDQ6VXNlcjU4MTY1NjIz","avatar_url":"https://avatars.githubusercontent.com/u/58165623?v=4","gravatar_id":"","url":"https://api.github.com/users/FArthur-cmd","html_url":"https://github.com/FArthur-cmd","followers_url":"https://api.github.com/users/FArthur-cmd/followers","following_url":"https://api.github.com/users/FArthur-cmd/following{/other_user}","gists_url":"https://api.github.com/users/FArthur-cmd/gists{/gist_id}","starred_url":"https://api.github.com/users/FArthur-cmd/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/FArthur-cmd/subscriptions","organizations_url":"https://api.github.com/users/FArthur-cmd/orgs","repos_url":"https://api.github.com/users/FArthur-cmd/repos","events_url":"https://api.github.com/users/FArthur-cmd/events{/privacy}","received_events_url":"https://api.github.com/users/FArthur-cmd/received_events","type":"User","site_admin":false},"labels":[{"id":1309674771,"node_id":"MDU6TGFiZWwxMzA5Njc0Nzcx","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/pr-feature","name":"pr-feature","color":"007700","default":false,"description":"Pull request with new product feature"},{"id":1807683251,"node_id":"MDU6TGFiZWwxODA3NjgzMjUx","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/doc-alert","name":"doc-alert","color":"e51068","default":false,"description":"PR where any documentation work is needed or proceeded"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-07-26T13:14:36Z","updated_at":"2021-12-09T14:59:33Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"draft":true,"pull_request":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/pulls/26810","html_url":"https://github.com/ClickHouse/ClickHouse/pull/26810","diff_url":"https://github.com/ClickHouse/ClickHouse/pull/26810.diff","patch_url":"https://github.com/ClickHouse/ClickHouse/pull/26810.patch","merged_at":null},"body":"I hereby agree to the terms of the CLA available at: https://yandex.ru/legal/cla/?lang=en\r\n\r\nChangelog category (leave one):\r\n- New Feature\r\n\r\nChangelog entry (a user-readable short description of the changes that goes to CHANGELOG.md):\r\n- Adding documentation support\r\n\r\nDetailed description / Documentation draft:\r\n# Documentation\r\n\r\nDocumentation from `clickhouse-client` is now supported. You can get all information using select queries.\r\n\r\nUsing select query (for example, `select documentation from system.table_functions`) client can get documentation in markdown format.\r\n\r\nAlso add application `clickhouse-documentation` to generate or get documentation in markdown.\r\n\r\n**Syntax**\r\nProgram can be used by itself:\r\n`clickhouse-documentation [group name] [name of object] [path to file where to put (optional)]`\r\n\r\nor \r\n\r\n`clickhouse-documentation` and enter interactive mode, where commands will be same.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26810/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26810/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26809","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26809/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26809/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26809/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26809","id":952814707,"node_id":"MDU6SXNzdWU5NTI4MTQ3MDc=","number":26809,"title":"Invalid number of columns in chunk pushed to OutputPort","user":{"login":"qoega","id":2159081,"node_id":"MDQ6VXNlcjIxNTkwODE=","avatar_url":"https://avatars.githubusercontent.com/u/2159081?v=4","gravatar_id":"","url":"https://api.github.com/users/qoega","html_url":"https://github.com/qoega","followers_url":"https://api.github.com/users/qoega/followers","following_url":"https://api.github.com/users/qoega/following{/other_user}","gists_url":"https://api.github.com/users/qoega/gists{/gist_id}","starred_url":"https://api.github.com/users/qoega/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/qoega/subscriptions","organizations_url":"https://api.github.com/users/qoega/orgs","repos_url":"https://api.github.com/users/qoega/repos","events_url":"https://api.github.com/users/qoega/events{/privacy}","received_events_url":"https://api.github.com/users/qoega/received_events","type":"User","site_admin":false},"labels":[{"id":1357578153,"node_id":"MDU6TGFiZWwxMzU3NTc4MTUz","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-joins","name":"comp-joins","color":"b5bcff","default":false,"description":"JOINs"},{"id":2104602822,"node_id":"MDU6TGFiZWwyMTA0NjAyODIy","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/fuzz","name":"fuzz","color":"abc4ea","default":false,"description":""}],"state":"open","locked":false,"assignee":{"login":"vdimir","id":7023786,"node_id":"MDQ6VXNlcjcwMjM3ODY=","avatar_url":"https://avatars.githubusercontent.com/u/7023786?v=4","gravatar_id":"","url":"https://api.github.com/users/vdimir","html_url":"https://github.com/vdimir","followers_url":"https://api.github.com/users/vdimir/followers","following_url":"https://api.github.com/users/vdimir/following{/other_user}","gists_url":"https://api.github.com/users/vdimir/gists{/gist_id}","starred_url":"https://api.github.com/users/vdimir/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vdimir/subscriptions","organizations_url":"https://api.github.com/users/vdimir/orgs","repos_url":"https://api.github.com/users/vdimir/repos","events_url":"https://api.github.com/users/vdimir/events{/privacy}","received_events_url":"https://api.github.com/users/vdimir/received_events","type":"User","site_admin":false},"assignees":[{"login":"vdimir","id":7023786,"node_id":"MDQ6VXNlcjcwMjM3ODY=","avatar_url":"https://avatars.githubusercontent.com/u/7023786?v=4","gravatar_id":"","url":"https://api.github.com/users/vdimir","html_url":"https://github.com/vdimir","followers_url":"https://api.github.com/users/vdimir/followers","following_url":"https://api.github.com/users/vdimir/following{/other_user}","gists_url":"https://api.github.com/users/vdimir/gists{/gist_id}","starred_url":"https://api.github.com/users/vdimir/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vdimir/subscriptions","organizations_url":"https://api.github.com/users/vdimir/orgs","repos_url":"https://api.github.com/users/vdimir/repos","events_url":"https://api.github.com/users/vdimir/events{/privacy}","received_events_url":"https://api.github.com/users/vdimir/received_events","type":"User","site_admin":false}],"milestone":null,"comments":4,"created_at":"2021-07-26T11:44:18Z","updated_at":"2021-12-08T21:52:20Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"https://clickhouse-test-reports.s3.yandex.net/0/f559c4ffff55ffe62a9928cdffb47a0e0efd763d/fuzzer_debug/report.html\r\n\r\n```\r\nqoega@qoega-dev:~/tmp$ grep -a 'b8ce2393-842f-43e2-b6b7-101b8bf0f619\\|Fatal' server.log.4\r\n2021.07.25 23:25:50.872339 [ 49 ] {b8ce2393-842f-43e2-b6b7-101b8bf0f619} <Debug> executeQuery: (from [::1]:33508) SELECT key, s1.value, s2.value FROM (SELECT 'key1' AS key, 'value1' AS value) AS s1 ALL LEFT JOIN (SELECT 'key1' AS key, '' AS value UNION ALL SELECT 'key2' AS key, toNullable('') AS value) AS s2 USING (key)\r\n2021.07.25 23:25:50.874120 [ 49 ] {b8ce2393-842f-43e2-b6b7-101b8bf0f619} <Trace> ContextAccess (default): Access granted: SELECT(dummy) ON system.one\r\n2021.07.25 23:25:50.875663 [ 49 ] {b8ce2393-842f-43e2-b6b7-101b8bf0f619} <Trace> ContextAccess (default): Access granted: SELECT(dummy) ON system.one\r\n2021.07.25 23:25:50.877080 [ 49 ] {b8ce2393-842f-43e2-b6b7-101b8bf0f619} <Trace> ContextAccess (default): Access granted: SELECT(dummy) ON system.one\r\n2021.07.25 23:25:50.879112 [ 49 ] {b8ce2393-842f-43e2-b6b7-101b8bf0f619} <Trace> ContextAccess (default): Access granted: SELECT(dummy) ON system.one\r\n2021.07.25 23:25:50.881666 [ 49 ] {b8ce2393-842f-43e2-b6b7-101b8bf0f619} <Trace> ContextAccess (default): Access granted: SELECT(dummy) ON system.one\r\n2021.07.25 23:25:50.883277 [ 49 ] {b8ce2393-842f-43e2-b6b7-101b8bf0f619} <Trace> ContextAccess (default): Access granted: SELECT(dummy) ON system.one\r\n2021.07.25 23:25:50.884702 [ 49 ] {b8ce2393-842f-43e2-b6b7-101b8bf0f619} <Trace> ContextAccess (default): Access granted: SELECT(dummy) ON system.one\r\n2021.07.25 23:25:50.886196 [ 49 ] {b8ce2393-842f-43e2-b6b7-101b8bf0f619} <Trace> ContextAccess (default): Access granted: SELECT(dummy) ON system.one\r\n2021.07.25 23:25:50.886703 [ 49 ] {b8ce2393-842f-43e2-b6b7-101b8bf0f619} <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n2021.07.25 23:25:50.888178 [ 49 ] {b8ce2393-842f-43e2-b6b7-101b8bf0f619} <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n2021.07.25 23:25:50.889652 [ 49 ] {b8ce2393-842f-43e2-b6b7-101b8bf0f619} <Debug> HashJoin: Right sample block: s2.key String String(size = 0), s2.value Nullable(String) Const(size = 0, Nullable(size = 1, String(size = 1), UInt8(size = 1)))\r\n2021.07.25 23:25:50.891151 [ 49 ] {b8ce2393-842f-43e2-b6b7-101b8bf0f619} <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n2021.07.25 23:25:50.891505 [ 49 ] {b8ce2393-842f-43e2-b6b7-101b8bf0f619} <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n2021.07.25 23:25:50.903819 [ 265 ] {b8ce2393-842f-43e2-b6b7-101b8bf0f619} <Fatal> : Logical error: 'Invalid number of columns in chunk pushed to OutputPort. Expected 2, found 3\r\n2021.07.25 23:25:50.904941 [ 270 ] {} <Fatal> BaseDaemon: ########################################\r\n2021.07.25 23:25:50.905208 [ 270 ] {} <Fatal> BaseDaemon: (version 21.9.1.7568 (official build), build id: 4F19C0D7A3AACFFEDE5FD338CD4415052F7B345C) (from thread 265) (query_id: b8ce2393-842f-43e2-b6b7-101b8bf0f619) Received signal Aborted (6)\r\n2021.07.25 23:25:50.905554 [ 270 ] {} <Fatal> BaseDaemon:\r\n2021.07.25 23:25:50.905936 [ 270 ] {} <Fatal> BaseDaemon: Stack trace: 0x7fde210b218b 0x7fde21091859 0x12f991a6 0x12f992b5 0x1f0c7b22 0x1cf58801 0x1f12dbf6 0x1f130fbe 0x1f12ffb5 0x1f150e08 0x1f150ec4 0x1f12bea5 0x1d5bcf4a 0x1e2ca9ac 0x1e2ca65c 0x1e2ca59b 0x1e2a52ef 0x1f46dba9 0x1f1325bc 0x1f13251f 0x1f1324bd 0x1f13247d 0x1f132455 0x1f13241d 0x12fe7f49 0x12fe7075 0x1f130e0d 0x1f1317f9 0x1f1336a9 0x1f1335fd 0x1f1335a1 0x1f1334b2 0x1f13338c 0x1f13329d 0x1f13325d 0x1f133235 0x1f133200 0x12fe7f49 0x12fe7075 0x1300e04e 0x13015364\r\n2021.07.25 23:25:50.906344 [ 270 ] {} <Fatal> BaseDaemon: 4. raise @ 0x4618b in /usr/lib/x86_64-linux-gnu/libc-2.31.so\r\n2021.07.25 23:25:50.906555 [ 270 ] {} <Fatal> BaseDaemon: 5. abort @ 0x25859 in /usr/lib/x86_64-linux-gnu/libc-2.31.so\r\n2021.07.25 23:25:51.175003 [ 270 ] {} <Fatal> BaseDaemon: 6. ./obj-x86_64-linux-gnu/../src/Common/Exception.cpp:53: DB::handle_error_code(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, bool, std::__1::vector<void*, std::__1::allocator<void*> > const&) @ 0x12f991a6 in /workspace/clickhouse\r\n2021.07.25 23:25:51.430216 [ 270 ] {} <Fatal> BaseDaemon: 7. ./obj-x86_64-linux-gnu/../src/Common/Exception.cpp:60: DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, bool) @ 0x12f992b5 in /workspace/clickhouse\r\n2021.07.25 23:25:51.558265 [ 270 ] {} <Fatal> BaseDaemon: 8.1. inlined from ./obj-x86_64-linux-gnu/../src/Processors/Port.h:413: DB::OutputPort::pushData(DB::Port::State::Data)\r\n2021.07.25 23:25:51.558546 [ 270 ] {} <Fatal> BaseDaemon: 8. ../src/Processors/ISource.cpp:35: DB::ISource::prepare() @ 0x1f0c7b22 in /workspace/clickhouse\r\n2021.07.25 23:25:51.916157 [ 270 ] {} <Fatal> BaseDaemon: 9. ./obj-x86_64-linux-gnu/../src/Processors/IProcessor.h:186: DB::IProcessor::prepare(std::__1::vector<unsigned long, std::__1::allocator<unsigned long> > const&, std::__1::vector<unsigned long, std::__1::allocator<unsigned long> > const&) @ 0x1cf58801 in /workspace/clickhouse\r\n2021.07.25 23:25:52.373270 [ 270 ] {} <Fatal> BaseDaemon: 10. ./obj-x86_64-linux-gnu/../src/Processors/Executors/PipelineExecutor.cpp:216: DB::PipelineExecutor::prepareProcessor(unsigned long, unsigned long, std::__1::queue<DB::ExecutingGraph::Node*, std::__1::deque<DB::ExecutingGraph::Node*, std::__1::allocator<DB::ExecutingGraph::Node*> > >&, std::__1::queue<DB::ExecutingGraph::Node*, std::__1::deque<DB::ExecutingGraph::Node*, std::__1::allocator<DB::ExecutingGraph::Node*> > >&, std::__1::unique_lock<std::__1::mutex>) @ 0x1f12dbf6 in /workspace/clickhouse\r\n2021.07.25 23:25:52.831217 [ 270 ] {} <Fatal> BaseDaemon: 11. ./obj-x86_64-linux-gnu/../src/Processors/Executors/PipelineExecutor.cpp:615: DB::PipelineExecutor::executeStepImpl(unsigned long, unsigned long, std::__1::atomic<bool>*) @ 0x1f130fbe in /workspace/clickhouse\r\n2021.07.25 23:25:53.296884 [ 270 ] {} <Fatal> BaseDaemon: 12. ./obj-x86_64-linux-gnu/../src/Processors/Executors/PipelineExecutor.cpp:427: DB::PipelineExecutor::executeStep(std::__1::atomic<bool>*) @ 0x1f12ffb5 in /workspace/clickhouse\r\n2021.07.25 23:25:53.642851 [ 270 ] {} <Fatal> BaseDaemon: 13. ./obj-x86_64-linux-gnu/../src/Processors/Executors/PullingPipelineExecutor.cpp:37: DB::PullingPipelineExecutor::pull(DB::Chunk&) @ 0x1f150e08 in /workspace/clickhouse\r\n2021.07.25 23:25:53.991958 [ 270 ] {} <Fatal> BaseDaemon: 14. ./obj-x86_64-linux-gnu/../src/Processors/Executors/PullingPipelineExecutor.cpp:48: DB::PullingPipelineExecutor::pull(DB::Block&) @ 0x1f150ec4 in /workspace/clickhouse\r\n2021.07.25 23:25:54.184654 [ 270 ] {} <Fatal> BaseDaemon: 15. ./obj-x86_64-linux-gnu/../src/Processors/Executors/PipelineExecutingBlockInputStream.cpp:57: DB::PipelineExecutingBlockInputStream::readImpl() @ 0x1f12bea5 in /workspace/clickhouse\r\n2021.07.25 23:25:54.369925 [ 270 ] {} <Fatal> BaseDaemon: 16. ./obj-x86_64-linux-gnu/../src/DataStreams/IBlockInputStream.cpp:57: DB::IBlockInputStream::read() @ 0x1d5bcf4a in /workspace/clickhouse\r\n2021.07.25 23:25:54.891477 [ 270 ] {} <Fatal> BaseDaemon: 17. ./obj-x86_64-linux-gnu/../src/Interpreters/MergeJoin.cpp:591: DB::MergeJoin::mergeInMemoryRightBlocks() @ 0x1e2ca9ac in /workspace/clickhouse\r\n2021.07.25 23:25:55.412340 [ 270 ] {} <Fatal> BaseDaemon: 18. ./obj-x86_64-linux-gnu/../src/Interpreters/MergeJoin.cpp:567: DB::MergeJoin::mergeRightBlocks() @ 0x1e2ca65c in /workspace/clickhouse\r\n2021.07.25 23:25:55.933079 [ 270 ] {} <Fatal> BaseDaemon: 19. ./obj-x86_64-linux-gnu/../src/Interpreters/MergeJoin.cpp:558: DB::MergeJoin::setTotals(DB::Block const&) @ 0x1e2ca59b in /workspace/clickhouse\r\n2021.07.25 23:25:56.147611 [ 270 ] {} <Fatal> BaseDaemon: 20. ./obj-x86_64-linux-gnu/../src/Interpreters/JoinSwitcher.h:42: DB::JoinSwitcher::setTotals(DB::Block const&) @ 0x1e2a52ef in /workspace/clickhouse\r\n2021.07.25 23:25:56.319889 [ 270 ] {} <Fatal> BaseDaemon: 21. ./obj-x86_64-linux-gnu/../src/Processors/Transforms/JoiningTransform.cpp:290: DB::FillingRightJoinSideTransform::work() @ 0x1f46dba9 in /workspace/clickhouse\r\n2021.07.25 23:25:56.810709 [ 270 ] {} <Fatal> BaseDaemon: 22. ./obj-x86_64-linux-gnu/../src/Processors/Executors/PipelineExecutor.cpp:80: DB::executeJob(DB::IProcessor*) @ 0x1f1325bc in /workspace/clickhouse\r\n2021.07.25 23:25:57.281945 [ 270 ] {} <Fatal> BaseDaemon: 23. ./obj-x86_64-linux-gnu/../src/Processors/Executors/PipelineExecutor.cpp:97: DB::PipelineExecutor::addJob(DB::ExecutingGraph::Node*)::$_0::operator()() const @ 0x1f13251f in /workspace/clickhouse\r\n2021.07.25 23:25:57.761977 [ 270 ] {} <Fatal> BaseDaemon: 24. ./obj-x86_64-linux-gnu/../contrib/libcxx/include/type_traits:3676: decltype(std::__1::forward<DB::PipelineExecutor::addJob(DB::ExecutingGraph::Node*)::$_0&>(fp)()) std::__1::__invoke<DB::PipelineExecutor::addJob(DB::ExecutingGraph::Node*)::$_0&>(DB::PipelineExecutor::addJob(DB::ExecutingGraph::Node*)::$_0&) @ 0x1f1324bd in /workspace/clickhouse\r\n2021.07.25 23:25:58.236052 [ 270 ] {} <Fatal> BaseDaemon: 25. ./obj-x86_64-linux-gnu/../contrib/libcxx/include/__functional_base:349: void std::__1::__invoke_void_return_wrapper<void>::__call<DB::PipelineExecutor::addJob(DB::ExecutingGraph::Node*)::$_0&>(DB::PipelineExecutor::addJob(DB::ExecutingGraph::Node*)::$_0&) @ 0x1f13247d in /workspace/clickhouse\r\n2021.07.25 23:25:58.707648 [ 270 ] {} <Fatal> BaseDaemon: 26. ./obj-x86_64-linux-gnu/../contrib/libcxx/include/functional:1608: std::__1::__function::__default_alloc_func<DB::PipelineExecutor::addJob(DB::ExecutingGraph::Node*)::$_0, void ()>::operator()() @ 0x1f132455 in /workspace/clickhouse\r\n2021.07.25 23:25:59.180362 [ 270 ] {} <Fatal> BaseDaemon: 27. ./obj-x86_64-linux-gnu/../contrib/libcxx/include/functional:2089: void std::__1::__function::__policy_invoker<void ()>::__call_impl<std::__1::__function::__default_alloc_func<DB::PipelineExecutor::addJob(DB::ExecutingGraph::Node*)::$_0, void ()> >(std::__1::__function::__policy_storage const*) @ 0x1f13241d in /workspace/clickhouse\r\n2021.07.25 23:25:59.418274 [ 270 ] {} <Fatal> BaseDaemon: 28. ./obj-x86_64-linux-gnu/../contrib/libcxx/include/functional:2221: std::__1::__function::__policy_func<void ()>::operator()() const @ 0x12fe7f49 in /workspace/clickhouse\r\n2021.07.25 23:25:59.653364 [ 270 ] {} <Fatal> BaseDaemon: 29. ./obj-x86_64-linux-gnu/../contrib/libcxx/include/functional:2560: std::__1::function<void ()>::operator()() const @ 0x12fe7075 in /workspace/clickhouse\r\n2021.07.25 23:26:00.116337 [ 270 ] {} <Fatal> BaseDaemon: 30. ./obj-x86_64-linux-gnu/../src/Processors/Executors/PipelineExecutor.cpp:589: DB::PipelineExecutor::executeStepImpl(unsigned long, unsigned long, std::__1::atomic<bool>*) @ 0x1f130e0d in /workspace/clickhouse\r\n2021.07.25 23:26:00.571742 [ 270 ] {} <Fatal> BaseDaemon: 31. ./obj-x86_64-linux-gnu/../src/Processors/Executors/PipelineExecutor.cpp:474: DB::PipelineExecutor::executeSingleThread(unsigned long, unsigned long) @ 0x1f1317f9 in /workspace/clickhouse\r\n2021.07.25 23:26:01.055351 [ 270 ] {} <Fatal> BaseDaemon: 32. ./obj-x86_64-linux-gnu/../src/Processors/Executors/PipelineExecutor.cpp:777: DB::PipelineExecutor::executeImpl(unsigned long)::$_4::operator()() const @ 0x1f1336a9 in /workspace/clickhouse\r\n2021.07.25 23:26:01.541727 [ 270 ] {} <Fatal> BaseDaemon: 33. ./obj-x86_64-linux-gnu/../contrib/libcxx/include/type_traits:3682: decltype(std::__1::forward<DB::PipelineExecutor::executeImpl(unsigned long)::$_4&>(fp)()) std::__1::__invoke_constexpr<DB::PipelineExecutor::executeImpl(unsigned long)::$_4&>(DB::PipelineExecutor::executeImpl(unsigned long)::$_4&) @ 0x1f1335fd in /workspace/clickhouse\r\n2021.07.25 23:26:02.038736 [ 270 ] {} <Fatal> BaseDaemon: 34. ./obj-x86_64-linux-gnu/../contrib/libcxx/include/tuple:1415: decltype(auto) std::__1::__apply_tuple_impl<DB::PipelineExecutor::executeImpl(unsigned long)::$_4&, std::__1::tuple<>&>(DB::PipelineExecutor::executeImpl(unsigned long)::$_4&, std::__1::tuple<>&, std::__1::__tuple_indices<>) @ 0x1f1335a1 in /workspace/clickhouse\r\n2021.07.25 23:26:02.531525 [ 270 ] {} <Fatal> BaseDaemon: 35. ./obj-x86_64-linux-gnu/../contrib/libcxx/include/tuple:1424: decltype(auto) std::__1::apply<DB::PipelineExecutor::executeImpl(unsigned long)::$_4&, std::__1::tuple<>&>(DB::PipelineExecutor::executeImpl(unsigned long)::$_4&, std::__1::tuple<>&) @ 0x1f1334b2 in /workspace/clickhouse\r\n2021.07.25 23:26:03.015454 [ 270 ] {} <Fatal> BaseDaemon: 36. ./obj-x86_64-linux-gnu/../src/Common/ThreadPool.h:182: ThreadFromGlobalPool::ThreadFromGlobalPool<DB::PipelineExecutor::executeImpl(unsigned long)::$_4>(DB::PipelineExecutor::executeImpl(unsigned long)::$_4&&)::'lambda'()::operator()() @ 0x1f13338c in /workspace/clickhouse\r\n2021.07.25 23:26:03.501857 [ 270 ] {} <Fatal> BaseDaemon: 37. ./obj-x86_64-linux-gnu/../contrib/libcxx/include/type_traits:3676: decltype(std::__1::forward<DB::PipelineExecutor::executeImpl(unsigned long)::$_4>(fp)()) std::__1::__invoke<ThreadFromGlobalPool::ThreadFromGlobalPool<DB::PipelineExecutor::executeImpl(unsigned long)::$_4>(DB::PipelineExecutor::executeImpl(unsigned long)::$_4&&)::'lambda'()&>(DB::PipelineExecutor::executeImpl(unsigned long)::$_4&&) @ 0x1f13329d in /workspace/clickhouse\r\n2021.07.25 23:26:03.994789 [ 270 ] {} <Fatal> BaseDaemon: 38. ./obj-x86_64-linux-gnu/../contrib/libcxx/include/__functional_base:349: void std::__1::__invoke_void_return_wrapper<void>::__call<ThreadFromGlobalPool::ThreadFromGlobalPool<DB::PipelineExecutor::executeImpl(unsigned long)::$_4>(DB::PipelineExecutor::executeImpl(unsigned long)::$_4&&)::'lambda'()&>(DB::PipelineExecutor::executeImpl(unsigned long)::$_4&&...) @ 0x1f13325d in /workspace/clickhouse\r\n2021.07.25 23:26:04.476717 [ 270 ] {} <Fatal> BaseDaemon: 39. ./obj-x86_64-linux-gnu/../contrib/libcxx/include/functional:1608: std::__1::__function::__default_alloc_func<ThreadFromGlobalPool::ThreadFromGlobalPool<DB::PipelineExecutor::executeImpl(unsigned long)::$_4>(DB::PipelineExecutor::executeImpl(unsigned long)::$_4&&)::'lambda'(), void ()>::operator()() @ 0x1f133235 in /workspace/clickhouse\r\n2021.07.25 23:26:04.957943 [ 270 ] {} <Fatal> BaseDaemon: 40. ./obj-x86_64-linux-gnu/../contrib/libcxx/include/functional:2089: void std::__1::__function::__policy_invoker<void ()>::__call_impl<std::__1::__function::__default_alloc_func<ThreadFromGlobalPool::ThreadFromGlobalPool<DB::PipelineExecutor::executeImpl(unsigned long)::$_4>(DB::PipelineExecutor::executeImpl(unsigned long)::$_4&&)::'lambda'(), void ()> >(std::__1::__function::__policy_storage const*) @ 0x1f133200 in /workspace/clickhouse\r\n2021.07.25 23:26:05.196092 [ 270 ] {} <Fatal> BaseDaemon: 41. ./obj-x86_64-linux-gnu/../contrib/libcxx/include/functional:2221: std::__1::__function::__policy_func<void ()>::operator()() const @ 0x12fe7f49 in /workspace/clickhouse\r\n2021.07.25 23:26:05.430431 [ 270 ] {} <Fatal> BaseDaemon: 42. ./obj-x86_64-linux-gnu/../contrib/libcxx/include/functional:2560: std::__1::function<void ()>::operator()() const @ 0x12fe7075 in /workspace/clickhouse\r\n2021.07.25 23:26:05.515588 [ 270 ] {} <Fatal> BaseDaemon: 43. ./obj-x86_64-linux-gnu/../src/Common/ThreadPool.cpp:266: ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) @ 0x1300e04e in /workspace/clickhouse\r\n2021.07.25 23:26:05.609264 [ 270 ] {} <Fatal> BaseDaemon: 44. ./obj-x86_64-linux-gnu/../src/Common/ThreadPool.cpp:136: void ThreadPoolImpl<std::__1::thread>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda0'()::operator()() const @ 0x13015364 in /workspace/clickhouse\r\n2021.07.25 23:26:06.812866 [ 270 ] {} <Fatal> BaseDaemon: Checksum of the binary: 13529ECE019FE8F0CB80A4E925C2A9A5, integrity check passed.\r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26809/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26809/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26801","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26801/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26801/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26801/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26801","id":952721560,"node_id":"MDU6SXNzdWU5NTI3MjE1NjA=","number":26801,"title":"Fuse some aggregate functions #3 - aggregated tables / states","user":{"login":"filimonov","id":1549571,"node_id":"MDQ6VXNlcjE1NDk1NzE=","avatar_url":"https://avatars.githubusercontent.com/u/1549571?v=4","gravatar_id":"","url":"https://api.github.com/users/filimonov","html_url":"https://github.com/filimonov","followers_url":"https://api.github.com/users/filimonov/followers","following_url":"https://api.github.com/users/filimonov/following{/other_user}","gists_url":"https://api.github.com/users/filimonov/gists{/gist_id}","starred_url":"https://api.github.com/users/filimonov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/filimonov/subscriptions","organizations_url":"https://api.github.com/users/filimonov/orgs","repos_url":"https://api.github.com/users/filimonov/repos","events_url":"https://api.github.com/users/filimonov/events{/privacy}","received_events_url":"https://api.github.com/users/filimonov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":1365579236,"node_id":"MDU6TGFiZWwxMzY1NTc5MjM2","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/minor","name":"minor","color":"FFF8F8","default":false,"description":"Priority: minor"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-07-26T09:56:15Z","updated_at":"2021-07-26T21:10:53Z","closed_at":null,"author_association":"COLLABORATOR","active_lock_reason":null,"body":"Use case: i have aggregatingMergeTree table with avgState in.\r\nWant to 'merge' it to sum or to count.\r\n\r\ni.e. sumMerge can be applied to AggregateFunction()\r\n\r\n```\r\nSELECT\r\n    sumMerge(x),\r\n    avgMerge(x),\r\n    countMerge(x)\r\nFROM\r\n(\r\n    SELECT avgState(number) AS x\r\n    FROM numbers(10)\r\n)\r\n```\r\n\r\nAlternative: \r\ndo sum & count separately, do division to get the average (more files need to be processed). ","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26801/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26801/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26778","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26778/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26778/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26778/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26778","id":952119287,"node_id":"MDU6SXNzdWU5NTIxMTkyODc=","number":26778,"title":"Add option so that clickhouse server recommends the appropriate index","user":{"login":"chhetripradeep","id":30620077,"node_id":"MDQ6VXNlcjMwNjIwMDc3","avatar_url":"https://avatars.githubusercontent.com/u/30620077?v=4","gravatar_id":"","url":"https://api.github.com/users/chhetripradeep","html_url":"https://github.com/chhetripradeep","followers_url":"https://api.github.com/users/chhetripradeep/followers","following_url":"https://api.github.com/users/chhetripradeep/following{/other_user}","gists_url":"https://api.github.com/users/chhetripradeep/gists{/gist_id}","starred_url":"https://api.github.com/users/chhetripradeep/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/chhetripradeep/subscriptions","organizations_url":"https://api.github.com/users/chhetripradeep/orgs","repos_url":"https://api.github.com/users/chhetripradeep/repos","events_url":"https://api.github.com/users/chhetripradeep/events{/privacy}","received_events_url":"https://api.github.com/users/chhetripradeep/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-07-24T17:50:28Z","updated_at":"2021-07-24T17:57:50Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Use case**\r\nCurrently in clickhouse, finding the right index requires some good knowledge and testing. I would like to propose adding a way in which clickhouse recommends the right index if one doesn't exist.  \r\n\r\n**Describe the solution you'd like**\r\nIn sqlite,  there is a  `expert` command which suggests the appropriate index based on the query (if one doesn't exists):\r\n```\r\n❯ sqlite3\r\nsqlite> CREATE TABLE x1(a, b, c);                  -- Create table in database \r\nsqlite> .expert\r\nsqlite> SELECT * FROM x1 WHERE a=? AND b>?;        -- Analyze this SELECT \r\nCREATE INDEX x1_idx_000123a7 ON x1(a, b);\r\n\r\n0|0|0|SEARCH TABLE x1 USING INDEX x1_idx_000123a7 (a=? AND b>?)\r\n\r\nsqlite> CREATE INDEX x1ab ON x1(a, b);             -- Create the recommended index \r\nsqlite> .expert\r\nsqlite> SELECT * FROM x1 WHERE a=? AND b>?;        -- Re-analyze the same SELECT \r\n(no new indexes)\r\n\r\n0|0|0|SEARCH TABLE x1 USING INDEX x1ab (a=? AND b>?)\r\n```\r\nThis way if the user knows the most common query, it can ask clickhouse to recommend the appropriate index.\r\n\r\nIt will be great if we can have something similar in clickhouse world.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26778/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26778/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26773","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26773/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26773/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26773/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26773","id":951966958,"node_id":"MDU6SXNzdWU5NTE5NjY5NTg=","number":26773,"title":"How long does it take the system to remove delete_tmp partitions and free disk space?","user":{"login":"q0987","id":16629186,"node_id":"MDQ6VXNlcjE2NjI5MTg2","avatar_url":"https://avatars.githubusercontent.com/u/16629186?v=4","gravatar_id":"","url":"https://api.github.com/users/q0987","html_url":"https://github.com/q0987","followers_url":"https://api.github.com/users/q0987/followers","following_url":"https://api.github.com/users/q0987/following{/other_user}","gists_url":"https://api.github.com/users/q0987/gists{/gist_id}","starred_url":"https://api.github.com/users/q0987/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/q0987/subscriptions","organizations_url":"https://api.github.com/users/q0987/orgs","repos_url":"https://api.github.com/users/q0987/repos","events_url":"https://api.github.com/users/q0987/events{/privacy}","received_events_url":"https://api.github.com/users/q0987/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-07-24T00:41:41Z","updated_at":"2021-07-27T02:23:35Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Hello,\r\n\r\nI used `truncate table default.ABC` to empty the table.\r\nAfter issuing the command, I saw the deleted partitions are still not removed by the system while the system is completely idle.\r\n\r\nQuestion> How long does the clickhouse remove those delete_tmp_* files?\r\n\r\n\r\n```\r\n/db/ClickHouseBinLog/data/default/ABC\r\ndrwxr-x--- 2 clickhouse clickhouse 24576 Jul 16 15:17 delete_tmp_20210716_5290_5290_0\r\ndrwxr-x--- 2 clickhouse clickhouse 20480 Jul 16 15:21 delete_tmp_20210716_5291_5291_0\r\ndrwxr-x--- 2 clickhouse clickhouse 24576 Jul 16 15:25 delete_tmp_20210716_5292_5292_0\r\ndrwxr-x--- 2 clickhouse clickhouse 20480 Jul 16 15:31 delete_tmp_20210716_5293_5293_0\r\ndrwxr-x--- 2 clickhouse clickhouse 20480 Jul 16 16:05 delete_tmp_20210716_5294_5294_0\r\ndrwxr-x--- 2 clickhouse clickhouse  4096 Jul 16 15:17 detached\r\n-rw-r----- 1 clickhouse clickhouse     1 May  4 15:29 format_version.txt\r\n```\r\n\r\nThank you","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26773/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26773/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26746","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26746/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26746/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26746/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26746","id":951708439,"node_id":"MDU6SXNzdWU5NTE3MDg0Mzk=","number":26746,"title":"RBAC create table with sub-queries does not return not enough privileges error after revoke","user":{"login":"vzakaznikov","id":41681088,"node_id":"MDQ6VXNlcjQxNjgxMDg4","avatar_url":"https://avatars.githubusercontent.com/u/41681088?v=4","gravatar_id":"","url":"https://api.github.com/users/vzakaznikov","html_url":"https://github.com/vzakaznikov","followers_url":"https://api.github.com/users/vzakaznikov/followers","following_url":"https://api.github.com/users/vzakaznikov/following{/other_user}","gists_url":"https://api.github.com/users/vzakaznikov/gists{/gist_id}","starred_url":"https://api.github.com/users/vzakaznikov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vzakaznikov/subscriptions","organizations_url":"https://api.github.com/users/vzakaznikov/orgs","repos_url":"https://api.github.com/users/vzakaznikov/repos","events_url":"https://api.github.com/users/vzakaznikov/events{/privacy}","received_events_url":"https://api.github.com/users/vzakaznikov/received_events","type":"User","site_admin":false},"labels":[{"id":386401505,"node_id":"MDU6TGFiZWwzODY0MDE1MDU=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/bug","name":"bug","color":"ee0701","default":true,"description":"Confirmed user-visible misbehaviour in official release"}],"state":"open","locked":false,"assignee":{"login":"vitlibar","id":45142681,"node_id":"MDQ6VXNlcjQ1MTQyNjgx","avatar_url":"https://avatars.githubusercontent.com/u/45142681?v=4","gravatar_id":"","url":"https://api.github.com/users/vitlibar","html_url":"https://github.com/vitlibar","followers_url":"https://api.github.com/users/vitlibar/followers","following_url":"https://api.github.com/users/vitlibar/following{/other_user}","gists_url":"https://api.github.com/users/vitlibar/gists{/gist_id}","starred_url":"https://api.github.com/users/vitlibar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vitlibar/subscriptions","organizations_url":"https://api.github.com/users/vitlibar/orgs","repos_url":"https://api.github.com/users/vitlibar/repos","events_url":"https://api.github.com/users/vitlibar/events{/privacy}","received_events_url":"https://api.github.com/users/vitlibar/received_events","type":"User","site_admin":false},"assignees":[{"login":"vitlibar","id":45142681,"node_id":"MDQ6VXNlcjQ1MTQyNjgx","avatar_url":"https://avatars.githubusercontent.com/u/45142681?v=4","gravatar_id":"","url":"https://api.github.com/users/vitlibar","html_url":"https://github.com/vitlibar","followers_url":"https://api.github.com/users/vitlibar/followers","following_url":"https://api.github.com/users/vitlibar/following{/other_user}","gists_url":"https://api.github.com/users/vitlibar/gists{/gist_id}","starred_url":"https://api.github.com/users/vitlibar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vitlibar/subscriptions","organizations_url":"https://api.github.com/users/vitlibar/orgs","repos_url":"https://api.github.com/users/vitlibar/repos","events_url":"https://api.github.com/users/vitlibar/events{/privacy}","received_events_url":"https://api.github.com/users/vitlibar/received_events","type":"User","site_admin":false}],"milestone":null,"comments":0,"created_at":"2021-07-23T16:07:31Z","updated_at":"2021-07-23T17:14:29Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Describe the bug**\r\n\r\nRBAC test for creating a table with sub-queries started to fail on master. As you can see from the commands below\r\nwe revoke select privilege on table2, but grant on table0 and table1. Because we don't have select privilege on table2 we expect\r\nthe create command to fail with not enough privileges error but now we get that table already exists error. \r\n```\r\n                 3ms                      [clickhouse1] bash# echo -e \"REVOKE SELECT ON table2_create_with_subquery_privilege_granted_directly_265f3a5d_e830_11eb_bd7d_15b32ea213f3 FROM user_create_with_subquery_privilege_granted_directly_or_via_role_265f3a58_e830_11eb_bd7d_15b32ea213f3\" | clickhouse client -n\r\n                37ms                      [clickhouse1] bash# echo $?\r\n                38ms                      [clickhouse1] 0\r\n                38ms                      [clickhouse1] bash#\r\n                 3ms                      [clickhouse1] bash# echo -e \"GRANT SELECT ON table0_create_with_subquery_privilege_granted_directly_265f3a5b_e830_11eb_bd7d_15b32ea213f3 TO user_create_with_subquery_privilege_granted_directly_or_via_role_265f3a58_e830_11eb_bd7d_15b32ea213f3\" | clickhouse client -n\r\n                40ms                      [clickhouse1] bash# echo $?\r\n                40ms                      [clickhouse1] 0\r\n                41ms                      [clickhouse1] bash#\r\n                 3ms                      [clickhouse1] bash# echo -e \"GRANT SELECT ON table1_create_with_subquery_privilege_granted_directly_265f3a5c_e830_11eb_bd7d_15b32ea213f3 TO user_create_with_subquery_privilege_granted_directly_or_via_role_265f3a58_e830_11eb_bd7d_15b32ea213f3\" | clickhouse client -n\r\n                38ms                      [clickhouse1] bash# echo $?\r\n                38ms                      [clickhouse1] 0\r\n                38ms                      [clickhouse1] bash#\r\n                 2ms                        [clickhouse1] bash# echo -e \"CREATE TABLE table_create_with_subquery_privilege_granted_directly_265f3a5a_e830_11eb_bd7d_15b32ea213f3 ENGINE = Memory AS SELECT * FROM table0_create_with_subquery_privilege_granted_directly_265f3a5b_e830_11eb_bd7d_15b32ea213f3 WHERE y IN (SELECT y FROM table1_create_with_subquery_privilege_granted_directly_265f3a5c_e830_11eb_bd7d_15b32ea213f3 WHERE y IN (SELECT y FROM table2_create_with_subquery_privilege_granted_directly_265f3a5d_e830_11eb_bd7d_15b32ea213f3 WHERE y<2))\" | clickhouse client -n --user \"user_create_with_subquery_privilege_granted_directly_or_via_role_265f3a58_e830_11eb_bd7d_15b32ea213f3\"\r\n                45ms                        [clickhouse1] Received exception from server (version 21.9.1):\r\n                45ms                        [clickhouse1] Code: 57. DB::Exception: Received from localhost:9000. DB::Exception: Table default.table_create_with_subquery_privilege_granted_directly_265f3a5a_e830_11eb_bd7d_15b32ea213f3 already exists.. (TABLE_ALREADY_EXISTS)\r\n                51ms                        [clickhouse1] bash# echo $?\r\n                51ms                        [clickhouse1] 57\r\n                51ms                        [clickhouse1] bash#\r\n```\r\n\r\nSee https://clickhouse-test-reports.s3.yandex.net/26468/70701d2606abe934cef48f77f52ed9ef536eaa23/testflows_check.html#fail1 for details. \r\n\r\nThe following tests have to be crossed out because of this issue:\r\n```\r\n\"/rbac/privileges/create table/create with subquery privilege granted directly or via role/create with subquery, privilege granted directly\"\r\n\"/rbac/privileges/create table/create with subquery privilege granted directly or via role/create with subquery, privilege granted through a role\"\r\n\"/rbac/views/live view/create with join subquery privilege granted directly or via role/create with join subquery, privilege granted directly\"\r\n\"/rbac/views/live view/create with join subquery privilege granted directly or via role/create with join subquery, privilege granted through a role\"\r\n```\r\n**Does it reproduce on recent release?**\r\n\r\nReproduced on current master.\r\n\r\n**How to reproduce**\r\n\r\nRun TestFlows RBAC tests and make sure the following tests pass and don't have either Fail of XFail result.\r\n\r\n**Expected behavior**\r\n\r\nTests should pass.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26746/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26746/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26711","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26711/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26711/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26711/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26711","id":950803237,"node_id":"MDU6SXNzdWU5NTA4MDMyMzc=","number":26711,"title":"DNS Resolver polluting the logs","user":{"login":"Algunenano","id":664253,"node_id":"MDQ6VXNlcjY2NDI1Mw==","avatar_url":"https://avatars.githubusercontent.com/u/664253?v=4","gravatar_id":"","url":"https://api.github.com/users/Algunenano","html_url":"https://github.com/Algunenano","followers_url":"https://api.github.com/users/Algunenano/followers","following_url":"https://api.github.com/users/Algunenano/following{/other_user}","gists_url":"https://api.github.com/users/Algunenano/gists{/gist_id}","starred_url":"https://api.github.com/users/Algunenano/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Algunenano/subscriptions","organizations_url":"https://api.github.com/users/Algunenano/orgs","repos_url":"https://api.github.com/users/Algunenano/repos","events_url":"https://api.github.com/users/Algunenano/events{/privacy}","received_events_url":"https://api.github.com/users/Algunenano/received_events","type":"User","site_admin":false},"labels":[{"id":845247686,"node_id":"MDU6TGFiZWw4NDUyNDc2ODY=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/usability","name":"usability","color":"ebf28c","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":4,"created_at":"2021-07-22T15:41:43Z","updated_at":"2021-07-22T16:19:14Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Describe the bug**\r\n\r\nIf a hostname used is invalid, the dns resolver will keep throwing errors in each update after the server is restarted.\r\n\r\n**Does it reproduce on recent release?**\r\n\r\nYes\r\n\r\n**How to reproduce**\r\n\r\nRun `01946_test_wrong_host_name_access` and keep an eye on the logs after.  In each refresh you will see an error like this although the user was already deleted:\r\n\r\n```\r\n2021.07.22 17:39:03.783264 [ 694783 ] {} <Debug> DNSResolver: Updating DNS cache\r\n2021.07.22 17:39:03.808051 [ 694783 ] {} <Error> DNSResolver: Cannot resolve host (non.existing.host.name), error 0: non.existing.host.name.\r\n2021.07.22 17:39:03.808244 [ 694783 ] {} <Error> bool DB::DNSResolver::updateCacheImpl(UpdateF &&, ElemsT &&, const DB::String &) [UpdateF = bool (DB::DNSResolver::*)(const std::string &), ElemsT = std::unordered_set<std::string> &]: Code: 198. DB::Exception: Not found address of host: non.existing.host.name. (DNS_ERROR), Stack trace (when copying this message, always include the lines below):\r\n\r\n0. /mnt/ch/ClickHouse/contrib/poco/Foundation/src/Exception.cpp:28: Poco::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int) @ 0x11733a in /mnt/ch/ClickHouse/build/contrib/poco-cmake/Foundation/lib_poco_foundation.so\r\n1. /mnt/ch/ClickHouse/src/Common/Exception.cpp:59: DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, bool) @ 0x11216e in /mnt/ch/ClickHouse/build/src/libclickhouse_common_io.so\r\n2. /mnt/ch/ClickHouse/src/Common/DNSResolver.cpp:0: DB::resolveIPAddressImpl(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) @ 0xffe53 in /mnt/ch/ClickHouse/build/src/libclickhouse_common_io.so\r\n3. /mnt/ch/ClickHouse/contrib/libcxx/include/__mutex_base:91: std::__1::vector<Poco::Net::IPAddress, std::__1::allocator<Poco::Net::IPAddress> > SimpleCache<std::__1::vector<Poco::Net::IPAddress, std::__1::allocator<Poco::Net::IPAddress> > (std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&), &(DB::resolveIPAddressImpl(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&))>::operator()<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&>(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) @ 0x100a54 in /mnt/ch/ClickHouse/build/src/libclickhouse_common_io.so\r\n4. /mnt/ch/ClickHouse/contrib/libcxx/include/memory:1627: DB::DNSResolver::updateHost(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) @ 0x102779 in /mnt/ch/ClickHouse/build/src/libclickhouse_common_io.so\r\n5. /mnt/ch/ClickHouse/src/Common/DNSResolver.cpp:262: bool DB::DNSResolver::updateCacheImpl<bool (DB::DNSResolver::*)(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&), std::__1::unordered_set<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::hash<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::equal_to<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > >&>(bool (DB::DNSResolver::*&&)(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&), std::__1::unordered_set<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::hash<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::equal_to<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > >&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) @ 0x102f5f in /mnt/ch/ClickHouse/build/src/libclickhouse_common_io.so\r\n6. /mnt/ch/ClickHouse/contrib/libcxx/include/string:1444: DB::DNSResolver::updateCache() @ 0x10206b in /mnt/ch/ClickHouse/build/src/libclickhouse_common_io.so\r\n7. /mnt/ch/ClickHouse/src/Interpreters/DNSCacheUpdater.cpp:23: DB::DNSCacheUpdater::run() @ 0x946033 in /mnt/ch/ClickHouse/build/src/libclickhouse_interpreters.so\r\n8. /mnt/ch/ClickHouse/contrib/libcxx/include/functional:0: DB::BackgroundSchedulePoolTaskInfo::execute() @ 0xc2c88 in /mnt/ch/ClickHouse/build/src/libclickhouse_core.so\r\n9. /mnt/ch/ClickHouse/contrib/poco/Foundation/include/Poco/AtomicCounter.h:314: DB::BackgroundSchedulePool::threadFunction() @ 0xc4695 in /mnt/ch/ClickHouse/build/src/libclickhouse_core.so\r\n10. /mnt/ch/ClickHouse/src/Core/BackgroundSchedulePool.cpp:0: void std::__1::__function::__policy_invoker<void ()>::__call_impl<std::__1::__function::__default_alloc_func<ThreadFromGlobalPool::ThreadFromGlobalPool<DB::BackgroundSchedulePool::BackgroundSchedulePool(unsigned long, unsigned long, char const*)::$_1>(DB::BackgroundSchedulePool::BackgroundSchedulePool(unsigned long, unsigned long, char const*)::$_1&&)::'lambda'(), void ()> >(std::__1::__function::__policy_storage const*) @ 0xc4caa in /mnt/ch/ClickHouse/build/src/libclickhouse_core.so\r\n11. /mnt/ch/ClickHouse/contrib/libcxx/include/functional:2210: ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) @ 0x16726e in /mnt/ch/ClickHouse/build/src/libclickhouse_common_io.so\r\n12. /mnt/ch/ClickHouse/contrib/libcxx/include/memory:1655: void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, void ThreadPoolImpl<std::__1::thread>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda0'()> >(void*) @ 0x1697c9 in /mnt/ch/ClickHouse/build/src/libclickhouse_common_io.so\r\n13. start_thread @ 0x9259 in /usr/lib/libpthread-2.33.so\r\n14. __clone @ 0xfe5e3 in /usr/lib/libc-2.33.so\r\n (version 21.9.1.1)\r\n2021.07.22 17:39:03.808439 [ 694783 ] {} <Debug> DNSResolver: Updated DNS cache\r\n```\r\n\r\n**Expected behavior**\r\n\r\nThe element should be removed from the cache on error, so it's only shown once (or when accessing it again), but not in every refresh.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26711/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26711/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26702","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26702/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26702/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26702/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26702","id":950656097,"node_id":"MDU6SXNzdWU5NTA2NTYwOTc=","number":26702,"title":"Clickhouse-copier removing materialized column, but column is PARTITION key","user":{"login":"orloffv","id":504986,"node_id":"MDQ6VXNlcjUwNDk4Ng==","avatar_url":"https://avatars.githubusercontent.com/u/504986?v=4","gravatar_id":"","url":"https://api.github.com/users/orloffv","html_url":"https://github.com/orloffv","followers_url":"https://api.github.com/users/orloffv/followers","following_url":"https://api.github.com/users/orloffv/following{/other_user}","gists_url":"https://api.github.com/users/orloffv/gists{/gist_id}","starred_url":"https://api.github.com/users/orloffv/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/orloffv/subscriptions","organizations_url":"https://api.github.com/users/orloffv/orgs","repos_url":"https://api.github.com/users/orloffv/repos","events_url":"https://api.github.com/users/orloffv/events{/privacy}","received_events_url":"https://api.github.com/users/orloffv/received_events","type":"User","site_admin":false},"labels":[{"id":386401505,"node_id":"MDU6TGFiZWwzODY0MDE1MDU=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/bug","name":"bug","color":"ee0701","default":true,"description":"Confirmed user-visible misbehaviour in official release"},{"id":1401853216,"node_id":"MDU6TGFiZWwxNDAxODUzMjE2","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-copier","name":"comp-copier","color":"b5bcff","default":false,"description":"clickhouse-copier"}],"state":"open","locked":false,"assignee":{"login":"nikitamikhaylov","id":25705399,"node_id":"MDQ6VXNlcjI1NzA1Mzk5","avatar_url":"https://avatars.githubusercontent.com/u/25705399?v=4","gravatar_id":"","url":"https://api.github.com/users/nikitamikhaylov","html_url":"https://github.com/nikitamikhaylov","followers_url":"https://api.github.com/users/nikitamikhaylov/followers","following_url":"https://api.github.com/users/nikitamikhaylov/following{/other_user}","gists_url":"https://api.github.com/users/nikitamikhaylov/gists{/gist_id}","starred_url":"https://api.github.com/users/nikitamikhaylov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nikitamikhaylov/subscriptions","organizations_url":"https://api.github.com/users/nikitamikhaylov/orgs","repos_url":"https://api.github.com/users/nikitamikhaylov/repos","events_url":"https://api.github.com/users/nikitamikhaylov/events{/privacy}","received_events_url":"https://api.github.com/users/nikitamikhaylov/received_events","type":"User","site_admin":false},"assignees":[{"login":"nikitamikhaylov","id":25705399,"node_id":"MDQ6VXNlcjI1NzA1Mzk5","avatar_url":"https://avatars.githubusercontent.com/u/25705399?v=4","gravatar_id":"","url":"https://api.github.com/users/nikitamikhaylov","html_url":"https://github.com/nikitamikhaylov","followers_url":"https://api.github.com/users/nikitamikhaylov/followers","following_url":"https://api.github.com/users/nikitamikhaylov/following{/other_user}","gists_url":"https://api.github.com/users/nikitamikhaylov/gists{/gist_id}","starred_url":"https://api.github.com/users/nikitamikhaylov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nikitamikhaylov/subscriptions","organizations_url":"https://api.github.com/users/nikitamikhaylov/orgs","repos_url":"https://api.github.com/users/nikitamikhaylov/repos","events_url":"https://api.github.com/users/nikitamikhaylov/events{/privacy}","received_events_url":"https://api.github.com/users/nikitamikhaylov/received_events","type":"User","site_admin":false}],"milestone":null,"comments":0,"created_at":"2021-07-22T13:18:45Z","updated_at":"2021-07-22T14:26:23Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"clickhouse-copier\r\n21.7.4\r\nclickhouse server\r\n21.7.4\r\n\r\nTable schema\r\n```\r\nCREATE TABLE name\r\n(\r\n    `timestamp` DateTime,\r\n    `queue` String DEFAULT 'general',\r\n    `totalUnknown` Int64,\r\n    `unknown1h` Int64,\r\n    `unknown2h` Int64,\r\n    `unknown4h` Int64,\r\n    `unknown8h` Int64,\r\n    `unknown16h` Int64,\r\n    `unknown24h` Int64,\r\n    `unknownPlus24h` Int64,\r\n    `unknownToday` Int64,\r\n    `moderatedToday` Int64,\r\n    `date` Date MATERIALIZED toDate(timestamp)\r\n)\r\nENGINE = ReplicatedMergeTree('/clickhouse/tables/{shard}/name', '{replica}')\r\nPARTITION BY date\r\nORDER BY timestamp\r\nSETTINGS index_granularity = 8192\r\n```\r\n\r\n```\r\n2021.07.22 16:04:36.298184 [ 143304 ] {} <Information> Application: Executing INSERT query: INSERT INTO _local.`.split.destination_cluster.name_shard_piece_0` FORMAT Native\r\n2021.07.22 16:04:36.299314 [ 143304 ] {} <Trace> InterpreterSelectQuery: Complete -> Complete\r\n2021.07.22 16:04:36.346703 [ 143304 ] {} <Debug> DistributedBlockOutputStream: _local.`.split.destination_cluster.name_piece_0`: column date will be removed, because it is MATERIALIZED\r\n2021.07.22 16:04:36.347098 [ 143304 ] {} <Trace> StorageDistributed (.read_shard_0.destination_cluster.name): (source-hostname:9000) Cancelling query\r\n2021.07.22 16:04:36.347302 [ 143304 ] {} <Error> Application: An error occurred during copying, partition will be marked as dirty: Code: 10, e.displayText() = DB::Exception: Not found column date in block: while executing 'INPUT : 0 -> date Date : 0', Stack trace (when copying this message, always include the lines below):\r\n\r\n0. DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, bool) @ 0x8d2aa5a in /usr/bin/clickhouse\r\n1. DB::Exception::Exception<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&>(int, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) @ 0x8dcf063 in /usr/bin/clickhouse\r\n2. DB::ExpressionActions::execute(DB::Block&, unsigned long&, bool) const @ 0xf818ab1 in /usr/bin/clickhouse\r\n3. DB::ExpressionActions::execute(DB::Block&, bool) const @ 0xf819262 in /usr/bin/clickhouse\r\n4. DB::DistributedBlockOutputStream::createSelector(DB::Block const&) const @ 0x102fb418 in /usr/bin/clickhouse\r\n5. DB::DistributedBlockOutputStream::writeSync(DB::Block const&) @ 0x102f8542 in /usr/bin/clickhouse\r\n6. DB::DistributedBlockOutputStream::write(DB::Block const&) @ 0x102f792b in /usr/bin/clickhouse\r\n7. DB::PushingToViewsBlockOutputStream::write(DB::Block const&) @ 0xfac0132 in /usr/bin/clickhouse\r\n8. DB::AddingDefaultBlockOutputStream::write(DB::Block const&) @ 0xfac9e8b in /usr/bin/clickhouse\r\n9. DB::CountingBlockOutputStream::write(DB::Block const&) @ 0xf80f47e in /usr/bin/clickhouse\r\n10. void DB::copyDataImpl<std::__1::function<bool ()> const&, std::__1::function<void (DB::Block const&)> const&>(DB::IBlockInputStream&, DB::IBlockOutputStream&, std::__1::function<bool ()> const&, std::__1::function<void (DB::Block const&)> const&) @ 0xf537d68 in /usr/bin/clickhouse\r\n11. DB::ClusterCopier::processPartitionPieceTaskImpl(DB::ConnectionTimeouts const&, DB::ShardPartition&, unsigned long, bool) @ 0x8e93efc in /usr/bin/clickhouse\r\n12. DB::ClusterCopier::iterateThroughAllPiecesInPartition(DB::ConnectionTimeouts const&, DB::ShardPartition&, bool) @ 0x8e8ea9f in /usr/bin/clickhouse\r\n13. DB::ClusterCopier::tryProcessPartitionTask(DB::ConnectionTimeouts const&, DB::ShardPartition&, bool) @ 0x8e8da73 in /usr/bin/clickhouse\r\n14. DB::ClusterCopier::tryProcessTable(DB::ConnectionTimeouts const&, DB::TaskTable&) @ 0x8e77af6 in /usr/bin/clickhouse\r\n15. DB::ClusterCopier::process(DB::ConnectionTimeouts const&) @ 0x8e75463 in /usr/bin/clickhouse\r\n16. DB::ClusterCopierApp::mainImpl() @ 0x8e66a3d in /usr/bin/clickhouse\r\n17. DB::ClusterCopierApp::main(std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&) @ 0x8e6993d in /usr/bin/clickhouse\r\n18. Poco::Util::Application::run() @ 0x1339a2a3 in /usr/bin/clickhouse\r\n19. mainEntryClickHouseClusterCopier(int, char**) @ 0x8e69be6 in /usr/bin/clickhouse\r\n20. main @ 0x8d257de in /usr/bin/clickhouse\r\n21. /build/glibc-S7Ft5T/glibc-2.23/csu/../csu/libc-start.c:325: __libc_start_main @ 0x20840 in /usr/lib/debug/lib/x86_64-linux-gnu/libc-2.23.so\r\n22. _start @ 0x8cf0aee in /usr/bin/clickhouse\r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26702/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26702/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26692","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26692/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26692/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26692/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26692","id":950477101,"node_id":"MDU6SXNzdWU5NTA0NzcxMDE=","number":26692,"title":"How to measure disk operations caused by max_bytes_before_external_group_by or max_bytes_before_external_sort","user":{"login":"browcio","id":1354998,"node_id":"MDQ6VXNlcjEzNTQ5OTg=","avatar_url":"https://avatars.githubusercontent.com/u/1354998?v=4","gravatar_id":"","url":"https://api.github.com/users/browcio","html_url":"https://github.com/browcio","followers_url":"https://api.github.com/users/browcio/followers","following_url":"https://api.github.com/users/browcio/following{/other_user}","gists_url":"https://api.github.com/users/browcio/gists{/gist_id}","starred_url":"https://api.github.com/users/browcio/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/browcio/subscriptions","organizations_url":"https://api.github.com/users/browcio/orgs","repos_url":"https://api.github.com/users/browcio/repos","events_url":"https://api.github.com/users/browcio/events{/privacy}","received_events_url":"https://api.github.com/users/browcio/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-07-22T09:40:32Z","updated_at":"2021-07-22T09:40:32Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"I wonder if there is a way to visualize how much data is written to disk when max_bytes_before_external_group_by or max_bytes_before_external_sort is in use. From what i searched, there are no matching column in a system.query_log or in system metrics.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26692/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26692/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26686","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26686/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26686/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26686/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26686","id":950353513,"node_id":"MDU6SXNzdWU5NTAzNTM1MTM=","number":26686,"title":"ReplacingMergeTree Query with FINAL Modifier and LIMIT Modifier unexpect result","user":{"login":"zhaixun","id":19722719,"node_id":"MDQ6VXNlcjE5NzIyNzE5","avatar_url":"https://avatars.githubusercontent.com/u/19722719?v=4","gravatar_id":"","url":"https://api.github.com/users/zhaixun","html_url":"https://github.com/zhaixun","followers_url":"https://api.github.com/users/zhaixun/followers","following_url":"https://api.github.com/users/zhaixun/following{/other_user}","gists_url":"https://api.github.com/users/zhaixun/gists{/gist_id}","starred_url":"https://api.github.com/users/zhaixun/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/zhaixun/subscriptions","organizations_url":"https://api.github.com/users/zhaixun/orgs","repos_url":"https://api.github.com/users/zhaixun/repos","events_url":"https://api.github.com/users/zhaixun/events{/privacy}","received_events_url":"https://api.github.com/users/zhaixun/received_events","type":"User","site_admin":false},"labels":[{"id":386401505,"node_id":"MDU6TGFiZWwzODY0MDE1MDU=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/bug","name":"bug","color":"ee0701","default":true,"description":"Confirmed user-visible misbehaviour in official release"},{"id":906438147,"node_id":"MDU6TGFiZWw5MDY0MzgxNDc=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/st-fixed","name":"st-fixed","color":"e5b890","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-07-22T06:48:57Z","updated_at":"2022-01-24T11:57:42Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"**Describe the bug**\r\nClickHouse client version 21.3.3.14 (official build).\r\n\r\nWhen i use  FINAL Modifier and LIMIT Modifier  on ReplacingMergeTree Engine, the returned result is not the final status\r\n\r\n**How to reproduce**\r\n\r\n\r\nStep 1:\r\nCREATE TABLE test\r\n(\r\n    `uid` String,\r\n\t`status` String,\r\n    `finalDate` DateTime DEFAULT now()\r\n)\r\nENGINE = ReplacingMergeTree(finalDate)\r\nPARTITION BY javaHash(uid) % 10\r\nORDER BY uid SETTINGS index_granularity = 8192\r\n\r\nStep2:\r\ninsert into table test(uid,status) values ('id1','0')\r\ninsert into table test(uid,status) values ('id1','1')\r\n\r\nStep3:\r\nselect * from test final\r\n┌─uid─┬─status─┬───────────finalDate─┐\r\n│ id1 │ 1      │ 2021-07-22 14:44:01 │\r\n└─────┴────────┴─────────────────────┘\r\n\r\nStep4:\r\nselect * from test final  limit 1\r\n┌─uid─┬─status─┬───────────finalDate─┐\r\n│ id1 │ 0      │ 2021-07-22 14:43:58 │\r\n└─────┴────────┴─────────────────────┘\r\n\r\nexpected result is id1,1,2021-07-22 14:44:01\r\n\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26686/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26686/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26682","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26682/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26682/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26682/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26682","id":950084699,"node_id":"MDU6SXNzdWU5NTAwODQ2OTk=","number":26682,"title":"CREATE TABLE : Can't use COMMENT inside 'Nested' columns","user":{"login":"PavelRuban","id":2482396,"node_id":"MDQ6VXNlcjI0ODIzOTY=","avatar_url":"https://avatars.githubusercontent.com/u/2482396?v=4","gravatar_id":"","url":"https://api.github.com/users/PavelRuban","html_url":"https://github.com/PavelRuban","followers_url":"https://api.github.com/users/PavelRuban/followers","following_url":"https://api.github.com/users/PavelRuban/following{/other_user}","gists_url":"https://api.github.com/users/PavelRuban/gists{/gist_id}","starred_url":"https://api.github.com/users/PavelRuban/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/PavelRuban/subscriptions","organizations_url":"https://api.github.com/users/PavelRuban/orgs","repos_url":"https://api.github.com/users/PavelRuban/repos","events_url":"https://api.github.com/users/PavelRuban/events{/privacy}","received_events_url":"https://api.github.com/users/PavelRuban/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-07-21T20:28:38Z","updated_at":"2021-07-21T20:40:42Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"I would like to use 'Nested' column type in this way: \r\n\r\n```SQL\r\nCREATE TABLE example0\r\n(\r\n    date            DateTime COMMENT 'date',\r\n    id              UInt32 COMMENT 'identity',\r\n    stats           String COMMENT 'some statistics',\r\n    nest            Nested (\r\n                        data    String COMMENT 'useful data',\r\n                        data2   String COMMENT 'one more useful data'\r\n                    )\r\n) ENGINE = MergeTree ORDER BY (date);\r\n```\r\n\r\nUnfortunately COMMENT sections under 'Nested' type is not accepted:\r\n\r\n```SHELL\r\ndefault> CREATE TABLE example0\r\n         (\r\n             date            DateTime COMMENT 'date',\r\n             id              UInt32 COMMENT 'identity',\r\n             stats           String COMMENT 'some statistics',\r\n             nest            Nested (\r\n                                 data    String COMMENT 'useful data',\r\n                                 data2   String COMMENT 'one more useful data'\r\n                             )\r\n         ) ENGINE = MergeTree ORDER BY (date)\r\n[2021-07-21 22:37:01] Code: 62, e.displayText() = DB::Exception: Syntax error: failed at position 245 ('COMMENT') (line 7, col 40): COMMENT 'useful data',\r\n[2021-07-21 22:37:01] \t                        data2   String COMMENT 'one more useful data'\r\n[2021-07-21 22:37:01] \t                    )\r\n[2021-07-21 22:37:01] \t) ENGINE = MergeTree ORDER BY (date). Expected one of: Comma, token (version 21.3.9.83 (official build))\r\n```\r\n\r\nAs soon as 'Nested' is a syntax sugar for several array columns, I expect this sugar to fully support the column definition syntax, including COMMENT section. \r\nFor now I can only put the same comment for all nested arrays (which is completely different from what I try to achieve):\r\n\r\n```SQL\r\nCREATE TABLE example1\r\n(\r\n    date            DateTime COMMENT 'date',\r\n    id              UInt32 COMMENT 'identity',\r\n    stats           String COMMENT 'some statistics',\r\n    nest            Nested (\r\n                        data    String,\r\n                        data2   String\r\n                    ) COMMENT 'nested structure'\r\n) ENGINE = MergeTree ORDER BY (date);\r\n```\r\n```SQL\r\nSELECT name, type, comment FROM system.columns WHERE table = 'example1';\r\n```\r\n| name | type | comment |\r\n| :--- | :--- | :--- |\r\n| date | DateTime | date |\r\n| id | UInt32 | identity |\r\n| stats | String | some statistics |\r\n| nest.data | Array\\(String\\) | nested structure |\r\n| nest.data2 | Array\\(String\\) | nested structure |\r\n\r\nAnother solution is to avoid 'Nested' syntax sugar and describe each array column separately:\r\n\r\n```SQL\r\nCREATE TABLE example2\r\n(\r\n    date            DateTime COMMENT 'date',\r\n    id              UInt32 COMMENT 'identity',\r\n    stats           String COMMENT 'some statistics',\r\n    `nest.data`     Array(String) COMMENT 'useful data',\r\n    `nest.data2`    Array(String) COMMENT 'one more useful data'\r\n) ENGINE = MergeTree ORDER BY (date);\r\n```\r\n```SQL\r\nSELECT name, type, comment FROM system.columns WHERE table = 'example2';\r\n```\r\n| name | type | comment |\r\n| :--- | :--- | :--- |\r\n| date | DateTime | date |\r\n| id | UInt32 | identity |\r\n| stats | String | some statistics |\r\n| nest.data | Array\\(String\\) | useful data |\r\n| nest.data2 | Array\\(String\\) | one more useful data |\r\n\r\nThis option lets me create the desired structure, but unfortunately it leaves my DDL script unsugared, which makes me unhappy.\r\n\r\nAs far as I know some people faced the same issue with the other column definition properties, for example CODEC doesn't sugared as well, as described in issue [12758](https://github.com/ClickHouse/ClickHouse/issues/12758).\r\n\r\nCan you please let me know if there is some way to achieve both syntax sugaring and different column definitions at the same time?\r\nIf there is no any way to do so currently, would you be so kind to provide such a possibility in future releases?\r\n\r\nIt seems to be a minor problem in general, but I'm afraid that any syntax sugar in this world appears to be a bit useless without full support of sugared syntax. \r\n\r\nThanks.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26682/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26682/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26674","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26674/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26674/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26674/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26674","id":949747550,"node_id":"MDU6SXNzdWU5NDk3NDc1NTA=","number":26674,"title":"POWER BI cyclic aliases ","user":{"login":"UnamedRus","id":9449405,"node_id":"MDQ6VXNlcjk0NDk0MDU=","avatar_url":"https://avatars.githubusercontent.com/u/9449405?v=4","gravatar_id":"","url":"https://api.github.com/users/UnamedRus","html_url":"https://github.com/UnamedRus","followers_url":"https://api.github.com/users/UnamedRus/followers","following_url":"https://api.github.com/users/UnamedRus/following{/other_user}","gists_url":"https://api.github.com/users/UnamedRus/gists{/gist_id}","starred_url":"https://api.github.com/users/UnamedRus/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/UnamedRus/subscriptions","organizations_url":"https://api.github.com/users/UnamedRus/orgs","repos_url":"https://api.github.com/users/UnamedRus/repos","events_url":"https://api.github.com/users/UnamedRus/events{/privacy}","received_events_url":"https://api.github.com/users/UnamedRus/received_events","type":"User","site_admin":false},"labels":[{"id":845247686,"node_id":"MDU6TGFiZWw4NDUyNDc2ODY=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/usability","name":"usability","color":"ebf28c","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2021-07-21T14:07:45Z","updated_at":"2021-07-22T03:36:51Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Describe the issue**\r\nPOWER BI generating queries heavily using aliases.\r\n\r\n\r\n**How to reproduce**\r\nClickhouse version 21.9\r\n\r\n```\r\n\r\nSELECT\r\n    Carrier,\r\n    sum(toFloat64(C3)) AS C1,\r\n    sum(toFloat64(C1)) AS C2,\r\n    sum(toFloat64(C2)) AS C3\r\nFROM\r\n(\r\n    SELECT\r\n        1 AS Carrier,\r\n        count(CAST(1, 'Nullable(Int32)')) AS C1,\r\n        max(rand()) AS C2,\r\n        min(rand32()) AS C3\r\n    FROM numbers(10)\r\n    GROUP BY Carrier\r\n) AS ITBL\r\nGROUP BY Carrier\r\nLIMIT 1000001\r\n\r\nQuery id: 72e17ae7-8d52-4fbf-a6c4-df05f707f92a\r\n\r\n\r\n0 rows in set. Elapsed: 0.003 sec.\r\n\r\nReceived exception from server (version 21.9.1):\r\nCode: 174. DB::Exception: Received from localhost:9000. DB::Exception: Cyclic aliases.\r\n\r\nset prefer_column_name_to_alias=1;\r\n\r\n\r\nSELECT\r\n    Carrier,\r\n    sum(toFloat64(C3)) AS C1,\r\n    sum(toFloat64(C1)) AS C2,\r\n    sum(toFloat64(C2)) AS C3\r\nFROM\r\n(\r\n    SELECT\r\n        1 AS Carrier,\r\n        count(CAST(1, 'Nullable(Int32)')) AS C1,\r\n        max(rand()) AS C2,\r\n        min(rand32()) AS C3\r\n    FROM numbers(10)\r\n    GROUP BY Carrier\r\n) AS ITBL\r\nGROUP BY Carrier\r\nLIMIT 1000001\r\n\r\nQuery id: 79b97002-40c1-4be3-a333-4262716c45ab\r\n\r\n\r\n0 rows in set. Elapsed: 0.003 sec.\r\n\r\nReceived exception from server (version 21.9.1):\r\nCode: 47. DB::Exception: Received from localhost:9000. DB::Exception: Unknown identifier: C1; there are columns: Carrier, C3, toFloat64(C3): While processing toFloat64(C1).\r\n```\r\n\r\nRelated https://github.com/ClickHouse/ClickHouse/issues/23194\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26674/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26674/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26578","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26578/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26578/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26578/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26578","id":948670198,"node_id":"MDU6SXNzdWU5NDg2NzAxOTg=","number":26578,"title":"PROJECTION TTL","user":{"login":"UnamedRus","id":9449405,"node_id":"MDQ6VXNlcjk0NDk0MDU=","avatar_url":"https://avatars.githubusercontent.com/u/9449405?v=4","gravatar_id":"","url":"https://api.github.com/users/UnamedRus","html_url":"https://github.com/UnamedRus","followers_url":"https://api.github.com/users/UnamedRus/followers","following_url":"https://api.github.com/users/UnamedRus/following{/other_user}","gists_url":"https://api.github.com/users/UnamedRus/gists{/gist_id}","starred_url":"https://api.github.com/users/UnamedRus/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/UnamedRus/subscriptions","organizations_url":"https://api.github.com/users/UnamedRus/orgs","repos_url":"https://api.github.com/users/UnamedRus/repos","events_url":"https://api.github.com/users/UnamedRus/events{/privacy}","received_events_url":"https://api.github.com/users/UnamedRus/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":1401282669,"node_id":"MDU6TGFiZWwxNDAxMjgyNjY5","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-ttl","name":"comp-ttl","color":"b5bcff","default":false,"description":"TTL"},{"id":3045757785,"node_id":"MDU6TGFiZWwzMDQ1NzU3Nzg1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-projections","name":"comp-projections","color":"b5bcff","default":false,"description":""}],"state":"open","locked":false,"assignee":{"login":"amosbird","id":5085485,"node_id":"MDQ6VXNlcjUwODU0ODU=","avatar_url":"https://avatars.githubusercontent.com/u/5085485?v=4","gravatar_id":"","url":"https://api.github.com/users/amosbird","html_url":"https://github.com/amosbird","followers_url":"https://api.github.com/users/amosbird/followers","following_url":"https://api.github.com/users/amosbird/following{/other_user}","gists_url":"https://api.github.com/users/amosbird/gists{/gist_id}","starred_url":"https://api.github.com/users/amosbird/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/amosbird/subscriptions","organizations_url":"https://api.github.com/users/amosbird/orgs","repos_url":"https://api.github.com/users/amosbird/repos","events_url":"https://api.github.com/users/amosbird/events{/privacy}","received_events_url":"https://api.github.com/users/amosbird/received_events","type":"User","site_admin":false},"assignees":[{"login":"amosbird","id":5085485,"node_id":"MDQ6VXNlcjUwODU0ODU=","avatar_url":"https://avatars.githubusercontent.com/u/5085485?v=4","gravatar_id":"","url":"https://api.github.com/users/amosbird","html_url":"https://github.com/amosbird","followers_url":"https://api.github.com/users/amosbird/followers","following_url":"https://api.github.com/users/amosbird/following{/other_user}","gists_url":"https://api.github.com/users/amosbird/gists{/gist_id}","starred_url":"https://api.github.com/users/amosbird/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/amosbird/subscriptions","organizations_url":"https://api.github.com/users/amosbird/orgs","repos_url":"https://api.github.com/users/amosbird/repos","events_url":"https://api.github.com/users/amosbird/events{/privacy}","received_events_url":"https://api.github.com/users/amosbird/received_events","type":"User","site_admin":false}],"milestone":null,"comments":2,"created_at":"2021-07-20T13:45:02Z","updated_at":"2021-07-21T12:23:52Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Use case**\r\nIt's needed to keep raw data for X months.\r\nBut we want to speed up queries with aggregated data without huge storage impact.\r\nAnd we do know that most of queries would use only recent data.\r\n\r\n**Describe the solution you'd like**\r\n\r\nGive ability to clear projections with ttl.\r\nSo it would be possible to generate detailed projections only for recent data and drop them for data older than Y months.\r\n\r\n**Describe alternatives you've considered**\r\nUsing materialized view, but it would require to rewrite queries based on time range which affects user experience.\r\n\r\nOr manually run CLEAR PROJECTION IN PARTITION\r\n\r\n```\r\n-   `ALTER TABLE [db.]table CLEAR PROJECTION name IN PARTITION partition_name` - Deletes projection files from disk without removing description.\r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26578/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26578/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26553","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26553/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26553/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26553/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26553","id":948521498,"node_id":"MDU6SXNzdWU5NDg1MjE0OTg=","number":26553,"title":"UInt64 bitmap operations performance decreased dramatically","user":{"login":"maehrlae","id":72405354,"node_id":"MDQ6VXNlcjcyNDA1MzU0","avatar_url":"https://avatars.githubusercontent.com/u/72405354?v=4","gravatar_id":"","url":"https://api.github.com/users/maehrlae","html_url":"https://github.com/maehrlae","followers_url":"https://api.github.com/users/maehrlae/followers","following_url":"https://api.github.com/users/maehrlae/following{/other_user}","gists_url":"https://api.github.com/users/maehrlae/gists{/gist_id}","starred_url":"https://api.github.com/users/maehrlae/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/maehrlae/subscriptions","organizations_url":"https://api.github.com/users/maehrlae/orgs","repos_url":"https://api.github.com/users/maehrlae/repos","events_url":"https://api.github.com/users/maehrlae/events{/privacy}","received_events_url":"https://api.github.com/users/maehrlae/received_events","type":"User","site_admin":false},"labels":[{"id":756395244,"node_id":"MDU6TGFiZWw3NTYzOTUyNDQ=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/performance","name":"performance","color":"c2e0c6","default":false,"description":null},{"id":2316851926,"node_id":"MDU6TGFiZWwyMzE2ODUxOTI2","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-bitmaps","name":"comp-bitmaps","color":"b5bcff","default":false,"description":"roaring bitmaps"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":4,"created_at":"2021-07-20T10:32:30Z","updated_at":"2021-08-05T10:45:50Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"**Describe the situation**\r\nComing from version 20.8.11.17 the performance of operations using bitmaps with datatype UInt64 decreased  after we upgraded to the current LTS version 21.3.14.1. The problem is also included in the current stable version.\r\n\r\nExample times from our applicataion:\r\n\r\nClickhouse 20.8.11.17 \r\n\r\n```sql\r\nCREATE TABLE vv1\r\nENGINE = Memory AS\r\nSELECT groupBitmapState(cityHash64(POSITION_ID)) AS r\r\nFROM POSITION_I\r\nWHERE (FIELDNAME = 'PTY001') AND (VALUE = 1)\r\n\r\nOk.\r\n\r\n0 rows in set. Elapsed: 2.986 sec. Processed 40.63 million rows, 2.41 GB (13.61 million rows/s., 805.86 MB/s.)\r\n```\r\ncompared to Clickhouse 21.3.14.1 \r\n```sql\r\nCREATE TABLE vv1\r\nENGINE = Memory AS\r\nSELECT groupBitmapState(cityHash64(POSITION_ID)) AS r\r\nFROM POSITION_I\r\nWHERE (FIELDNAME = 'PTY001') AND (VALUE = 1)\r\n\r\nQuery id: 80de41ae-339f-41c9-a8b7-2dde5faf4e22\r\n\r\nOk.\r\n\r\n0 rows in set. Elapsed: 70.690 sec. Processed 40.63 million rows, 2.41 GB (574.74 thousand rows/s., 34.03 MB/s.)\r\n```\r\n\r\nThose are 3 seconds versus 70 seconds for the same operation on the same data on the same machine.\r\n\r\n\r\n**How to reproduce**\r\n* Which ClickHouse server version to use\r\nClickhouse 20.8.11.17 versus Clickhouse 21.3.14.1 (or newer)\r\n\r\n* Queries to run that lead to slow performance\r\n\r\n```sql\r\nCREATE TABLE t1\r\nENGINE = Memory AS\r\nSELECT groupBitmapState(rand64()) AS r\r\nFROM numbers(30000000)\r\n\r\n\r\nSELECT bitmapCardinality(r)\r\nFROM t1\r\n```\r\n\r\n**Expected performance**\r\nExpected performance is similar to 20.8.11.17. That is\r\n\r\nCREATE TABLE t1 ....  -> around 12s\r\nSELECT bitmapCardinality(r) ... -> less than 0.01s\r\n\r\nactually it is with 21.3.14.1\r\n\r\nCREATE TABLE t1 ....  -> around 65s\r\nSELECT bitmapCardinality(r) ... -> 19s\r\n\r\nEspecially the difference for the SELECT bitmapCardinality(r) is dramatic. From 0.003s to 19s. \r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26553/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26553/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26518","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26518/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26518/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26518/events","html_url":"https://github.com/ClickHouse/ClickHouse/pull/26518","id":947793003,"node_id":"MDExOlB1bGxSZXF1ZXN0NjkyNzI2NDQz","number":26518,"title":"optimize the low cardinality column merge process","user":{"login":"compasses","id":10161171,"node_id":"MDQ6VXNlcjEwMTYxMTcx","avatar_url":"https://avatars.githubusercontent.com/u/10161171?v=4","gravatar_id":"","url":"https://api.github.com/users/compasses","html_url":"https://github.com/compasses","followers_url":"https://api.github.com/users/compasses/followers","following_url":"https://api.github.com/users/compasses/following{/other_user}","gists_url":"https://api.github.com/users/compasses/gists{/gist_id}","starred_url":"https://api.github.com/users/compasses/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/compasses/subscriptions","organizations_url":"https://api.github.com/users/compasses/orgs","repos_url":"https://api.github.com/users/compasses/repos","events_url":"https://api.github.com/users/compasses/events{/privacy}","received_events_url":"https://api.github.com/users/compasses/received_events","type":"User","site_admin":false},"labels":[{"id":1309683578,"node_id":"MDU6TGFiZWwxMzA5NjgzNTc4","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/pr-performance","name":"pr-performance","color":"007700","default":false,"description":"Pull request with some performance improvements"}],"state":"open","locked":false,"assignee":{"login":"KochetovNicolai","id":4092911,"node_id":"MDQ6VXNlcjQwOTI5MTE=","avatar_url":"https://avatars.githubusercontent.com/u/4092911?v=4","gravatar_id":"","url":"https://api.github.com/users/KochetovNicolai","html_url":"https://github.com/KochetovNicolai","followers_url":"https://api.github.com/users/KochetovNicolai/followers","following_url":"https://api.github.com/users/KochetovNicolai/following{/other_user}","gists_url":"https://api.github.com/users/KochetovNicolai/gists{/gist_id}","starred_url":"https://api.github.com/users/KochetovNicolai/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/KochetovNicolai/subscriptions","organizations_url":"https://api.github.com/users/KochetovNicolai/orgs","repos_url":"https://api.github.com/users/KochetovNicolai/repos","events_url":"https://api.github.com/users/KochetovNicolai/events{/privacy}","received_events_url":"https://api.github.com/users/KochetovNicolai/received_events","type":"User","site_admin":false},"assignees":[{"login":"KochetovNicolai","id":4092911,"node_id":"MDQ6VXNlcjQwOTI5MTE=","avatar_url":"https://avatars.githubusercontent.com/u/4092911?v=4","gravatar_id":"","url":"https://api.github.com/users/KochetovNicolai","html_url":"https://github.com/KochetovNicolai","followers_url":"https://api.github.com/users/KochetovNicolai/followers","following_url":"https://api.github.com/users/KochetovNicolai/following{/other_user}","gists_url":"https://api.github.com/users/KochetovNicolai/gists{/gist_id}","starred_url":"https://api.github.com/users/KochetovNicolai/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/KochetovNicolai/subscriptions","organizations_url":"https://api.github.com/users/KochetovNicolai/orgs","repos_url":"https://api.github.com/users/KochetovNicolai/repos","events_url":"https://api.github.com/users/KochetovNicolai/events{/privacy}","received_events_url":"https://api.github.com/users/KochetovNicolai/received_events","type":"User","site_admin":false}],"milestone":null,"comments":6,"created_at":"2021-07-19T15:50:43Z","updated_at":"2021-12-09T14:59:32Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"draft":false,"pull_request":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/pulls/26518","html_url":"https://github.com/ClickHouse/ClickHouse/pull/26518","diff_url":"https://github.com/ClickHouse/ClickHouse/pull/26518.diff","patch_url":"https://github.com/ClickHouse/ClickHouse/pull/26518.patch","merged_at":null},"body":"I hereby agree to the terms of the CLA available at: https://yandex.ru/legal/cla/?lang=en\r\n\r\nChangelog category (leave one):\r\n- Performance Improvement\r\n\r\nChangelog entry (a user-readable short description of the changes that goes to CHANGELOG.md):\r\n\r\nOptimized the low cardinality column merge process for the vertical merge algorithm. \r\n\r\nDetailed description / Documentation draft:\r\nThe improvement focus on the low cardinality column merge process, and implemented a new way to gather the low cardinality column during vertical merge.\r\nBefore the improvement, during vertical merge, each block would be gathered from several parts, and each insert would compute the dictionary, and each assembled block would cost many times dictionary compute / index cut etc.\r\nAnd this PR improve that by build a shared dictionary among the merged parts. The index of the merged parts will be transformed based on the shared dictionary, and then during the merge process only insert the index to the result column.\r\n\r\nA little performance test:\r\n\r\n```\r\nCREATE TABLE default.LCDict\r\n(\r\n    `d2` UInt32,\r\n    `d1` UInt32,\r\n    `uintlc` LowCardinality(UInt64),\r\n    `fltlc` LowCardinality(Float64),\r\n    `strlc` LowCardinality(String)\r\n)\r\nENGINE = MergeTree\r\nPARTITION BY d2\r\nORDER BY (d2, d1)\r\nSETTINGS index_granularity = 8192, vertical_merge_algorithm_min_rows_to_activate = 100000, vertical_merge_algorithm_min_columns_to_activate = 2, min_bytes_for_wide_part = 10000\r\n\r\n\r\nINSERT INTO LCDict  SELECT intDiv(number, 5000000) AS d2,number AS d1,  (rand64() % 7000 +1)*10000 AS uint,    uint * pi() as flt, ['one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten'][rand()%10+1] AS str FROM numbers(50000000) order by rand()\r\n\r\n**Before**:\r\n2021.07.19 17:52:25.304170 [ 2388944 ] {f565d0cc-a597-453b-8fe5-f2a7d8c0f9cd} <Debug> ColumnGathererStream: Gathered column uintlc (2.859778113188539 bytes/elem.) in 0.344000575 sec., 3231791.1096514883 rows/sec., 8.81 MiB/sec.\r\n2021.07.19 17:52:25.664465 [ 2388944 ] {f565d0cc-a597-453b-8fe5-f2a7d8c0f9cd} <Debug> ColumnGathererStream: Gathered column fltlc (2.859778113188539 bytes/elem.) in 0.356000595 sec., 3122854.3311844748 rows/sec., 8.52 MiB/sec.\r\n2021.07.19 17:52:25.956497 [ 2388944 ] {f565d0cc-a597-453b-8fe5-f2a7d8c0f9cd} <Debug> ColumnGathererStream: Gathered column strlc (1.0022343393857185 bytes/elem.) in 0.288000481 sec., 3860194.941827198 rows/sec., 3.69 MiB/sec.\r\n2021.07.19 17:52:25.957880 [ 2388944 ] {f565d0cc-a597-453b-8fe5-f2a7d8c0f9cd} <Debug> default.LCDict (7bfa27cc-9106-4f5a-bbfa-27cc91066f5a) (MergerMutator): Merge sorted 1111738 rows, containing 5 columns (2 merged, 3 gathered) in 1.1057698 sec., 1005397.3259172026 rows/sec., 26.01 MiB/sec.\r\n\r\n**After the improvement**:\r\n2021.07.19 17:54:02.875385 [ 2391020 ] {d59e2e5b-3f9a-474a-b9c1-d7230599766e} <Debug> ColumnGathererStream: Gathered column uintlc (2.1006459287798154 bytes/elem.) in 0.120000201 sec., 9274742.798139146 rows/sec., 18.58 MiB/sec.\r\n2021.07.19 17:54:03.000718 [ 2391020 ] {d59e2e5b-3f9a-474a-b9c1-d7230599766e} <Debug> ColumnGathererStream: Gathered column fltlc (2.1006459287798154 bytes/elem.) in 0.120000201 sec., 9274742.798139146 rows/sec., 18.58 MiB/sec.\r\n2021.07.19 17:54:03.036786 [ 2391020 ] {d59e2e5b-3f9a-474a-b9c1-d7230599766e} <Debug> ColumnGathererStream: Gathered column strlc (1.0002479848980792 bytes/elem.) in 0.032000054 sec., 34780285.058268964 rows/sec., 33.18 MiB/sec.\r\n2021.07.19 17:54:03.038090 [ 2391020 ] {d59e2e5b-3f9a-474a-b9c1-d7230599766e} <Debug> default.LCDict (7bfa27cc-9106-4f5a-bbfa-27cc91066f5a) (MergerMutator): Merge sorted 1112971 rows, containing 5 columns (2 merged, 3 gathered) in 0.392421579 sec., 2836161.565926526 rows/sec., 73.32 MiB/sec.\r\n\r\n```\r\n\r\nThe test result shows more efficient after the improvement, especially with many low cardinality columns, and the gathered block assembled scrappy from many parts.\r\n\r\n\r\nInformation about CI checks: https://clickhouse.tech/docs/en/development/continuous-integration/\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26518/reactions","total_count":4,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":4,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26518/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26503","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26503/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26503/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26503/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26503","id":947653577,"node_id":"MDU6SXNzdWU5NDc2NTM1Nzc=","number":26503,"title":"Remove 'delete_tmp_' directories on server start-up","user":{"login":"abyss7","id":5627721,"node_id":"MDQ6VXNlcjU2Mjc3MjE=","avatar_url":"https://avatars.githubusercontent.com/u/5627721?v=4","gravatar_id":"","url":"https://api.github.com/users/abyss7","html_url":"https://github.com/abyss7","followers_url":"https://api.github.com/users/abyss7/followers","following_url":"https://api.github.com/users/abyss7/following{/other_user}","gists_url":"https://api.github.com/users/abyss7/gists{/gist_id}","starred_url":"https://api.github.com/users/abyss7/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/abyss7/subscriptions","organizations_url":"https://api.github.com/users/abyss7/orgs","repos_url":"https://api.github.com/users/abyss7/repos","events_url":"https://api.github.com/users/abyss7/events{/privacy}","received_events_url":"https://api.github.com/users/abyss7/received_events","type":"User","site_admin":false},"labels":[{"id":1006992822,"node_id":"MDU6TGFiZWwxMDA2OTkyODIy","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/operations","name":"operations","color":"7fe8ba","default":false,"description":""},{"id":1365579236,"node_id":"MDU6TGFiZWwxMzY1NTc5MjM2","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/minor","name":"minor","color":"FFF8F8","default":false,"description":"Priority: minor"},{"id":3679617212,"node_id":"LA_kwDOA5dJV87bUoC8","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/yandex","name":"yandex","color":"ffcc00","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-07-19T13:26:28Z","updated_at":"2022-01-20T10:45:20Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"For some reasons when we delete a MergeTree Part in atomic way something may go wrong - and leave the `delete_tmp_*` folder or it's part on disk. This may lead to a disk space consumption over time.\r\n\r\nIt's suggested to delete this folders at least at server start-up. Current solution with `clearOldTemporaryDirectories()` doesn't work because this method is called periodically from a thread without any locks or advisory on folders - it may cause the race conditions.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26503/reactions","total_count":2,"+1":2,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26503/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26501","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26501/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26501/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26501/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26501","id":947590592,"node_id":"MDU6SXNzdWU5NDc1OTA1OTI=","number":26501,"title":"Set datatype (just like in mysql)","user":{"login":"UnamedRus","id":9449405,"node_id":"MDQ6VXNlcjk0NDk0MDU=","avatar_url":"https://avatars.githubusercontent.com/u/9449405?v=4","gravatar_id":"","url":"https://api.github.com/users/UnamedRus","html_url":"https://github.com/UnamedRus","followers_url":"https://api.github.com/users/UnamedRus/followers","following_url":"https://api.github.com/users/UnamedRus/following{/other_user}","gists_url":"https://api.github.com/users/UnamedRus/gists{/gist_id}","starred_url":"https://api.github.com/users/UnamedRus/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/UnamedRus/subscriptions","organizations_url":"https://api.github.com/users/UnamedRus/orgs","repos_url":"https://api.github.com/users/UnamedRus/repos","events_url":"https://api.github.com/users/UnamedRus/events{/privacy}","received_events_url":"https://api.github.com/users/UnamedRus/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-07-19T12:13:23Z","updated_at":"2021-07-19T12:13:23Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"ref doc http://download.nust.na/pub6/mysql/tech-resources/articles/mysql-set-datatype.html\r\n\r\n**Use case**\r\nWhen you have set of flags which could be applied at once.\r\nAnd you want to store them efficiently.\r\n\r\n\r\n**Describe the solution you'd like**\r\n\r\n```\r\nflags SET('SYN', 'ACK','FIN', 'URG', 'PSH', 'RST', 'ECE', 'CWR')\r\n```\r\n\r\n**Describe alternatives you've considered**\r\n\r\n```\r\nSELECT CAST(bitmaskToArray(toInt8(214)), 'Array(Enum8(\\'SYN\\' = 1, \\'ACK\\' = 2, \\'FIN\\' = 4, \\'URG\\' = 8, \\'PSH\\' = 16, \\'RST\\' = 32, \\'ECE\\' = 64, \\'CWR\\' = -128))') AS res\r\n┌─res─────────────────────────────┐\r\n│ ['ACK','FIN','PSH','ECE','CWR'] │\r\n└─────────────────────────────────┘\r\nSELECT bitTest(214, 1) -- is SYN \r\n```\r\n\r\n**Additional context**\r\n\r\nIt would also improve support for mysql integration.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26501/reactions","total_count":1,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":1},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26501/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26500","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26500/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26500/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26500/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26500","id":947554915,"node_id":"MDU6SXNzdWU5NDc1NTQ5MTU=","number":26500,"title":"change settings merge_max_block_size does not affect memory as stated in document","user":{"login":"xiaokang","id":680838,"node_id":"MDQ6VXNlcjY4MDgzOA==","avatar_url":"https://avatars.githubusercontent.com/u/680838?v=4","gravatar_id":"","url":"https://api.github.com/users/xiaokang","html_url":"https://github.com/xiaokang","followers_url":"https://api.github.com/users/xiaokang/followers","following_url":"https://api.github.com/users/xiaokang/following{/other_user}","gists_url":"https://api.github.com/users/xiaokang/gists{/gist_id}","starred_url":"https://api.github.com/users/xiaokang/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/xiaokang/subscriptions","organizations_url":"https://api.github.com/users/xiaokang/orgs","repos_url":"https://api.github.com/users/xiaokang/repos","events_url":"https://api.github.com/users/xiaokang/events{/privacy}","received_events_url":"https://api.github.com/users/xiaokang/received_events","type":"User","site_admin":false},"labels":[{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-07-19T11:26:30Z","updated_at":"2021-07-19T11:29:41Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"(you don't have to strictly follow this form)\r\n\r\n**Describe the unexpected behaviour**\r\nAccording to the document https://clickhouse.tech/docs/en/operations/settings/merge-tree-settings/#merge-max-block-size, merge memory size should be (num_merging_parts * merge_max_block_size * avg_row_size). But the actual memory is not as expected.\r\n\r\n**How to reproduce**\r\n* Which ClickHouse server version to use\r\n  * all\r\n* Which interface to use, if matters\r\n  * all\r\n* Non-default settings, if any\r\n  * no\r\n* `CREATE TABLE` statements for all tables involved\r\n  * no special requirement\r\n* Sample data for all these tables, use [clickhouse-obfuscator](https://github.com/ClickHouse/ClickHouse/blob/master/programs/obfuscator/Obfuscator.cpp#L42-L80) if necessary\r\n* Queries to run that lead to unexpected result\r\n  * background merge\r\n* Steps\r\n1. create a test table t1 using MergeTree Engine\r\n2. insert data to t1 with average row size 1KB\r\n3. execute 'system stop merges' to stop all merges\r\n4. wait for insert parts to be 50\r\n5. execute 'system start merges' to start merges\r\n6. execute 'select table, result_part_name, num_parts,round(memory_usage/1024/1024) as mb from system.merges' to check \r\nmerge memory usage\r\n7. change merge_max_block_size from default 8192 to 1024, and re-run steps 1-6, then compare merge memory usage\r\n\r\n\r\n**Expected behavior**\r\nIf we change merge_max_block_size from default 8192 to 1024, merge memory should decrease to 1/8. But actually it decrease only a little.\r\n\r\n**Error message and/or stacktrace**\r\nno\r\n\r\n**Additional context**\r\nno\r\n\r\n**Reason**\r\nmerge_max_block_size does not affect read buffer for each merging part due to the following code in MergeTreeSequentialSource.\r\n\r\nhttps://github.com/ClickHouse/ClickHouse/blob/c373b8674332cab5fc4a4541b49b025276a84c09/src/Storages/MergeTree/MergeTreeSequentialSource.cpp#L74\r\n\r\n```\r\nChunk MergeTreeSequentialSource::generate()\r\ntry\r\n{\r\n    const auto & header = getPort().getHeader();\r\n\r\n    if (!isCancelled() && current_row < data_part->rows_count)\r\n    {\r\n        size_t rows_to_read = data_part->index_granularity.getMarkRows(current_mark);\r\n        bool continue_reading = (current_mark != 0);\r\n\r\n        const auto & sample = reader->getColumns();\r\n        Columns columns(sample.size());\r\n        size_t rows_read = reader->readRows(current_mark, continue_reading, rows_to_read, columns);\r\n...\r\n\r\n```\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26500/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26500/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26490","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26490/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26490/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26490/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26490","id":947338658,"node_id":"MDU6SXNzdWU5NDczMzg2NTg=","number":26490,"title":"MongoDB engine can return null value when  some record lack of property in mongo collection?","user":{"login":"etdick","id":31947496,"node_id":"MDQ6VXNlcjMxOTQ3NDk2","avatar_url":"https://avatars.githubusercontent.com/u/31947496?v=4","gravatar_id":"","url":"https://api.github.com/users/etdick","html_url":"https://github.com/etdick","followers_url":"https://api.github.com/users/etdick/followers","following_url":"https://api.github.com/users/etdick/following{/other_user}","gists_url":"https://api.github.com/users/etdick/gists{/gist_id}","starred_url":"https://api.github.com/users/etdick/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/etdick/subscriptions","organizations_url":"https://api.github.com/users/etdick/orgs","repos_url":"https://api.github.com/users/etdick/repos","events_url":"https://api.github.com/users/etdick/events{/privacy}","received_events_url":"https://api.github.com/users/etdick/received_events","type":"User","site_admin":false},"labels":[{"id":386401507,"node_id":"MDU6TGFiZWwzODY0MDE1MDc=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/enhancement","name":"enhancement","color":"84b6eb","default":true,"description":null},{"id":1365689344,"node_id":"MDU6TGFiZWwxMzY1Njg5MzQ0","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-foreign-db","name":"comp-foreign-db","color":"b5bcff","default":false,"description":"Integrations with other databases"},{"id":1507888214,"node_id":"MDU6TGFiZWwxNTA3ODg4MjE0","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/st-accepted","name":"st-accepted","color":"e5b890","default":false,"description":"The issue is in our backlog, ready to take"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-07-19T07:07:56Z","updated_at":"2022-01-26T07:02:43Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"How to reproduce：\r\n1.docker image : clickhouse-server : 21.6.8.62\r\n2.CREATE TABLE statements for all tables involved\r\nCREATE TABLE IF NOT EXISTS mongo_table\r\n(\r\n_id UInt64,\r\nupdated_time DateTime,\r\naccount Nullable(String)\r\n)\r\nENGINE = MongoDB(':', '<DB_NAME>', '<COLLECTION_NAME>', '', '')\r\n\r\n3.Queries to run that lead to unexpected result\r\n\r\nselect * from mongo_table\r\nReceived exception from server (version 21.6.8):\r\nCode: 10. DB::Exception: Received from localhost:9000. DB::Exception: Column account is absent in MongoDB collection: While executing SourceFromInputStream.\r\n\r\n\r\ni found some record have no \"account \" in mongodb collection . i epxect null value when some record have no \"account \" \r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26490/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26490/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26472","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26472/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26472/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26472/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26472","id":946991505,"node_id":"MDU6SXNzdWU5NDY5OTE1MDU=","number":26472,"title":"Connection reset by peer while uploading large csv ","user":{"login":"abhinavraj23","id":32960257,"node_id":"MDQ6VXNlcjMyOTYwMjU3","avatar_url":"https://avatars.githubusercontent.com/u/32960257?v=4","gravatar_id":"","url":"https://api.github.com/users/abhinavraj23","html_url":"https://github.com/abhinavraj23","followers_url":"https://api.github.com/users/abhinavraj23/followers","following_url":"https://api.github.com/users/abhinavraj23/following{/other_user}","gists_url":"https://api.github.com/users/abhinavraj23/gists{/gist_id}","starred_url":"https://api.github.com/users/abhinavraj23/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/abhinavraj23/subscriptions","organizations_url":"https://api.github.com/users/abhinavraj23/orgs","repos_url":"https://api.github.com/users/abhinavraj23/repos","events_url":"https://api.github.com/users/abhinavraj23/events{/privacy}","received_events_url":"https://api.github.com/users/abhinavraj23/received_events","type":"User","site_admin":false},"labels":[{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2021-07-18T09:20:20Z","updated_at":"2021-07-19T15:39:05Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"**Describe the unexpected behaviour**\r\nGetting this error \r\n\r\n```\r\nCode: 210. DB::NetException: Connection reset by peer, while writing to socket (10.107.146.25:9000): data for INSERT was parsed from stdin\r\n```\r\n\r\n**How to reproduce**\r\n* Which ClickHouse server version to use\r\n21.6.5.37\r\n\r\n* `CREATE TABLE` statements for all tables involved\r\n```\r\n CREATE TABLE table_names\r\n(\r\n\r\n    {column_names and types}\r\n)\r\nENGINE = MergeTree\r\nORDER BY tuple()\r\nSETTINGS index_granularity = 8192,\r\n allow_nullable_key = 1\r\n```\r\n\r\nThe number of columns here is more than 90 and row count is roughly 2.5 M\r\n\r\n* what command am I running? \r\n```\r\ncat {filepath}.csv | sudo docker run -i --rm yandex/clickhouse-client -m --host {host}  -u {user} --input_format_allow_errors_num=10 --input_format_allow_errors_ratio=0.1  --max_memory_usage=150000000 --format_csv_allow_single_quotes 0 --input_format_skip_unknown_fields 1 --query='INSERT INTO table_name FORMAT CSVWithNames'\r\n```\r\n\r\n**Expected behavior**\r\nThe complete data  from the csv should have been inserted, and the row count should have matched, but there is a difference of > 1M rows in the row count.\r\n\r\n**Error message and/or stacktrace**\r\nCommand like error ->  \r\n```\r\nCode: 210. DB::NetException: Connection reset by peer, while writing to socket (10.107.146.25:9000): data for INSERT was parsed from stdin\r\n```\r\nError from DB (query logs)\r\n\r\n```\r\nCode: 33, e.displayText() = DB::Exception: Cannot read all data. Bytes read: 65735. Bytes expected: 134377. (version 21.6.5.37 (official build))\r\n```\r\nStacktrace (query logs)\r\n```\r\n0. DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, bool) @ 0x8b6cbba in /usr/bin/clickhouse\r\n1. DB::ReadBuffer::readStrict(char*, unsigned long) @ 0x8ba7c4d in /usr/bin/clickhouse\r\n2. DB::CompressedReadBufferBase::readCompressedData(unsigned long&, unsigned long&, bool) @ 0xf2347bc in /usr/bin/clickhouse\r\n3. DB::CompressedReadBuffer::nextImpl() @ 0xf233f27 in /usr/bin/clickhouse\r\n4. void DB::readVarUIntImpl<false>(unsigned long&, DB::ReadBuffer&) @ 0x8ba7eac in /usr/bin/clickhouse\r\n5. ? @ 0xf40843b in /usr/bin/clickhouse\r\n6. DB::SerializationString::deserializeBinaryBulk(DB::IColumn&, DB::ReadBuffer&, unsigned long, double) const @ 0xf40723b in /usr/bin/clickhouse\r\n7. DB::ISerialization::deserializeBinaryBulkWithMultipleStreams(COW<DB::IColumn>::immutable_ptr<DB::IColumn>&, unsigned long, DB::ISerialization::DeserializeBinaryBulkSettings&, std::__1::shared_ptr<DB::ISerialization::DeserializeBinaryBulkState>&, std::__1::unordered_map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, COW<DB::IColumn>::immutable_ptr<DB::IColumn>, std::__1::hash<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::equal_to<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const, COW<DB::IColumn>::immutable_ptr<DB::IColumn> > > >*) const @ 0xf3d4dd5 in /usr/bin/clickhouse\r\n8. DB::SerializationNullable::deserializeBinaryBulkWithMultipleStreams(COW<DB::IColumn>::immutable_ptr<DB::IColumn>&, unsigned long, DB::ISerialization::DeserializeBinaryBulkSettings&, std::__1::shared_ptr<DB::ISerialization::DeserializeBinaryBulkState>&, std::__1::unordered_map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, COW<DB::IColumn>::immutable_ptr<DB::IColumn>, std::__1::hash<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::equal_to<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const, COW<DB::IColumn>::immutable_ptr<DB::IColumn> > > >*) const @ 0xf3f550f in /usr/bin/clickhouse\r\n9. DB::NativeBlockInputStream::readData(DB::IDataType const&, COW<DB::IColumn>::immutable_ptr<DB::IColumn>&, DB::ReadBuffer&, unsigned long, double) @ 0xfa9f8f5 in /usr/bin/clickhouse\r\n10. DB::NativeBlockInputStream::readImpl() @ 0xfaa07b3 in /usr/bin/clickhouse\r\n11. DB::IBlockInputStream::read() @ 0xf30f452 in /usr/bin/clickhouse\r\n12. DB::TCPHandler::receiveData(bool) @ 0x104403c4 in /usr/bin/clickhouse\r\n13. DB::TCPHandler::receivePacket() @ 0x10435bec in /usr/bin/clickhouse\r\n14. DB::TCPHandler::readDataNext(unsigned long, long) @ 0x10437e5f in /usr/bin/clickhouse\r\n15. DB::TCPHandler::processInsertQuery(DB::Settings const&) @ 0x1043625e in /usr/bin/clickhouse\r\n16. DB::TCPHandler::runImpl() @ 0x1042eb09 in /usr/bin/clickhouse\r\n17. DB::TCPHandler::run() @ 0x10441839 in /usr/bin/clickhouse\r\n18. Poco::Net::TCPServerConnection::start() @ 0x12a3fd4f in /usr/bin/clickhouse\r\n19. Poco::Net::TCPServerDispatcher::run() @ 0x12a417da in /usr/bin/clickhouse\r\n20. Poco::PooledThread::run() @ 0x12b7ab39 in /usr/bin/clickhouse\r\n21. Poco::ThreadImpl::runnableEntry(void*) @ 0x12b76b2a in /usr/bin/clickhouse\r\n22. start_thread @ 0x9609 in /usr/lib/x86_64-linux-gnu/libpthread-2.31.so\r\n23. __clone @ 0x122293 in /usr/lib/x86_64-linux-gnu/libc-2.31.so\r\n\r\n```\r\n\r\n**Additional context**\r\nI initially though this was due to partitioning and order key, I removed everything, still the same issue comes and row count differs by more than 1 M rows, I am trying to insert data of 2.5M rows having more than 90 columns.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26472/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26472/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26467","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26467/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26467/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26467/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26467","id":946834473,"node_id":"MDU6SXNzdWU5NDY4MzQ0NzM=","number":26467,"title":"Table's order by allows repeating columns.","user":{"login":"den-crane","id":19737682,"node_id":"MDQ6VXNlcjE5NzM3Njgy","avatar_url":"https://avatars.githubusercontent.com/u/19737682?v=4","gravatar_id":"","url":"https://api.github.com/users/den-crane","html_url":"https://github.com/den-crane","followers_url":"https://api.github.com/users/den-crane/followers","following_url":"https://api.github.com/users/den-crane/following{/other_user}","gists_url":"https://api.github.com/users/den-crane/gists{/gist_id}","starred_url":"https://api.github.com/users/den-crane/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/den-crane/subscriptions","organizations_url":"https://api.github.com/users/den-crane/orgs","repos_url":"https://api.github.com/users/den-crane/repos","events_url":"https://api.github.com/users/den-crane/events{/privacy}","received_events_url":"https://api.github.com/users/den-crane/received_events","type":"User","site_admin":false},"labels":[{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-07-17T14:27:05Z","updated_at":"2021-07-17T14:29:49Z","closed_at":null,"author_association":"COLLABORATOR","active_lock_reason":null,"body":"Not sure is UB or expected B.\r\n\r\n```sql\r\nCREATE TABLE test\r\n(\r\n    `a` Int64\r\n)\r\nENGINE = MergeTree\r\nPRIMARY KEY a\r\nORDER BY (a, a);\r\n\r\nALTER TABLE test\r\n    ADD COLUMN `b` Int64,     MODIFY ORDER BY (a, a, b, b, b);\r\n\r\nSHOW CREATE TABLE test;\r\n\r\nCREATE TABLE test\r\n(\r\n    `a` Int64,\r\n    `b` Int64\r\n)\r\nENGINE = MergeTree\r\nPRIMARY KEY a\r\nORDER BY (a, a, b, b, b)\r\nSETTINGS index_granularity = 8192\r\n```\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26467/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26467/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26395","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26395/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26395/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26395/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26395","id":946066195,"node_id":"MDU6SXNzdWU5NDYwNjYxOTU=","number":26395,"title":"Read and Write separation implementation. ","user":{"login":"moweonlee","id":16459517,"node_id":"MDQ6VXNlcjE2NDU5NTE3","avatar_url":"https://avatars.githubusercontent.com/u/16459517?v=4","gravatar_id":"","url":"https://api.github.com/users/moweonlee","html_url":"https://github.com/moweonlee","followers_url":"https://api.github.com/users/moweonlee/followers","following_url":"https://api.github.com/users/moweonlee/following{/other_user}","gists_url":"https://api.github.com/users/moweonlee/gists{/gist_id}","starred_url":"https://api.github.com/users/moweonlee/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/moweonlee/subscriptions","organizations_url":"https://api.github.com/users/moweonlee/orgs","repos_url":"https://api.github.com/users/moweonlee/repos","events_url":"https://api.github.com/users/moweonlee/events{/privacy}","received_events_url":"https://api.github.com/users/moweonlee/received_events","type":"User","site_admin":false},"labels":[{"id":756395244,"node_id":"MDU6TGFiZWw3NTYzOTUyNDQ=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/performance","name":"performance","color":"c2e0c6","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2021-07-16T08:31:08Z","updated_at":"2021-07-19T04:27:55Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"I have been looking for some documents to implement Read/Write separation in distributed table.\r\n\r\nAnd I found an issue that read-write separation can be archived by using \"always_fetch_merged_parts\" in following [link].(https://github.com/ClickHouse/ClickHouse/issues/18452) \r\n\r\nBut I can't find any detail instruction to do that.\r\n\r\nSo can I get any detail instruction to do read-write separation ? \r\n\r\n\r\nBut anyway I think I could do that like this .\r\n\r\n I have thought there should be some nodes to ingest write and merge them to deliver merged data to read only cluster and also exactly same number of nodes are necessary in read only cluster because we can't divide or merge data parts.\r\nSo this is a constraint that I think. I just want to say this to confirm that my understanding right or wrong. \r\n\r\n The basic ideas that I have thought are each ReplicatedMergeTree should be defined with a extra remote replica in read only node.\r\nAnd a distributed table is also required to connect every ReplicatedMergeTree to read them at once in read cluster.\r\n \r\n But I'm not sure how it can explicitly define the master node and secondary node to read only merged-data in read only cluster. \r\n\r\nAny examples or guides are welcome . \r\n\r\nThanks in advance.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26395/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26395/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26376","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26376/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26376/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26376/events","html_url":"https://github.com/ClickHouse/ClickHouse/pull/26376","id":945526581,"node_id":"MDExOlB1bGxSZXF1ZXN0NjkwODQ0NTEy","number":26376,"title":"Allow promotion to common type in table function Merge","user":{"login":"kssenii","id":54203879,"node_id":"MDQ6VXNlcjU0MjAzODc5","avatar_url":"https://avatars.githubusercontent.com/u/54203879?v=4","gravatar_id":"","url":"https://api.github.com/users/kssenii","html_url":"https://github.com/kssenii","followers_url":"https://api.github.com/users/kssenii/followers","following_url":"https://api.github.com/users/kssenii/following{/other_user}","gists_url":"https://api.github.com/users/kssenii/gists{/gist_id}","starred_url":"https://api.github.com/users/kssenii/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kssenii/subscriptions","organizations_url":"https://api.github.com/users/kssenii/orgs","repos_url":"https://api.github.com/users/kssenii/repos","events_url":"https://api.github.com/users/kssenii/events{/privacy}","received_events_url":"https://api.github.com/users/kssenii/received_events","type":"User","site_admin":false},"labels":[{"id":1304141686,"node_id":"MDU6TGFiZWwxMzA0MTQxNjg2","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/pr-improvement","name":"pr-improvement","color":"007700","default":false,"description":"Pull request with some product improvements"}],"state":"open","locked":false,"assignee":{"login":"CurtizJ","id":20361854,"node_id":"MDQ6VXNlcjIwMzYxODU0","avatar_url":"https://avatars.githubusercontent.com/u/20361854?v=4","gravatar_id":"","url":"https://api.github.com/users/CurtizJ","html_url":"https://github.com/CurtizJ","followers_url":"https://api.github.com/users/CurtizJ/followers","following_url":"https://api.github.com/users/CurtizJ/following{/other_user}","gists_url":"https://api.github.com/users/CurtizJ/gists{/gist_id}","starred_url":"https://api.github.com/users/CurtizJ/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/CurtizJ/subscriptions","organizations_url":"https://api.github.com/users/CurtizJ/orgs","repos_url":"https://api.github.com/users/CurtizJ/repos","events_url":"https://api.github.com/users/CurtizJ/events{/privacy}","received_events_url":"https://api.github.com/users/CurtizJ/received_events","type":"User","site_admin":false},"assignees":[{"login":"CurtizJ","id":20361854,"node_id":"MDQ6VXNlcjIwMzYxODU0","avatar_url":"https://avatars.githubusercontent.com/u/20361854?v=4","gravatar_id":"","url":"https://api.github.com/users/CurtizJ","html_url":"https://github.com/CurtizJ","followers_url":"https://api.github.com/users/CurtizJ/followers","following_url":"https://api.github.com/users/CurtizJ/following{/other_user}","gists_url":"https://api.github.com/users/CurtizJ/gists{/gist_id}","starred_url":"https://api.github.com/users/CurtizJ/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/CurtizJ/subscriptions","organizations_url":"https://api.github.com/users/CurtizJ/orgs","repos_url":"https://api.github.com/users/CurtizJ/repos","events_url":"https://api.github.com/users/CurtizJ/events{/privacy}","received_events_url":"https://api.github.com/users/CurtizJ/received_events","type":"User","site_admin":false}],"milestone":null,"comments":4,"created_at":"2021-07-15T15:48:30Z","updated_at":"2021-12-09T15:51:46Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"draft":false,"pull_request":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/pulls/26376","html_url":"https://github.com/ClickHouse/ClickHouse/pull/26376","diff_url":"https://github.com/ClickHouse/ClickHouse/pull/26376.diff","patch_url":"https://github.com/ClickHouse/ClickHouse/pull/26376.patch","merged_at":null},"body":"I hereby agree to the terms of the CLA available at: https://yandex.ru/legal/cla/?lang=en\r\n\r\nChangelog category (leave one):\r\n- Improvement\r\n\r\nChangelog entry (a user-readable short description of the changes that goes to CHANGELOG.md):\r\nAllow promotion to common type in table function Merge. Closes https://github.com/ClickHouse/ClickHouse/issues/14700.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26376/reactions","total_count":2,"+1":0,"-1":0,"laugh":0,"hooray":2,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26376/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26369","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26369/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26369/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26369/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26369","id":945390289,"node_id":"MDU6SXNzdWU5NDUzOTAyODk=","number":26369,"title":"Projections are not very smart about datetime dimension.","user":{"login":"den-crane","id":19737682,"node_id":"MDQ6VXNlcjE5NzM3Njgy","avatar_url":"https://avatars.githubusercontent.com/u/19737682?v=4","gravatar_id":"","url":"https://api.github.com/users/den-crane","html_url":"https://github.com/den-crane","followers_url":"https://api.github.com/users/den-crane/followers","following_url":"https://api.github.com/users/den-crane/following{/other_user}","gists_url":"https://api.github.com/users/den-crane/gists{/gist_id}","starred_url":"https://api.github.com/users/den-crane/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/den-crane/subscriptions","organizations_url":"https://api.github.com/users/den-crane/orgs","repos_url":"https://api.github.com/users/den-crane/repos","events_url":"https://api.github.com/users/den-crane/events{/privacy}","received_events_url":"https://api.github.com/users/den-crane/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":3045757785,"node_id":"MDU6TGFiZWwzMDQ1NzU3Nzg1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-projections","name":"comp-projections","color":"b5bcff","default":false,"description":""}],"state":"open","locked":false,"assignee":{"login":"amosbird","id":5085485,"node_id":"MDQ6VXNlcjUwODU0ODU=","avatar_url":"https://avatars.githubusercontent.com/u/5085485?v=4","gravatar_id":"","url":"https://api.github.com/users/amosbird","html_url":"https://github.com/amosbird","followers_url":"https://api.github.com/users/amosbird/followers","following_url":"https://api.github.com/users/amosbird/following{/other_user}","gists_url":"https://api.github.com/users/amosbird/gists{/gist_id}","starred_url":"https://api.github.com/users/amosbird/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/amosbird/subscriptions","organizations_url":"https://api.github.com/users/amosbird/orgs","repos_url":"https://api.github.com/users/amosbird/repos","events_url":"https://api.github.com/users/amosbird/events{/privacy}","received_events_url":"https://api.github.com/users/amosbird/received_events","type":"User","site_admin":false},"assignees":[{"login":"amosbird","id":5085485,"node_id":"MDQ6VXNlcjUwODU0ODU=","avatar_url":"https://avatars.githubusercontent.com/u/5085485?v=4","gravatar_id":"","url":"https://api.github.com/users/amosbird","html_url":"https://github.com/amosbird","followers_url":"https://api.github.com/users/amosbird/followers","following_url":"https://api.github.com/users/amosbird/following{/other_user}","gists_url":"https://api.github.com/users/amosbird/gists{/gist_id}","starred_url":"https://api.github.com/users/amosbird/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/amosbird/subscriptions","organizations_url":"https://api.github.com/users/amosbird/orgs","repos_url":"https://api.github.com/users/amosbird/repos","events_url":"https://api.github.com/users/amosbird/events{/privacy}","received_events_url":"https://api.github.com/users/amosbird/received_events","type":"User","site_admin":false}],"milestone":null,"comments":1,"created_at":"2021-07-15T13:38:57Z","updated_at":"2022-01-09T18:05:05Z","closed_at":null,"author_association":"COLLABORATOR","active_lock_reason":null,"body":"```sql\r\ncreate table ptest ( account UInt64, clip UInt64, ts DateTime, v Int64, play Int64,  uid Int64 )  Engine = MergeTree order by tuple();\r\n\r\ninsert into ptest select number%3, number%7, toDateTime('2020-01-01 00:00:00') + number*100, number, number, number from  numbers(10000000);\r\n\r\n\r\nalter table ptest add projection pr1 \r\n    (select account, clip, toDate(ts),  sum(v) as loads, sum(play) as plays,  \r\n     uniq(uid) as unique_loads group by account,clip, \r\n     toDate(ts));\r\n\r\nalter table ptest materialize projection pr1;\r\n\r\nset allow_experimental_projection_optimization = 1;\r\n```\r\n\r\n### Projection is used \r\n\r\n```sql\r\nselect clip,  sum(v), sum(play), uniq(uid) \r\nfrom ptest　\r\nwhere account=1 and toDate(ts) >= '2020-03-01' AND toDate(ts) <= '2020-04-01'\r\ngroup by clip \r\nformat Null;\r\n\r\nProcessed 127.56 thousand rows\r\n\r\nselect clip, toDate(ts), sum(v), sum(play), uniq(uid) \r\nfrom ptest　\r\nwhere account=1 and toDate(ts) >= '2020-03-01' AND toDate(ts) <= '2020-04-01'\r\ngroup by clip, toDate(ts) \r\nformat Null;\r\n\r\nProcessed 127.56 thousand rows\r\n```\r\n\r\n### Projection is not used \r\n```sql\r\nselect clip, toYYYYMM(ts), sum(v), sum(play), uniq(uid) \r\nfrom ptest　\r\nwhere account=1 and toDate(ts) >= '2020-03-01' AND toDate(ts) <= '2020-04-01'\r\ngroup by clip, toYYYYMM(ts) \r\nformat Null;\r\n\r\nProcessed 10.00 million rows\r\n\r\n\r\nselect clip, sum(v), sum(play), uniq(uid) \r\nfrom ptest　\r\nwhere account=1 and \r\n        toStartOfMonth(ts) >= toStartOfMonth(toDate('2020-03-01')) AND toStartOfMonth(ts) <= toStartOfMonth(toDate('2020-04-01'))\r\ngroup by clip\r\nformat Null;\r\n\r\nProcessed 10.00 million rows\r\n```\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26369/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26369/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26331","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26331/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26331/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26331/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26331","id":944823174,"node_id":"MDU6SXNzdWU5NDQ4MjMxNzQ=","number":26331,"title":"ttl_only_drop_parts affects TTL for columns in a strange way","user":{"login":"SaltTan","id":20357526,"node_id":"MDQ6VXNlcjIwMzU3NTI2","avatar_url":"https://avatars.githubusercontent.com/u/20357526?v=4","gravatar_id":"","url":"https://api.github.com/users/SaltTan","html_url":"https://github.com/SaltTan","followers_url":"https://api.github.com/users/SaltTan/followers","following_url":"https://api.github.com/users/SaltTan/following{/other_user}","gists_url":"https://api.github.com/users/SaltTan/gists{/gist_id}","starred_url":"https://api.github.com/users/SaltTan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/SaltTan/subscriptions","organizations_url":"https://api.github.com/users/SaltTan/orgs","repos_url":"https://api.github.com/users/SaltTan/repos","events_url":"https://api.github.com/users/SaltTan/events{/privacy}","received_events_url":"https://api.github.com/users/SaltTan/received_events","type":"User","site_admin":false},"labels":[{"id":1401282669,"node_id":"MDU6TGFiZWwxNDAxMjgyNjY5","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-ttl","name":"comp-ttl","color":"b5bcff","default":false,"description":"TTL"},{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-07-14T21:50:10Z","updated_at":"2021-07-15T00:20:13Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"I enabled TTL for several columns, and I used different TTL expressions with different TTL periods.\r\nI also enabled `ttl_only_drop_parts` because I didn't want ClickHouse to re-merge older parts (I know for sure my TTL expressions lead to the same value for all rows in a part).\r\nHowever the merges were still being scheduled, and only for the parts where all TTL columns got expired, i.e for the longest TTL period.\r\nAs a result only the column with the longest TTL period was getting cleaned.\r\n\r\nTo be more specific:\r\n```\r\n-- different TTL expressions for different columns\r\n  `test_k` Array(String) TTL access_day + toIntervalDay (30),\r\n  `test_n` Array(String) TTL access_day + toIntervalDay (2),\r\nPARTITION BY access_day\r\n\r\n-- performed TTL merges\r\nevent_type | event_time_microseconds    | duration_ms | partition_id\r\n-----------+----------------------------+-------------+-------------\r\nMergeParts | 2021-07-13 00:26:05.206236 |     1562765 | 20210613    \r\nMergeParts | 2021-07-14 00:25:36.490712 |     1532606 | 20210614    \r\n\r\n-- I disabled ttl_only_drop_parts\r\nevent_time          | query                                                                                                                                                     \r\n--------------------+--------------------------------\r\n2021-07-14 17:08:26 | alter table shard modify setting ttl_only_drop_parts=0\r\n\r\n-- Which triggered merges for the parts with the expired `test_n` column\r\nminus(event_time, divide(duration_ms, 1000)) | event_time          | event_type | partition_id\r\n---------------------------------------------+---------------------+------------+-------------\r\n2021-07-14 17:08:28                          | 2021-07-14 17:46:02 | MergeParts | 20210706    \r\n2021-07-14 17:46:03                          | 2021-07-14 17:46:48 | MergeParts | 20210707    \r\n2021-07-14 17:46:49                          | 2021-07-14 18:21:12 | MergeParts | 20210708    \r\n2021-07-14 18:21:12                          | 2021-07-14 18:48:00 | MergeParts | 20210709    \r\n2021-07-14 18:48:01                          | 2021-07-14 19:14:54 | MergeParts | 20210710    \r\n2021-07-14 19:14:54                          | 2021-07-14 19:46:05 | MergeParts | 20210711    \r\n2021-07-14 19:46:06                          | 2021-07-14 20:13:48 | MergeParts | 20210712    \r\n```\r\n\r\nI would expect ClickHouse to schedule two TTL operations every day, one for `test_k` and one for `test_n`.\r\nI also expect ClickHouse to just drop the column's files from eligible parts without merging everything else if `ttl_only_drop_parts` is enabled.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26331/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26331/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26328","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26328/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26328/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26328/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26328","id":944733401,"node_id":"MDU6SXNzdWU5NDQ3MzM0MDE=","number":26328,"title":"TTL for columns does not need to merge the table if it only needs to clear a column","user":{"login":"SaltTan","id":20357526,"node_id":"MDQ6VXNlcjIwMzU3NTI2","avatar_url":"https://avatars.githubusercontent.com/u/20357526?v=4","gravatar_id":"","url":"https://api.github.com/users/SaltTan","html_url":"https://github.com/SaltTan","followers_url":"https://api.github.com/users/SaltTan/followers","following_url":"https://api.github.com/users/SaltTan/following{/other_user}","gists_url":"https://api.github.com/users/SaltTan/gists{/gist_id}","starred_url":"https://api.github.com/users/SaltTan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/SaltTan/subscriptions","organizations_url":"https://api.github.com/users/SaltTan/orgs","repos_url":"https://api.github.com/users/SaltTan/repos","events_url":"https://api.github.com/users/SaltTan/events{/privacy}","received_events_url":"https://api.github.com/users/SaltTan/received_events","type":"User","site_admin":false},"labels":[{"id":1401282669,"node_id":"MDU6TGFiZWwxNDAxMjgyNjY5","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-ttl","name":"comp-ttl","color":"b5bcff","default":false,"description":"TTL"},{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-07-14T19:33:00Z","updated_at":"2021-07-15T00:20:04Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"When TTL for a column expires it triggers a merge.\r\nInstead of re-merging all parts TTL for columns can work more like CLEAR COLUMN, at least when `ttl_only_drop_parts` is enabled.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26328/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26328/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26327","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26327/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26327/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26327/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26327","id":944728930,"node_id":"MDU6SXNzdWU5NDQ3Mjg5MzA=","number":26327,"title":"If server killed in a moment after table metadata was changed in ZooKeeper but before it was changed locally (by ALTER MODIFY COLUMN) query, it may refuse to start.","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":2104602822,"node_id":"MDU6TGFiZWwyMTA0NjAyODIy","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/fuzz","name":"fuzz","color":"abc4ea","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-07-14T19:25:56Z","updated_at":"2021-08-26T11:49:10Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"https://clickhouse-test-reports.s3.yandex.net/0/1b4d2cbc6da217f0f89ba791f40fec3ca05d464e/stress_test_(thread).html\r\n\r\n```\r\n4095002:2021.07.07 14:51:03.075351 [ 42181 ] {} <Information> test_21.concurrent_mutate_kill (4b4fbb74-5d6c-44b0-8b4f-bb745d6c44b0): Metadata changed in ZooKeeper. Applying changes locally.\r\n...\r\nSIGKILL received\r\n...\r\n2021.07.07 14:58:20.636554 [ 355147 ] {} <Error> Application: DB::Exception: Table columns structure in ZooKeeper is different from local table structure: Cannot attach table `test_21`.`concurrent_mutate_kill` from metadata file /var/lib/clickhouse/store/c2a/c2a4cf77-eba8-42ed-82a4-cf77eba862ed/concurrent_mutate_kill.sql from query ATTACH TABLE test_21.concurrent_mutate_kill UUID '4b4fbb74-5d6c-44b0-8b4f-bb745d6c44b0' (`key` UInt64, `value` UInt64) ENGINE = ReplicatedMergeTree('/clickhouse/tables/01593_concurrent_alter_mutations_kill_test_21/concurrent_mutate_kill', '1') PARTITION BY key % 100 ORDER BY key SETTINGS max_replicated_mutations_in_queue = 1000, number_of_free_entries_in_pool_to_execute_mutation = 0, max_replicated_merges_in_queue = 1000, index_granularity = 8192: while loading database `test_21` from path /var/lib/clickhouse/metadata/test_21\r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26327/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26327/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26315","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26315/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26315/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26315/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26315","id":944415462,"node_id":"MDU6SXNzdWU5NDQ0MTU0NjI=","number":26315,"title":"ORDER BY LIMIT x constraint optimization.","user":{"login":"UnamedRus","id":9449405,"node_id":"MDQ6VXNlcjk0NDk0MDU=","avatar_url":"https://avatars.githubusercontent.com/u/9449405?v=4","gravatar_id":"","url":"https://api.github.com/users/UnamedRus","html_url":"https://github.com/UnamedRus","followers_url":"https://api.github.com/users/UnamedRus/followers","following_url":"https://api.github.com/users/UnamedRus/following{/other_user}","gists_url":"https://api.github.com/users/UnamedRus/gists{/gist_id}","starred_url":"https://api.github.com/users/UnamedRus/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/UnamedRus/subscriptions","organizations_url":"https://api.github.com/users/UnamedRus/orgs","repos_url":"https://api.github.com/users/UnamedRus/repos","events_url":"https://api.github.com/users/UnamedRus/events{/privacy}","received_events_url":"https://api.github.com/users/UnamedRus/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-07-14T13:12:45Z","updated_at":"2021-07-14T13:14:27Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Use case**\r\nWe have column (rating) which could have only specific values in it: (1-10 or [1,5,10])\r\nAnd we use this column in ORDER BY clause:\r\n\r\n```\r\nSELECT * FROM table ORDER BY rating DESC LIMIT 5;\r\n```\r\n\r\nAnd we do know in advantage that this column can't have value bigger than 10.\r\nSo we don't need to sort all table to first find largest value / apply order by / limit\r\nWe can just stop searching after first 5 rows with rating column = 10 will be found.\r\n\r\n\r\n**Describe the solution you'd like**\r\nOptimization build in clickhouse\r\n\r\n\r\n**Additional context**\r\nRelated to https://github.com/ClickHouse/ClickHouse/pull/18787\r\nRelated to https://github.com/ClickHouse/ClickHouse/pull/26286\r\nAnd also could be used with min_max skip indexes.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26315/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26315/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26306","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26306/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26306/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26306/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26306","id":944277359,"node_id":"MDU6SXNzdWU5NDQyNzczNTk=","number":26306,"title":"Users created by RBAC /access_management,  use \"show databases\" to return no data  ","user":{"login":"FanWuu","id":41465662,"node_id":"MDQ6VXNlcjQxNDY1NjYy","avatar_url":"https://avatars.githubusercontent.com/u/41465662?v=4","gravatar_id":"","url":"https://api.github.com/users/FanWuu","html_url":"https://github.com/FanWuu","followers_url":"https://api.github.com/users/FanWuu/followers","following_url":"https://api.github.com/users/FanWuu/following{/other_user}","gists_url":"https://api.github.com/users/FanWuu/gists{/gist_id}","starred_url":"https://api.github.com/users/FanWuu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/FanWuu/subscriptions","organizations_url":"https://api.github.com/users/FanWuu/orgs","repos_url":"https://api.github.com/users/FanWuu/repos","events_url":"https://api.github.com/users/FanWuu/events{/privacy}","received_events_url":"https://api.github.com/users/FanWuu/received_events","type":"User","site_admin":false},"labels":[{"id":386401509,"node_id":"MDU6TGFiZWwzODY0MDE1MDk=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/invalid","name":"invalid","color":"e6e6e6","default":true,"description":null},{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""}],"state":"open","locked":false,"assignee":{"login":"vitlibar","id":45142681,"node_id":"MDQ6VXNlcjQ1MTQyNjgx","avatar_url":"https://avatars.githubusercontent.com/u/45142681?v=4","gravatar_id":"","url":"https://api.github.com/users/vitlibar","html_url":"https://github.com/vitlibar","followers_url":"https://api.github.com/users/vitlibar/followers","following_url":"https://api.github.com/users/vitlibar/following{/other_user}","gists_url":"https://api.github.com/users/vitlibar/gists{/gist_id}","starred_url":"https://api.github.com/users/vitlibar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vitlibar/subscriptions","organizations_url":"https://api.github.com/users/vitlibar/orgs","repos_url":"https://api.github.com/users/vitlibar/repos","events_url":"https://api.github.com/users/vitlibar/events{/privacy}","received_events_url":"https://api.github.com/users/vitlibar/received_events","type":"User","site_admin":false},"assignees":[{"login":"vitlibar","id":45142681,"node_id":"MDQ6VXNlcjQ1MTQyNjgx","avatar_url":"https://avatars.githubusercontent.com/u/45142681?v=4","gravatar_id":"","url":"https://api.github.com/users/vitlibar","html_url":"https://github.com/vitlibar","followers_url":"https://api.github.com/users/vitlibar/followers","following_url":"https://api.github.com/users/vitlibar/following{/other_user}","gists_url":"https://api.github.com/users/vitlibar/gists{/gist_id}","starred_url":"https://api.github.com/users/vitlibar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vitlibar/subscriptions","organizations_url":"https://api.github.com/users/vitlibar/orgs","repos_url":"https://api.github.com/users/vitlibar/repos","events_url":"https://api.github.com/users/vitlibar/events{/privacy}","received_events_url":"https://api.github.com/users/vitlibar/received_events","type":"User","site_admin":false}],"milestone":null,"comments":4,"created_at":"2021-07-14T10:24:03Z","updated_at":"2021-07-15T07:11:44Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"### this is user.xml\r\n    <yandex>\r\n    <users>\r\n        <default>\r\n            <password>TEST123</password>\r\n            <networks>\r\n                <ip>::/0</ip>\r\n            </networks>\r\n            <profile>default</profile>\r\n            <quota>default</quota>\r\n            <databases>\r\n                <system>\r\n                    <tables>\r\n                        <filter>database != 'system'</filter>\r\n                    </tables>\r\n                    <databases>\r\n                        <filter>name != 'system'</filter>\r\n                    </databases>\r\n                </system>\r\n            </databases>\r\n        </default>\r\n    </users>\r\n    </yandex>\r\n\r\n### create user  by  RBAC /access_management\r\necho \"CREATE USER admin IDENTIFIED WITH PLAINTEXT_PASSWORD BY '123' \" | clickhouse-client -u default\r\necho \"GRANT ALL ON . TO admin WITH GRANT OPTION \" | clickhouse-client -u default\r\n\r\n### show database , show tables \r\necho \"show databases \" | clickhouse-client -u admin\r\necho \"show tables \" | clickhouse-client -u admin\r\n\r\n#### sql returns empty results\r\n\r\n![8a11c627fb3f50441fc75e79a6fb3b6](https://user-images.githubusercontent.com/41465662/125605336-ae48a4ee-3c40-4321-bfb2-39ae53299bd2.png)\r\n\r\n### remove /user/databases in  user.xml\r\n      <databases>\r\n              <system>\r\n                      <tables>\r\n                          <filter>database != 'system'</filter>\r\n                      </tables>\r\n                      <databases>\r\n                          <filter>name != 'system'</filter>\r\n                      </databases>\r\n                  </system>\r\n         </databases>\r\n\r\n\r\nUsers \"admin\"  created by RBAC /access_management    \r\nwhen  database filter  in user.xml   , echo ''show databases ‘' |clickhouse-client   -u admin   returns empty results\r\nwhen remove  database filter  in user.xml  ,  echo ''show databases ‘' |clickhouse-client   -u admin    Can return the result normally .\r\nIs This a bug,？ or other configurations need to be modified\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26306/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26306/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26268","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26268/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26268/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26268/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26268","id":943131125,"node_id":"MDU6SXNzdWU5NDMxMzExMjU=","number":26268,"title":"Optimization Union/Join at query filtration","user":{"login":"fantom0005","id":3921689,"node_id":"MDQ6VXNlcjM5MjE2ODk=","avatar_url":"https://avatars.githubusercontent.com/u/3921689?v=4","gravatar_id":"","url":"https://api.github.com/users/fantom0005","html_url":"https://github.com/fantom0005","followers_url":"https://api.github.com/users/fantom0005/followers","following_url":"https://api.github.com/users/fantom0005/following{/other_user}","gists_url":"https://api.github.com/users/fantom0005/gists{/gist_id}","starred_url":"https://api.github.com/users/fantom0005/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/fantom0005/subscriptions","organizations_url":"https://api.github.com/users/fantom0005/orgs","repos_url":"https://api.github.com/users/fantom0005/repos","events_url":"https://api.github.com/users/fantom0005/events{/privacy}","received_events_url":"https://api.github.com/users/fantom0005/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":1357578153,"node_id":"MDU6TGFiZWwxMzU3NTc4MTUz","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-joins","name":"comp-joins","color":"b5bcff","default":false,"description":"JOINs"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":6,"created_at":"2021-07-13T10:22:27Z","updated_at":"2021-09-27T12:36:57Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"**Use case**\r\nWe join/union several tables with billions of rows of ad campaigns data, filtered by time range. For the most of the cases we need only recent months of data. But now it spends a lot of memory because the external filter doesn't apply on table which we join/union. \r\nSo all data in the joined table is loaded into RAM.\r\n\r\nSomeone in Clickhouse support chat (telegram) has recommended a workaround with the suggestion to join sub queries parametrized via custom settings. But it isn't convenient as we want to create views with joins/unions and use them for directly connected BI tools (different filters applied on fly).\r\n\r\n\r\n**Describe the solution you'd like**\r\nWe have 2 tables and we write join sql.\r\n```sql\r\ncreate table ads_report\r\n(\r\n    date Date,\r\n    ad_id String,\r\n    clicks Float64\r\n)\r\nengine = MergeTree PARTITION BY toYYYYMM(date)\r\nORDER BY date;\r\n\r\ncreate table ads_report_2\r\n(\r\n    date Date,\r\n    ad_id String,\r\n    impression Float64\r\n)\r\nengine = MergeTree PARTITION BY toYYYYMM(date)\r\nORDER BY date;\r\n```\r\n```sql\r\n# query with join\r\nselect * from ads_report ar\r\njoin ads_report_2 ar2 on ar.ad_id=ar2.ad_id and ar.date = ar2.date\r\nwhere ar.date >= '2021-01-01';\r\n\r\n# current plan\r\nEXPLAIN\r\nSELECT *\r\nFROM ads_report AS ar\r\nINNER JOIN ads_report_2 AS ar2 ON ar.ad_id = ar2.ad_id\r\nWHERE ar.date >= '2021-01-01'\r\n\r\n┌─explain─────────────────────────────────────────────────────────────────────────────┐\r\n│ Expression (Projection)                                                             │\r\n│   CreatingSets (Create sets before main query execution)                            │\r\n│     Expression (Before ORDER BY)                                                    │\r\n│       Filter (WHERE)                                                                │\r\n│         Join (JOIN)                                                                 │\r\n│           Expression (Before JOIN)                                                  │\r\n│             SettingQuotaAndLimits (Set limits and quota after reading from storage) │\r\n│               ReadFromPreparedSource (Read from NullSource)                         │\r\n│     CreatingSet (Create set for JOIN)                                               │\r\n│       Expression (Projection + Before ORDER BY)                                     │\r\n│         SettingQuotaAndLimits (Set limits and quota after reading from storage)     │\r\n│           ReadFromPreparedSource (Read from NullSource)                             │\r\n└─────────────────────────────────────────────────────────────────────────────────────┘\r\n\r\n# --------------------------------------\r\n# desired plan. It's like use subquery\r\n\r\n\r\nEXPLAIN\r\nSELECT *\r\nFROM ads_report AS ar\r\nINNER JOIN \r\n(\r\n    SELECT *\r\n    FROM ads_report_2\r\n    WHERE date >= '2021-01-01'\r\n) AS ar2 ON (ar.ad_id = ar2.ad_id) AND (ar.date = ar2.date)\r\nWHERE ar.date >= '2021-01-01'\r\n\r\n\r\n┌─explain─────────────────────────────────────────────────────────────────────────────┐\r\n│ Expression (Projection)                                                             │\r\n│   CreatingSets (Create sets before main query execution)                            │\r\n│     Expression (Before ORDER BY)                                                    │\r\n│       Filter (WHERE)                                                                │\r\n│         Join (JOIN)                                                                 │\r\n│           Expression (Before JOIN)                                                  │\r\n│             SettingQuotaAndLimits (Set limits and quota after reading from storage) │\r\n│               ReadFromPreparedSource (Read from NullSource)                         │\r\n│     CreatingSet (Create set for JOIN)                                               │\r\n│       Expression (Projection + Before ORDER BY)                                     │\r\n│         Filter (WHERE)   # need to this filter                                      │\r\n│           SettingQuotaAndLimits (Set limits and quota after reading from storage)   │\r\n│             ReadFromPreparedSource (Read from NullSource)                           │\r\n└─────────────────────────────────────────────────────────────────────────────────────┘\r\n```\r\n\r\n\r\n***High level solution***\r\nGuys, I know that the steps are naive and not so simple. But I imagine it this way:\r\n* receive fields which tables joined\r\n* get external filters by this fields\r\n* apply filters on SQL for the query which loaded data from joined table \r\n* ... do standard algorithm\r\n\r\n\r\n\r\n**PS**\r\nPossibly we can develop this feature ourselves. But we don't have experience with clickhouse.\r\nCan you say how difficult it is?\r\nHow long can implantation take?\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26268/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26268/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26255","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26255/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26255/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26255/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26255","id":942251171,"node_id":"MDU6SXNzdWU5NDIyNTExNzE=","number":26255,"title":"FR: Expose what triggered the merge in system.part_log","user":{"login":"SaltTan","id":20357526,"node_id":"MDQ6VXNlcjIwMzU3NTI2","avatar_url":"https://avatars.githubusercontent.com/u/20357526?v=4","gravatar_id":"","url":"https://api.github.com/users/SaltTan","html_url":"https://github.com/SaltTan","followers_url":"https://api.github.com/users/SaltTan/followers","following_url":"https://api.github.com/users/SaltTan/following{/other_user}","gists_url":"https://api.github.com/users/SaltTan/gists{/gist_id}","starred_url":"https://api.github.com/users/SaltTan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/SaltTan/subscriptions","organizations_url":"https://api.github.com/users/SaltTan/orgs","repos_url":"https://api.github.com/users/SaltTan/repos","events_url":"https://api.github.com/users/SaltTan/events{/privacy}","received_events_url":"https://api.github.com/users/SaltTan/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":644208617,"node_id":"MDU6TGFiZWw2NDQyMDg2MTc=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/easy%20task","name":"easy task","color":"0e8a16","default":false,"description":"Good for first contributors"},{"id":1401282669,"node_id":"MDU6TGFiZWwxNDAxMjgyNjY5","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-ttl","name":"comp-ttl","color":"b5bcff","default":false,"description":"TTL"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":7,"created_at":"2021-07-12T16:52:00Z","updated_at":"2021-12-23T08:50:58Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"It would be great to see what TTL rule triggered a particular merge.\r\nThe other reasons are nice to see as well, like an OPTIMIZE statement etc.\r\nMaybe add a row when a merge starts? Like in system.query_log.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26255/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26255/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26253","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26253/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26253/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26253/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26253","id":942184229,"node_id":"MDU6SXNzdWU5NDIxODQyMjk=","number":26253,"title":"Allow custom merge in AggregatingMergeTree when column is of simple type","user":{"login":"asafcombo","id":12124039,"node_id":"MDQ6VXNlcjEyMTI0MDM5","avatar_url":"https://avatars.githubusercontent.com/u/12124039?v=4","gravatar_id":"","url":"https://api.github.com/users/asafcombo","html_url":"https://github.com/asafcombo","followers_url":"https://api.github.com/users/asafcombo/followers","following_url":"https://api.github.com/users/asafcombo/following{/other_user}","gists_url":"https://api.github.com/users/asafcombo/gists{/gist_id}","starred_url":"https://api.github.com/users/asafcombo/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/asafcombo/subscriptions","organizations_url":"https://api.github.com/users/asafcombo/orgs","repos_url":"https://api.github.com/users/asafcombo/repos","events_url":"https://api.github.com/users/asafcombo/events{/privacy}","received_events_url":"https://api.github.com/users/asafcombo/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2021-07-12T15:30:50Z","updated_at":"2021-07-18T11:45:35Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"**Use case**\r\nThe current behavior of `AggregatingMergeTree` for simple columns is to do an `any` merge ( although according to my tests it looks like `anyFirst` ).\r\n\r\nI suggest to allow a custom setting in the table settings to allow other function as well - for example `max`.\r\n\r\nThis will allow a more simple schema design that is more easy to maintain and read. See a more complex example later.\r\n\r\nSo let's look at the below\r\n\r\n```sql\r\ncreate database tests;\r\n-- \r\nCREATE TABLE tests.example\r\n(\r\n    `timestamp` DateTime Codec (DoubleDelta, LZ4),\r\n    `ne`                 Int32,\r\n    `request_id`        String,\r\n\r\n    `field_a`       String\r\n\r\n)\r\nENGINE = AggregatingMergeTree()\r\n    PARTITION BY (ne)\r\n    ORDER BY (ne, timestamp, request_id);\r\n\r\n-- \r\n\r\ninsert into tests.example values ('2021-06-21T01:00:00', 5, '0-0-0-1', '');  -- first insert of key\r\ninsert into tests.example values ('2021-06-21T01:00:00', 5, '0-0-0-1', 'a_2');  -- update of key\r\n-- \r\noptimize table  tests.example final;\r\n-- \r\nselect * from tests.example;\r\n-- '2021-06-21T01:00:00' |  5 | '0-0-0-1' | ''\r\n```\r\n\r\n`timestamp, ne, request_id` are primary key fields and exists in each and every insert, however `field_a` is an updateable field and only exists on some of the inserts.  As its type is a simple String - the merge could either get the value 'a_2' or could get us the default value of ''.\r\n\r\nThe normal thing to do is to declare `field_a` as such:\r\n\r\n```sql\r\n    `field_a`       SimpleAggregateFunction(max, String),\r\n```\r\n\r\nhowever it causes the schema to be more complex than it has to be, and also causes some downstream issues ( like querying ion superset ).\r\n\r\nWith the current behavior CH  is handling it behind the scenes like: \r\n```sql\r\n    `field_a`       SimpleAggregateFunction(any, String),\r\n```\r\n\r\nThis will really come in handy for my use case where we have a few streams that needs to be merged. All streams know what the primary key is, but the first stream ( main stream )  has around 100 fields that exist only there.  It is not possible to append these fields to other streams as it is both redundant and is costly.\r\n\r\nHowever for the secondary streams  only 1,2 fields are updated or appended, and we could use either explicit \r\n`SimpleAggregateFunction` or `AggregateFunction`  according to what we want to achieve. \r\n\r\n\r\n\r\n**Describe the solution you'd like**\r\nI propose to add a table setting `default_agg_merge` that would work only on columns that are of a simple type that will allow to customize to default action when merging these columns.\r\n\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26253/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26253/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26251","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26251/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26251/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26251/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26251","id":942166095,"node_id":"MDU6SXNzdWU5NDIxNjYwOTU=","number":26251,"title":"Unfold all macros when creating ReplicatedMergeTree","user":{"login":"siradjev","id":10959667,"node_id":"MDQ6VXNlcjEwOTU5NjY3","avatar_url":"https://avatars.githubusercontent.com/u/10959667?v=4","gravatar_id":"","url":"https://api.github.com/users/siradjev","html_url":"https://github.com/siradjev","followers_url":"https://api.github.com/users/siradjev/followers","following_url":"https://api.github.com/users/siradjev/following{/other_user}","gists_url":"https://api.github.com/users/siradjev/gists{/gist_id}","starred_url":"https://api.github.com/users/siradjev/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/siradjev/subscriptions","organizations_url":"https://api.github.com/users/siradjev/orgs","repos_url":"https://api.github.com/users/siradjev/repos","events_url":"https://api.github.com/users/siradjev/events{/privacy}","received_events_url":"https://api.github.com/users/siradjev/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":1507886722,"node_id":"MDU6TGFiZWwxNTA3ODg2NzIy","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/st-discussion","name":"st-discussion","color":"e5b890","default":false,"description":"The story requires discussion /research / expert help / design & decomposition before will be taken"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-07-12T15:11:30Z","updated_at":"2021-07-12T16:27:13Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"**Use case**\r\nCurrently on creation of replicated merge tree, metadata SQL files are kept as-is (except for {database}, {table}) macros. \r\nAs every replicated merge tree relies heavily on zookeeper path, and zookeeper path is assumed to be constant and never changing, it makes more sense to resolve all of the macros, not just {database} and {table}. \r\nWith current behavior clickhouse won't load existing table correctly in case macro is updated (e.g. replica name is modified, or shard numbering strategy is decided to be changed). \r\nBecause zookeeper does not allow renaming, it does not make much sense to keep placeholders, except for manual moving sql files to new cluster. \r\n\r\n**Describe the solution you'd like**\r\nWhen creating Replicated Merge tree, all of macros to be unfolded / resolved. \r\nOriginal macros string may remain in metadata.sql or creation script as commented line for simplicity. \r\nit has already been fixed for {database} and {table} macros before, since it was leading to problems like #25953. \r\n\r\nthere is another thought by @alexey-milovidov in https://github.com/ClickHouse/ClickHouse/issues/6917#issuecomment-531702719\r\n\r\n```\r\nWe can unfold these macros at the table creation\r\nbut we should not unfold all other macros (shard, layer, etc.)\r\nbecause there is typical scenario when table metadata (.sql) is copied between shards.\r\n\r\nAnd the proposed logic of unfolding some macros and not unfolding other macros looks questionable.\r\n```\r\n\r\nHowever, it's not clear about potential issues. \"ON CLUSTER\" syntax is more correct way of creating table across shards. \r\n\r\n**Describe alternatives you've considered**\r\nCurrently the only alternative is to manually create script that bulk traverses through all metadata and makes necessary replacements. \r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26251/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26251/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26242","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26242/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26242/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26242/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26242","id":941898938,"node_id":"MDU6SXNzdWU5NDE4OTg5Mzg=","number":26242,"title":"how to write the sql using clickhouse, if i want to get the aggregate results fo each items select from table?","user":{"login":"aohan237","id":3992281,"node_id":"MDQ6VXNlcjM5OTIyODE=","avatar_url":"https://avatars.githubusercontent.com/u/3992281?v=4","gravatar_id":"","url":"https://api.github.com/users/aohan237","html_url":"https://github.com/aohan237","followers_url":"https://api.github.com/users/aohan237/followers","following_url":"https://api.github.com/users/aohan237/following{/other_user}","gists_url":"https://api.github.com/users/aohan237/gists{/gist_id}","starred_url":"https://api.github.com/users/aohan237/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/aohan237/subscriptions","organizations_url":"https://api.github.com/users/aohan237/orgs","repos_url":"https://api.github.com/users/aohan237/repos","events_url":"https://api.github.com/users/aohan237/events{/privacy}","received_events_url":"https://api.github.com/users/aohan237/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""},{"id":845267693,"node_id":"MDU6TGFiZWw4NDUyNjc2OTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/st-need-info","name":"st-need-info","color":"e5b890","default":false,"description":"We need extra data to continue"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":5,"created_at":"2021-07-12T10:16:19Z","updated_at":"2021-07-16T02:53:09Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"search all the ways from google to sf, no same questions.\r\n\r\nsay i have a table，which is about 1T large:\r\n\r\nuser_id|  pay_time | pay_info\r\n-|-|-\r\n1 | 1232323 | {'num':10, \"total\":100}\r\n1  |1232324 | {'num':11, \"total\":110}\r\n1  |1232325  |{'num':12, \"total\":120}\r\n2  |1232326 | {'num':13, \"total\":130}\r\n2  |1232327 | {'num':14, \"total\":140}\r\n2  |1232328 | {'num':15, \"total\":150}\r\n2  |1232329 | {'num':16, \"total\":160}\r\n\r\nhow i get each user' sum total or sum num when he make payments,   he has already spent, which is pay_time less than this current payment's paytime. results as follows:\r\n\r\nuser_id | pay_time | sum_num| sum_total\r\n-|-|-|-\r\n1 | 1232323  |0 |0\r\n1|  12323234 |10| 100\r\n1 | 12323234 |21 |210\r\n2 | 1232326  |0 |0 \r\n2| 1232327   |13 |130\r\n2  |1232328  |27 |270\r\n2 | 1232329  |42 |420\r\n\r\ni have read the docs, but it seems no results.  \r\n\r\nand allow_experimental_window_functions seems not working, dont know why.\r\n\r\nthanks in advance\r\n\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26242/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26242/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26240","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26240/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26240/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26240/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26240","id":941870749,"node_id":"MDU6SXNzdWU5NDE4NzA3NDk=","number":26240,"title":"Unclear error message on insert when materialized view query have different column name from parent table","user":{"login":"kokizzu","id":1061610,"node_id":"MDQ6VXNlcjEwNjE2MTA=","avatar_url":"https://avatars.githubusercontent.com/u/1061610?v=4","gravatar_id":"","url":"https://api.github.com/users/kokizzu","html_url":"https://github.com/kokizzu","followers_url":"https://api.github.com/users/kokizzu/followers","following_url":"https://api.github.com/users/kokizzu/following{/other_user}","gists_url":"https://api.github.com/users/kokizzu/gists{/gist_id}","starred_url":"https://api.github.com/users/kokizzu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kokizzu/subscriptions","organizations_url":"https://api.github.com/users/kokizzu/orgs","repos_url":"https://api.github.com/users/kokizzu/repos","events_url":"https://api.github.com/users/kokizzu/events{/privacy}","received_events_url":"https://api.github.com/users/kokizzu/received_events","type":"User","site_admin":false},"labels":[{"id":845247686,"node_id":"MDU6TGFiZWw4NDUyNDc2ODY=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/usability","name":"usability","color":"ebf28c","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-07-12T09:45:30Z","updated_at":"2021-07-12T09:48:21Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Trying to rename a column by dropping:\r\n\r\n```\r\nCREATE TABLE foo(id UInt64) ENGINE=ReplacingMergeTree() ORDER BY id;\r\nCREATE MATERIALIZED VIEW bar ENGINE=MergeTree() ORDER BY x AS SELECT id+1 AS x FROM foo;\r\nDROP TABLE foo; -- <-- should show warning\r\nCREATE TABLE foo(bla UInt64) ENGINE=ReplacingMergeTree() ORDER BY bla;\r\nINSERT INTO foo(bla) VALUES(1); -- <-- should show which MV caused the error, since i have lots of materialized view\r\n-- Code: 47. DB::Exception: Received from localhost:9000. DB::Exception: Missing columns: 'id' while processing query: 'SELECT id + 1 AS x FROM default.foo', required columns: 'id'. \r\n\r\n```\r\n\r\nwhen dropping dependency should show warning that it's being used by another materialized view. \r\nwhen inserting should show which materialized view that causes the error, so we can drop it.\r\n\r\n**Does it reproduce on recent release?**\r\n\r\nonly test with 21.6.5, pretty sure still happened in the latest.\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26240/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26240/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26239","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26239/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26239/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26239/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26239","id":941839348,"node_id":"MDU6SXNzdWU5NDE4MzkzNDg=","number":26239,"title":"Inefficient join on ordered data","user":{"login":"scf37","id":1148465,"node_id":"MDQ6VXNlcjExNDg0NjU=","avatar_url":"https://avatars.githubusercontent.com/u/1148465?v=4","gravatar_id":"","url":"https://api.github.com/users/scf37","html_url":"https://github.com/scf37","followers_url":"https://api.github.com/users/scf37/followers","following_url":"https://api.github.com/users/scf37/following{/other_user}","gists_url":"https://api.github.com/users/scf37/gists{/gist_id}","starred_url":"https://api.github.com/users/scf37/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/scf37/subscriptions","organizations_url":"https://api.github.com/users/scf37/orgs","repos_url":"https://api.github.com/users/scf37/repos","events_url":"https://api.github.com/users/scf37/events{/privacy}","received_events_url":"https://api.github.com/users/scf37/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":756395244,"node_id":"MDU6TGFiZWw3NTYzOTUyNDQ=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/performance","name":"performance","color":"c2e0c6","default":false,"description":null},{"id":1357578153,"node_id":"MDU6TGFiZWwxMzU3NTc4MTUz","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-joins","name":"comp-joins","color":"b5bcff","default":false,"description":"JOINs"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":5,"created_at":"2021-07-12T09:08:46Z","updated_at":"2021-07-16T11:20:43Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"**Describe the situation**\r\n\r\nJoining tables by sort key should use constant memory - it is basically merging two sorted streams.\r\n\r\n```sql\r\nCREATE TABLE target_stocks\r\n(\r\n    `SKU` String,\r\n    `STORE` String,\r\n    `ERDAT` Date,\r\n    `SSTCK` Decimal(10, 3),\r\n)\r\nENGINE = MergeTree\r\nORDER BY (SKU, STORE, ERDAT)\r\nSETTINGS index_granularity = 8192 │\r\n```\r\n\r\nAnd then\r\n```sql\r\nselect max(SSTCK) from target_stocks a  join target_stocks b using (SKU, STORE, ERDAT)\r\n```\r\n\r\nExpectation:\r\nJoining two ordered streams should be about 2x slower than simple `select max(SSTCK) from target_stocks`\r\n\r\nReality:\r\nMemory limit (for query) exceeded\r\n\r\n**Additional context**\r\nClickhouse 21.6.5 revision 54448\r\n\r\nWhat is the right way to aggregate over function of two metrics stored under the same or similar sorting key in different tables? It can be done by O(n) at application level so why not do that at clickhouse.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26239/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26239/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26238","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26238/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26238/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26238/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26238","id":941824628,"node_id":"MDU6SXNzdWU5NDE4MjQ2Mjg=","number":26238,"title":"Users created by RBAC /access_management, use \"show databases\" to return no data ","user":{"login":"FanWuu","id":41465662,"node_id":"MDQ6VXNlcjQxNDY1NjYy","avatar_url":"https://avatars.githubusercontent.com/u/41465662?v=4","gravatar_id":"","url":"https://api.github.com/users/FanWuu","html_url":"https://github.com/FanWuu","followers_url":"https://api.github.com/users/FanWuu/followers","following_url":"https://api.github.com/users/FanWuu/following{/other_user}","gists_url":"https://api.github.com/users/FanWuu/gists{/gist_id}","starred_url":"https://api.github.com/users/FanWuu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/FanWuu/subscriptions","organizations_url":"https://api.github.com/users/FanWuu/orgs","repos_url":"https://api.github.com/users/FanWuu/repos","events_url":"https://api.github.com/users/FanWuu/events{/privacy}","received_events_url":"https://api.github.com/users/FanWuu/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""}],"state":"open","locked":false,"assignee":{"login":"vitlibar","id":45142681,"node_id":"MDQ6VXNlcjQ1MTQyNjgx","avatar_url":"https://avatars.githubusercontent.com/u/45142681?v=4","gravatar_id":"","url":"https://api.github.com/users/vitlibar","html_url":"https://github.com/vitlibar","followers_url":"https://api.github.com/users/vitlibar/followers","following_url":"https://api.github.com/users/vitlibar/following{/other_user}","gists_url":"https://api.github.com/users/vitlibar/gists{/gist_id}","starred_url":"https://api.github.com/users/vitlibar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vitlibar/subscriptions","organizations_url":"https://api.github.com/users/vitlibar/orgs","repos_url":"https://api.github.com/users/vitlibar/repos","events_url":"https://api.github.com/users/vitlibar/events{/privacy}","received_events_url":"https://api.github.com/users/vitlibar/received_events","type":"User","site_admin":false},"assignees":[{"login":"vitlibar","id":45142681,"node_id":"MDQ6VXNlcjQ1MTQyNjgx","avatar_url":"https://avatars.githubusercontent.com/u/45142681?v=4","gravatar_id":"","url":"https://api.github.com/users/vitlibar","html_url":"https://github.com/vitlibar","followers_url":"https://api.github.com/users/vitlibar/followers","following_url":"https://api.github.com/users/vitlibar/following{/other_user}","gists_url":"https://api.github.com/users/vitlibar/gists{/gist_id}","starred_url":"https://api.github.com/users/vitlibar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vitlibar/subscriptions","organizations_url":"https://api.github.com/users/vitlibar/orgs","repos_url":"https://api.github.com/users/vitlibar/repos","events_url":"https://api.github.com/users/vitlibar/events{/privacy}","received_events_url":"https://api.github.com/users/vitlibar/received_events","type":"User","site_admin":false}],"milestone":null,"comments":0,"created_at":"2021-07-12T08:52:12Z","updated_at":"2021-07-14T10:09:01Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"## this  is  user.xml\r\n\t<yandex>\r\n    <users>\r\n        <default>\r\n            <password>TEST123</password>\r\n            <networks>\r\n                <ip>::/0</ip>\r\n            </networks>\r\n            <profile>default</profile>\r\n            <quota>default</quota>\r\n            <databases>\r\n                <system>\r\n                    <tables>\r\n                        <filter>database != 'system'</filter>\r\n                    </tables>\r\n                    <databases>\r\n                        <filter>name != 'system'</filter>\r\n                    </databases>\r\n                </system>\r\n            </databases>\r\n        </default>\r\n    </users>\r\n    </yandex>\r\n\r\n## create  user \r\necho \"CREATE USER admin IDENTIFIED WITH PLAINTEXT_PASSWORD BY '123' \" | clickhouse-client -u default  \r\necho \"GRANT ALL ON *.* TO admin WITH GRANT OPTION \" | clickhouse-client -u default\r\n\r\n## show database  , show tables \r\necho \"show databases \"  | clickhouse-client -u admin  \r\necho \"show tables  \"  | clickhouse-client -u admin  \r\n\r\nsql returns empty results \r\n![8a11c627fb3f50441fc75e79a6fb3b6](https://user-images.githubusercontent.com/41465662/125258873-57bf7580-e331-11eb-8638-f260f761b51a.png)\r\n\r\n##  remove   /user/databases  of user.xml\r\n    <databases>\r\n            <system>\r\n                    <tables>\r\n                        <filter>database != 'system'</filter>\r\n                    </tables>\r\n                    <databases>\r\n                        <filter>name != 'system'</filter>\r\n                    </databases>\r\n                </system>\r\n       </databases>\r\n\r\nwhen   remove    /user/database ,  clickhouse-client  Can return the result normally , but Cannot hide the system database ，\r\n Is  This  a bug,？  or other configurations need to be modified \r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26238/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26238/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26220","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26220/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26220/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26220/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26220","id":941408369,"node_id":"MDU6SXNzdWU5NDE0MDgzNjk=","number":26220,"title":"LDAP: use special account to perform search in the directory","user":{"login":"amoskaliov","id":22944004,"node_id":"MDQ6VXNlcjIyOTQ0MDA0","avatar_url":"https://avatars.githubusercontent.com/u/22944004?v=4","gravatar_id":"","url":"https://api.github.com/users/amoskaliov","html_url":"https://github.com/amoskaliov","followers_url":"https://api.github.com/users/amoskaliov/followers","following_url":"https://api.github.com/users/amoskaliov/following{/other_user}","gists_url":"https://api.github.com/users/amoskaliov/gists{/gist_id}","starred_url":"https://api.github.com/users/amoskaliov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/amoskaliov/subscriptions","organizations_url":"https://api.github.com/users/amoskaliov/orgs","repos_url":"https://api.github.com/users/amoskaliov/repos","events_url":"https://api.github.com/users/amoskaliov/events{/privacy}","received_events_url":"https://api.github.com/users/amoskaliov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-07-11T09:11:06Z","updated_at":"2021-07-15T14:50:00Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"**Problem**\r\nCurrently Clickhouse offers the following scenario of LDAP login:\r\n1. Directly bind with the user's login and password.\r\n2. While bound find the user's groups.\r\n\r\nI have 2 problems with this scenario:\r\n1. Users use `uid` attribute to login (it looks like `j.doe`), while the user's DN in LDAP looks like `cn=John Doe,ou=People,dc=***,dc=ru`. So I can't set appropriate `bind_dn` parameter.\r\n2. Due to security reasons users are not allowed to perform search in the directory. \r\n\r\n**Describe the solution you'd like**\r\nThese problems can be solved if Clickhouse uses special LDAP account to find the DN and groups of the user. So the scenario will look like:\r\n1. The user enters uid and password.\r\n2. Clickhouse binds with its own special account and performs search with filter `(&amp;(objectClass=posixAccount)(uid={user_name}))` to get the DN of the user (string like `cn=John Doe,ou=People,dc=***,dc=ru`).\r\n3. Using the found DN and entered password Clickhouse binds to the LDAP to check the password.\r\n4. Then unbinds and with its own account finds user's groups (user's account is not allowed to search, while Clickhouses's account is).\r\n\r\nThis scenario looks complicated but it's actually widespread. It's supported in many applications we use (actually Clickhouse is the only exception). It's supported in PostgreSQL: https://www.postgresql.org/docs/13/auth-ldap.html (it's called `the search+bind mode`).\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26220/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26220/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26215","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26215/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26215/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26215/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26215","id":941357846,"node_id":"MDU6SXNzdWU5NDEzNTc4NDY=","number":26215,"title":"Ridiculous amount of `statfs` syscalls.","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":756395244,"node_id":"MDU6TGFiZWw3NTYzOTUyNDQ=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/performance","name":"performance","color":"c2e0c6","default":false,"description":null},{"id":1546440057,"node_id":"MDU6TGFiZWwxNTQ2NDQwMDU3","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/development","name":"development","color":"fc80df","default":false,"description":"Developement process & source code & implementation details"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":13,"created_at":"2021-07-11T02:23:15Z","updated_at":"2021-09-02T21:30:51Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"About 10 seconds:\r\n\r\n```\r\n% time     seconds  usecs/call     calls    errors syscall\r\n------ ----------- ----------- --------- --------- ----------------\r\n 66,48    0,371504          33     11004           statfs\r\n 22,26    0,124408          38      3226           openat\r\n  5,51    0,030767          37       821        81 stat\r\n  5,28    0,029505          43       672        10 unlink\r\n  0,16    0,000890          49        18         9 mkdir\r\n  0,14    0,000781          41        19           rename\r\n  0,09    0,000507          50        10           rmdir\r\n  0,05    0,000267          29         9           utime\r\n  0,03    0,000162          81         2           getcwd\r\n------ ----------- ----------- --------- --------- ----------------\r\n100.00    0,558791                 15781       100 total\r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26215/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26215/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26211","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26211/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26211/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26211/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26211","id":941347852,"node_id":"MDU6SXNzdWU5NDEzNDc4NTI=","number":26211,"title":"Add `addressToLineWithInlines` function.","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":386401508,"node_id":"MDU6TGFiZWwzODY0MDE1MDg=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/help%20wanted","name":"help wanted","color":"128A0C","default":true,"description":null},{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":644208617,"node_id":"MDU6TGFiZWw2NDQyMDg2MTc=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/easy%20task","name":"easy task","color":"0e8a16","default":false,"description":"Good for first contributors"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":5,"created_at":"2021-07-11T00:42:35Z","updated_at":"2021-12-23T08:48:44Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"**Use case**\r\nSimilar to `addressToLine` but outputs an array with inlined places in code.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26211/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26211/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26209","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26209/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26209/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26209/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26209","id":941336411,"node_id":"MDU6SXNzdWU5NDEzMzY0MTE=","number":26209,"title":"Miserable quality of documentation search","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":2668414603,"node_id":"MDU6TGFiZWwyNjY4NDE0NjAz","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/bug%20on%20website","name":"bug on website","color":"EA39C8","default":false,"description":""}],"state":"open","locked":false,"assignee":{"login":"rfraposa","id":5323324,"node_id":"MDQ6VXNlcjUzMjMzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/5323324?v=4","gravatar_id":"","url":"https://api.github.com/users/rfraposa","html_url":"https://github.com/rfraposa","followers_url":"https://api.github.com/users/rfraposa/followers","following_url":"https://api.github.com/users/rfraposa/following{/other_user}","gists_url":"https://api.github.com/users/rfraposa/gists{/gist_id}","starred_url":"https://api.github.com/users/rfraposa/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rfraposa/subscriptions","organizations_url":"https://api.github.com/users/rfraposa/orgs","repos_url":"https://api.github.com/users/rfraposa/repos","events_url":"https://api.github.com/users/rfraposa/events{/privacy}","received_events_url":"https://api.github.com/users/rfraposa/received_events","type":"User","site_admin":false},"assignees":[{"login":"rfraposa","id":5323324,"node_id":"MDQ6VXNlcjUzMjMzMjQ=","avatar_url":"https://avatars.githubusercontent.com/u/5323324?v=4","gravatar_id":"","url":"https://api.github.com/users/rfraposa","html_url":"https://github.com/rfraposa","followers_url":"https://api.github.com/users/rfraposa/followers","following_url":"https://api.github.com/users/rfraposa/following{/other_user}","gists_url":"https://api.github.com/users/rfraposa/gists{/gist_id}","starred_url":"https://api.github.com/users/rfraposa/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rfraposa/subscriptions","organizations_url":"https://api.github.com/users/rfraposa/orgs","repos_url":"https://api.github.com/users/rfraposa/repos","events_url":"https://api.github.com/users/rfraposa/events{/privacy}","received_events_url":"https://api.github.com/users/rfraposa/received_events","type":"User","site_admin":false}],"milestone":null,"comments":0,"created_at":"2021-07-10T22:54:02Z","updated_at":"2022-01-16T03:23:34Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"Cannot find a page about ClickHouse Keeper.\r\n\r\n![Screenshot_20210711_015246](https://user-images.githubusercontent.com/18581488/125178165-d3fb7100-e1ea-11eb-8474-e63bea3ae932.png)\r\n\r\nhttps://clickhouse.tech/docs/en/operations/clickhouse-keeper/","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26209/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26209/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26176","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26176/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26176/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26176/events","html_url":"https://github.com/ClickHouse/ClickHouse/pull/26176","id":941177395,"node_id":"MDExOlB1bGxSZXF1ZXN0Njg3MTMwMjg3","number":26176,"title":"Release pull request for branch 21.8","user":{"login":"robot-ch-test-poll","id":45356221,"node_id":"MDQ6VXNlcjQ1MzU2MjIx","avatar_url":"https://avatars.githubusercontent.com/u/45356221?v=4","gravatar_id":"","url":"https://api.github.com/users/robot-ch-test-poll","html_url":"https://github.com/robot-ch-test-poll","followers_url":"https://api.github.com/users/robot-ch-test-poll/followers","following_url":"https://api.github.com/users/robot-ch-test-poll/following{/other_user}","gists_url":"https://api.github.com/users/robot-ch-test-poll/gists{/gist_id}","starred_url":"https://api.github.com/users/robot-ch-test-poll/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/robot-ch-test-poll/subscriptions","organizations_url":"https://api.github.com/users/robot-ch-test-poll/orgs","repos_url":"https://api.github.com/users/robot-ch-test-poll/repos","events_url":"https://api.github.com/users/robot-ch-test-poll/events{/privacy}","received_events_url":"https://api.github.com/users/robot-ch-test-poll/received_events","type":"User","site_admin":false},"labels":[{"id":1261360622,"node_id":"MDU6TGFiZWwxMjYxMzYwNjIy","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/release","name":"release","color":"34d3a1","default":false,"description":"Label for release pull request"},{"id":2107435505,"node_id":"MDU6TGFiZWwyMTA3NDM1NTA1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/submodule%20changed","name":"submodule changed","color":"b7130b","default":false,"description":"At least one submodule changed in this PR."},{"id":2588535996,"node_id":"MDU6TGFiZWwyNTg4NTM1OTk2","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/release-lts","name":"release-lts","color":"58e89b","default":false,"description":"LTS release-branch (label name is hardcoded into backport automation)"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":4,"created_at":"2021-07-10T05:23:01Z","updated_at":"2022-01-26T08:05:11Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"draft":false,"pull_request":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/pulls/26176","html_url":"https://github.com/ClickHouse/ClickHouse/pull/26176","diff_url":"https://github.com/ClickHouse/ClickHouse/pull/26176.diff","patch_url":"https://github.com/ClickHouse/ClickHouse/pull/26176.patch","merged_at":null},"body":"\nThis PullRequest is part of ClickHouse release cycle. It's used by CI system only. Don't perform any changes with it.\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26176/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26176/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26173","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26173/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26173/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26173/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26173","id":941159089,"node_id":"MDU6SXNzdWU5NDExNTkwODk=","number":26173,"title":"FR: Expose TTL expression for columns in the system database","user":{"login":"SaltTan","id":20357526,"node_id":"MDQ6VXNlcjIwMzU3NTI2","avatar_url":"https://avatars.githubusercontent.com/u/20357526?v=4","gravatar_id":"","url":"https://api.github.com/users/SaltTan","html_url":"https://github.com/SaltTan","followers_url":"https://api.github.com/users/SaltTan/followers","following_url":"https://api.github.com/users/SaltTan/following{/other_user}","gists_url":"https://api.github.com/users/SaltTan/gists{/gist_id}","starred_url":"https://api.github.com/users/SaltTan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/SaltTan/subscriptions","organizations_url":"https://api.github.com/users/SaltTan/orgs","repos_url":"https://api.github.com/users/SaltTan/repos","events_url":"https://api.github.com/users/SaltTan/events{/privacy}","received_events_url":"https://api.github.com/users/SaltTan/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":1401282669,"node_id":"MDU6TGFiZWwxNDAxMjgyNjY5","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-ttl","name":"comp-ttl","color":"b5bcff","default":false,"description":"TTL"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-07-10T03:11:19Z","updated_at":"2021-07-15T00:21:02Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"It would be great to have this information in both system.columns and system.parts_columns","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26173/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26173/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26121","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26121/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26121/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26121/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26121","id":940607979,"node_id":"MDU6SXNzdWU5NDA2MDc5Nzk=","number":26121,"title":"The distributed table IN specifies that all table data is faster than some of its data","user":{"login":"sileiH","id":34700762,"node_id":"MDQ6VXNlcjM0NzAwNzYy","avatar_url":"https://avatars.githubusercontent.com/u/34700762?v=4","gravatar_id":"","url":"https://api.github.com/users/sileiH","html_url":"https://github.com/sileiH","followers_url":"https://api.github.com/users/sileiH/followers","following_url":"https://api.github.com/users/sileiH/following{/other_user}","gists_url":"https://api.github.com/users/sileiH/gists{/gist_id}","starred_url":"https://api.github.com/users/sileiH/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/sileiH/subscriptions","organizations_url":"https://api.github.com/users/sileiH/orgs","repos_url":"https://api.github.com/users/sileiH/repos","events_url":"https://api.github.com/users/sileiH/events{/privacy}","received_events_url":"https://api.github.com/users/sileiH/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2021-07-09T09:52:50Z","updated_at":"2021-07-15T02:32:30Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"CREATE TABLE test.test_local\r\n(\r\n    `fid` String,\r\n    `imei` String,\r\n    `app` String\r\n)\r\nENGINE = ReplicatedMergeTree('/clickhouse/tables/{layer}-{shard}/test_local', '{replica}')\r\nORDER BY app\r\nSETTINGS storage_policy = 'hdd_in_order', index_granularity = 8192 \r\n\r\n CREATE TABLE test.test\r\n(\r\n    `fid` String,\r\n    `imei` String,\r\n    `app` String\r\n)\r\nENGINE = Distributed('report_shards_replicas', 'test', 'test_local', rand())\r\n\r\n CREATE TABLE test.mysql_test\r\n(\r\n    `task_id` String,\r\n    `import_day` Date,\r\n    `data` String\r\n)\r\nENGINE = MySQL('xxxx', 'xxx', 'xxx', 'xxx', 'xxx')\r\n\r\n-- query_1\r\n\r\nSELECT count(1)\r\nFROM test.test\r\nWHERE imei IN \r\n(\r\n    SELECT data\r\n    FROM test.mysql_test\r\n    WHERE task_id = '72c4fa9efadb4230ba92831631796037'\r\n)\r\nGROUP BY app\r\n<img width=\"813\" alt=\"WeChatcbd23e466845058830990e9ad9558620\" src=\"https://user-images.githubusercontent.com/34700762/125058816-36fee200-e0dd-11eb-9123-25aca21e79ef.png\">\r\n\r\n-- query_2\r\n\r\nSELECT count(1)\r\nFROM test.test\r\nWHERE imei IN \r\n(\r\n    SELECT data\r\n    FROM test.mysql_test\r\n)\r\nGROUP BY app\r\n<img width=\"795\" alt=\"WeChat13e73ac0108a3aafce327ff447457f6e\" src=\"https://user-images.githubusercontent.com/34700762/125058797-32d2c480-e0dd-11eb-8f6b-ea4614f3f8d0.png\">\r\n\r\n\r\nThe distributed table is about 7 billion, The mysql external table value is 2000W, and the task_id value is 200W, Query2 is dozens of times faster than Query1,What is the cause of this\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26121/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26121/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26116","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26116/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26116/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26116/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26116","id":940457417,"node_id":"MDU6SXNzdWU5NDA0NTc0MTc=","number":26116,"title":"AMQP-CPP issues","user":{"login":"kssenii","id":54203879,"node_id":"MDQ6VXNlcjU0MjAzODc5","avatar_url":"https://avatars.githubusercontent.com/u/54203879?v=4","gravatar_id":"","url":"https://api.github.com/users/kssenii","html_url":"https://github.com/kssenii","followers_url":"https://api.github.com/users/kssenii/followers","following_url":"https://api.github.com/users/kssenii/following{/other_user}","gists_url":"https://api.github.com/users/kssenii/gists{/gist_id}","starred_url":"https://api.github.com/users/kssenii/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kssenii/subscriptions","organizations_url":"https://api.github.com/users/kssenii/orgs","repos_url":"https://api.github.com/users/kssenii/repos","events_url":"https://api.github.com/users/kssenii/events{/privacy}","received_events_url":"https://api.github.com/users/kssenii/received_events","type":"User","site_admin":false},"labels":[{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""},{"id":2314441866,"node_id":"MDU6TGFiZWwyMzE0NDQxODY2","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-rabbitmq","name":"comp-rabbitmq","color":"b5bcff","default":false,"description":""}],"state":"open","locked":false,"assignee":{"login":"kssenii","id":54203879,"node_id":"MDQ6VXNlcjU0MjAzODc5","avatar_url":"https://avatars.githubusercontent.com/u/54203879?v=4","gravatar_id":"","url":"https://api.github.com/users/kssenii","html_url":"https://github.com/kssenii","followers_url":"https://api.github.com/users/kssenii/followers","following_url":"https://api.github.com/users/kssenii/following{/other_user}","gists_url":"https://api.github.com/users/kssenii/gists{/gist_id}","starred_url":"https://api.github.com/users/kssenii/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kssenii/subscriptions","organizations_url":"https://api.github.com/users/kssenii/orgs","repos_url":"https://api.github.com/users/kssenii/repos","events_url":"https://api.github.com/users/kssenii/events{/privacy}","received_events_url":"https://api.github.com/users/kssenii/received_events","type":"User","site_admin":false},"assignees":[{"login":"kssenii","id":54203879,"node_id":"MDQ6VXNlcjU0MjAzODc5","avatar_url":"https://avatars.githubusercontent.com/u/54203879?v=4","gravatar_id":"","url":"https://api.github.com/users/kssenii","html_url":"https://github.com/kssenii","followers_url":"https://api.github.com/users/kssenii/followers","following_url":"https://api.github.com/users/kssenii/following{/other_user}","gists_url":"https://api.github.com/users/kssenii/gists{/gist_id}","starred_url":"https://api.github.com/users/kssenii/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kssenii/subscriptions","organizations_url":"https://api.github.com/users/kssenii/orgs","repos_url":"https://api.github.com/users/kssenii/repos","events_url":"https://api.github.com/users/kssenii/events{/privacy}","received_events_url":"https://api.github.com/users/kssenii/received_events","type":"User","site_admin":false}],"milestone":null,"comments":0,"created_at":"2021-07-09T06:22:13Z","updated_at":"2021-07-09T10:29:41Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"- [ ] ***crash 1:***\r\n```\r\n1. AMQP::TcpConnection::onData(AMQP::Connection*, char const*, unsigned long) @ 0x12456274 in /usr/lib/debug/.build-id/cf/d133a618715680c43aa5458cc9782f35c3b1e7.debug',\r\n2. AMQP::ConnectionImpl::send(AMQP::Frame const&) @ 0x1244bbff in /usr/lib/debug/.build-id/cf/d133a618715680c43aa5458cc9782f35c3b1e7.debug',\r\n3. AMQP::ConnectionImpl::ConnectionImpl(AMQP::Connection*, AMQP::ConnectionHandler*, AMQP::Login const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) @ 0x1244ba4b in /usr/lib/debug/.build-id/cf/d133a618715680c43aa5458cc9782f35c3b1e7.debug',\r\n4. AMQP::TcpConnection::TcpConnection(AMQP::TcpHandler*, AMQP::Address const&) @ 0x12455b80 in /usr/lib/debug/.build-id/cf/d133a618715680c43aa5458cc9782f35c3b1e7.debug',\r\n5. DB::StorageRabbitMQ::restoreConnection(bool) @ 0xfb21872 in /usr/lib/debug/.build-id/cf/d133a618715680c43aa5458cc9782f35c3b1e7.debug',\r\n6. void std::__1::__function::__policy_invoker<void ()>::__call_impl<std::__1::__function::__default_alloc_func<**DB::StorageRabbitMQ::StorageRabbitMQ**(DB::StorageID const&, DB::Context const&, DB::ColumnsDescription const&, std::__1::unique_ptr<DB::RabbitMQSettings, std::__1::default_delete<DB::RabbitMQSettings> >)::$_2, void ()> >(std::__1::__function::__policy_storage const*) @ 0xfb2cec1 in /usr/lib/debug/.build-id/cf/d133a618715680c43aa5458cc9782f35c3b1e7.debug',\r\n7. DB::BackgroundSchedulePoolTaskInfo::execute() @ 0xf0cbf80 in /usr/lib/debug/.build-id/cf/d133a618715680c43aa5458cc9782f35c3b1e7.debug',\r\n8. DB::BackgroundSchedulePool::threadFunction() @ 0xf0cdf77 in /usr/lib/debug/.build-id/cf/d133a618715680c43aa5458cc9782f35c3b1e7.debug',\r\n9. void std::__1::__function::__policy_invoker<void ()>::__call_impl<std::__1::__function::__default_alloc_func<ThreadFromGlobalPool::ThreadFromGlobalPool<DB::BackgroundSchedulePool::BackgroundSchedulePool(unsigned long, unsigned long, char const*)::$_1>(DB::BackgroundSchedulePool::BackgroundSchedulePool(unsigned long, unsigned long, char const*)::$_1&&)::\\'lambda\\'(), void ()> >(std::__1::__function::__policy_storage const*) @ 0xf0ced42 in /usr/lib/debug/.build-id/cf/d133a618715680c43aa5458cc9782f35c3b1e7.debug',\r\n10. ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) @ 0x88372bf in /usr/lib/debug/.build-id/cf/d133a618715680c43aa5458cc9782f35c3b1e7.debug',\r\n11. void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, void ThreadPoolImpl<std::__1::thread>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::\\'lambda1\\'()> >(void*) @ 0x883ade3 in /usr/lib/debug/.build-id/cf/d133a618715680c43aa5458cc9782f35c3b1e7.debug',\r\n12. start_thread @ 0x76db in /lib/x86_64-linux-gnu/libpthread-2.27.so','13. clone @ 0x12171f in /lib/x86_64-linux-gnu/libc-2.27.so']\r\n```\r\n\r\n- [ ]  ***crash 2:***\r\n```\r\n1. std::__1::vector<char, std::__1::allocator<char> >& std::__1::deque<std::__1::vector<char, std::__1::allocator<char> >, std::__1::allocator<std::__1::vector<char, std::__1::allocator<char> > > >::emplace_back<char const*&, char const*>(char const*&, char const*&&) @ 0x12445fc9 in /usr/lib/debug/.build-id/77/51a440c37cde5f9e50cfeb03e7cb14f6dc1109.debug',\r\n2. AMQP::TcpResolver::send(char const*, unsigned long) @ 0x124437ad in /usr/lib/debug/.build-id/77/51a440c37cde5f9e50cfeb03e7cb14f6dc1109.debug',\r\n3. AMQP::ConnectionImpl::send(AMQP::Frame const&) @ 0x124384cf in /usr/lib/debug/.build-id/77/51a440c37cde5f9e50cfeb03e7cb14f6dc1109.debug',\r\n4. AMQP::ConnectionImpl::ConnectionImpl(AMQP::Connection*, AMQP::ConnectionHandler*, AMQP::Login const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) @ 0x1243831b in /usr/lib/debug/.build-id/77/51a440c37cde5f9e50cfeb03e7cb14f6dc1109.debug',\r\n5. AMQP::TcpConnection::TcpConnection(AMQP::TcpHandler*, AMQP::Address const&) @ 0x12442450 in /usr/lib/debug/.build-id/77/51a440c37cde5f9e50cfeb03e7cb14f6dc1109.debug',\r\n6. DB::StorageRabbitMQ::restoreConnection(bool) @ 0xfb0fb92 in /usr/lib/debug/.build-id/77/51a440c37cde5f9e50cfeb03e7cb14f6dc1109.debug',\r\n7. DB::StorageRabbitMQ::streamingToViewsFunc() @ 0xfb17dfd in /usr/lib/debug/.build-id/77/51a440c37cde5f9e50cfeb03e7cb14f6dc1109.debug',\r\n8. DB::BackgroundSchedulePoolTaskInfo::execute() @ 0xf0b5870 in /usr/lib/debug/.build-id/77/51a440c37cde5f9e50cfeb03e7cb14f6dc1109.debug',\r\n9. DB::BackgroundSchedulePool::threadFunction() @ 0xf0b7867 in /usr/lib/debug/.build-id/77/51a440c37cde5f9e50cfeb03e7cb14f6dc1109.debug',\r\n10. void std::__1::__function::__policy_invoker<void ()>::__call_impl<std::__1::__function::__default_alloc_func<ThreadFromGlobalPool::ThreadFromGlobalPool<DB::BackgroundSchedulePool::BackgroundSchedulePool(unsigned long, unsigned long, char const*)::$_1>(DB::BackgroundSchedulePool::BackgroundSchedulePool(unsigned long, unsigned long, char const*)::$_1&&)::\\'lambda\\'(), void ()> >(std::__1::__function::__policy_storage const*) @ 0xf0b8632 in /usr/lib/debug/.build-id/77/51a440c37cde5f9e50cfeb03e7cb14f6dc1109.debug',\r\n11. ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) @ 0x882883f in /usr/lib/debug/.build-id/77/51a440c37cde5f9e50cfeb03e7cb14f6dc1109.debug',\r\n12. void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, void ThreadPoolImpl<std::__1::thread>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::\\'lambda1\\'()> >(void*) @ 0x882c363 in /usr/lib/debug/.build-id/77/51a440c37cde5f9e50cfeb03e7cb14f6dc1109.debug','13. start_thread @ 0x76db in /lib/x86_64-linux-gnu/libpthread-2.27.so','14. clone @ 0x12171f in /lib/x86_64-linux-gnu/libc-2.27.so']\r\n```\r\n\r\n- [ ] ***crash 3:***\r\n```\r\n1. AMQP::ConnectionImpl::ConnectionImpl(AMQP::Connection*, AMQP::ConnectionHandler*, AMQP::Login const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) @ 0x11e2a7a0 in /usr/lib/debug/.build-id/93/5a293066a3b70bc15412a2ac994369bdf672a9.debug',\r\n2. AMQP::TcpConnection::TcpConnection(AMQP::TcpHandler*, AMQP::Address const&) @ 0x11e34ae0 in /usr/lib/debug/.build-id/93/5a293066a3b70bc15412a2ac994369bdf672a9.debug',\r\n3. DB::StorageRabbitMQ::restoreConnection(bool) @ 0xf521d82 in /usr/lib/debug/.build-id/93/5a293066a3b70bc15412a2ac994369bdf672a9.debug',\r\n4. DB::StorageRabbitMQ::streamingToViewsFunc() @ 0xf529dcd in /usr/lib/debug/.build-id/93/5a293066a3b70bc15412a2ac994369bdf672a9.debug',\r\n5. DB::BackgroundSchedulePoolTaskInfo::execute() @ 0xeaf2050 in /usr/lib/debug/.build-id/93/5a293066a3b70bc15412a2ac994369bdf672a9.debug',\r\n6. DB::BackgroundSchedulePool::threadFunction() @ 0xeaf4047 in /usr/lib/debug/.build-id/93/5a293066a3b70bc15412a2ac994369bdf672a9.debug',\r\n7. void std::__1::__function::__policy_invoker<void ()>::__call_impl<std::__1::__function::__default_alloc_func<ThreadFromGlobalPool::ThreadFromGlobalPool<DB::BackgroundSchedulePool::BackgroundSchedulePool(unsigned long, unsigned long, char const*)::$_1>(DB::BackgroundSchedulePool::BackgroundSchedulePool(unsigned long, unsigned long, char const*)::$_1&&)::\\'lambda\\'(), void ()> >(std::__1::__function::__policy_storage const*) @ 0xeaf4e12 in /usr/lib/debug/.build-id/93/5a293066a3b70bc15412a2ac994369bdf672a9.debug',\r\n8. ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) @ 0x86579af in /usr/lib/debug/.build-id/93/5a293066a3b70bc15412a2ac994369bdf672a9.debug',\r\n9. void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, void ThreadPoolImpl<std::__1::thread>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::\\'lambda1\\'()> >(void*) @ 0x865b443 in /usr/lib/debug/.build-id/93/5a293066a3b70bc15412a2ac994369bdf672a9.debug',\r\n10. start_thread @ 0x76db in /lib/x86_64-linux-gnu/libpthread-2.27.so','11. __clone @ 0x12171f in /lib/x86_64-linux-gnu/libc-2.27.so']\r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26116/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26116/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26098","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26098/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26098/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26098/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26098","id":940176907,"node_id":"MDU6SXNzdWU5NDAxNzY5MDc=","number":26098,"title":"Distributed Join() tables?","user":{"login":"Alekky09","id":54728966,"node_id":"MDQ6VXNlcjU0NzI4OTY2","avatar_url":"https://avatars.githubusercontent.com/u/54728966?v=4","gravatar_id":"","url":"https://api.github.com/users/Alekky09","html_url":"https://github.com/Alekky09","followers_url":"https://api.github.com/users/Alekky09/followers","following_url":"https://api.github.com/users/Alekky09/following{/other_user}","gists_url":"https://api.github.com/users/Alekky09/gists{/gist_id}","starred_url":"https://api.github.com/users/Alekky09/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Alekky09/subscriptions","organizations_url":"https://api.github.com/users/Alekky09/orgs","repos_url":"https://api.github.com/users/Alekky09/repos","events_url":"https://api.github.com/users/Alekky09/events{/privacy}","received_events_url":"https://api.github.com/users/Alekky09/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":4,"created_at":"2021-07-08T20:00:15Z","updated_at":"2021-10-20T06:09:48Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Hello,\r\nI have created a table with engine Join() on my cluster of nodes, however I can't access the data from all of the nodes, just the one from which I did INSERT. Is there a Distributed version of this table?\r\n\r\nIt seems like it would fit my needs as I do large JOINs frequently, and I'd avoid the speed slowdown with this Join() table engine.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26098/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26098/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26095","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26095/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26095/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26095/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26095","id":940050741,"node_id":"MDU6SXNzdWU5NDAwNTA3NDE=","number":26095,"title":"sequenceMatch fails often even for trivial amounts of data (hardcoded limit)","user":{"login":"andrea-s","id":9706626,"node_id":"MDQ6VXNlcjk3MDY2MjY=","avatar_url":"https://avatars.githubusercontent.com/u/9706626?v=4","gravatar_id":"","url":"https://api.github.com/users/andrea-s","html_url":"https://github.com/andrea-s","followers_url":"https://api.github.com/users/andrea-s/followers","following_url":"https://api.github.com/users/andrea-s/following{/other_user}","gists_url":"https://api.github.com/users/andrea-s/gists{/gist_id}","starred_url":"https://api.github.com/users/andrea-s/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/andrea-s/subscriptions","organizations_url":"https://api.github.com/users/andrea-s/orgs","repos_url":"https://api.github.com/users/andrea-s/repos","events_url":"https://api.github.com/users/andrea-s/events{/privacy}","received_events_url":"https://api.github.com/users/andrea-s/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""},{"id":386401511,"node_id":"MDU6TGFiZWwzODY0MDE1MTE=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/st-wontfix","name":"st-wontfix","color":"e5b890","default":false,"description":"Known issue, no plans to fix it currenlty"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":6,"created_at":"2021-07-08T16:55:19Z","updated_at":"2021-07-13T06:51:17Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"```\r\nroot@18575791bbaa:/# clickhouse-client -m\r\nClickHouse client version 21.6.6.51 (official build).\r\nConnecting to localhost:9000 as user default.\r\nConnected to ClickHouse server version 21.6.6 revision 54448.\r\n\r\n18575791bbaa :) SELECT sequenceMatch('(?1)(?t>1)(?2)')(timestamp, number <= 1000, number > 1000) AS seq\r\n:-] FROM\r\n:-] (\r\n:-]     SELECT\r\n:-]         number,\r\n:-]         toDateTime('2021-01-01 00:00:00') + number AS timestamp\r\n:-]     FROM system.numbers\r\n:-]     LIMIT 1000\r\n:-] );\r\n\r\nSELECT sequenceMatch('(?1)(?t>1)(?2)')(timestamp, number <= 1000, number > 1000) AS seq\r\nFROM\r\n(\r\n    SELECT\r\n        number,\r\n        toDateTime('2021-01-01 00:00:00') + number AS timestamp\r\n    FROM system.numbers\r\n    LIMIT 1000\r\n)\r\n\r\nQuery id: 4a8058c7-24e8-409d-8cdf-efa05a45e430\r\n\r\n\r\n0 rows in set. Elapsed: 0.007 sec.\r\n\r\nReceived exception from server (version 21.6.6):\r\nCode: 160. DB::Exception: Received from localhost:9000. DB::Exception: Pattern application proves too difficult, exceeding max iterations (1000000): While executing ConvertingAggregatedToChunksTransform.\r\n```\r\n\r\nThe limit seems to be hardcoded (https://github.com/ClickHouse/ClickHouse/blob/7a56ab8b1dc833d40e2140a35b95c65f383e4132/src/AggregateFunctions/AggregateFunctionSequenceMatch.h#L138), is there a way that we could expose this in settings at least? Unfortunately situations like the above happen quite a bit with \"real life\" datasets and it makes it hard to use sequenceMatch in production.\r\n\r\nThe above query could be rewritten like this of course:\r\n\r\n```\r\nSELECT coalesce(maxIfOrNull(timestamp, number > 1000) - minIfOrNull(timestamp, number <= 1000), 0) > 1 AS seq\r\nFROM\r\n(\r\n    SELECT\r\n        number,\r\n        toDateTime('2021-01-01 00:00:00') + number AS timestamp\r\n    FROM system.numbers\r\n    LIMIT 1000\r\n)\r\n```\r\n\r\nbut it's not always practical.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26095/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26095/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26086","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26086/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26086/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26086/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26086","id":939944621,"node_id":"MDU6SXNzdWU5Mzk5NDQ2MjE=","number":26086,"title":"When using XML/YAML based user configuration if profile or quota is not defined then default ones are used","user":{"login":"nvartolomei","id":543193,"node_id":"MDQ6VXNlcjU0MzE5Mw==","avatar_url":"https://avatars.githubusercontent.com/u/543193?v=4","gravatar_id":"","url":"https://api.github.com/users/nvartolomei","html_url":"https://github.com/nvartolomei","followers_url":"https://api.github.com/users/nvartolomei/followers","following_url":"https://api.github.com/users/nvartolomei/following{/other_user}","gists_url":"https://api.github.com/users/nvartolomei/gists{/gist_id}","starred_url":"https://api.github.com/users/nvartolomei/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nvartolomei/subscriptions","organizations_url":"https://api.github.com/users/nvartolomei/orgs","repos_url":"https://api.github.com/users/nvartolomei/repos","events_url":"https://api.github.com/users/nvartolomei/events{/privacy}","received_events_url":"https://api.github.com/users/nvartolomei/received_events","type":"User","site_admin":false},"labels":[{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":{"login":"vitlibar","id":45142681,"node_id":"MDQ6VXNlcjQ1MTQyNjgx","avatar_url":"https://avatars.githubusercontent.com/u/45142681?v=4","gravatar_id":"","url":"https://api.github.com/users/vitlibar","html_url":"https://github.com/vitlibar","followers_url":"https://api.github.com/users/vitlibar/followers","following_url":"https://api.github.com/users/vitlibar/following{/other_user}","gists_url":"https://api.github.com/users/vitlibar/gists{/gist_id}","starred_url":"https://api.github.com/users/vitlibar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vitlibar/subscriptions","organizations_url":"https://api.github.com/users/vitlibar/orgs","repos_url":"https://api.github.com/users/vitlibar/repos","events_url":"https://api.github.com/users/vitlibar/events{/privacy}","received_events_url":"https://api.github.com/users/vitlibar/received_events","type":"User","site_admin":false},"assignees":[{"login":"vitlibar","id":45142681,"node_id":"MDQ6VXNlcjQ1MTQyNjgx","avatar_url":"https://avatars.githubusercontent.com/u/45142681?v=4","gravatar_id":"","url":"https://api.github.com/users/vitlibar","html_url":"https://github.com/vitlibar","followers_url":"https://api.github.com/users/vitlibar/followers","following_url":"https://api.github.com/users/vitlibar/following{/other_user}","gists_url":"https://api.github.com/users/vitlibar/gists{/gist_id}","starred_url":"https://api.github.com/users/vitlibar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vitlibar/subscriptions","organizations_url":"https://api.github.com/users/vitlibar/orgs","repos_url":"https://api.github.com/users/vitlibar/repos","events_url":"https://api.github.com/users/vitlibar/events{/privacy}","received_events_url":"https://api.github.com/users/vitlibar/received_events","type":"User","site_admin":false}],"milestone":null,"comments":1,"created_at":"2021-07-08T14:53:25Z","updated_at":"2021-07-08T15:40:22Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"Previously (until RBAC was introduced) users were not allowed to connect to ClickHouse if user definition referenced a non-existing profile/quota. `DB::Exception: There is no profile 'does_not_exist' in configuration file..`\r\n\r\nAfter RBAC was introduced this behavior changed and now users can connect and they are assigned default profile. This is unexpected and is easy to make mistakes (eg typos) that would give users more privileges than expected (allow_ddl, readonly).\r\n\r\ncc @vitlibar ","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26086/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26086/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26069","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26069/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26069/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26069/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26069","id":939521306,"node_id":"MDU6SXNzdWU5Mzk1MjEzMDY=","number":26069,"title":"Sequence match/count: provide timestamp(s) in which a user qualified for a certain sequence","user":{"login":"andrea-s","id":9706626,"node_id":"MDQ6VXNlcjk3MDY2MjY=","avatar_url":"https://avatars.githubusercontent.com/u/9706626?v=4","gravatar_id":"","url":"https://api.github.com/users/andrea-s","html_url":"https://github.com/andrea-s","followers_url":"https://api.github.com/users/andrea-s/followers","following_url":"https://api.github.com/users/andrea-s/following{/other_user}","gists_url":"https://api.github.com/users/andrea-s/gists{/gist_id}","starred_url":"https://api.github.com/users/andrea-s/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/andrea-s/subscriptions","organizations_url":"https://api.github.com/users/andrea-s/orgs","repos_url":"https://api.github.com/users/andrea-s/repos","events_url":"https://api.github.com/users/andrea-s/events{/privacy}","received_events_url":"https://api.github.com/users/andrea-s/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":1546506700,"node_id":"MDU6TGFiZWwxNTQ2NTA2NzAw","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-functions","name":"comp-functions","color":"b5bcff","default":false,"description":"Relates to some SQL function"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-07-08T06:35:33Z","updated_at":"2022-01-04T22:19:33Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"When using sequenceMatch / sequenceCount, it would be interesting to have a way to extract the timestamps in which a user qualifies for the match (I would say the first timestamp is ok for sequenceMatch, and probably an array of timestamps for sequenceCount?).\r\n\r\nUse case: qualify changes in size for a calculated segment of users in an efficient way.\r\n\r\nedit: this is somehow possible today for some simplified sequences, by using arrays, but of course it does not scale as nicely!","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26069/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26069/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26066","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26066/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26066/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26066/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26066","id":939404117,"node_id":"MDU6SXNzdWU5Mzk0MDQxMTc=","number":26066,"title":"sorting by Int and by DateTime results in very different query timings","user":{"login":"akamensky","id":985805,"node_id":"MDQ6VXNlcjk4NTgwNQ==","avatar_url":"https://avatars.githubusercontent.com/u/985805?v=4","gravatar_id":"","url":"https://api.github.com/users/akamensky","html_url":"https://github.com/akamensky","followers_url":"https://api.github.com/users/akamensky/followers","following_url":"https://api.github.com/users/akamensky/following{/other_user}","gists_url":"https://api.github.com/users/akamensky/gists{/gist_id}","starred_url":"https://api.github.com/users/akamensky/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/akamensky/subscriptions","organizations_url":"https://api.github.com/users/akamensky/orgs","repos_url":"https://api.github.com/users/akamensky/repos","events_url":"https://api.github.com/users/akamensky/events{/privacy}","received_events_url":"https://api.github.com/users/akamensky/received_events","type":"User","site_admin":false},"labels":[{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":{"login":"CurtizJ","id":20361854,"node_id":"MDQ6VXNlcjIwMzYxODU0","avatar_url":"https://avatars.githubusercontent.com/u/20361854?v=4","gravatar_id":"","url":"https://api.github.com/users/CurtizJ","html_url":"https://github.com/CurtizJ","followers_url":"https://api.github.com/users/CurtizJ/followers","following_url":"https://api.github.com/users/CurtizJ/following{/other_user}","gists_url":"https://api.github.com/users/CurtizJ/gists{/gist_id}","starred_url":"https://api.github.com/users/CurtizJ/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/CurtizJ/subscriptions","organizations_url":"https://api.github.com/users/CurtizJ/orgs","repos_url":"https://api.github.com/users/CurtizJ/repos","events_url":"https://api.github.com/users/CurtizJ/events{/privacy}","received_events_url":"https://api.github.com/users/CurtizJ/received_events","type":"User","site_admin":false},"assignees":[{"login":"CurtizJ","id":20361854,"node_id":"MDQ6VXNlcjIwMzYxODU0","avatar_url":"https://avatars.githubusercontent.com/u/20361854?v=4","gravatar_id":"","url":"https://api.github.com/users/CurtizJ","html_url":"https://github.com/CurtizJ","followers_url":"https://api.github.com/users/CurtizJ/followers","following_url":"https://api.github.com/users/CurtizJ/following{/other_user}","gists_url":"https://api.github.com/users/CurtizJ/gists{/gist_id}","starred_url":"https://api.github.com/users/CurtizJ/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/CurtizJ/subscriptions","organizations_url":"https://api.github.com/users/CurtizJ/orgs","repos_url":"https://api.github.com/users/CurtizJ/repos","events_url":"https://api.github.com/users/CurtizJ/events{/privacy}","received_events_url":"https://api.github.com/users/CurtizJ/received_events","type":"User","site_admin":false}],"milestone":null,"comments":13,"created_at":"2021-07-08T02:20:07Z","updated_at":"2021-07-09T09:20:22Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"**Describe the unexpected behaviour**\r\nWe have a table with a few columns, two of those columns are Int64 (col A) which represent a Unix timestamp with nanoseconds and another is DateTime64(3) (col B). Both are exactly the same value with column A having last 6 digits as 0s. The table is ordered by col B and partitioned by toStartOfHour(col B).\r\n\r\nWith the setup above we noticed very big difference in which column used for sorting -- queries that use `ORDER BY A` are significantly faster than `ORDER BY B`. On the order of 10-100 times (depending on amount of data queried).\r\n\r\nIn a very basic example the difference would be `ORDER BY A DESC` ~3 seconds, `ORDER BY B DESC` ~20 seconds\r\n\r\n**Expected behavior**\r\nTimings are not significantly different\r\n\r\n**Error message and/or stacktrace**\r\nN/A\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26066/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26066/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26025","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26025/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26025/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26025/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26025","id":937835905,"node_id":"MDU6SXNzdWU5Mzc4MzU5MDU=","number":26025,"title":"Requested cluster 'xxx' not found: while loading database `default` from path /var/lib/clickhouse/metadata/default","user":{"login":"rsaphala","id":13609625,"node_id":"MDQ6VXNlcjEzNjA5NjI1","avatar_url":"https://avatars.githubusercontent.com/u/13609625?v=4","gravatar_id":"","url":"https://api.github.com/users/rsaphala","html_url":"https://github.com/rsaphala","followers_url":"https://api.github.com/users/rsaphala/followers","following_url":"https://api.github.com/users/rsaphala/following{/other_user}","gists_url":"https://api.github.com/users/rsaphala/gists{/gist_id}","starred_url":"https://api.github.com/users/rsaphala/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rsaphala/subscriptions","organizations_url":"https://api.github.com/users/rsaphala/orgs","repos_url":"https://api.github.com/users/rsaphala/repos","events_url":"https://api.github.com/users/rsaphala/events{/privacy}","received_events_url":"https://api.github.com/users/rsaphala/received_events","type":"User","site_admin":false},"labels":[{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2021-07-06T12:16:58Z","updated_at":"2021-07-06T21:58:16Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"When upgrading from 20.12.3 to 21.6.6.51, the below error occurs and one of the server won't start (one of the shards).  I run a cluster of 2 shards with 1 replica each on kubernetes.\r\n\r\nAfter downgrading back, query from ` system.clusters` table shows that the cluster actually exists. \r\n\r\n```\r\n2021.07.06 11:56:06.871645 [ 45 ] {} <Error> Application: Caught exception while loading metadata: Code: 170, e.displayText() = DB::Exception: Requested cluster 'xxx' not found: while loading database `default` from path /var/lib/clickhouse/metadata/default, Stack trace (when copying this message, always include the lines below):\r\n\r\n0. DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, bool) @ 0x8b770fa in /usr/bin/clickhouse\r\n1. DB::Context::getCluster(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) const @ 0xf562778 in /usr/bin/clickhouse\r\n2. DB::StorageDistributed::getCluster() const @ 0xfe2a2f7 in /usr/bin/clickhouse\r\n3. DB::StorageDistributedDirectoryMonitor::createPool(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, DB::StorageDistributed const&) @ 0x100c8d39 in /usr/bin/clickhouse\r\n4. DB::StorageDistributed::requireDirectoryMonitor(std::__1::shared_ptr<DB::IDisk> const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) @ 0xfe34e40 in /usr/bin/clickhouse\r\n5. DB::StorageDistributed::createDirectoryMonitors(std::__1::shared_ptr<DB::IDisk> const&) @ 0xfe32b23 in /usr/bin/clickhouse\r\n6. DB::StorageDistributed::startup() @ 0xfe30a4b in /usr/bin/clickhouse\r\n7. ? @ 0xf47731b in /usr/bin/clickhouse\r\n8. ThreadPoolImpl<ThreadFromGlobalPool>::worker(std::__1::__list_iterator<ThreadFromGlobalPool, void*>) @ 0x8bb9ed8 in /usr/bin/clickhouse\r\n9. ThreadFromGlobalPool::ThreadFromGlobalPool<void ThreadPoolImpl<ThreadFromGlobalPool>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda1'()>(void&&, void ThreadPoolImpl<ThreadFromGlobalPool>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda1'()&&...)::'lambda'()::operator()() @ 0x8bbb89f in /usr/bin/clickhouse\r\n10. ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) @ 0x8bb741f in /usr/bin/clickhouse\r\n11. ? @ 0x8bba943 in /usr/bin/clickhouse\r\n12. start_thread @ 0x9609 in /usr/lib/x86_64-linux-gnu/libpthread-2.31.so\r\n13. clone @ 0x122293 in /usr/lib/x86_64-linux-gnu/libc-2.31.so\r\n (version 21.6.6.51 (official build))\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26025/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26025/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26016","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26016/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26016/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26016/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/26016","id":937617403,"node_id":"MDU6SXNzdWU5Mzc2MTc0MDM=","number":26016,"title":"Is there any best practice for running functional-test in docker?","user":{"login":"hssrs","id":49379415,"node_id":"MDQ6VXNlcjQ5Mzc5NDE1","avatar_url":"https://avatars.githubusercontent.com/u/49379415?v=4","gravatar_id":"","url":"https://api.github.com/users/hssrs","html_url":"https://github.com/hssrs","followers_url":"https://api.github.com/users/hssrs/followers","following_url":"https://api.github.com/users/hssrs/following{/other_user}","gists_url":"https://api.github.com/users/hssrs/gists{/gist_id}","starred_url":"https://api.github.com/users/hssrs/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/hssrs/subscriptions","organizations_url":"https://api.github.com/users/hssrs/orgs","repos_url":"https://api.github.com/users/hssrs/repos","events_url":"https://api.github.com/users/hssrs/events{/privacy}","received_events_url":"https://api.github.com/users/hssrs/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""},{"id":1546440057,"node_id":"MDU6TGFiZWwxNTQ2NDQwMDU3","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/development","name":"development","color":"fc80df","default":false,"description":"Developement process & source code & implementation details"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2021-07-06T07:51:37Z","updated_at":"2021-10-17T14:10:58Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"We made some adaptive and intrusive modifications to the ClickHouse source code, so we wanted to test ClickHouse locally. I found that the integration test has a ReadMe file, which is helpful. I was able to run the integration test in docker successfully, but I didn’t find the instructions for running functional-test **in docker**.\r\nThe reason why I want to run with docker is because I encountered some environmental problems when running locally:\r\n```\r\nexport PATH=$PATH:/clickhouse/build/programs \r\n\"/clickhouse/build/programs/clickhouse\" --server -C /clickhouse/programs/server/config.xml & sleep 5\r\n\"/clickhouse/tests/clickhouse-test\" -j16 --no-zookeeper --no-shard --no-stateful --use-skip-list > /clickhouse/tests/function_test_log\r\n``` \r\n\r\nwe get some FAIL cases in function_test_log, for example:\r\n\r\n```\r\n00825_protobuf_format_enum_mapping:                                     [ FAIL ] - return code 1\r\nTraceback (most recent call last):\r\n  File \"/clickhouse/tests/queries/0_stateless/helpers/protobuf_length_delimited_encoder.py\", line 174, in <module>\r\n    decode_and_check(input, output, args.format_schema)\r\n  File \"/clickhouse/tests/queries/0_stateless/helpers/protobuf_length_delimited_encoder.py\", line 126, in decode_and_check\r\n    decode(tmp_input, tmp_decoded, format_schema)\r\n  File \"/clickhouse/tests/queries/0_stateless/helpers/protobuf_length_delimited_encoder.py\", line 77, in decode\r\n    shell=False) as proc:\r\n  File \"/usr/lib64/python3.7/subprocess.py\", line 775, in __init__\r\n    restore_signals, start_new_session)\r\n  File \"/usr/lib64/python3.7/subprocess.py\", line 1522, in _execute_child\r\n    raise child_exception_type(errno_num, err_msg, err_filename)\r\nFileNotFoundError: [Errno 2] No such file or directory: 'protoc': 'protoc'\r\n, result:\r\n\r\nSecond\r\nThird\r\nFirst\r\nFirst\r\nSecond\r\n\r\nBinary representation:\r\n00000000  02 08 01 02 08 64 00 00  02 08 01                 |.....d.....|\r\n0000000b\r\n\r\nOR\r\n\r\n01676_long_clickhouse_client_autocomplete:                              [ FAIL ] - result differs with reference:\r\n--- /clickhouse/tests/queries/0_stateless/01676_long_clickhouse_client_autocomplete.reference   2021-07-05 20:00:17.271835663 +0800\r\n+++ /clickhouse/tests/queries/0_stateless/01676_long_clickhouse_client_autocomplete.stdout      2021-07-05 22:40:07.743460581 +0800\r\n@@ -0,0 +1,2 @@\r\n+[FAIL] test_shard_localhost (positive)\r\n+[FAIL] default_path_test (positive)\r\n``` \r\n\r\nIt looks like some tools are not installed, so I think we may need to use the docker  from your side, e.g. `yandex/clickhouse-stateless-test` , but I am very new to docker and fail to make it run.\r\n```\r\ndocker run -it yandex/clickhouse-stateless-test:latest /bin/bash\r\n```\r\nShould I rebuild the docker since I have modified the source code?\r\nIs there any document or practice that I can learn how to run the functional-test **in docker**? \r\nThank in advance！","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26016/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/26016/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25999","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25999/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25999/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25999/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/25999","id":937226197,"node_id":"MDU6SXNzdWU5MzcyMjYxOTc=","number":25999,"title":"Reusing CTE twice in a filter makes query performance worse 4+ times","user":{"login":"simPod","id":327717,"node_id":"MDQ6VXNlcjMyNzcxNw==","avatar_url":"https://avatars.githubusercontent.com/u/327717?v=4","gravatar_id":"","url":"https://api.github.com/users/simPod","html_url":"https://github.com/simPod","followers_url":"https://api.github.com/users/simPod/followers","following_url":"https://api.github.com/users/simPod/following{/other_user}","gists_url":"https://api.github.com/users/simPod/gists{/gist_id}","starred_url":"https://api.github.com/users/simPod/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/simPod/subscriptions","organizations_url":"https://api.github.com/users/simPod/orgs","repos_url":"https://api.github.com/users/simPod/repos","events_url":"https://api.github.com/users/simPod/events{/privacy}","received_events_url":"https://api.github.com/users/simPod/received_events","type":"User","site_admin":false},"labels":[{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2021-07-05T16:12:42Z","updated_at":"2021-07-07T07:42:15Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"This is my table definition\r\n\r\n```sql\r\nCREATE TABLE table_a\r\n(\r\n    `timefield` DateTime,\r\n    `a` UUID,\r\n    `e` UUID,\r\n    `f` LowCardinality(String),\r\n    `g` LowCardinality(String),\r\n    `h` UUID,\r\n    `i` UUID,\r\n    `b` UInt32,\r\n    `c` LowCardinality(String),\r\n    `d` LowCardinality(String),\r\n    `bytes` AggregateFunction(sum, UInt32)\r\n)\r\nENGINE = ReplicatedAggregatingMergeTree('/clickhouse/tables/{shard}/table_a', '{replica}')\r\nPARTITION BY toDate(received_at)\r\nORDER BY (a, b, c, d, e, f, g, h, i, timefield)\r\nTTL timefield + toIntervalDay(90)\r\nSETTINGS index_granularity = 8192\r\n```\r\n\r\n_Bellow is my query._\r\n\r\nThere are 3 CTEs: `now`, `w1` and `w4`. I'm basically selecting values from now as `now` and values from a week ago and 4 weeks ago as `w1` and `w4`.\r\n\r\nI tried to filter values in `w1` and `w4` CTEs using values from `now` and expected to make the result set to select from smaller. \r\n\r\nSo I added `AND (c) IN (SELECT c FROM now)` to `w1` and `w4` CTEs. \r\n\r\n**Surprisingly, without a filter the query is much faster. Why is it so?**\r\n\r\nPerformance when `AND (c) IN (SELECT c FROM now)` is omitted:\r\n\r\n```\r\n0 rows in set. Elapsed: 1.312 sec. Processed 108.86 million rows, 4.86 GB (82.98 million rows/s., 3.70 GB/s.)\r\n```\r\n\r\nPerformance when the filter is kept:\r\n\r\n```\r\n0 rows in set. Elapsed: 4.423 sec. Processed 108.86 million rows, 4.87 GB (24.61 million rows/s., 1.10 GB/s.)\r\n```\r\n\r\n-----------\r\n\r\n```sql\r\nWITH now AS (\r\n    SELECT\r\n        max(metric) AS max,\r\n        max((timefield, metric)).2 AS last,\r\n        c\r\n    FROM (\r\n        SELECT\r\n            timefield,\r\n            sumMerge(bytes) * 8 / 300 AS metric,\r\n            c\r\n        FROM table_a\r\n        WHERE timefield BETWEEN '2021-06-28 09:30:00' AND '2021-06-30 09:29:59'\r\n            AND 1 = 1 AND a IN (...) AND f NOT IN (...) AND b <> 60068\r\n        GROUP BY timefield, c\r\n    )\r\n    GROUP BY c\r\n    ORDER BY max DESC\r\n    LIMIT 50\r\n),\r\nw1 AS (\r\n    SELECT\r\n        max(metric) AS max,\r\n        max((timefield, metric)).2 AS last,\r\n        c\r\n    FROM (\r\n        SELECT\r\n            timefield,\r\n            sumMerge(bytes) * 8 / 300 AS metric,\r\n            c\r\n        FROM table_a\r\n        WHERE timefield BETWEEN '2021-06-21 09:30:00' AND '2021-06-23 09:29:59'\r\n            AND 1 = 1 AND a IN (...) AND f NOT IN (...) AND b <> 60068\r\n            AND (c) IN (SELECT c FROM now)\r\n        GROUP BY timefield, c\r\n    )\r\n    GROUP BY c\r\n    ORDER BY max DESC\r\n),\r\nw4 AS (\r\n    SELECT\r\n        max(metric) AS max,\r\n        max((timefield, metric)).2 AS last,\r\n        c\r\n    FROM (\r\n        SELECT\r\n            timefield,\r\n            sumMerge(bytes) * 8 / 300 AS metric,\r\n            c\r\n        FROM table_a\r\n        WHERE timefield BETWEEN '2021-05-31 09:30:00' AND '2021-06-02 09:29:59'\r\n            AND 1 = 1 AND a IN (...) AND f NOT IN (...) AND b <> 60068\r\n            AND (c) IN (SELECT c FROM now)\r\n        GROUP BY timefield, c\r\n    )\r\n    GROUP BY c\r\n    ORDER BY max DESC\r\n)\r\nSELECT\r\n    now.c,\r\n    now.max AS max,\r\n    w1.max AS max_w1,\r\n    w4.max AS max_w4,\r\n    (max - max_w1) / max_w1 AS max_change_w1,\r\n    (max - max_w4) / max_w4 AS max_change_w4\r\nFROM now\r\nLEFT JOIN w1 ON now.c = w1.c\r\nLEFT JOIN w4 ON now.c = w4.c\r\nFORMAT Null;\r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25999/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25999/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25998","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25998/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25998/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25998/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/25998","id":937221589,"node_id":"MDU6SXNzdWU5MzcyMjE1ODk=","number":25998,"title":"Limit mutations by number of parts or partitions to prevent large table mutations","user":{"login":"siradjev","id":10959667,"node_id":"MDQ6VXNlcjEwOTU5NjY3","avatar_url":"https://avatars.githubusercontent.com/u/10959667?v=4","gravatar_id":"","url":"https://api.github.com/users/siradjev","html_url":"https://github.com/siradjev","followers_url":"https://api.github.com/users/siradjev/followers","following_url":"https://api.github.com/users/siradjev/following{/other_user}","gists_url":"https://api.github.com/users/siradjev/gists{/gist_id}","starred_url":"https://api.github.com/users/siradjev/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/siradjev/subscriptions","organizations_url":"https://api.github.com/users/siradjev/orgs","repos_url":"https://api.github.com/users/siradjev/repos","events_url":"https://api.github.com/users/siradjev/events{/privacy}","received_events_url":"https://api.github.com/users/siradjev/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-07-05T16:06:14Z","updated_at":"2021-07-05T16:06:27Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"(you don't have to strictly follow this form)\r\n\r\n**Use case**\r\nAccidental mutations on large partitioned tables cause clickhouse to die in loop of not merging/not mutating due to not having enough background pools in thread, and typically those are human errors as syntax for partition pruning is not something enforced.\r\nProblem happens frequently, and there are plenty of tickets about it... \r\n\r\n**Describe the solution you'd like**\r\nOne of the following options (or both) would be helpful for enhancing operations:\r\n\r\n* add parts_to_throw_mutation setting, defaulting to 5~10 range. This would work on any table. In case of replicated it may be enough to check on initiating replica.\r\n* add force_partition_key_for_mutation setting. In this case for partitioned tables \"ALTER ...IN PARTITION\" syntax would be mandatory. (related via #13403 #13026)\r\n\r\n**Describe alternatives you've considered**\r\nThere are no really other alternatives, as there is no command trigger in clickhouse. \r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25998/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25998/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25985","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25985/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25985/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25985/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/25985","id":936665090,"node_id":"MDU6SXNzdWU5MzY2NjUwOTA=","number":25985,"title":"The CH progress was killed by OOM killer","user":{"login":"HyaZz","id":41811181,"node_id":"MDQ6VXNlcjQxODExMTgx","avatar_url":"https://avatars.githubusercontent.com/u/41811181?v=4","gravatar_id":"","url":"https://api.github.com/users/HyaZz","html_url":"https://github.com/HyaZz","followers_url":"https://api.github.com/users/HyaZz/followers","following_url":"https://api.github.com/users/HyaZz/following{/other_user}","gists_url":"https://api.github.com/users/HyaZz/gists{/gist_id}","starred_url":"https://api.github.com/users/HyaZz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/HyaZz/subscriptions","organizations_url":"https://api.github.com/users/HyaZz/orgs","repos_url":"https://api.github.com/users/HyaZz/repos","events_url":"https://api.github.com/users/HyaZz/events{/privacy}","received_events_url":"https://api.github.com/users/HyaZz/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-07-05T04:13:41Z","updated_at":"2021-07-05T04:13:41Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Recently,our team meets a problem!The length of user's queries is big,even bigger than max_query_size sometime.In addition,some of them are RAM high-consumed including group by,join and so on.Our servers‘ RAM are 256G.The CH version is 20.8.5.45.The cluster have 45 nodes(15 shards & 3 replicas)\r\n\r\nThe correlative config settings at beginning are as follow:\r\n1.max_query_size (default:256K)\r\n2.max_memory_usage_for_user 230G\r\n3.max_bytes_before_external_group_by 100G\r\n4.max_bytes_before_external_sort 100G\r\n\r\nThe CH progress was killed by OOM killer now and then，just like this:\r\n`[16944749.606371] Out of memory: Kill process 223459 (clickhouse-serv) score 958 or sacrifice child\r\n[16944749.606463] Killed process 223459 (clickhouse-serv) total-vm:605840272kB, anon-rss:251523284kB, file-rss:0kB, shmem-rss:0kB`\r\n\r\nWe made an effort to solve this sutiation:\r\n1.set max_query_size 512K\r\n2.max_memory_usage 160G\r\n3.max_memory_usage_for_user 180G\r\n4.max_bytes_before_external_group_by 80G\r\n5.max_bytes_before_external_sort 80G\r\n\r\nBut there is nothing to be change.The problem still exists.The memory limit exception didn't be thrown,so that can free the memory allocated to aviod to be killed by OOM killer.\r\n\r\nSo,we raise this issue for help.did anyone meet this problem too?and how to solve?and perhaps some untracked memory?Thanks!","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25985/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25985/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25964","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25964/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25964/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25964/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/25964","id":936361037,"node_id":"MDU6SXNzdWU5MzYzNjEwMzc=","number":25964,"title":"Aggregate function to check if a random process is stationary","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-07-04T02:19:32Z","updated_at":"2021-07-04T02:41:49Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"**Use case**\r\nI have a ton of time series, but I want to look only at time series where something is actually changing.\r\nExample: if CPU temperature oscillates around the same mean with the same variance - I don't even want to look at the graph. I just want to look at the \"interesting\" graphs and create a dashboard of the most interesting graphs.\r\n\r\n**Describe the solution you'd like**\r\nAn aggregate or window function that takes two arguments: time and value, and outputs a 0..1 score about how non-stationary the random process is.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25964/reactions","total_count":1,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":1},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25964/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25925","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25925/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25925/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25925/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/25925","id":936138175,"node_id":"MDU6SXNzdWU5MzYxMzgxNzU=","number":25925,"title":"Review and possibly integrate codecs for floating point data","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":1546440057,"node_id":"MDU6TGFiZWwxNTQ2NDQwMDU3","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/development","name":"development","color":"fc80df","default":false,"description":"Developement process & source code & implementation details"}],"state":"open","locked":false,"assignee":{"login":"koloshmet","id":44980299,"node_id":"MDQ6VXNlcjQ0OTgwMjk5","avatar_url":"https://avatars.githubusercontent.com/u/44980299?v=4","gravatar_id":"","url":"https://api.github.com/users/koloshmet","html_url":"https://github.com/koloshmet","followers_url":"https://api.github.com/users/koloshmet/followers","following_url":"https://api.github.com/users/koloshmet/following{/other_user}","gists_url":"https://api.github.com/users/koloshmet/gists{/gist_id}","starred_url":"https://api.github.com/users/koloshmet/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/koloshmet/subscriptions","organizations_url":"https://api.github.com/users/koloshmet/orgs","repos_url":"https://api.github.com/users/koloshmet/repos","events_url":"https://api.github.com/users/koloshmet/events{/privacy}","received_events_url":"https://api.github.com/users/koloshmet/received_events","type":"User","site_admin":false},"assignees":[{"login":"koloshmet","id":44980299,"node_id":"MDQ6VXNlcjQ0OTgwMjk5","avatar_url":"https://avatars.githubusercontent.com/u/44980299?v=4","gravatar_id":"","url":"https://api.github.com/users/koloshmet","html_url":"https://github.com/koloshmet","followers_url":"https://api.github.com/users/koloshmet/followers","following_url":"https://api.github.com/users/koloshmet/following{/other_user}","gists_url":"https://api.github.com/users/koloshmet/gists{/gist_id}","starred_url":"https://api.github.com/users/koloshmet/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/koloshmet/subscriptions","organizations_url":"https://api.github.com/users/koloshmet/orgs","repos_url":"https://api.github.com/users/koloshmet/repos","events_url":"https://api.github.com/users/koloshmet/events{/privacy}","received_events_url":"https://api.github.com/users/koloshmet/received_events","type":"User","site_admin":false}],"milestone":null,"comments":1,"created_at":"2021-07-03T01:15:02Z","updated_at":"2022-01-19T19:19:00Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"Example from Acumuli, author @Lazin, license Apache 2.0: \r\n\r\nhttps://github.com/akumuli/Akumuli/blob/master/libakumuli/storage_engine/compression.h\r\n(search FCM and DFCM)\r\n\r\n> State of the art compression, ~1GB/s encoding throughput per core. ","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25925/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25925/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25911","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25911/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25911/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25911/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/25911","id":935364794,"node_id":"MDU6SXNzdWU5MzUzNjQ3OTQ=","number":25911,"title":"about bloom_filter","user":{"login":"ys-zhaoyh","id":30956381,"node_id":"MDQ6VXNlcjMwOTU2Mzgx","avatar_url":"https://avatars.githubusercontent.com/u/30956381?v=4","gravatar_id":"","url":"https://api.github.com/users/ys-zhaoyh","html_url":"https://github.com/ys-zhaoyh","followers_url":"https://api.github.com/users/ys-zhaoyh/followers","following_url":"https://api.github.com/users/ys-zhaoyh/following{/other_user}","gists_url":"https://api.github.com/users/ys-zhaoyh/gists{/gist_id}","starred_url":"https://api.github.com/users/ys-zhaoyh/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ys-zhaoyh/subscriptions","organizations_url":"https://api.github.com/users/ys-zhaoyh/orgs","repos_url":"https://api.github.com/users/ys-zhaoyh/repos","events_url":"https://api.github.com/users/ys-zhaoyh/events{/privacy}","received_events_url":"https://api.github.com/users/ys-zhaoyh/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-07-02T02:55:50Z","updated_at":"2021-07-02T02:55:50Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"May I ask, who can briefly introduce the realization principle of bloom_filter,not Bloom filter.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25911/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25911/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25905","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25905/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25905/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25905/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/25905","id":935125933,"node_id":"MDU6SXNzdWU5MzUxMjU5MzM=","number":25905,"title":"Code: 33. DB::Exception: Cannot read all data. : data for INSERT was parsed from stdin","user":{"login":"q0987","id":16629186,"node_id":"MDQ6VXNlcjE2NjI5MTg2","avatar_url":"https://avatars.githubusercontent.com/u/16629186?v=4","gravatar_id":"","url":"https://api.github.com/users/q0987","html_url":"https://github.com/q0987","followers_url":"https://api.github.com/users/q0987/followers","following_url":"https://api.github.com/users/q0987/following{/other_user}","gists_url":"https://api.github.com/users/q0987/gists{/gist_id}","starred_url":"https://api.github.com/users/q0987/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/q0987/subscriptions","organizations_url":"https://api.github.com/users/q0987/orgs","repos_url":"https://api.github.com/users/q0987/repos","events_url":"https://api.github.com/users/q0987/events{/privacy}","received_events_url":"https://api.github.com/users/q0987/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":7,"created_at":"2021-07-01T18:54:11Z","updated_at":"2021-07-03T18:25:26Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Hello all,\r\n\r\nWe have a process that is used to import data of RowBinary into ClickHouseDB.\r\n\r\nFor example,\r\n\r\n`$ cat abc.rowbinary | clickhouse-client --query=\"insert into default.test FORMAT RowBinary\"`\r\n\r\nIt has been working fine without issues. However, this morning, it crashed and reported the following errors:\r\n\r\n> Code: 33. DB::Exception: Cannot read all data. Bytes read: 377261643. Bytes expected: 16812728239.: (at row 4)\r\n> : data for INSERT was parsed from stdin\r\n\r\nI manually checked the abc.rowbinary with clickhouse-local and the file looks fine. After I rerun the process, the file was imported correctly.\r\n\r\nQuestion> What might cause this issues early this morning since I cannot reproduce the same error?\r\n\r\nThank you","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25905/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25905/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25891","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25891/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25891/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25891/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/25891","id":934790188,"node_id":"MDU6SXNzdWU5MzQ3OTAxODg=","number":25891,"title":"clickhouse-client shows \"default\" (incorrect) database name in the prompt ","user":{"login":"den-crane","id":19737682,"node_id":"MDQ6VXNlcjE5NzM3Njgy","avatar_url":"https://avatars.githubusercontent.com/u/19737682?v=4","gravatar_id":"","url":"https://api.github.com/users/den-crane","html_url":"https://github.com/den-crane","followers_url":"https://api.github.com/users/den-crane/followers","following_url":"https://api.github.com/users/den-crane/following{/other_user}","gists_url":"https://api.github.com/users/den-crane/gists{/gist_id}","starred_url":"https://api.github.com/users/den-crane/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/den-crane/subscriptions","organizations_url":"https://api.github.com/users/den-crane/orgs","repos_url":"https://api.github.com/users/den-crane/repos","events_url":"https://api.github.com/users/den-crane/events{/privacy}","received_events_url":"https://api.github.com/users/den-crane/received_events","type":"User","site_admin":false},"labels":[{"id":845247686,"node_id":"MDU6TGFiZWw4NDUyNDc2ODY=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/usability","name":"usability","color":"ebf28c","default":false,"description":""},{"id":993003747,"node_id":"MDU6TGFiZWw5OTMwMDM3NDc=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-cli","name":"comp-cli","color":"b5bcff","default":false,"description":"Console & command line"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-07-01T12:26:13Z","updated_at":"2021-07-04T16:53:24Z","closed_at":null,"author_association":"COLLABORATOR","active_lock_reason":null,"body":"```\r\ncat /etc/clickhouse-client/conf.d/propmt.xml\r\n<config>\r\n    <prompt_by_server_display_name>\r\n\t    <default>{database}@{host} :) </default>\r\n    </prompt_by_server_display_name>\r\n</config>\r\n\r\n\r\ncat /etc/clickhouse-server/conf.d/default_database.xml\r\n<?xml version=\"1.0\"?>\r\n<yandex>\r\n    <default_database>dw</default_database>\r\n</yandex>\r\n\r\n$ clickhouse-client\r\nClickHouse client version 21.6.5.37 (official build).\r\nConnecting to localhost:9000 as user default.\r\nConnected to ClickHouse server version 21.6.5 revision 54448.\r\n\r\ndefault@localhost :) select currentDatabase();\r\n\r\nSELECT currentDatabase()\r\n\r\nQuery id: efd2952e-a0d5-4250-be3c-5c3a929d3256\r\n\r\n┌─currentDatabase()─┐\r\n│ dw                │\r\n└───────────────────┘\r\n```\r\n\r\nnow: `default@localhost :)`\r\nexpected: `dw@localhost :)`","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25891/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25891/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25883","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25883/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25883/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25883/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/25883","id":933868738,"node_id":"MDU6SXNzdWU5MzM4Njg3Mzg=","number":25883,"title":"Add IN PARTITION clause for non-replicated tables","user":{"login":"jaumeNPAW","id":22289987,"node_id":"MDQ6VXNlcjIyMjg5OTg3","avatar_url":"https://avatars.githubusercontent.com/u/22289987?v=4","gravatar_id":"","url":"https://api.github.com/users/jaumeNPAW","html_url":"https://github.com/jaumeNPAW","followers_url":"https://api.github.com/users/jaumeNPAW/followers","following_url":"https://api.github.com/users/jaumeNPAW/following{/other_user}","gists_url":"https://api.github.com/users/jaumeNPAW/gists{/gist_id}","starred_url":"https://api.github.com/users/jaumeNPAW/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jaumeNPAW/subscriptions","organizations_url":"https://api.github.com/users/jaumeNPAW/orgs","repos_url":"https://api.github.com/users/jaumeNPAW/repos","events_url":"https://api.github.com/users/jaumeNPAW/events{/privacy}","received_events_url":"https://api.github.com/users/jaumeNPAW/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2021-06-30T16:05:58Z","updated_at":"2021-07-05T08:02:18Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"I would like to have IN PARTITION clause available for non-replicated tables, in order to perform mutations only to specified partition/partitions.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25883/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25883/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25873","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25873/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25873/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25873/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/25873","id":933722658,"node_id":"MDU6SXNzdWU5MzM3MjI2NTg=","number":25873,"title":"centos7 pidfile location systemd service vs init.d","user":{"login":"filimonov","id":1549571,"node_id":"MDQ6VXNlcjE1NDk1NzE=","avatar_url":"https://avatars.githubusercontent.com/u/1549571?v=4","gravatar_id":"","url":"https://api.github.com/users/filimonov","html_url":"https://github.com/filimonov","followers_url":"https://api.github.com/users/filimonov/followers","following_url":"https://api.github.com/users/filimonov/following{/other_user}","gists_url":"https://api.github.com/users/filimonov/gists{/gist_id}","starred_url":"https://api.github.com/users/filimonov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/filimonov/subscriptions","organizations_url":"https://api.github.com/users/filimonov/orgs","repos_url":"https://api.github.com/users/filimonov/repos","events_url":"https://api.github.com/users/filimonov/events{/privacy}","received_events_url":"https://api.github.com/users/filimonov/received_events","type":"User","site_admin":false},"labels":[{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2021-06-30T13:41:37Z","updated_at":"2021-07-04T14:23:20Z","closed_at":null,"author_association":"COLLABORATOR","active_lock_reason":null,"body":"```\r\ncat /etc/systemd/system/clickhouse-server.service\r\n[Unit]\r\nDescription=ClickHouse Server (analytic DBMS for big data)\r\nRequires=network-online.target\r\nAfter=network-online.target\r\n\r\n[Service]\r\nType=simple\r\nUser=clickhouse\r\nGroup=clickhouse\r\nRestart=always\r\nRestartSec=30\r\nRuntimeDirectory=clickhouse-server\r\nExecStart=/usr/bin/clickhouse-server --config=/etc/clickhouse-server/config.xml --pid-file=/run/clickhouse-server/clickhouse-server.pid\r\nLimitCORE=infinity\r\nLimitNOFILE=500000\r\nCapabilityBoundingSet=CAP_NET_ADMIN CAP_IPC_LOCK CAP_SYS_NICE\r\n\r\n[Install]\r\nWantedBy=multi-user.target\r\n```\r\n\r\n```\r\nps -AF | grep clickhouse-server\r\nclickho+  60812  59517  0 28178   972   2 13:38 pts/1    00:00:00 grep clickhouse-server\r\nclickho+ 102507      1 60 5023771 2196264 2 cze28 ?      1-03:38:32 clickhouse-server --daemon --pid-file=/var/run/clickhouse-server/clickhouse-server.pid --config-file=/etc/clickhouse-server/config.xml\r\n```\r\n\r\n```\r\nbash-4.2$ ls -la /var/run/clickhouse-server/clickhouse-server.pid\r\nls: cannot access /var/run/clickhouse-server/clickhouse-server.pid: No such file or directory\r\nbash-4.2$ ls -la /var/run/clickhouse-server/\r\nls: cannot access /var/run/clickhouse-server/: No such file or directory\r\nbash-4.2$ ls -la /var/run/cli*\r\nls: cannot access /var/run/cli*: No such file or directory\r\nbash-4.2$ \r\n\r\n\r\n$ ls -la /run/clickhouse-server/*\r\n-rw-r-----. 1 clickhouse clickhouse 5 06-30 13:39 /run/clickhouse-server/clickhouse-server.pid\r\nbash-4.2$ cat /run/clickhouse-server/clickhouse-server.pid\r\n60972\r\n```\r\n\r\n```\r\ncat /etc/init.d/clickhouse-server | grep PIDDIR\r\nCLICKHOUSE_PIDDIR=/var/run/$PROGRAM\r\nCLICKHOUSE_PIDFILE=\"$CLICKHOUSE_PIDDIR/$PROGRAM.pid\"\r\n    ${CLICKHOUSE_GENERIC_PROGRAM} install --user \"${CLICKHOUSE_USER}\" --pid-path \"${CLICKHOUSE_PIDDIR}\" --config-path \"${CLICKHOUSE_CONFDIR}\" --binary-path \"${CLICKHOUSE_BINDIR}\"\r\n    ${CLICKHOUSE_GENERIC_PROGRAM} start --user \"${CLICKHOUSE_USER}\" --pid-path \"${CLICKHOUSE_PIDDIR}\" --config-path \"${CLICKHOUSE_CONFDIR}\" --binary-path \"${CLICKHOUSE_BINDIR}\"\r\n    ${CLICKHOUSE_GENERIC_PROGRAM} stop --pid-path \"${CLICKHOUSE_PIDDIR}\"\r\n    ${CLICKHOUSE_GENERIC_PROGRAM} restart --user \"${CLICKHOUSE_USER}\" --pid-path \"${CLICKHOUSE_PIDDIR}\" --config-path \"${CLICKHOUSE_CONFDIR}\" --binary-path \"${CLICKHOUSE_BINDIR}\"\r\n    ${CLICKHOUSE_GENERIC_PROGRAM} stop --force --pid-path \"${CLICKHOUSE_PIDDIR}\"\r\n    ${CLICKHOUSE_GENERIC_PROGRAM} status --pid-path \"${CLICKHOUSE_PIDDIR}\"\r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25873/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25873/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25865","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25865/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25865/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25865/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/25865","id":933659857,"node_id":"MDU6SXNzdWU5MzM2NTk4NTc=","number":25865,"title":"USER/ROLES comments","user":{"login":"UnamedRus","id":9449405,"node_id":"MDQ6VXNlcjk0NDk0MDU=","avatar_url":"https://avatars.githubusercontent.com/u/9449405?v=4","gravatar_id":"","url":"https://api.github.com/users/UnamedRus","html_url":"https://github.com/UnamedRus","followers_url":"https://api.github.com/users/UnamedRus/followers","following_url":"https://api.github.com/users/UnamedRus/following{/other_user}","gists_url":"https://api.github.com/users/UnamedRus/gists{/gist_id}","starred_url":"https://api.github.com/users/UnamedRus/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/UnamedRus/subscriptions","organizations_url":"https://api.github.com/users/UnamedRus/orgs","repos_url":"https://api.github.com/users/UnamedRus/repos","events_url":"https://api.github.com/users/UnamedRus/events{/privacy}","received_events_url":"https://api.github.com/users/UnamedRus/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-06-30T12:34:46Z","updated_at":"2021-06-30T12:34:46Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Use case**\r\nHave ability to add comment's to user/roles\r\n\r\n**Describe the solution you'd like**\r\n\r\n```\r\nCREATE USER test_user_01075 COMMENT 'test';\r\n```\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25865/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25865/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25864","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25864/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25864/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25864/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/25864","id":933651139,"node_id":"MDU6SXNzdWU5MzM2NTExMzk=","number":25864,"title":"S3 DB::Exception: The type \"null\" of an input column not supported for conversion from a Parquet data format","user":{"login":"gjaehrling","id":7389104,"node_id":"MDQ6VXNlcjczODkxMDQ=","avatar_url":"https://avatars.githubusercontent.com/u/7389104?v=4","gravatar_id":"","url":"https://api.github.com/users/gjaehrling","html_url":"https://github.com/gjaehrling","followers_url":"https://api.github.com/users/gjaehrling/followers","following_url":"https://api.github.com/users/gjaehrling/following{/other_user}","gists_url":"https://api.github.com/users/gjaehrling/gists{/gist_id}","starred_url":"https://api.github.com/users/gjaehrling/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/gjaehrling/subscriptions","organizations_url":"https://api.github.com/users/gjaehrling/orgs","repos_url":"https://api.github.com/users/gjaehrling/repos","events_url":"https://api.github.com/users/gjaehrling/events{/privacy}","received_events_url":"https://api.github.com/users/gjaehrling/received_events","type":"User","site_admin":false},"labels":[{"id":1401255404,"node_id":"MDU6TGFiZWwxNDAxMjU1NDA0","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-formats","name":"comp-formats","color":"b5bcff","default":false,"description":"Input / output formats"},{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-06-30T12:24:07Z","updated_at":"2022-01-17T16:04:20Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"### SELECT queries from S3 with WHERE condition not working for Parquet input-files \r\nI'm trying to use clickhouse on S3 buckets with Parquet data. The following create statement was used: \r\n\r\n`CREATE TABLE s3_sensor_data_2 (LogID Nullable(String), LoggingTime Nullable(Datetime), LoggingValue Nullable(Float)) ENGINE = S3('https://s3.eu-central-1.amazonaws.com/bucket/*.parquet', 'Parquet');`\r\n\r\nI'm able to query the data using a simple select statement: \r\n\r\n```\r\nSELECT *\r\nFROM s3_sensor_data\r\nLIMIT 10\r\n\r\nQuery id: 22430c33-6460-4074-8771-2894e15ad152\r\n\r\n┌─LogID────────────────────────────────┬─────────LoggingTime─┬─LoggingValue─┐\r\n│ 0022AA50-6984-44CE-A9FF-E448CC7A7889 │ 2015-09-21 08:47:00 │         0.34 │\r\n│ 0022AA50-6984-44CE-A9FF-E448CC7A7889 │ 2015-09-21 08:48:00 │         0.35 │\r\n│ 0022AA50-6984-44CE-A9FF-E448CC7A7889 │ 2015-09-21 08:49:00 │         0.35 │\r\n│ 0022AA50-6984-44CE-A9FF-E448CC7A7889 │ 2015-09-21 08:50:00 │         0.33 │\r\n│ 0022AA50-6984-44CE-A9FF-E448CC7A7889 │ 2015-09-21 08:51:00 │         0.33 │\r\n│ 0022AA50-6984-44CE-A9FF-E448CC7A7889 │ 2015-09-21 08:52:00 │         0.32 │\r\n│ 0022AA50-6984-44CE-A9FF-E448CC7A7889 │ 2015-09-21 08:53:00 │         0.32 │\r\n│ 0022AA50-6984-44CE-A9FF-E448CC7A7889 │ 2015-09-21 08:54:00 │         0.31 │\r\n│ 0022AA50-6984-44CE-A9FF-E448CC7A7889 │ 2015-09-21 08:55:00 │         0.31 │\r\n│ 0022AA50-6984-44CE-A9FF-E448CC7A7889 │ 2015-09-21 08:56:00 │         0.30 │\r\n└──────────────────────────────────────┴─────────────────────┴──────────────┘\r\n```\r\nBut its not possible to use a WHERE condition or anything else in the SELECT.\r\nIf I load the same Parquet file locally to clickhouse it is working.\r\n\r\nExample: \r\n`select * from s3_sensor_data_2 where LogID = '0022AA50-6984-44CE-A9FF-E448CC7A7889' limit 10;`\r\n\r\nError message: \r\n\r\n```\r\nQuery id: fbe0aaaf-fe6a-45d8-a8cc-1af9ac766db0\r\n\r\n↙ Progress: 3.72 million rows, 208.20 MB (553.83 thousand rows/s., 31.01 MB/s.) \r\n0 rows in set. Elapsed: 8.145 sec. Processed 3.72 million rows, 208.20 MB (456.46 thousand rows/s., 25.56 MB/s.)\r\n\r\nReceived exception from server (version 21.6.5):\r\nCode: 70. DB::Exception: Received from localhost:9000. DB::Exception: The type \"null\" of an input column \"LogID\" is not supported for conversion from a Parquet data format: While executing S3. Stack trace:\r\n```\r\n```\r\n\r\nStack trace: \r\n```\r\n```\r\n0. DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, bool) @ 0x8b6cbba in /usr/bin/clickhouse\r\n1. ? @ 0x104c094c in /usr/bin/clickhouse\r\n2. ? @ 0x104c02e5 in /usr/bin/clickhouse\r\n3. DB::ArrowColumnToCHColumn::arrowTableToCHChunk(DB::Chunk&, std::__1::shared_ptr<arrow::Table>&, DB::Block const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >) @ 0x104bf3b3 in /usr/bin/clickhouse\r\n4. DB::ParquetBlockInputFormat::generate() @ 0x1053366c in /usr/bin/clickhouse\r\n5. DB::ISource::tryGenerate() @ 0x1046f555 in /usr/bin/clickhouse\r\n6. DB::ISource::work() @ 0x1046f13a in /usr/bin/clickhouse\r\n7. DB::InputStreamFromInputFormat::readImpl() @ 0xdacd9ff in /usr/bin/clickhouse\r\n8. DB::IBlockInputStream::read() @ 0xf30f452 in /usr/bin/clickhouse\r\n9. DB::StorageS3Source::generate() @ 0xff78cf6 in /usr/bin/clickhouse\r\n10. DB::ISource::tryGenerate() @ 0x1046f555 in /usr/bin/clickhouse\r\n11. DB::ISource::work() @ 0x1046f13a in /usr/bin/clickhouse\r\n12. DB::SourceWithProgress::work() @ 0x1062ee2a in /usr/bin/clickhouse\r\n13. ? @ 0x104aa3dd in /usr/bin/clickhouse\r\n14. DB::PipelineExecutor::executeStepImpl(unsigned long, unsigned long, std::__1::atomic<bool>*) @ 0x104a6f71 in /usr/bin/clickhouse\r\n15. ? @ 0x104ab9f6 in /usr/bin/clickhouse\r\n16. ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) @ 0x8bacedf in /usr/bin/clickhouse\r\n17. ? @ 0x8bb0403 in /usr/bin/clickhouse\r\n18. start_thread @ 0x9609 in /usr/lib/x86_64-linux-gnu/libpthread-2.31.so\r\n19. clone @ 0x122293 in /usr/lib/x86_64-linux-gnu/libc-2.31.so\r\n```\r\n```\r\n\r\n```\r\n\r\n**How to reproduce**\r\n* ClickHouse server version 21.6.5\r\n* Interface: clickhouse-client\r\n* Only default settings\r\n* `CREATE TABLE` statements see above\r\n* Queries to run see above\r\n\r\n**Expected behavior**\r\nThe expected behavior is achieved when loading the same(!!!) Parquet files for local directory:\r\n\r\n```\r\na75ba35cec96 :) select * from sensor_data_local where LogID = '0022AA50-6984-44CE-A9FF-E448CC7A7889' limit 10;\r\n\r\nSELECT *\r\nFROM sensor_data\r\nWHERE LogID = '0022AA50-6984-44CE-A9FF-E448CC7A7889'\r\nLIMIT 10\r\n\r\nQuery id: e72f72c0-e27e-47d0-8064-0aa1fed25405\r\n\r\n┌─LogID────────────────────────────────┬─────────LoggingTime─┬─LoggingValue─┐\r\n│ 0022AA50-6984-44CE-A9FF-E448CC7A7889 │ 2019-04-08 16:18:00 │           23 │\r\n│ 0022AA50-6984-44CE-A9FF-E448CC7A7889 │ 2019-04-08 16:19:00 │         41.5 │\r\n│ 0022AA50-6984-44CE-A9FF-E448CC7A7889 │ 2019-04-08 16:20:00 │         60.5 │\r\n│ 0022AA50-6984-44CE-A9FF-E448CC7A7889 │ 2019-04-08 16:21:00 │           76 │\r\n│ 0022AA50-6984-44CE-A9FF-E448CC7A7889 │ 2019-04-08 16:22:00 │           76 │\r\n│ 0022AA50-6984-44CE-A9FF-E448CC7A7889 │ 2019-04-08 16:23:00 │           73 │\r\n│ 0022AA50-6984-44CE-A9FF-E448CC7A7889 │ 2019-04-08 16:24:00 │           73 │\r\n│ 0022AA50-6984-44CE-A9FF-E448CC7A7889 │ 2019-04-08 16:25:00 │           70 │\r\n│ 0022AA50-6984-44CE-A9FF-E448CC7A7889 │ 2019-04-08 16:26:00 │           61 │\r\n│ 0022AA50-6984-44CE-A9FF-E448CC7A7889 │ 2019-04-08 16:27:00 │           52 │\r\n└──────────────────────────────────────┴─────────────────────┴──────────────┘\r\n\r\n10 rows in set. Elapsed: 0.053 sec. Processed 2.40 million rows, 108.42 MB (44.84 million rows/s., 2.03 GB/s.)\r\n\r\n```\r\n\r\n\r\n**Error message and/or stacktrace**\r\nDB::Exception: The type \"null\" of an input column \"LogID\" is not supported for conversion from a Parquet data format: While executing S3. Stack trace:\r\n\r\nStack trace above.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25864/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25864/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25853","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25853/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25853/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25853/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/25853","id":933461858,"node_id":"MDU6SXNzdWU5MzM0NjE4NTg=","number":25853,"title":"Aggregated measurements have higher values in Materialized View than in the table which it built on","user":{"login":"mkocztorz","id":3668945,"node_id":"MDQ6VXNlcjM2Njg5NDU=","avatar_url":"https://avatars.githubusercontent.com/u/3668945?v=4","gravatar_id":"","url":"https://api.github.com/users/mkocztorz","html_url":"https://github.com/mkocztorz","followers_url":"https://api.github.com/users/mkocztorz/followers","following_url":"https://api.github.com/users/mkocztorz/following{/other_user}","gists_url":"https://api.github.com/users/mkocztorz/gists{/gist_id}","starred_url":"https://api.github.com/users/mkocztorz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mkocztorz/subscriptions","organizations_url":"https://api.github.com/users/mkocztorz/orgs","repos_url":"https://api.github.com/users/mkocztorz/repos","events_url":"https://api.github.com/users/mkocztorz/events{/privacy}","received_events_url":"https://api.github.com/users/mkocztorz/received_events","type":"User","site_admin":false},"labels":[{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":{"login":"den-crane","id":19737682,"node_id":"MDQ6VXNlcjE5NzM3Njgy","avatar_url":"https://avatars.githubusercontent.com/u/19737682?v=4","gravatar_id":"","url":"https://api.github.com/users/den-crane","html_url":"https://github.com/den-crane","followers_url":"https://api.github.com/users/den-crane/followers","following_url":"https://api.github.com/users/den-crane/following{/other_user}","gists_url":"https://api.github.com/users/den-crane/gists{/gist_id}","starred_url":"https://api.github.com/users/den-crane/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/den-crane/subscriptions","organizations_url":"https://api.github.com/users/den-crane/orgs","repos_url":"https://api.github.com/users/den-crane/repos","events_url":"https://api.github.com/users/den-crane/events{/privacy}","received_events_url":"https://api.github.com/users/den-crane/received_events","type":"User","site_admin":false},"assignees":[{"login":"den-crane","id":19737682,"node_id":"MDQ6VXNlcjE5NzM3Njgy","avatar_url":"https://avatars.githubusercontent.com/u/19737682?v=4","gravatar_id":"","url":"https://api.github.com/users/den-crane","html_url":"https://github.com/den-crane","followers_url":"https://api.github.com/users/den-crane/followers","following_url":"https://api.github.com/users/den-crane/following{/other_user}","gists_url":"https://api.github.com/users/den-crane/gists{/gist_id}","starred_url":"https://api.github.com/users/den-crane/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/den-crane/subscriptions","organizations_url":"https://api.github.com/users/den-crane/orgs","repos_url":"https://api.github.com/users/den-crane/repos","events_url":"https://api.github.com/users/den-crane/events{/privacy}","received_events_url":"https://api.github.com/users/den-crane/received_events","type":"User","site_admin":false}],"milestone":null,"comments":5,"created_at":"2021-06-30T08:55:48Z","updated_at":"2021-07-15T06:59:50Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"**Describe the unexpected behaviour**\r\n\r\nWhen connecting to one node and performing inserts on Distributed table the data in Materialized View do not match aggregated values from original table, but only on a shard where the inserts are NOT done.\r\n\r\nWe have four nodes:\r\n- Shard 1 Replica 1\r\n- Shard 1 Replica 2\r\n- Shard 2 Replica 1\r\n- Shard 2 Replica 2\r\n\r\nI have Distributed table `events` designed for writes and reads from `event_shard` which is `ReplicatedSummingMergeTree` engine.\r\nOn each node there is a  `Materialized View` called `event_hourly_shard` which holds same data as `event_shard` just preaggregated to full hours.\r\n\r\nTables are created ON CLUSTER.\r\n\r\nThe event_shard table\r\n---\r\n```\r\nCREATE TABLE IF NOT EXISTS insights.event_shard ON CLUSTER 'clickhouse-main'\r\n(\r\n    event_at     DateTime,\r\n    visit_at     DateTime,\r\n    event_type   String,\r\n    publisher_id UInt32,\r\n    count        UInt64\r\n)\r\n    ENGINE = ReplicatedSummingMergeTree('/clickhouse/tables/{cluster}/{shard}/event', '{replica}')\r\n        PARTITION BY event_at\r\n        PRIMARY KEY (event_at, visit_at, event_type, publisher_id)\r\n        ORDER BY (event_at, visit_at, event_type, publisher_id)\r\n```\r\nDistributed event table (used for inserts)\r\n---\r\n```\r\nCREATE TABLE IF NOT EXISTS insights.event ON CLUSTER 'clickhouse-main'\r\n(\r\n    event_at     DateTime,\r\n    visit_at     DateTime,\r\n    event_type   String,\r\n    publisher_id UInt32,\r\n    count        UInt64\r\n)\r\n    ENGINE = Distributed('clickhouse-main', insights, event_shard, rand())\r\n```\r\nMaterialized view for event_shard table (hourly aggregate):\r\n---\r\n```\r\nCREATE MATERIALIZED VIEW IF NOT EXISTS insights.event_hourly_shard\r\n            ON CLUSTER 'clickhouse-main'\r\n            ENGINE = ReplicatedSummingMergeTree('/clickhouse/tables/{cluster}/{shard}/event_hourly', '{replica}')\r\n                PARTITION BY event_at\r\n                PRIMARY KEY (event_at, visit_at, event_type, publisher_id)\r\n                ORDER BY (event_at, visit_at, event_type, publisher_id)\r\n            POPULATE\r\nAS\r\nSELECT toStartOfHour(event_at) as event_at,\r\n       toStartOfHour(visit_at) as visit_at,\r\n       event_type,\r\n       publisher_id,\r\n       sum(count) as count\r\nFROM insights.event_shard\r\nGROUP BY toStartOfHour(event_at) as event_at,\r\n         toStartOfHour(visit_at) as visit_at,\r\n         event_type,\r\n         publisher_id\r\n```\r\nAdditional Distributed table on top of event_hourly_shard (not part of the issue, just to show full picture)\r\n---\r\n```\r\nCREATE TABLE IF NOT EXISTS insights.event_hourly ON CLUSTER 'clickhouse-main'\r\n(\r\n    event_at        DateTime,\r\n    visit_at        DateTime,\r\n    event_type      String,\r\n    publisher_id    UInt32,\r\n    count           UInt64\r\n)\r\n    ENGINE = Distributed('clickhouse-main', insights, event_hourly_shard, rand())\r\n```\r\n\r\n\r\n**How to reproduce**\r\n\r\nInsert data to Distributed `event` table only on `Shard 2 Replica 2`. I know it's not optimal.\r\n\r\nThen, run query on Shard 1 and Shard 2 (any of 2 replicas)\r\n```\r\nWITH 1 as pid, '2021-06-29' as date, 14 as hour\r\nSELECT 'quarterly' as version, toDate(visit_at), sum(count)\r\nFROM insights.event_shard\r\nwhere publisher_id = pid\r\n  and toHour(visit_at) = hour\r\n  and toDate(visit_at) = date\r\ngroup by toDate(visit_at), event_type\r\nORDER BY toDate(visit_at) desc\r\n\r\nUNION ALL\r\n\r\nSELECT 'hourly' as version, toDate(visit_at), sum(count)\r\nFROM insights.event_hourly_shard\r\nwhere publisher_id = pid\r\n  and toHour(visit_at) = hour\r\n  and toDate(visit_at) = date\r\ngroup by toDate(visit_at)\r\nORDER BY toDate(visit_at) desc;\r\n```\r\n\r\n**Expected behavior**\r\n\r\nThis is result of above query on Shard 2 (the one the inserts were done) - both counts are equal as expected\r\n\r\ntable        | date           | count\r\n------------- |-------------| -----\r\nquarterly|2021-06-29|29538570\r\nhourly|2021-06-29|29538570\r\n\r\n\r\n**Unexpected behavior**\r\n\r\nThis is result of above query on Shard 1 (where no inserts were done directly) - counts are different\r\n\r\n\r\ntable        | date           | count\r\n------------- |-------------| -----\r\nquarterly|2021-06-29|29548831\r\nhourly|2021-06-29|30467668\r\n\r\nWhat is even more puzzling, the value from materialized view is higher than the value from event_shard table.\r\n\r\nI confirmed the values in `event_shard` table are valid. The higher count from `event_hourly_shard` is invalid.\r\n\r\nWhen I modified the code to insert data to `event_shard` directly and distributed the inserts, then both shards behave correctly. This points the issue is somewhere on the `event` Distributed table, while forwarding the inserts to the other shard.\r\n\r\n* Which ClickHouse server version to use\r\n`ClickHouse server version 21.5.7.9 (official build).`","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25853/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25853/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25815","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25815/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25815/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25815/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/25815","id":932691317,"node_id":"MDU6SXNzdWU5MzI2OTEzMTc=","number":25815,"title":"DATE_SUB(date, INTERVAL xxx unit) - works, but is not documented","user":{"login":"pakud","id":30438339,"node_id":"MDQ6VXNlcjMwNDM4MzM5","avatar_url":"https://avatars.githubusercontent.com/u/30438339?v=4","gravatar_id":"","url":"https://api.github.com/users/pakud","html_url":"https://github.com/pakud","followers_url":"https://api.github.com/users/pakud/followers","following_url":"https://api.github.com/users/pakud/following{/other_user}","gists_url":"https://api.github.com/users/pakud/gists{/gist_id}","starred_url":"https://api.github.com/users/pakud/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pakud/subscriptions","organizations_url":"https://api.github.com/users/pakud/orgs","repos_url":"https://api.github.com/users/pakud/repos","events_url":"https://api.github.com/users/pakud/events{/privacy}","received_events_url":"https://api.github.com/users/pakud/received_events","type":"User","site_admin":false},"labels":[{"id":785082162,"node_id":"MDU6TGFiZWw3ODUwODIxNjI=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-documentation","name":"comp-documentation","color":"b5bcff","default":false,"description":"Used to run automatic builds of the documentation"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-06-29T13:43:42Z","updated_at":"2021-06-30T06:13:57Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"**Describe the issue**\r\nClickHouse seems to handle correctly this type of expressions:\r\n\r\n- DATE_SUB(NOW(), INTERVAL 1 DAY)\r\n- DATE_ADD(NOW(), INTERVAL 1 WEEK)\r\n\r\nhandling of this format is in https://github.com/ClickHouse/ClickHouse/blob/a52bba91b776034654a96f88b2b3f81bc6170a83/src/Parsers/ExpressionElementParsers.cpp#L1369 but is not documented in https://clickhouse.tech/docs/en/sql-reference/functions/date-time-functions/#date_sub\r\n\r\n**Additional context**\r\nabove is based on ClickHouse 21.3.5. maybe the documentation can be updated to match behavior of the code?\r\n\r\nlooks like DATE_SUB, DATE_ADD can behave just like https://clickhouse.tech/docs/en/sql-reference/functions/date-time-functions/#timestamp_add\r\n\r\nthank you!","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25815/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25815/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25809","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25809/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25809/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25809/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/25809","id":932420847,"node_id":"MDU6SXNzdWU5MzI0MjA4NDc=","number":25809,"title":"distribution_product_mode generates different behaviors.","user":{"login":"etah000","id":7627204,"node_id":"MDQ6VXNlcjc2MjcyMDQ=","avatar_url":"https://avatars.githubusercontent.com/u/7627204?v=4","gravatar_id":"","url":"https://api.github.com/users/etah000","html_url":"https://github.com/etah000","followers_url":"https://api.github.com/users/etah000/followers","following_url":"https://api.github.com/users/etah000/following{/other_user}","gists_url":"https://api.github.com/users/etah000/gists{/gist_id}","starred_url":"https://api.github.com/users/etah000/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/etah000/subscriptions","organizations_url":"https://api.github.com/users/etah000/orgs","repos_url":"https://api.github.com/users/etah000/repos","events_url":"https://api.github.com/users/etah000/events{/privacy}","received_events_url":"https://api.github.com/users/etah000/received_events","type":"User","site_admin":false},"labels":[{"id":1357578153,"node_id":"MDU6TGFiZWwxMzU3NTc4MTUz","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-joins","name":"comp-joins","color":"b5bcff","default":false,"description":"JOINs"},{"id":1507888214,"node_id":"MDU6TGFiZWwxNTA3ODg4MjE0","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/st-accepted","name":"st-accepted","color":"e5b890","default":false,"description":"The issue is in our backlog, ready to take"},{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-06-29T09:33:36Z","updated_at":"2021-11-08T08:34:22Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"clickhouse version:\r\n   21.3.13.1-lts\r\n\r\nFor a cluster with 3 nodes: N1, N2, N3; the virtual cluster: all_nodes\r\n\r\non N1, execute the following statements:\r\n\r\n```\r\ncreate database test on cluster all_nodes;\r\ncreate table test.t1_local  on cluster all_nodes (a Int32, b Int32) engine=MergeTree() order by a;\r\ncreate table test.t1_all  on cluster all_nodes as test.t1_local engine=Distributed('all_nodes', 'test', 't1_local', a);\r\n\r\ninsert into test.t1_all values(1, 1), (2,2), (3,3);\r\n\r\ncreate table test.t2_local  on cluster all_nodes  as test.t1_local;\r\ncreate table test.t2_all  on cluster all_nodes as test.t2_local engine=Distributed('all_nodes', 'test', 't2_local', rand());\r\ninsert into test.t2_local values(1, 1), (2,2), (3,3);\r\n\r\nselect * from test.t1_all t1 where t1.a in (select t2.a from test.t2_all t2);\r\nselect t1.* from test.t1_all t1 join test.t2_all t2 on t1.a = t2.a;\r\n\r\n\r\n\r\nnode153 :) set distributed_product_mode = 'local';;\r\n\r\nSET distributed_product_mode = 'local'\r\n\r\nOk.\r\n\r\n0 rows in set. Elapsed: 0.001 sec.\r\n\r\nnode153 :) select t1.* from test.t1_all t1 join test.t2_all t2 on t1.a = t2.a;\r\n\r\nSELECT t1.*\r\nFROM test.t1_all AS t1\r\nINNER JOIN test.t2_all AS t2 ON t1.a = t2.a\r\n\r\n┌─a─┬─b─┐\r\n│ 2 │ 2 │\r\n└───┴───┘\r\n┌─a─┬─b─┐\r\n│ 3 │ 3 │\r\n└───┴───┘\r\n┌─a─┬─b─┐\r\n│ 1 │ 1 │\r\n└───┴───┘\r\n\r\n3 rows in set. Elapsed: 0.016 sec.\r\n\r\nnode153 :) select * from test.t1_all t1 where t1.a in (select t2.a from test.t2_all t2);\r\n\r\nSELECT *\r\nFROM test.t1_all AS t1\r\nWHERE t1.a IN\r\n(\r\n    SELECT t2.a\r\n    FROM test.t2_all AS t2\r\n)\r\n\r\n┌─a─┬─b─┐\r\n│ 2 │ 2 │\r\n└───┴───┘\r\n\r\n1 rows in set. Elapsed: 0.010 sec.\r\n\r\nnode153 :) set distributed_product_mode = 'global';;\r\n\r\nSET distributed_product_mode = 'global'\r\n\r\nOk.\r\n\r\n0 rows in set. Elapsed: 0.001 sec.\r\n\r\nnode153 :) select t1.* from test.t1_all t1 join test.t2_all t2 on t1.a = t2.a;\r\n\r\nSELECT t1.*\r\nFROM test.t1_all AS t1\r\nINNER JOIN test.t2_all AS t2 ON t1.a = t2.a\r\n\r\n┌─a─┬─b─┐\r\n│ 2 │ 2 │\r\n└───┴───┘\r\n┌─a─┬─b─┐\r\n│ 3 │ 3 │\r\n└───┴───┘\r\n┌─a─┬─b─┐\r\n│ 1 │ 1 │\r\n└───┴───┘\r\n\r\n3 rows in set. Elapsed: 0.019 sec.\r\n\r\nnode153 :) select * from test.t1_all t1 where t1.a in (select t2.a from test.t2_all t2);\r\n\r\nSELECT *\r\nFROM test.t1_all AS t1\r\nWHERE t1.a IN\r\n(\r\n    SELECT t2.a\r\n    FROM test.t2_all AS t2\r\n)\r\n\r\n┌─a─┬─b─┐\r\n│ 2 │ 2 │\r\n└───┴───┘\r\n┌─a─┬─b─┐\r\n│ 1 │ 1 │\r\n└───┴───┘\r\n┌─a─┬─b─┐\r\n│ 3 │ 3 │\r\n└───┴───┘\r\n\r\n3 rows in set. Elapsed: 0.012 sec.\r\n\r\n```\r\n\r\nIf \"distributed_product_mode\" is set to \"local\", when queries were sent to remote servers,  the \"t2_all\" in \"in subquery\"  is transformed to \"t2_local\" as expected, but the \"t2_all\" as the right join table remains the same. Consequently, they generate different results.\r\n\r\nIn the  earlier version, two big table join requires that the two table collocated, that is, their sharding keys are the same as the join keys so “DB1. T1 join DB1.T2_local” can return the correct result.  if one of replicas of T1 failed, it can fallback to anthoer replica. But in circular relication mode, the second replica for T2_local locates in different database, such as \"DB2\". So this kind of join statement loses its HA. \r\n\r\nMaybe it is a better choice that \"join\" keeps the same behavior as \"in subquery\" .\r\n\r\n\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25809/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25809/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25808","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25808/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25808/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25808/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/25808","id":932350496,"node_id":"MDU6SXNzdWU5MzIzNTA0OTY=","number":25808,"title":"ALTER TABLE with temporary tables does not works","user":{"login":"Grian","id":65714,"node_id":"MDQ6VXNlcjY1NzE0","avatar_url":"https://avatars.githubusercontent.com/u/65714?v=4","gravatar_id":"","url":"https://api.github.com/users/Grian","html_url":"https://github.com/Grian","followers_url":"https://api.github.com/users/Grian/followers","following_url":"https://api.github.com/users/Grian/following{/other_user}","gists_url":"https://api.github.com/users/Grian/gists{/gist_id}","starred_url":"https://api.github.com/users/Grian/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Grian/subscriptions","organizations_url":"https://api.github.com/users/Grian/orgs","repos_url":"https://api.github.com/users/Grian/repos","events_url":"https://api.github.com/users/Grian/events{/privacy}","received_events_url":"https://api.github.com/users/Grian/received_events","type":"User","site_admin":false},"labels":[{"id":845247686,"node_id":"MDU6TGFiZWw4NDUyNDc2ODY=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/usability","name":"usability","color":"ebf28c","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-06-29T08:14:41Z","updated_at":"2021-11-19T17:54:43Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"You have to provide the following information whenever possible.\r\n\r\n```\r\n  CREATE TABLE IF NOT EXISTS products (id UInt32) Engine=Memory();\r\n  CREATE TEMPORARY TABLE IF NOT EXISTS temp (id UInt32) Engine=Memory();\r\n  INSERT INTO temp(id) VALUES (1), (2);\r\n  ALTER TABLE products DELETE WHERE id IN (SELECT id FROM temp);\r\n\r\n  -- cleanup test\r\n  DROP TABLE products;\r\n  DROP TABLE temp;\r\n```\r\n\r\n```\r\nReceived exception from server (version 21.5.6):\r\nCode: 60. DB::Exception: Received from click.test.int:9000. DB::Exception: Table test.temp doesn't exist: \r\nWhile processing isZeroOrNull(id IN ((SELECT id FROM test.temp) AS _subquery23)).\r\n```\r\n\r\n```\r\nClickHouse client version 21.6.5.37 (official build).\r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25808/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/25808/timeline","performed_via_github_app":null}]

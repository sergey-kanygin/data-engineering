[{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15449","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15449/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15449/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15449/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/15449","id":711191380,"node_id":"MDU6SXNzdWU3MTExOTEzODA=","number":15449,"title":"ALIAS column in secondary index usage.","user":{"login":"UnamedRus","id":9449405,"node_id":"MDQ6VXNlcjk0NDk0MDU=","avatar_url":"https://avatars.githubusercontent.com/u/9449405?v=4","gravatar_id":"","url":"https://api.github.com/users/UnamedRus","html_url":"https://github.com/UnamedRus","followers_url":"https://api.github.com/users/UnamedRus/followers","following_url":"https://api.github.com/users/UnamedRus/following{/other_user}","gists_url":"https://api.github.com/users/UnamedRus/gists{/gist_id}","starred_url":"https://api.github.com/users/UnamedRus/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/UnamedRus/subscriptions","organizations_url":"https://api.github.com/users/UnamedRus/orgs","repos_url":"https://api.github.com/users/UnamedRus/repos","events_url":"https://api.github.com/users/UnamedRus/events{/privacy}","received_events_url":"https://api.github.com/users/UnamedRus/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":1357507723,"node_id":"MDU6TGFiZWwxMzU3NTA3NzIz","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-skipidx","name":"comp-skipidx","color":"b5bcff","default":false,"description":"Data skipping indices"},{"id":1842603313,"node_id":"MDU6TGFiZWwxODQyNjAzMzEz","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-alias-columns","name":"comp-alias-columns","color":"b5bcff","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2020-09-29T14:51:02Z","updated_at":"2021-01-31T09:57:31Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Use case**\r\nWe have some complex function, which we would like to use in secondary index, and we want to create an alias column as that function in order to have simple and memoriable name to it, which we can use in WHERE clause.\r\n\r\n**Describe the solution you'd like**\r\nClickhouse server version 20.9.2.20\r\n```\r\nCREATE TABLE test_index\r\n(\r\n    `key_string` String,\r\n    `key_uint32` ALIAS toUInt32(key_string),\r\n    INDEX idx key_uint32 TYPE set(0) GRANULARITY 1\r\n)\r\nENGINE = MergeTree\r\nPARTITION BY tuple()\r\nPRIMARY KEY tuple()\r\nORDER BY key_string\r\n\r\n\r\nReceived exception from server (version 20.9.2):\r\nCode: 47. DB::Exception: Received from localhost:9000. DB::Exception: Missing columns: 'key_uint32' while processing query: 'key_uint32', required columns: 'key_uint32', source columns: 'key_string'.\r\n\r\n\r\nCREATE TABLE test_index\r\n(\r\n    `key_string` String,\r\n    `key_uint32` ALIAS toUInt32(key_string),\r\n    INDEX idx toUInt32(key_string) TYPE set(0) GRANULARITY 1\r\n)\r\nENGINE = MergeTree\r\nPARTITION BY tuple()\r\nPRIMARY KEY tuple()\r\nORDER BY key_string;\r\n\r\nINSERT INTO test_index SELECT * FROM numbers(1000000);\r\n\r\nSELECT *\r\nFROM test_index\r\nWHERE key_uint32 = 1\r\n\r\n┌─key_string─┐\r\n│ 1          │\r\n└────────────┘\r\n\r\n1 rows in set. Elapsed: 0.010 sec. Processed 1.00 million rows, 14.89 MB (99.93 million rows/s., 1.49 GB/s.)\r\n\r\nSELECT *\r\nFROM test_index\r\nWHERE toUInt32(key_string) = 1\r\n\r\n┌─key_string─┐\r\n│ 1          │\r\n└────────────┘\r\n\r\n1 rows in set. Elapsed: 0.008 sec. Processed 8.19 thousand rows, 121.96 KB (1.02 million rows/s., 15.20 MB/s.)\r\n```\r\n**Describe alternatives you've considered**\r\nWrite that kind of conditions in full form, but that makes less sense when we have the ability to use ALIAS columns.\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15449/reactions","total_count":1,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":1},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15449/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15427","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15427/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15427/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15427/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/15427","id":710615658,"node_id":"MDU6SXNzdWU3MTA2MTU2NTg=","number":15427,"title":"Do not read column granules which column values in table ORDER BY not changed.","user":{"login":"UnamedRus","id":9449405,"node_id":"MDQ6VXNlcjk0NDk0MDU=","avatar_url":"https://avatars.githubusercontent.com/u/9449405?v=4","gravatar_id":"","url":"https://api.github.com/users/UnamedRus","html_url":"https://github.com/UnamedRus","followers_url":"https://api.github.com/users/UnamedRus/followers","following_url":"https://api.github.com/users/UnamedRus/following{/other_user}","gists_url":"https://api.github.com/users/UnamedRus/gists{/gist_id}","starred_url":"https://api.github.com/users/UnamedRus/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/UnamedRus/subscriptions","organizations_url":"https://api.github.com/users/UnamedRus/orgs","repos_url":"https://api.github.com/users/UnamedRus/repos","events_url":"https://api.github.com/users/UnamedRus/events{/privacy}","received_events_url":"https://api.github.com/users/UnamedRus/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":756395244,"node_id":"MDU6TGFiZWw3NTYzOTUyNDQ=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/performance","name":"performance","color":"c2e0c6","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2020-09-28T22:17:51Z","updated_at":"2020-10-13T22:13:35Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"Example:\r\nWe have a table and it has column values and mark distribution similar to that.\r\n```\r\n  Whole data:     [-----------------------------------------------------------------------------------------]\r\n  CounterID:      [aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaabbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb]\r\n  Date:           [11111111111111111111112222222222222222222222211111111111111111111111112222222222222222222]\r\n  Marks:           |      |      |      |      |      |      |      |      |      |      |      |      |   |\r\n                  a,1    a,1    a,1    a,1    a,2    a,2    a,2    b,1    b,1    b,1    b,2    b,2    b,2 b,2\r\n  Marks numbers:   0      1      2      3      4      5      6      7      8      9      10     11     12  13\r\n```\r\n```\r\nSELECT sum(col_D) FROM table WHERE CounterID IN (a,b) AND Date = 1\r\n```\r\n \r\n\r\nBecause of clickhouse ORDER BY key, we do know, that values of columns (CounterID and DATE ) between marks 0-3 and 7-9 doesn't changed, so we can avoid of reading that columns ranges from disk and calculating conditions (CounterID IN (a,b) AND Date = 1) for that range.\r\n\r\nNow clickhouse will read and calculate conditions for that marks range: \r\ncol_d: 0-4,6-10 = 8\r\nCounterID: 0-4,6-10 = 8\r\nDate: 0-4,6-10 = 8\r\n~ 24 marks\r\n\r\nAfter that change:\r\ncol_d: 0-4,6-10 = 8\r\nCounterID: 3-4,6-7,9-10 = 3\r\nDate: 3-4,6-7,9-10 = 3\r\n~ 14 marks\r\n\r\n**Describe the solution you'd like**\r\nAvoid reading unneeded columns and calculating conditions, that will effectively reduce the amount of readed data from disk and cpu spent on decompressing and calculating conditions.\r\n\r\n**Additional context**\r\nI played a bit with a wide SSB benchmark, and the difference can be close to multiple times, when you have multiple WHERE conditions which is true on somewhere wide ranges and reading additional columns is expensive.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15427/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15427/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15411","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15411/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15411/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15411/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/15411","id":710253031,"node_id":"MDU6SXNzdWU3MTAyNTMwMzE=","number":15411,"title":"Second argument to tupleElement must be a constant UInt or String","user":{"login":"victor-sushko","id":26111504,"node_id":"MDQ6VXNlcjI2MTExNTA0","avatar_url":"https://avatars.githubusercontent.com/u/26111504?v=4","gravatar_id":"","url":"https://api.github.com/users/victor-sushko","html_url":"https://github.com/victor-sushko","followers_url":"https://api.github.com/users/victor-sushko/followers","following_url":"https://api.github.com/users/victor-sushko/following{/other_user}","gists_url":"https://api.github.com/users/victor-sushko/gists{/gist_id}","starred_url":"https://api.github.com/users/victor-sushko/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/victor-sushko/subscriptions","organizations_url":"https://api.github.com/users/victor-sushko/orgs","repos_url":"https://api.github.com/users/victor-sushko/repos","events_url":"https://api.github.com/users/victor-sushko/events{/privacy}","received_events_url":"https://api.github.com/users/victor-sushko/received_events","type":"User","site_admin":false},"labels":[{"id":386401505,"node_id":"MDU6TGFiZWwzODY0MDE1MDU=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/bug","name":"bug","color":"ee0701","default":true,"description":"Confirmed user-visible misbehaviour in official release"},{"id":1507888214,"node_id":"MDU6TGFiZWwxNTA3ODg4MjE0","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/st-accepted","name":"st-accepted","color":"e5b890","default":false,"description":"The issue is in our backlog, ready to take"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2020-09-28T13:12:02Z","updated_at":"2020-11-09T00:18:59Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"An error occurs when a column of type `Array(Tuple(...))` is present in the query. There are only two possible calls of the function `tupleElement` in the query, none of them have non-constant second argument.\r\n\r\n**How to reproduce**\r\n* ClickHouse server version 20.9.2.20\r\n* Create two tables with one row in each\r\n```\r\nCREATE DATABASE IF NOT EXISTS test;\r\n\r\nCREATE TABLE IF NOT EXISTS test.tc engine = MergeTree PARTITION BY (inn, toYYYYMM(received)) ORDER BY (inn, sessionId)\r\nAS SELECT now() AS received, '123456789' AS inn, '42' AS sessionId;\r\n\r\nCREATE TABLE IF NOT EXISTS test.tj engine = MergeTree PARTITION BY (inn, toYYYYMM(received)) ORDER BY (inn, sessionId)\r\nAS SELECT now() AS received, '123456789' AS inn, '42' AS sessionId, '111' AS serial, '222' AS reg;\r\n```\r\n* Run query\r\n```\r\nSELECT rq.inn, arrayFirst(t -> isNotNull(t), regInfo.1), arrayFirst(t -> isNotNull(t), regInfo.2)\r\n    FROM test.tc AS rq\r\n    INNER JOIN (\r\n        SELECT rs.inn, rs.sessionId, groupArray((serial, reg)) AS regInfo\r\n            FROM test.tj AS rs\r\n            GROUP BY inn, sessionId\r\n    ) AS resp ON (rq.inn = resp.inn) AND (rq.sessionId = resp.sessionId)\r\nWHERE if('123456789' IS NOT NULL, rq.inn = '123456789', 1)\r\n```\r\n**Expected behavior**\r\nThe query should return the table with 3 columns and 1 row.\r\nIf replace the last line with `WHERE if('123456789' IS NOT NULL, rq.inn = '123456789', 3)` the query returns expected result.\r\n\r\n**Error message and/or stacktrace**\r\n```\r\nDB::Exception: Second argument to tupleElement must be a constant UInt or String (version 20.9.2.20 (official build)) (from [::ffff:192.168.121.148]:62635) (in query: [skipped, see reduced example]), Stack trace (when copying this message, always include the lines below):\r\n\r\n0. Poco::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int) @ 0x18e02790 in /usr/bin/clickhouse\r\n1. DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int) @ 0xe72fdad in /usr/bin/clickhouse\r\n2. DB::FunctionTupleElement::getElementNum(COW<DB::IColumn>::immutable_ptr<DB::IColumn> const&, DB::DataTypeTuple const&) const @ 0x1289aaf0 in /usr/bin/clickhouse\r\n3. DB::FunctionTupleElement::getReturnTypeImpl(std::__1::vector<DB::ColumnWithTypeAndName, std::__1::allocator<DB::ColumnWithTypeAndName> > const&) const @ 0x1289b918 in /usr/bin/clickhouse\r\n4. DB::DefaultOverloadResolver::getReturnType(std::__1::vector<DB::ColumnWithTypeAndName, std::__1::allocator<DB::ColumnWithTypeAndName> > const&) const @ 0xfb81505 in /usr/bin/clickhouse\r\n5. DB::FunctionOverloadResolverAdaptor::getReturnTypeWithoutLowCardinality(std::__1::vector<DB::ColumnWithTypeAndName, std::__1::allocator<DB::ColumnWithTypeAndName> > const&) const @ 0xfba7d2a in /usr/bin/clickhouse\r\n6. DB::FunctionOverloadResolverAdaptor::getReturnType(std::__1::vector<DB::ColumnWithTypeAndName, std::__1::allocator<DB::ColumnWithTypeAndName> > const&) const @ 0xfba8125 in /usr/bin/clickhouse\r\n7. DB::FunctionOverloadResolverAdaptor::build(std::__1::vector<DB::ColumnWithTypeAndName, std::__1::allocator<DB::ColumnWithTypeAndName> > const&) const @ 0xfbadfec in /usr/bin/clickhouse\r\n8. DB::ExpressionActions::addImpl(DB::ExpressionAction, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > >&) @ 0x15ad29de in /usr/bin/clickhouse\r\n9. DB::ExpressionActions::add(DB::ExpressionAction const&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > >&) @ 0x15ad2c4d in /usr/bin/clickhouse\r\n10. DB::ScopeStack::addAction(DB::ExpressionAction const&) @ 0x15b703cd in /usr/bin/clickhouse\r\n11. DB::ActionsMatcher::visit(DB::ASTFunction const&, std::__1::shared_ptr<DB::IAST> const&, DB::ActionsMatcher::Data&) @ 0x15b7ba0b in /usr/bin/clickhouse\r\n12. DB::ActionsMatcher::visit(DB::ASTFunction const&, std::__1::shared_ptr<DB::IAST> const&, DB::ActionsMatcher::Data&) @ 0x15b7a43b in /usr/bin/clickhouse\r\n13. DB::InDepthNodeVisitor<DB::ActionsMatcher, true, std::__1::shared_ptr<DB::IAST> const>::visit(std::__1::shared_ptr<DB::IAST> const&) @ 0x15b63039 in /usr/bin/clickhouse\r\n14. ? @ 0x15b53d93 in /usr/bin/clickhouse\r\n15. DB::SelectQueryExpressionAnalyzer::appendSelect(DB::ExpressionActionsChain&, bool) @ 0x15b557e6 in /usr/bin/clickhouse\r\n16. DB::ExpressionAnalysisResult::ExpressionAnalysisResult(DB::SelectQueryExpressionAnalyzer&, std::__1::shared_ptr<DB::StorageInMemoryMetadata const> const&, bool, bool, bool, std::__1::shared_ptr<DB::FilterInfo> const&, DB::Block const&) @ 0x15b5fa67 in /usr/bin/clickhouse\r\n17. DB::InterpreterSelectQuery::getSampleBlockImpl() @ 0x15b15f2d in /usr/bin/clickhouse\r\n18. ? @ 0x15b1c8ea in /usr/bin/clickhouse\r\n19. DB::InterpreterSelectQuery::InterpreterSelectQuery(std::__1::shared_ptr<DB::IAST> const&, DB::Context const&, std::__1::shared_ptr<DB::IBlockInputStream> const&, std::__1::optional<DB::Pipe>, std::__1::shared_ptr<DB::IStorage> const&, DB::SelectQueryOptions const&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&, std::__1::shared_ptr<DB::StorageInMemoryMetadata const> const&) @ 0x15b249e2 in /usr/bin/clickhouse\r\n20. DB::InterpreterSelectQuery::InterpreterSelectQuery(std::__1::shared_ptr<DB::IAST> const&, DB::Context const&, DB::SelectQueryOptions const&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&) @ 0x15b26479 in /usr/bin/clickhouse\r\n21. DB::InterpreterSelectWithUnionQuery::InterpreterSelectWithUnionQuery(std::__1::shared_ptr<DB::IAST> const&, DB::Context const&, DB::SelectQueryOptions const&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&) @ 0x15c9e897 in /usr/bin/clickhouse\r\n22. DB::StorageView::read(std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&, std::__1::shared_ptr<DB::StorageInMemoryMetadata const> const&, DB::SelectQueryInfo const&, DB::Context const&, DB::QueryProcessingStage::Enum, unsigned long, unsigned int) @ 0x160d0909 in /usr/bin/clickhouse\r\n23. DB::ReadFromStorageStep::ReadFromStorageStep(std::__1::shared_ptr<DB::RWLockImpl::LockHolderImpl>, std::__1::shared_ptr<DB::StorageInMemoryMetadata const>&, DB::SelectQueryOptions, std::__1::shared_ptr<DB::IStorage>, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&, DB::SelectQueryInfo const&, std::__1::shared_ptr<DB::Context>, DB::QueryProcessingStage::Enum, unsigned long, unsigned long) @ 0x167ed13a in /usr/bin/clickhouse\r\n24. DB::InterpreterSelectQuery::executeFetchColumns(DB::QueryProcessingStage::Enum, DB::QueryPlan&, std::__1::shared_ptr<DB::PrewhereInfo> const&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&) @ 0x15b1dff1 in /usr/bin/clickhouse\r\n25. DB::InterpreterSelectQuery::executeImpl(DB::QueryPlan&, std::__1::shared_ptr<DB::IBlockInputStream> const&, std::__1::optional<DB::Pipe>) @ 0x15b21ec3 in /usr/bin/clickhouse\r\n26. DB::InterpreterSelectQuery::buildQueryPlan(DB::QueryPlan&) @ 0x15b239b4 in /usr/bin/clickhouse\r\n27. DB::InterpreterSelectWithUnionQuery::buildQueryPlan(DB::QueryPlan&) @ 0x15c9d6f8 in /usr/bin/clickhouse\r\n28. DB::InterpreterSelectWithUnionQuery::execute() @ 0x15c9d8ca in /usr/bin/clickhouse\r\n29. ? @ 0x15e1ac62 in /usr/bin/clickhouse\r\n30. DB::executeQuery(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, DB::Context&, bool, DB::QueryProcessingStage::Enum, bool) @ 0x15e1c5c2 in /usr/bin/clickhouse\r\n31. DB::TCPHandler::runImpl() @ 0x164c3585 in /usr/bin/clickhouse\r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15411/reactions","total_count":1,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":1},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15411/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15395","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15395/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15395/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15395/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/15395","id":710170560,"node_id":"MDU6SXNzdWU3MTAxNzA1NjA=","number":15395,"title":"Wrong results while using an array and sum of the elements to produce new array in one select clause","user":{"login":"ibeleychev","id":6383218,"node_id":"MDQ6VXNlcjYzODMyMTg=","avatar_url":"https://avatars.githubusercontent.com/u/6383218?v=4","gravatar_id":"","url":"https://api.github.com/users/ibeleychev","html_url":"https://github.com/ibeleychev","followers_url":"https://api.github.com/users/ibeleychev/followers","following_url":"https://api.github.com/users/ibeleychev/following{/other_user}","gists_url":"https://api.github.com/users/ibeleychev/gists{/gist_id}","starred_url":"https://api.github.com/users/ibeleychev/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ibeleychev/subscriptions","organizations_url":"https://api.github.com/users/ibeleychev/orgs","repos_url":"https://api.github.com/users/ibeleychev/repos","events_url":"https://api.github.com/users/ibeleychev/events{/privacy}","received_events_url":"https://api.github.com/users/ibeleychev/received_events","type":"User","site_admin":false},"labels":[{"id":386401505,"node_id":"MDU6TGFiZWwzODY0MDE1MDU=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/bug","name":"bug","color":"ee0701","default":true,"description":"Confirmed user-visible misbehaviour in official release"},{"id":1365579236,"node_id":"MDU6TGFiZWwxMzY1NTc5MjM2","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/minor","name":"minor","color":"FFF8F8","default":false,"description":"Priority: minor"},{"id":1507888214,"node_id":"MDU6TGFiZWwxNTA3ODg4MjE0","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/st-accepted","name":"st-accepted","color":"e5b890","default":false,"description":"The issue is in our backlog, ready to take"},{"id":2121848770,"node_id":"MDU6TGFiZWwyMTIxODQ4Nzcw","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-sql","name":"comp-sql","color":"b5bcff","default":false,"description":"General SQL support"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2020-09-28T11:08:57Z","updated_at":"2021-01-25T18:42:38Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"**Describe the bug**\r\nFollowing code snippet calculates percents wrong when all the statements are on one SELECT block and calculates percents wright when ``arrayMap`` function is on the other SELECT clause\r\n\r\n**How to reproduce**\r\n```\r\nselect t.1 as cnt,\r\n       t.2 as name,\r\n       t.3 as percent\r\nfrom (\r\n      select arrayJoin(result) as t\r\n      from (\r\n            select [\r\n                       (79, 'name1'),\r\n                       (62, 'name2'),\r\n                       (44, 'name3')\r\n                       ]                                      as data,\r\n                   arraySum(arrayMap(t -> t.1, data)) as total,\r\n                   arrayMap(t ->\r\n                                tuple(t.1, t.2,\r\n                                      multiIf(total = 0, 0, t.1 > 0 and t.1 < 10, -1.0,\r\n                                              (toFloat32(t.1) / toFloat32(total)) * 100)\r\n                                    ),\r\n                            data\r\n                       )                                      as result\r\n               )\r\n         );\r\n```\r\n\r\n* Which ClickHouse server version to use\r\n20.9.2.20\r\n* Which interface to use, if matters\r\nRequest from intellij idea via jdbc\r\n\r\n**Expected behavior**\r\nExpected result is:\r\n```\r\ncnt,name,percent\r\n79,name1,42.7027027027027\r\n62,name2,33.513513513513516\r\n44,name3,23.783783783783786\r\n```\r\n**Actual result**\r\n```\r\ncnt,name,percent\r\n79,name1,33.33333333333333\r\n62,name2,33.33333333333333\r\n44,name3,33.33333333333333\r\n```\r\n\r\n**Additional context**\r\nI found out that this piece of code can work properly with following changes\r\n\r\n```\r\nselect t.1 as cnt,\r\n       t.2 as name,\r\n       t.3 as percent\r\nfrom (\r\n      select arrayJoin(result) t\r\n      from (\r\n            select arrayMap(t ->\r\n                                tuple(t.1, t.2,\r\n                                      multiIf(total = 0, 0, t.1 > 0 and t.1 < 10, - 1.0,\r\n                                              (toFloat32(t.1) / toFloat32(total)) * 100)\r\n                                    ),\r\n                            data\r\n                       ) as result\r\n            from (\r\n                  select [\r\n                             (79, 79),\r\n                             (62, 24),\r\n                             (44, 44)\r\n                             ]                                       as data,\r\n                         arraySum(arrayMap(t -> t.1, data)) as total\r\n                     )\r\n               )\r\n         );\r\n```\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15395/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15395/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15371","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15371/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15371/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15371/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/15371","id":709964333,"node_id":"MDU6SXNzdWU3MDk5NjQzMzM=","number":15371,"title":"While skipping the wrong rows according to the 'input_format_allow_errors_num' parameters during loading, there is a special place to record the abnormal records.","user":{"login":"cuijie0928","id":54469830,"node_id":"MDQ6VXNlcjU0NDY5ODMw","avatar_url":"https://avatars.githubusercontent.com/u/54469830?v=4","gravatar_id":"","url":"https://api.github.com/users/cuijie0928","html_url":"https://github.com/cuijie0928","followers_url":"https://api.github.com/users/cuijie0928/followers","following_url":"https://api.github.com/users/cuijie0928/following{/other_user}","gists_url":"https://api.github.com/users/cuijie0928/gists{/gist_id}","starred_url":"https://api.github.com/users/cuijie0928/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/cuijie0928/subscriptions","organizations_url":"https://api.github.com/users/cuijie0928/orgs","repos_url":"https://api.github.com/users/cuijie0928/repos","events_url":"https://api.github.com/users/cuijie0928/events{/privacy}","received_events_url":"https://api.github.com/users/cuijie0928/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":1401255404,"node_id":"MDU6TGFiZWwxNDAxMjU1NDA0","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-formats","name":"comp-formats","color":"b5bcff","default":false,"description":"Input / output formats"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2020-09-28T06:06:43Z","updated_at":"2020-09-28T18:36:52Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"**Describe the solution you'd like**\r\nEnable “input_format_allow_errors_num” or \"input_format_allow_errors_ratio\"  Ignore After loading the parameters, I would like to retrospectively process the exception records to guide us to deal with the cause of the exception before upstream","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15371/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15371/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15341","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15341/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15341/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15341/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/15341","id":709570877,"node_id":"MDU6SXNzdWU3MDk1NzA4Nzc=","number":15341,"title":"LIMIT clause for matching a range of records based on boundary conditions.","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":1507886722,"node_id":"MDU6TGFiZWwxNTA3ODg2NzIy","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/st-discussion","name":"st-discussion","color":"e5b890","default":false,"description":"The story requires discussion /research / expert help / design & decomposition before will be taken"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":5,"created_at":"2020-09-26T16:49:28Z","updated_at":"2021-09-12T12:10:16Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"**Use case**\r\nFrom a stream of data output a range of records from first record matched some condition until another record mathed another condition. This also can be extended by counter of matches or even some sequence patterns.\r\n\r\nApplications: log analysis, complex event processing.\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15341/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15341/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15318","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15318/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15318/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15318/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/15318","id":709169032,"node_id":"MDU6SXNzdWU3MDkxNjkwMzI=","number":15318,"title":"Renew Wikistat example in documentation","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":785082162,"node_id":"MDU6TGFiZWw3ODUwODIxNjI=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-documentation","name":"comp-documentation","color":"b5bcff","default":false,"description":"Used to run automatic builds of the documentation"},{"id":3360106261,"node_id":"MDU6TGFiZWwzMzYwMTA2MjYx","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/dataset","name":"dataset","color":"00CCCC","default":false,"description":""}],"state":"open","locked":false,"assignee":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"assignees":[{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false}],"milestone":null,"comments":3,"created_at":"2020-09-25T17:58:43Z","updated_at":"2022-01-29T21:50:20Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"https://clickhouse.tech/docs/en/getting-started/example-datasets/wikistat/\r\n\r\nIt's from 2016.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15318/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15318/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15309","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15309/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15309/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15309/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/15309","id":708986546,"node_id":"MDU6SXNzdWU3MDg5ODY1NDY=","number":15309,"title":"ARRAY JOIN in view prevent condition pushdown","user":{"login":"UnamedRus","id":9449405,"node_id":"MDQ6VXNlcjk0NDk0MDU=","avatar_url":"https://avatars.githubusercontent.com/u/9449405?v=4","gravatar_id":"","url":"https://api.github.com/users/UnamedRus","html_url":"https://github.com/UnamedRus","followers_url":"https://api.github.com/users/UnamedRus/followers","following_url":"https://api.github.com/users/UnamedRus/following{/other_user}","gists_url":"https://api.github.com/users/UnamedRus/gists{/gist_id}","starred_url":"https://api.github.com/users/UnamedRus/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/UnamedRus/subscriptions","organizations_url":"https://api.github.com/users/UnamedRus/orgs","repos_url":"https://api.github.com/users/UnamedRus/repos","events_url":"https://api.github.com/users/UnamedRus/events{/privacy}","received_events_url":"https://api.github.com/users/UnamedRus/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":756395244,"node_id":"MDU6TGFiZWw3NTYzOTUyNDQ=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/performance","name":"performance","color":"c2e0c6","default":false,"description":null},{"id":1401777979,"node_id":"MDU6TGFiZWwxNDAxNzc3OTc5","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-optimizers","name":"comp-optimizers","color":"b5bcff","default":false,"description":"Query optimizations"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2020-09-25T14:29:44Z","updated_at":"2020-11-10T19:05:31Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**How to reproduce**\r\nclickhouse version 20.3.15.133, 20.3.19.4, 20.9.2.20\r\n```\r\nCREATE TABLE test_view(key UInt32) ENGINE=MergeTree PARTITION BY tuple() ORDER BY key;\r\nINSERT INTO test_view SELECT number FROM numbers(100000);\r\nCREATE VIEW test_view_v AS SELECT key, [1,2] as arr FROM test_view;\r\nCREATE VIEW test_view_v_v AS SELECT key, arr FROM test_view_v ARRAY JOIN arr ;\r\nCREATE VIEW test_view_v_v2 AS SELECT key, arrayJoin(arr) as arr FROM test_view_v;\r\n\r\nset enable_debug_queries=1;\r\n\r\nView with ARRAY JOIN  WHERE condition pushdown is doesn't working\r\n\r\nSELECT *\r\nFROM test_view_v_v\r\nWHERE key = 10\r\nFORMAT Null\r\n\r\nOk.\r\n\r\n0 rows in set. Elapsed: 0.007 sec. Processed 100.00 thousand rows, 400.00 KB (13.48 million rows/s., 53.92 MB/s.)\r\n\r\nANALYZE\r\nSELECT *\r\nFROM test_view_v_v\r\nWHERE key = 10\r\n\r\nEXPLAIN \r\n\r\nSELECT\r\n    key,\r\n    arr\r\nFROM\r\n(\r\n    SELECT\r\n        key,\r\n        arr\r\n    FROM\r\n    (\r\n        SELECT\r\n            key,\r\n            [1, 2] AS arr\r\n        FROM default.test_view\r\n    )\r\n    ARRAY JOIN arr\r\n    WHERE key = 10\r\n)\r\nWHERE key = 10 \r\n\r\n\r\nView with arrayJoin WHERE condition pushdown is working\r\n\r\nSELECT *\r\nFROM test_view_v_v2\r\nWHERE key = 10\r\nFORMAT Null\r\n\r\nOk.\r\n\r\n0 rows in set. Elapsed: 0.010 sec. Processed 8.19 thousand rows, 32.77 KB (825.25 thousand rows/s., 3.30 MB/s.)\r\n\r\nSELECT\r\n    key,\r\n    arr\r\nFROM\r\n(\r\n    SELECT\r\n        key,\r\n        arrayJoin(arr) AS arr\r\n    FROM\r\n    (\r\n        SELECT\r\n            key,\r\n            [1, 2] AS arr\r\n        FROM default.test_view\r\n        WHERE key = 10\r\n    )\r\n    WHERE key = 10\r\n)\r\nWHERE key = 10\r\n\r\nEXPLAIN in 20.9.2.20\r\n\r\nSELECT\r\n    key,\r\n    arr\r\nFROM\r\n(\r\n    SELECT\r\n        key,\r\n        arrayJoin(arr) AS arr\r\n    FROM ssb.test_view_v\r\n    HAVING key = 10\r\n) AS test_view_v_v2\r\nWHERE key = 10\r\n\r\n```\r\n\r\n**Additional context**\r\n\r\nAmount of read columns in 20.9 is similar, but the explain is less detailed and it have used HAVING keyword instead of WHERE.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15309/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15309/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15261","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15261/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15261/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15261/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/15261","id":708536224,"node_id":"MDU6SXNzdWU3MDg1MzYyMjQ=","number":15261,"title":"Profiling on Processors level","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":{"login":"KochetovNicolai","id":4092911,"node_id":"MDQ6VXNlcjQwOTI5MTE=","avatar_url":"https://avatars.githubusercontent.com/u/4092911?v=4","gravatar_id":"","url":"https://api.github.com/users/KochetovNicolai","html_url":"https://github.com/KochetovNicolai","followers_url":"https://api.github.com/users/KochetovNicolai/followers","following_url":"https://api.github.com/users/KochetovNicolai/following{/other_user}","gists_url":"https://api.github.com/users/KochetovNicolai/gists{/gist_id}","starred_url":"https://api.github.com/users/KochetovNicolai/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/KochetovNicolai/subscriptions","organizations_url":"https://api.github.com/users/KochetovNicolai/orgs","repos_url":"https://api.github.com/users/KochetovNicolai/repos","events_url":"https://api.github.com/users/KochetovNicolai/events{/privacy}","received_events_url":"https://api.github.com/users/KochetovNicolai/received_events","type":"User","site_admin":false},"assignees":[{"login":"KochetovNicolai","id":4092911,"node_id":"MDQ6VXNlcjQwOTI5MTE=","avatar_url":"https://avatars.githubusercontent.com/u/4092911?v=4","gravatar_id":"","url":"https://api.github.com/users/KochetovNicolai","html_url":"https://github.com/KochetovNicolai","followers_url":"https://api.github.com/users/KochetovNicolai/followers","following_url":"https://api.github.com/users/KochetovNicolai/following{/other_user}","gists_url":"https://api.github.com/users/KochetovNicolai/gists{/gist_id}","starred_url":"https://api.github.com/users/KochetovNicolai/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/KochetovNicolai/subscriptions","organizations_url":"https://api.github.com/users/KochetovNicolai/orgs","repos_url":"https://api.github.com/users/KochetovNicolai/repos","events_url":"https://api.github.com/users/KochetovNicolai/events{/privacy}","received_events_url":"https://api.github.com/users/KochetovNicolai/received_events","type":"User","site_admin":false}],"milestone":null,"comments":0,"created_at":"2020-09-24T23:33:48Z","updated_at":"2020-09-24T23:33:48Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"**Describe the solution you'd like**\r\nEvery processor has a timer that's activated if profiling is enabled with a setting.\r\nThis timer measures the time spend:\r\n- in `work` method;\r\n- when processor did not execute but was ready for execution after `prepare` method;\r\n- when processor did not execute but was not ready for execution after `prepare` method due to lack of data or busy port;\r\n\r\nThe info is written to a new SystemLog table `processors_profile_log`.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15261/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15261/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15257","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15257/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15257/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15257/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/15257","id":708510144,"node_id":"MDU6SXNzdWU3MDg1MTAxNDQ=","number":15257,"title":"Optimizations based on functions preimage (was: Rewrite toDate/toStartOf* comparison to faster alternative)","user":{"login":"UnamedRus","id":9449405,"node_id":"MDQ6VXNlcjk0NDk0MDU=","avatar_url":"https://avatars.githubusercontent.com/u/9449405?v=4","gravatar_id":"","url":"https://api.github.com/users/UnamedRus","html_url":"https://github.com/UnamedRus","followers_url":"https://api.github.com/users/UnamedRus/followers","following_url":"https://api.github.com/users/UnamedRus/following{/other_user}","gists_url":"https://api.github.com/users/UnamedRus/gists{/gist_id}","starred_url":"https://api.github.com/users/UnamedRus/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/UnamedRus/subscriptions","organizations_url":"https://api.github.com/users/UnamedRus/orgs","repos_url":"https://api.github.com/users/UnamedRus/repos","events_url":"https://api.github.com/users/UnamedRus/events{/privacy}","received_events_url":"https://api.github.com/users/UnamedRus/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":9,"created_at":"2020-09-24T22:21:52Z","updated_at":"2020-09-25T07:47:13Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Use case**\r\nWhen you would like to filter values which belong to specific intervals, the most intuitive variant is to use toStartOf* functions, but it is not the fastest variant.\r\n\r\n**Describe the solution you'd like**\r\n\r\n```\r\ntoDate\r\n\r\nSELECT count()\r\nFROM numbers(1000000000)\r\nWHERE toDate(materialize(now())) = '2020-09-24'\r\n1 rows in set. Elapsed: 3.356 sec. Processed 1.00 billion rows, 8.00 GB (298.01 million rows/s., 2.38 GB/s.)\r\n\r\n\r\nSELECT count()\r\nFROM numbers(1000000000)\r\nWHERE (materialize(now()) >= '2020-09-24 00:00:00') AND (materialize(now()) < '2020-09-25 00:00:00')\r\n1 rows in set. Elapsed: 2.078 sec. Processed 1.00 billion rows, 8.00 GB (481.16 million rows/s., 3.85 GB/s.)\r\n\r\n\r\nSELECT count()\r\nFROM numbers(1000000000)\r\nWHERE toDate(materialize(now())) >= '2020-09-24'\r\n1 rows in set. Elapsed: 3.287 sec. Processed 1.00 billion rows, 8.00 GB (304.27 million rows/s., 2.43 GB/s.)\r\n\r\n\r\nSELECT count()\r\nFROM numbers(1000000000)\r\nWHERE materialize(now()) >= '2020-09-24 00:00:00'\r\n1 rows in set. Elapsed: 1.687 sec. Processed 1.00 billion rows, 8.00 GB (592.84 million rows/s., 4.74 GB/s.)\r\n\r\ntoStartOfHour\r\n\r\nSELECT count()\r\nFROM numbers(1000000000)\r\nWHERE toStartOfHour(materialize(now())) >= '2020-09-24 00:00:00'\r\n1 rows in set. Elapsed: 2.131 sec. Processed 1.00 billion rows, 8.00 GB (469.30 million rows/s., 3.75 GB/s.)\r\n\r\n\r\nSELECT count() FROM numbers(1000000000) WHERE toStartOfHour(materialize(now())) = '2020-09-24 00:00:00';\r\n1 rows in set. Elapsed: 1.534 sec. Processed 1.00 billion rows, 8.00 GB (651.81 million rows/s., 5.21 GB/s.)\r\n\r\n\r\nSELECT count() FROM numbers(1000000000) WHERE materialize(now()) >= '2020-09-24 00:00:00' AND  materialize(now()) < '2020-09-24 01:00:00' ;\r\n1 rows in set. Elapsed: 1.411 sec. Processed 1.00 billion rows, 8.00 GB (708.86 million rows/s., 5.67 GB/s.)\r\n\r\n\r\nSELECT count() FROM numbers(1000000000) WHERE toStartOfHour(materialize(now())) >= '2020-09-24 00:00:00';\r\n1 rows in set. Elapsed: 2.236 sec. Processed 1.00 billion rows, 8.00 GB (447.25 million rows/s., 3.58 GB/s.)\r\n\r\n\r\nSELECT count() FROM numbers(1000000000) WHERE materialize(now()) >= '2020-09-24 00:00:00';\r\n1 rows in set. Elapsed: 1.696 sec. Processed 1.00 billion rows, 8.00 GB (589.76 million rows/s., 4.72 GB/s.)\r\n\r\ntoStartOfYear\r\n\r\nSELECT count() FROM numbers(1000000000) WHERE toStartOfYear(materialize(now())) = '2020-01-01';\r\n1 rows in set. Elapsed: 4.185 sec. Processed 1.00 billion rows, 8.00 GB (238.94 million rows/s., 1.91 GB/s.)\r\n\r\n\r\nSELECT count() FROM numbers(1000000000) WHERE materialize(now()) >= '2020-01-01 00:00:00' AND materialize(now()) < '2021-01-01 00:00:00';\r\n1 rows in set. Elapsed: 2.015 sec. Processed 1.00 billion rows, 8.00 GB (496.19 million rows/s., 3.97 GB/s.)\r\n```\r\n\r\n**Describe alternatives you've considered**\r\nWrite those kinds of conditions by hand, but people don't like to write a lot of conditions and it is much easier to make a mistake.\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15257/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15257/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15249","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15249/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15249/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15249/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/15249","id":708374562,"node_id":"MDU6SXNzdWU3MDgzNzQ1NjI=","number":15249,"title":"CH allows invalid query `select distinct a  ... order by b`","user":{"login":"den-crane","id":19737682,"node_id":"MDQ6VXNlcjE5NzM3Njgy","avatar_url":"https://avatars.githubusercontent.com/u/19737682?v=4","gravatar_id":"","url":"https://api.github.com/users/den-crane","html_url":"https://github.com/den-crane","followers_url":"https://api.github.com/users/den-crane/followers","following_url":"https://api.github.com/users/den-crane/following{/other_user}","gists_url":"https://api.github.com/users/den-crane/gists{/gist_id}","starred_url":"https://api.github.com/users/den-crane/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/den-crane/subscriptions","organizations_url":"https://api.github.com/users/den-crane/orgs","repos_url":"https://api.github.com/users/den-crane/repos","events_url":"https://api.github.com/users/den-crane/events{/privacy}","received_events_url":"https://api.github.com/users/den-crane/received_events","type":"User","site_admin":false},"labels":[{"id":386401506,"node_id":"MDU6TGFiZWwzODY0MDE1MDY=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/duplicate","name":"duplicate","color":"cccccc","default":true,"description":null},{"id":845247686,"node_id":"MDU6TGFiZWw4NDUyNDc2ODY=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/usability","name":"usability","color":"ebf28c","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2020-09-24T18:10:03Z","updated_at":"2020-10-06T10:21:07Z","closed_at":null,"author_association":"COLLABORATOR","active_lock_reason":null,"body":"```sql\r\nselect distinct a from (select 1 a,2 b union all  select 2 a,-6 b) order by b\r\n┌─a─┐\r\n│ 2 │\r\n└───┘\r\n┌─a─┐\r\n│ 1 │\r\n└───┘\r\n\r\n```\r\n\r\nExpected an error: **b  must appear in select list**\r\n\r\n\r\nPG\r\n\r\n```sql\r\nselect distinct a from (select 1 a,2 b union all  select 2 a,-6 b) x order by b;\r\n\r\nERROR:  for SELECT DISTINCT, ORDER BY expressions must appear in select list\r\nLINE 1: ...om (select 1 a,2 b union all  select 2 a,-6 b) x order by b;\r\n                                                                     ^\r\n```\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15249/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15249/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15241","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15241/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15241/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15241/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/15241","id":708325633,"node_id":"MDU6SXNzdWU3MDgzMjU2MzM=","number":15241,"title":"Support for ALTER RENAME INDEX","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2020-09-24T16:50:10Z","updated_at":"2020-09-24T16:50:10Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"**Use case**\r\n#15234\r\n\r\n**Describe the solution you'd like**\r\nIndex names does not have any special meaning at all. They are just some names for the users.\r\nBut why don't allow to rename them?\r\n\r\nBut it will be not so easy - mutation is needed, similar to renaming a column.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15241/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15241/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15225","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15225/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15225/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15225/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/15225","id":707992651,"node_id":"MDU6SXNzdWU3MDc5OTI2NTE=","number":15225,"title":"join issue  when selecting different columns, the number of rows returned is much larger than the correct number","user":{"login":"jjtjiang","id":48897688,"node_id":"MDQ6VXNlcjQ4ODk3Njg4","avatar_url":"https://avatars.githubusercontent.com/u/48897688?v=4","gravatar_id":"","url":"https://api.github.com/users/jjtjiang","html_url":"https://github.com/jjtjiang","followers_url":"https://api.github.com/users/jjtjiang/followers","following_url":"https://api.github.com/users/jjtjiang/following{/other_user}","gists_url":"https://api.github.com/users/jjtjiang/gists{/gist_id}","starred_url":"https://api.github.com/users/jjtjiang/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jjtjiang/subscriptions","organizations_url":"https://api.github.com/users/jjtjiang/orgs","repos_url":"https://api.github.com/users/jjtjiang/repos","events_url":"https://api.github.com/users/jjtjiang/events{/privacy}","received_events_url":"https://api.github.com/users/jjtjiang/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""}],"state":"open","locked":false,"assignee":{"login":"den-crane","id":19737682,"node_id":"MDQ6VXNlcjE5NzM3Njgy","avatar_url":"https://avatars.githubusercontent.com/u/19737682?v=4","gravatar_id":"","url":"https://api.github.com/users/den-crane","html_url":"https://github.com/den-crane","followers_url":"https://api.github.com/users/den-crane/followers","following_url":"https://api.github.com/users/den-crane/following{/other_user}","gists_url":"https://api.github.com/users/den-crane/gists{/gist_id}","starred_url":"https://api.github.com/users/den-crane/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/den-crane/subscriptions","organizations_url":"https://api.github.com/users/den-crane/orgs","repos_url":"https://api.github.com/users/den-crane/repos","events_url":"https://api.github.com/users/den-crane/events{/privacy}","received_events_url":"https://api.github.com/users/den-crane/received_events","type":"User","site_admin":false},"assignees":[{"login":"den-crane","id":19737682,"node_id":"MDQ6VXNlcjE5NzM3Njgy","avatar_url":"https://avatars.githubusercontent.com/u/19737682?v=4","gravatar_id":"","url":"https://api.github.com/users/den-crane","html_url":"https://github.com/den-crane","followers_url":"https://api.github.com/users/den-crane/followers","following_url":"https://api.github.com/users/den-crane/following{/other_user}","gists_url":"https://api.github.com/users/den-crane/gists{/gist_id}","starred_url":"https://api.github.com/users/den-crane/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/den-crane/subscriptions","organizations_url":"https://api.github.com/users/den-crane/orgs","repos_url":"https://api.github.com/users/den-crane/repos","events_url":"https://api.github.com/users/den-crane/events{/privacy}","received_events_url":"https://api.github.com/users/den-crane/received_events","type":"User","site_admin":false}],"milestone":null,"comments":0,"created_at":"2020-09-24T09:01:59Z","updated_at":"2020-09-24T13:08:07Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"the clickhosue version is 20.6 .the first sql return 2 rows  that is right ; the second sql and other sql return more wrong rows.It's not because of the identified columns that caused the error, but because of many different column combinations.For example , first sql ,it's right when select HL_TXNID,    HL_DB,    HL_TABLE,    HL_PARTITION,    HL_LOCK_STATE,    HL_LOCK_TYPE,     HL_LAST_HEARTBEAT,\t HL_ACQUIRED_AT,    HL_HEARTBEAT_COUNT,\t    HL_BLOCKEDBY_EXT_ID,\t    HL_BLOCKEDBY_INT_ID,\t    offset,\t\tbinlog_time,\t\tentry_time from .....  .And second sql ,it's also right when select other cloumns(HL_USER  ,HL_AGENT_INFO) :select HL_USER  ,HL_AGENT_INFO from ......。But when select columns that are the first sql and add column HL_USER  ,it will wrong.\r\nbelow ,i will paste my sql 、return and table.\r\ntable ddl :\r\nCREATE TABLE default.hive_locks_copy\r\n(\r\n    `HL_LOCK_EXT_ID` Int64,\r\n    `HL_LOCK_INT_ID` Int64,\r\n    `HL_TXNID` Nullable(Int64),\r\n    `HL_DB` Nullable(String),\r\n    `HL_TABLE` Nullable(String),\r\n    `HL_PARTITION` Nullable(String),\r\n    `HL_LOCK_STATE` Nullable(String),\r\n    `HL_LOCK_TYPE` Nullable(String),\r\n    `HL_LAST_HEARTBEAT` Nullable(Int64),\r\n    `HL_ACQUIRED_AT` Nullable(Int64),\r\n    `HL_USER` Nullable(String),\r\n    `HL_HOST` Nullable(String),\r\n    `HL_HEARTBEAT_COUNT` Nullable(Int32),\r\n    `HL_AGENT_INFO` Nullable(String),\r\n    `HL_BLOCKEDBY_EXT_ID` Nullable(Int64),\r\n    `HL_BLOCKEDBY_INT_ID` Nullable(Int64),\r\n    `offset` Int64,\r\n    `binlog_time` Int64,\r\n    `entry_time` DateTime64(3),\r\n    `Sign` Int8\r\n)\r\nENGINE = MergeTree\r\nPARTITION BY toYYYYMMDD(entry_time)\r\nORDER BY HL_LOCK_EXT_ID\r\nSETTINGS index_granularity = 8192\r\n.\r\n\r\nFirst sql ：\r\n\r\n\r\n\r\nSELECT \r\n    HL_TXNID,\r\n    HL_DB,\r\n    HL_TABLE,\r\n    HL_PARTITION,\r\n    HL_LOCK_STATE,\r\n    HL_LOCK_TYPE,\r\n    HL_LAST_HEARTBEAT,\r\n    HL_ACQUIRED_AT,\r\n    HL_HEARTBEAT_COUNT,\r\n    HL_BLOCKEDBY_EXT_ID,\r\n    HL_BLOCKEDBY_INT_ID,\r\n    offset,\r\n    binlog_time,\r\n    entry_time,\r\n    Sign,\r\n    dateDiff('second', toDateTime(b.binlog_time / 1000), now()) AS exec_escape_time\r\nFROM \r\n(\r\n    SELECT \r\n        HL_LOCK_EXT_ID,\r\n        HL_LOCK_INT_ID,\r\n        sign,\r\n        arr_offset,\r\n        row_number\r\n    FROM \r\n    (\r\n        SELECT \r\n            HL_LOCK_EXT_ID,\r\n            HL_LOCK_INT_ID,\r\n            groupArray(Sign) AS arr_sign,\r\n            groupArray(offset) AS arr_offset,\r\n            arrayEnumerate(arr_offset) AS row_number\r\n        FROM \r\n        (\r\n            SELECT \r\n                HL_LOCK_EXT_ID,\r\n                HL_LOCK_INT_ID,\r\n                Sign,\r\n                offset\r\n            FROM default.hive_locks_copy AS hl\r\n            ORDER BY (offset, Sign) DESC\r\n        )\r\n        GROUP BY \r\n            HL_LOCK_EXT_ID,\r\n            HL_LOCK_INT_ID\r\n    )\r\n    ARRAY JOIN \r\n        arr_sign AS sign,\r\n        arr_offset,\r\n        row_number\r\n    WHERE (row_number = 1) AND (sign = 1)\r\n) AS t\r\nINNER JOIN default.hive_locks_copy AS b ON (t.HL_LOCK_EXT_ID = b.HL_LOCK_EXT_ID) AND (t.HL_LOCK_INT_ID = b.HL_LOCK_INT_ID) AND (t.arr_offset = b.offset)\r\nWHERE (t.row_number = 1) AND (b.Sign = 1);\r\n\r\nFirst sql return:\r\n\r\nHL_TXNID|HL_DB |HL_TABLE                      |HL_PARTITION|HL_LOCK_STATE|HL_LOCK_TYPE|HL_LAST_HEARTBEAT|HL_ACQUIRED_AT|HL_HEARTBEAT_COUNT|HL_BLOCKEDBY_EXT_ID|HL_BLOCKEDBY_INT_ID|offset |binlog_time  |entry_time             |Sign|exec_escape_time|\r\n--------|------|------------------------------|------------|-------------|------------|-----------------|--------------|------------------|-------------------|-------------------|-------|-------------|-----------------------|----|----------------|\r\n 5953368|ods_jp|ods_cis_dbo_order_header      |            |a            |e           |                0| 1600882974000|                 0|                  0|                  0|4385365|1600911774000|2020-09-23 18:43:00.008|   1|           26561|\r\n 5953368|ods_jp|ods_cis_dbo_order_header_trans|            |a            |r           |                0| 1600882974000|                 0|                  0|                  0|4385364|1600911774000|2020-09-23 18:43:00.008|   1|           26561|\r\n\r\nSecond sql :\r\nSELECT \r\nHL_USER  ,\r\nHL_AGENT_INFO\r\nFROM \r\n(\r\n    SELECT \r\n        HL_LOCK_EXT_ID,\r\n        HL_LOCK_INT_ID,\r\n\t\tsign,\r\n        arr_offset,\r\n        row_number\r\n    FROM \r\n    (\r\n        SELECT \r\n            HL_LOCK_EXT_ID,\r\n            HL_LOCK_INT_ID,\r\n\t\t\tgroupArray(Sign) arr_sign,\r\n            groupArray(offset) AS arr_offset,\r\n            arrayEnumerate(arr_offset) AS row_number\r\n        FROM \r\n        (\r\n            SELECT \r\n                HL_LOCK_EXT_ID,\r\n                HL_LOCK_INT_ID,\r\n\t\t\t\tSign,\r\n                offset\r\n            FROM default.hive_locks_copy AS hl\r\n            ORDER BY (offset, Sign) DESC\r\n        )\r\n        GROUP BY \r\n            HL_LOCK_EXT_ID,\r\n            HL_LOCK_INT_ID\r\n    )\r\n    ARRAY JOIN \r\n\t    arr_sign as sign,\r\n        arr_offset,\r\n        row_number\r\n\tWHERE (row_number = 1 and sign=1) \r\n) AS t\r\n JOIN default.hive_locks_copy AS b ON (t.HL_LOCK_EXT_ID = b.HL_LOCK_EXT_ID) AND (t.HL_LOCK_INT_ID = b.HL_LOCK_INT_ID) AND (t.arr_offset = b.offset)\r\nWHERE  t.row_number = 1\r\nAND b.Sign = 1\r\nSecond sql return also 2 rows :\r\nHL_USER|HL_AGENT_INFO                                           |\r\n-------|--------------------------------------------------------|\r\nhive   |hive_20200923184254_4d4abe74-e6a7-41ae-a09c-d4b38564e11b|\r\nhive   |hive_20200923184254_4d4abe74-e6a7-41ae-a09c-d4b38564e11b|\r\nThird sql and other sql :\r\n\r\n\r\nSELECT \r\nHL_USER,\r\n    HL_TXNID,\r\n    HL_DB,\r\n    HL_TABLE,\r\n    HL_PARTITION,\r\n    HL_LOCK_STATE,\r\n    HL_LOCK_TYPE,\r\n    HL_LAST_HEARTBEAT,\r\n\tHL_ACQUIRED_AT,\r\n    HL_HEARTBEAT_COUNT,\r\n\tHL_BLOCKEDBY_EXT_ID,\r\n\tHL_BLOCKEDBY_INT_ID,\r\n\toffset,\r\n\tbinlog_time,\r\n\tentry_time,\r\n\tSign,\r\n\tdateDiff('second', toDateTime(b.binlog_time / 1000), now()) AS exec_escape_time\r\nFROM \r\n(\r\n    SELECT \r\n        HL_LOCK_EXT_ID,\r\n        HL_LOCK_INT_ID,\r\n\t\tsign,\r\n        arr_offset,\r\n        row_number\r\n    FROM \r\n    (\r\n        SELECT \r\n            HL_LOCK_EXT_ID,\r\n            HL_LOCK_INT_ID,\r\n\t\t\tgroupArray(Sign) arr_sign,\r\n            groupArray(offset) AS arr_offset,\r\n            arrayEnumerate(arr_offset) AS row_number\r\n        FROM \r\n        (\r\n            SELECT \r\n                HL_LOCK_EXT_ID,\r\n                HL_LOCK_INT_ID,\r\n\t\t\t\tSign,\r\n                offset\r\n            FROM default.hive_locks_copy AS hl\r\n            ORDER BY (offset, Sign) DESC\r\n        )\r\n        GROUP BY \r\n            HL_LOCK_EXT_ID,\r\n            HL_LOCK_INT_ID\r\n    )\r\n    ARRAY JOIN \r\n\t    arr_sign as sign,\r\n        arr_offset,\r\n        row_number\r\n\tWHERE (row_number = 1 and sign=1) \r\n) AS t\r\n JOIN default.hive_locks_copy AS b ON (t.HL_LOCK_EXT_ID = b.HL_LOCK_EXT_ID) AND (t.HL_LOCK_INT_ID = b.HL_LOCK_INT_ID) AND (t.arr_offset = b.offset)\r\nWHERE  t.row_number = 1\r\nAND b.Sign = 1\r\n\r\nThird sql return thousands of rows,it's to many to paste ,now only paste  10 rows:\r\nHL_USER|HL_TXNID|HL_DB   |HL_TABLE                                    |HL_PARTITION        |HL_LOCK_STATE|HL_LOCK_TYPE|HL_LAST_HEARTBEAT|HL_ACQUIRED_AT|HL_HEARTBEAT_COUNT|HL_BLOCKEDBY_EXT_ID|HL_BLOCKEDBY_INT_ID|offset |binlog_time  |entry_time             |Sign|exec_escape_time|\r\n-------|--------|--------|--------------------------------------------|--------------------|-------------|------------|-----------------|--------------|------------------|-------------------|-------------------|-------|-------------|-----------------------|----|----------------|\r\nhive   | 5945015|dw_ca   |dwd_stellr_subscription_trans_di            |date_flag=2016-10-29|a            |r           |                0| 1600842311000|                 0|                  0|                  0|4151233|1600871111000|2020-09-23 07:26:00.202|   1|           66761|\r\nhive   | 5919876|ods_us  |ods_dw_prod_dbo_dw_orders_pl_trans          |date_flag=2020-01-13|w            |r           |                0|             0|                 0|                  0|                  0|3589007|1600787865000|2020-09-22 08:18:30.249|   1|          150007|\r\nhive   | 5919876|ods_us  |ods_dw_prod_dbo_dw_orders_pl_trans          |date_flag=2018-12-17|a            |r           |                0| 1600759065000|                 0|                  0|                  0|3592708|1600787865000|2020-09-22 08:18:30.249|   1|          150007|\r\nhive   | 5944049|dw_us   |dwd_stellr_subscription_contract_df         |date_flag=2020-07-13|a            |r           |                0| 1600838171000|                 0|                  0|                  0|4043486|1600866971000|2020-09-23 06:16:30.214|   1|           70901|\r\nhive   | 5944063|dw_ca   |dwd_stellr_subscription_contract_df         |date_flag=2020-06-22|w            |r           |                0|             0|                 0|                  0|                  0|4046205|1600866995000|2020-09-23 06:17:00.192|   1|           70877|\r\nhive   | 5947066|ods_us  |ods_dw_prod_dbo_dw_orders_trans             |date_flag=2004-04-27|a            |r           |                0| 1600855092000|                 0|                  0|                  0|4301326|1600883892000|2020-09-23 10:59:00.301|   1|           53980|\r\nhive   | 5919876|ods_us  |ods_dw_prod_dbo_dw_orders_pl_trans          |date_flag=2009-09-16|a            |r           |                0| 1600759065000|                 0|                  0|                  0|3592455|1600787865000|2020-09-22 08:18:30.249|   1|          150007|\r\nhive   | 5919876|ods_us  |ods_dw_prod_dbo_dw_orders_pl_trans          |date_flag=2009-11-09|w            |r           |                0|             0|                 0|                  0|                  0|3590699|1600787865000|2020-09-22 08:18:30.249|   1|          150007|\r\nhive   | 5947066|ods_us  |ods_dw_prod_dbo_dw_orders_trans             |date_flag=2010-05-21|a            |r           |                0| 1600855092000|                 0|                  0|                  0|4302860|1600883892000|2020-09-23 10:59:30.251|   1|           53980|\r\nhive   | 5947066|ods_us  |ods_dw_prod_dbo_dw_orders_trans             |date_flag=2009-06-28|a            |r           |                0| 1600855092000|                 0|                  0|                  0|4300121|1600883892000|2020-09-23 10:59:00.301|   1|           53980|\r\nhive   | 5945013|dm_wcla |dm_stellr_invoice_license_recurring         |date_flag=2020-09-22|w            |r           |                0|             0|                 0|                  0|                  0|4143969|1600871098000|2020-09-23 07:25:30.196|   1|           66774|\r\n......\r\n\r\n\r\n\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15225/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15225/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15210","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15210/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15210/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15210/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/15210","id":707818446,"node_id":"MDU6SXNzdWU3MDc4MTg0NDY=","number":15210,"title":"Create two or many shards on same node.","user":{"login":"yiguolei","id":9208457,"node_id":"MDQ6VXNlcjkyMDg0NTc=","avatar_url":"https://avatars.githubusercontent.com/u/9208457?v=4","gravatar_id":"","url":"https://api.github.com/users/yiguolei","html_url":"https://github.com/yiguolei","followers_url":"https://api.github.com/users/yiguolei/followers","following_url":"https://api.github.com/users/yiguolei/following{/other_user}","gists_url":"https://api.github.com/users/yiguolei/gists{/gist_id}","starred_url":"https://api.github.com/users/yiguolei/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yiguolei/subscriptions","organizations_url":"https://api.github.com/users/yiguolei/orgs","repos_url":"https://api.github.com/users/yiguolei/repos","events_url":"https://api.github.com/users/yiguolei/events{/privacy}","received_events_url":"https://api.github.com/users/yiguolei/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":5,"created_at":"2020-09-24T03:15:10Z","updated_at":"2020-09-24T12:53:25Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"Currently, I only have one machine， but my data will increasing very fast. I want to create 100 shard for the simple table on the machine and create a distribute table on it. \r\nBut I do not know how to do it.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15210/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15210/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15206","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15206/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15206/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15206/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/15206","id":707648533,"node_id":"MDU6SXNzdWU3MDc2NDg1MzM=","number":15206,"title":"ALTER MV MODIFY QUERY changes MV query but not columns list.","user":{"login":"den-crane","id":19737682,"node_id":"MDQ6VXNlcjE5NzM3Njgy","avatar_url":"https://avatars.githubusercontent.com/u/19737682?v=4","gravatar_id":"","url":"https://api.github.com/users/den-crane","html_url":"https://github.com/den-crane","followers_url":"https://api.github.com/users/den-crane/followers","following_url":"https://api.github.com/users/den-crane/following{/other_user}","gists_url":"https://api.github.com/users/den-crane/gists{/gist_id}","starred_url":"https://api.github.com/users/den-crane/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/den-crane/subscriptions","organizations_url":"https://api.github.com/users/den-crane/orgs","repos_url":"https://api.github.com/users/den-crane/repos","events_url":"https://api.github.com/users/den-crane/events{/privacy}","received_events_url":"https://api.github.com/users/den-crane/received_events","type":"User","site_admin":false},"labels":[{"id":845247686,"node_id":"MDU6TGFiZWw4NDUyNDc2ODY=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/usability","name":"usability","color":"ebf28c","default":false,"description":""},{"id":1350221495,"node_id":"MDU6TGFiZWwxMzUwMjIxNDk1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-matview","name":"comp-matview","color":"b5bcff","default":false,"description":"Materialized views"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2020-09-23T20:12:03Z","updated_at":"2020-10-15T10:05:16Z","closed_at":null,"author_association":"COLLABORATOR","active_lock_reason":null,"body":"```\r\nCREATE TABLE src(v UInt64) ENGINE = Null;\r\nCREATE TABLE dest(v UInt64) Engine = MergeTree() ORDER BY v;\r\nCREATE MATERIALIZED VIEW pipe TO dest AS SELECT v FROM src;\r\nALTER TABLE dest ADD COLUMN v2 UInt64;\r\n\r\nSET allow_experimental_alter_materialized_view_structure = 1;\r\n\r\nALTER TABLE pipe add column v2 Int64, MODIFY QUERY SELECT v * 2 as v, 1 as v2 FROM src;\r\n\r\nDESCRIBE TABLE pipe\r\n\r\n┌─name─┬─type───┬─default_type─┬─default_expression─┬─comment─┬─codec_expression─┬─ttl_expression─┐\r\n│ v    │ UInt64 │              │                    │         │                  │                │\r\n└──────┴────────┴──────────────┴────────────────────┴─────────┴──────────────────┴────────────────┘\r\n\r\nexpected 2 columns `v`, `v2`\r\n\r\nSHOW CREATE TABLE pipe\r\n\r\n┌─statement─────────────────────────────────────────────────────────────────────────────────────────────────┐\r\n│ CREATE MATERIALIZED VIEW dw.pipe TO dw.dest\r\n(\r\n    `v` UInt64\r\n) AS\r\nSELECT\r\n    v * 2 AS v,\r\n    1 AS v2\r\nFROM dw.src │\r\n└───────────────────────────────────────────────────────────────────────────────────────────────────────────┘\r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15206/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15206/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15172","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15172/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15172/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15172/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/15172","id":706651788,"node_id":"MDU6SXNzdWU3MDY2NTE3ODg=","number":15172,"title":"Allow multiple threads when reading a single file by s3 table function / S3 table.","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":2020016497,"node_id":"MDU6TGFiZWwyMDIwMDE2NDk3","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-s3","name":"comp-s3","color":"b5bcff","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2020-09-22T19:55:15Z","updated_at":"2021-07-24T00:56:31Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"When max_threads > 1, determine file size and read it by multiple ranges requests in parallel.\r\n\r\nMotivation: single-threaded reading from s3 is slow but s3 is inherently parallel (sometimes more than 100 threads is Ok for reading of a large file).\r\n\r\nThe benefits are proved by the followint examples:\r\n- `axel` - parallel download of files by ranges, alternative to `wget`;\r\n- `goofys` - implementation of FUSE over s3 with reasonable performance only due to exploitation of parallelism.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15172/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15172/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15165","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15165/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15165/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15165/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/15165","id":706607023,"node_id":"MDU6SXNzdWU3MDY2MDcwMjM=","number":15165,"title":"RBAC Distributed Tables - actions on remote servers required less privileges than on local servers.","user":{"login":"MyroTk","id":44327070,"node_id":"MDQ6VXNlcjQ0MzI3MDcw","avatar_url":"https://avatars.githubusercontent.com/u/44327070?v=4","gravatar_id":"","url":"https://api.github.com/users/MyroTk","html_url":"https://github.com/MyroTk","followers_url":"https://api.github.com/users/MyroTk/followers","following_url":"https://api.github.com/users/MyroTk/following{/other_user}","gists_url":"https://api.github.com/users/MyroTk/gists{/gist_id}","starred_url":"https://api.github.com/users/MyroTk/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/MyroTk/subscriptions","organizations_url":"https://api.github.com/users/MyroTk/orgs","repos_url":"https://api.github.com/users/MyroTk/repos","events_url":"https://api.github.com/users/MyroTk/events{/privacy}","received_events_url":"https://api.github.com/users/MyroTk/received_events","type":"User","site_admin":false},"labels":[{"id":386401509,"node_id":"MDU6TGFiZWwzODY0MDE1MDk=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/invalid","name":"invalid","color":"e6e6e6","default":true,"description":null},{"id":1634829961,"node_id":"MDU6TGFiZWwxNjM0ODI5OTYx","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-distributed","name":"comp-distributed","color":"b5bcff","default":false,"description":"Distributed tables"},{"id":2011606513,"node_id":"MDU6TGFiZWwyMDExNjA2NTEz","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-rbac","name":"comp-rbac","color":"b5bcff","default":false,"description":"Access control related"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":6,"created_at":"2020-09-22T18:38:56Z","updated_at":"2021-04-27T09:15:15Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Describe the bug**\r\nIn order to execute `SELECT` or `INSERT` on a distributed table, the user requires additional privileges on the table indicated in the distributed table. However, if that table does not exist locally, or the distributed table is sharded across multiple servers, then the user is not checked for those privileges and is able to execute the command.\r\n\r\n**How to reproduce**\r\n* ClickHouse 20.10.1.1 with revision 54440\r\n* `CREATE TABLE` statements\r\n`CREATE TABLE default.dist0 (a UInt64) ENGINE = Distributed(cluster23, default, table0)` - using table0 remotely.\r\n`CREATE TABLE default.dist1 (a UInt64) ENGINE = Distributed(cluster1, default, table0)` - using table0 locally.\r\n\r\n* Clusters from remote servers config\r\n```\r\n        <cluster1>\r\n            <shard>\r\n                <replica>\r\n                    <host>clickhouse1</host>\r\n                    <port>9440</port>\r\n                    <secure>1</secure>\r\n                </replica>\r\n            </shard>\r\n        </cluster1>\r\n\t<cluster23>\r\n            <shard>\r\n                <replica>\r\n                    <host>clickhouse2</host>\r\n                    <port>9000</port>\r\n                </replica>\r\n            </shard>\r\n            <shard>\r\n                <replica>\r\n                    <host>clickhouse3</host>\r\n                    <port>9000</port>\r\n                </replica>\r\n            </shard>\r\n        </cluster23>\r\n```\r\n* Queries to run that lead to unexpected result\r\n```\r\nroot@clickhouse1:/# echo -e \"SELECT * FROM dist1\" | clickhouse client -n -uuser0\r\nReceived exception from server (version 20.8.2):\r\nCode: 497. DB::Exception: Received from localhost:9000. DB::Exception: user0: Not enough privileges. To execute this query it's necessary to have the grant SELECT(a) ON default.table0.\r\n\r\nroot@clickhouse1:/# echo -e \"SELECT * FROM dist0\" | clickhouse client -n -uuser0\r\n\r\nroot@clickhouse1:/# echo -e \"SHOW GRANTS FOR user0\" | clickhouse client -n\r\nGRANT SELECT ON default.dist0 TO user0\r\nGRANT SELECT ON default.dist1 TO user0\r\n```\r\n**Expected behavior**\r\nConsistent  privilege requirements between local and remote tables.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15165/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15165/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15160","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15160/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15160/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15160/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/15160","id":706541335,"node_id":"MDU6SXNzdWU3MDY1NDEzMzU=","number":15160,"title":"Add new EXPLAIN query flavour to describe encountered policies for other queries","user":{"login":"abyss7","id":5627721,"node_id":"MDQ6VXNlcjU2Mjc3MjE=","avatar_url":"https://avatars.githubusercontent.com/u/5627721?v=4","gravatar_id":"","url":"https://api.github.com/users/abyss7","html_url":"https://github.com/abyss7","followers_url":"https://api.github.com/users/abyss7/followers","following_url":"https://api.github.com/users/abyss7/following{/other_user}","gists_url":"https://api.github.com/users/abyss7/gists{/gist_id}","starred_url":"https://api.github.com/users/abyss7/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/abyss7/subscriptions","organizations_url":"https://api.github.com/users/abyss7/orgs","repos_url":"https://api.github.com/users/abyss7/repos","events_url":"https://api.github.com/users/abyss7/events{/privacy}","received_events_url":"https://api.github.com/users/abyss7/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2020-09-22T16:49:11Z","updated_at":"2020-09-22T16:49:11Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"For queries like `SELECT …` it will be useful to have query e.g. `EXPLAIN POLICIES SELECT …` that will follow the execution conveyer and output all met grants and stop on first restriction - to prevent potential security breaches.\r\n\r\nIt's helpful to understand what policies affect what and to understand what `GRANT` is missing.\r\n\r\nTODO: add examples.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15160/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15160/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15121","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15121/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15121/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15121/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/15121","id":706157906,"node_id":"MDU6SXNzdWU3MDYxNTc5MDY=","number":15121,"title":"MergeTree table set TTL value, same setting on 4 tables,but some table don't take effect.","user":{"login":"yostlfog","id":54238903,"node_id":"MDQ6VXNlcjU0MjM4OTAz","avatar_url":"https://avatars.githubusercontent.com/u/54238903?v=4","gravatar_id":"","url":"https://api.github.com/users/yostlfog","html_url":"https://github.com/yostlfog","followers_url":"https://api.github.com/users/yostlfog/followers","following_url":"https://api.github.com/users/yostlfog/following{/other_user}","gists_url":"https://api.github.com/users/yostlfog/gists{/gist_id}","starred_url":"https://api.github.com/users/yostlfog/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yostlfog/subscriptions","organizations_url":"https://api.github.com/users/yostlfog/orgs","repos_url":"https://api.github.com/users/yostlfog/repos","events_url":"https://api.github.com/users/yostlfog/events{/privacy}","received_events_url":"https://api.github.com/users/yostlfog/received_events","type":"User","site_admin":false},"labels":[{"id":845247686,"node_id":"MDU6TGFiZWw4NDUyNDc2ODY=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/usability","name":"usability","color":"ebf28c","default":false,"description":""},{"id":1401282669,"node_id":"MDU6TGFiZWwxNDAxMjgyNjY5","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-ttl","name":"comp-ttl","color":"b5bcff","default":false,"description":"TTL"}],"state":"open","locked":false,"assignee":{"login":"CurtizJ","id":20361854,"node_id":"MDQ6VXNlcjIwMzYxODU0","avatar_url":"https://avatars.githubusercontent.com/u/20361854?v=4","gravatar_id":"","url":"https://api.github.com/users/CurtizJ","html_url":"https://github.com/CurtizJ","followers_url":"https://api.github.com/users/CurtizJ/followers","following_url":"https://api.github.com/users/CurtizJ/following{/other_user}","gists_url":"https://api.github.com/users/CurtizJ/gists{/gist_id}","starred_url":"https://api.github.com/users/CurtizJ/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/CurtizJ/subscriptions","organizations_url":"https://api.github.com/users/CurtizJ/orgs","repos_url":"https://api.github.com/users/CurtizJ/repos","events_url":"https://api.github.com/users/CurtizJ/events{/privacy}","received_events_url":"https://api.github.com/users/CurtizJ/received_events","type":"User","site_admin":false},"assignees":[{"login":"CurtizJ","id":20361854,"node_id":"MDQ6VXNlcjIwMzYxODU0","avatar_url":"https://avatars.githubusercontent.com/u/20361854?v=4","gravatar_id":"","url":"https://api.github.com/users/CurtizJ","html_url":"https://github.com/CurtizJ","followers_url":"https://api.github.com/users/CurtizJ/followers","following_url":"https://api.github.com/users/CurtizJ/following{/other_user}","gists_url":"https://api.github.com/users/CurtizJ/gists{/gist_id}","starred_url":"https://api.github.com/users/CurtizJ/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/CurtizJ/subscriptions","organizations_url":"https://api.github.com/users/CurtizJ/orgs","repos_url":"https://api.github.com/users/CurtizJ/repos","events_url":"https://api.github.com/users/CurtizJ/events{/privacy}","received_events_url":"https://api.github.com/users/CurtizJ/received_events","type":"User","site_admin":false}],"milestone":null,"comments":1,"created_at":"2020-09-22T07:52:25Z","updated_at":"2021-07-02T05:24:00Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"\r\n\r\n**Describe the issue**\r\nI use  TTL value for determines the lifetime   on 4 tables.\r\nAt first , the ttl setting is well worked.but someday i found 2 of the 4 tables  data over 15 days not delete by TTL setting . \r\n\r\n* Which ClickHouse server version to use\r\n\r\n20.3.12.112\r\n\r\n* Table DDL\r\n```\r\ncreate table if not exists test.test1\r\n(\r\n\tid UInt32,\r\n\tdate Date,\r\n\thour UInt8\r\n)\r\nengine = MergeTree PARTITION BY toYYYYMMDD(date) ORDER BY id TTL date + toIntervalDay(15) SETTINGS index_granularity = 8192;\r\n```\r\n* Question\r\n I want to know how to trouble shooting the TTL error and why it happened.\r\n\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15121/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15121/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15112","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15112/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15112/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15112/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/15112","id":706005453,"node_id":"MDU6SXNzdWU3MDYwMDU0NTM=","number":15112,"title":"Integrate \"sqllogictest\"","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":521113272,"node_id":"MDU6TGFiZWw1MjExMTMyNzI=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/build","name":"build","color":"800000","default":false,"description":""},{"id":2372525166,"node_id":"MDU6TGFiZWwyMzcyNTI1MTY2","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-ci","name":"comp-ci","color":"b5bcff","default":false,"description":"Continuous integration"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2020-09-22T00:51:08Z","updated_at":"2020-09-24T06:37:10Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"https://www.sqlite.org/sqllogictest/doc/trunk/about.wiki\r\nGitHub mirror: https://github.com/MaterializeInc/sqllogictest\r\n\r\nSQLLogicTest is a test suite for correctness of query execution.\r\nThe test suite is somewhat similar to out functional tests (it provides SQL queries and expected reference results).\r\n\r\nThere can be some minor details on syntax of CREATE TABLE statement (which can be workarounded) and CREATE INDEX (that can be ignored).","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15112/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15112/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15085","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15085/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15085/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15085/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/15085","id":705582853,"node_id":"MDU6SXNzdWU3MDU1ODI4NTM=","number":15085,"title":"SimpleAggregateFunction & -ForEach combinator","user":{"login":"UnamedRus","id":9449405,"node_id":"MDQ6VXNlcjk0NDk0MDU=","avatar_url":"https://avatars.githubusercontent.com/u/9449405?v=4","gravatar_id":"","url":"https://api.github.com/users/UnamedRus","html_url":"https://github.com/UnamedRus","followers_url":"https://api.github.com/users/UnamedRus/followers","following_url":"https://api.github.com/users/UnamedRus/following{/other_user}","gists_url":"https://api.github.com/users/UnamedRus/gists{/gist_id}","starred_url":"https://api.github.com/users/UnamedRus/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/UnamedRus/subscriptions","organizations_url":"https://api.github.com/users/UnamedRus/orgs","repos_url":"https://api.github.com/users/UnamedRus/repos","events_url":"https://api.github.com/users/UnamedRus/events{/privacy}","received_events_url":"https://api.github.com/users/UnamedRus/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2020-09-21T13:08:07Z","updated_at":"2021-01-14T01:18:42Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Use case**\r\nCurrently clickhouse supports a set of functions which can be used in SimpleAggregateFunction Data Type for AggregatingMergeTree, but it is not complete, for example it doesn't support -ForEach combinator which is stateless too.\r\n\r\n**Describe the solution you'd like**\r\nAdd -ForEach combinator as combinator which can be used in SimpleAggregateFunction.\r\n\r\n**Describe alternatives you've considered**\r\nUse AggregateFunction instead, but it requires you to use -Merge, -State combinators and takes more space on disk.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15085/reactions","total_count":2,"+1":2,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15085/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15072","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15072/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15072/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15072/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/15072","id":705441848,"node_id":"MDU6SXNzdWU3MDU0NDE4NDg=","number":15072,"title":"what is the plan to support truely distribued execution like other MPP databases ","user":{"login":"fzhedu","id":6490813,"node_id":"MDQ6VXNlcjY0OTA4MTM=","avatar_url":"https://avatars.githubusercontent.com/u/6490813?v=4","gravatar_id":"","url":"https://api.github.com/users/fzhedu","html_url":"https://github.com/fzhedu","followers_url":"https://api.github.com/users/fzhedu/followers","following_url":"https://api.github.com/users/fzhedu/following{/other_user}","gists_url":"https://api.github.com/users/fzhedu/gists{/gist_id}","starred_url":"https://api.github.com/users/fzhedu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/fzhedu/subscriptions","organizations_url":"https://api.github.com/users/fzhedu/orgs","repos_url":"https://api.github.com/users/fzhedu/repos","events_url":"https://api.github.com/users/fzhedu/events{/privacy}","received_events_url":"https://api.github.com/users/fzhedu/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2020-09-21T09:41:10Z","updated_at":"2020-09-21T15:11:22Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"**Use case**\r\nAs described in [Distributed Query Execution](https://clickhouse.tech/docs/en/development/architecture/#distributed-query-execution), `But this is not feasible for complicated queries with high cardinality GROUP BYs or with a large amount of temporary data for JOIN. In such cases, we need to “reshuffle” data between servers, which requires additional coordination. ClickHouse does not support that kind of query execution, and we need to work on it.`, ClickHouse lakes the `shuffle` operator to support MPP execution.\r\n\r\n**Describe the solution you'd like**\r\nClickHouse has a `shuffle` operator to support MPP exectuion for large GroupBy or Join, like the SparkSQL, Hawq, prestoSQL and other OLAP databases.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15072/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15072/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15005","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15005/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15005/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15005/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/15005","id":704587735,"node_id":"MDU6SXNzdWU3MDQ1ODc3MzU=","number":15005,"title":"GROUP BY LowCardinality(String/FixedString) perfomance","user":{"login":"UnamedRus","id":9449405,"node_id":"MDQ6VXNlcjk0NDk0MDU=","avatar_url":"https://avatars.githubusercontent.com/u/9449405?v=4","gravatar_id":"","url":"https://api.github.com/users/UnamedRus","html_url":"https://github.com/UnamedRus","followers_url":"https://api.github.com/users/UnamedRus/followers","following_url":"https://api.github.com/users/UnamedRus/following{/other_user}","gists_url":"https://api.github.com/users/UnamedRus/gists{/gist_id}","starred_url":"https://api.github.com/users/UnamedRus/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/UnamedRus/subscriptions","organizations_url":"https://api.github.com/users/UnamedRus/orgs","repos_url":"https://api.github.com/users/UnamedRus/repos","events_url":"https://api.github.com/users/UnamedRus/events{/privacy}","received_events_url":"https://api.github.com/users/UnamedRus/received_events","type":"User","site_admin":false},"labels":[{"id":756395244,"node_id":"MDU6TGFiZWw3NTYzOTUyNDQ=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/performance","name":"performance","color":"c2e0c6","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2020-09-18T18:56:08Z","updated_at":"2020-09-19T11:03:43Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**How to reproduce**\r\nClickhouse server version 20.8.2.3\r\n```\r\nCREATE TABLE test_group_by (key UInt32, key_a String, key_b String, key_c LowCardinality(String), key_d LowCardinality(String), key_e FixedString(14), key_f FixedString(14), key_g LowCardinality(FixedString(14)), key_h LowCardinality(FixedString(14)) ) ENGINE=MergeTree() PARTITION BY tuple() ORDER BY key;\r\nINSERT INTO test_group_by SELECT number % 40000 , ('number key ' || toString(number % 400)) AS a, ('number key ' || toString(number % 20)) AS b, a, b, a, b, a, b FROM numbers(30000000) ;\r\n```\r\nSingle key\r\n```\r\nString\r\nSELECT count() FROM test_group_by GROUP BY key_a  FORMAT Null;\r\n0 rows in set. Elapsed: 0.045 sec. Processed 30.00 million rows, 681.75 MB (665.30 million rows/s., 15.12 GB/s.)\r\nkey_string\r\n\r\nLC(String)\r\nSELECT count() FROM test_group_by GROUP BY key_c  FORMAT Null;\r\n0 rows in set. Elapsed: 0.018 sec. Processed 30.00 million rows, 65.09 MB (1.71 billion rows/s., 3.71 GB/s.)\r\nAggregation method: low_cardinality_key_string\r\n\r\nFixedString\r\nSELECT count() FROM test_group_by GROUP BY key_f  FORMAT Null;\r\n0 rows in set. Elapsed: 0.030 sec. Processed 30.00 million rows, 420.00 MB (1.00 billion rows/s., 14.04 GB/s.)\r\nAggregation method: keys128\r\n\r\nLC(FixedString)\r\nSELECT count() FROM test_group_by GROUP BY key_h  FORMAT Null;\r\n0 rows in set. Elapsed: 0.031 sec. Processed 30.00 million rows, 30.17 MB (981.24 million rows/s., 986.91 MB/s.)\r\nAggregation method: low_cardinality_keys128 \r\n```\r\nLC(FixedString) two times slower than LC(String) and it looks like happens because of:\r\n**low_cardinality_keys128** instead of [low_cardinality_key_fixed_string](https://github.com/ClickHouse/ClickHouse/blob/7c20aa2c621e31bcad50d4bc5eb2384d8a6286bd/src/Interpreters/Aggregator.cpp#L405)\r\nFixedString is using **keys128** instead of [key_fixed_string](https://github.com/ClickHouse/ClickHouse/blob/7c20aa2c621e31bcad50d4bc5eb2384d8a6286bd/src/Interpreters/Aggregator.cpp#L407) too.\r\n\r\nOther results are expected.\r\n\r\nMultiple key\r\n```\r\nString\r\nSELECT count() FROM test_group_by GROUP BY key_a, key_b  FORMAT Null;\r\n0 rows in set. Elapsed: 0.120 sec. Processed 30.00 million rows, 1.33 GB (249.21 million rows/s., 11.02 GB/s.)\r\nAggregation method: serialized\r\n\r\nLC(String)\r\nSELECT count() FROM test_group_by GROUP BY key_c, key_d  FORMAT Null;\r\n0 rows in set. Elapsed: 0.112 sec. Processed 30.00 million rows, 95.34 MB (268.63 million rows/s., 853.75 MB/s.)\r\nAggregation method: serialized\r\n\r\nFixedString\r\nSELECT count() FROM test_group_by GROUP BY key_e, key_f  FORMAT Null;\r\n0 rows in set. Elapsed: 0.046 sec. Processed 30.00 million rows, 840.01 MB (647.31 million rows/s., 18.13 GB/s.)\r\nAggregation method: keys256\r\n\r\nLC(FixedString)\r\nSELECT count() FROM test_group_by GROUP BY key_g, key_h  FORMAT Null;\r\n0 rows in set. Elapsed: 0.044 sec. Processed 30.00 million rows, 95.31 MB (684.91 million rows/s., 2.18 GB/s.)\r\nAggregation method: low_cardinality_keys256\r\n```\r\n\r\nClickhouse does have a special aggregate hashmap for single LowCardinality and can benefit greatly from it, but doesn't have that kind of map for multiple Low Cardinality keys or LC keys and fixed length values. And now you can't just use LC(FixedString) and put it in the table ORDER BY because of [issue with PK and LC(FixedString)](https://github.com/ClickHouse/ClickHouse/issues/14908).\r\n\r\n**Additional context**\r\nOn real table (SSB benchmark), difference between multiple LC(String) and LC(FixedString) keys even more and can be close to 4-5 times (120ms-340ms vs 50ms) and LC(String) has great scatter between repeating requests. \r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15005/reactions","total_count":1,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":1},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15005/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15004","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15004/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15004/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15004/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/15004","id":704571008,"node_id":"MDU6SXNzdWU3MDQ1NzEwMDg=","number":15004,"title":"Views and Materialized Views don't throw an exception when dropped while having dependancy.","user":{"login":"MyroTk","id":44327070,"node_id":"MDQ6VXNlcjQ0MzI3MDcw","avatar_url":"https://avatars.githubusercontent.com/u/44327070?v=4","gravatar_id":"","url":"https://api.github.com/users/MyroTk","html_url":"https://github.com/MyroTk","followers_url":"https://api.github.com/users/MyroTk/followers","following_url":"https://api.github.com/users/MyroTk/following{/other_user}","gists_url":"https://api.github.com/users/MyroTk/gists{/gist_id}","starred_url":"https://api.github.com/users/MyroTk/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/MyroTk/subscriptions","organizations_url":"https://api.github.com/users/MyroTk/orgs","repos_url":"https://api.github.com/users/MyroTk/repos","events_url":"https://api.github.com/users/MyroTk/events{/privacy}","received_events_url":"https://api.github.com/users/MyroTk/received_events","type":"User","site_admin":false},"labels":[{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2020-09-18T18:22:37Z","updated_at":"2020-09-18T18:22:37Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Describe the unexpected behaviour**\r\nLive views create an exception when dropping a live view that another table is dependent on. Views and Materialized views don't throw this exception. \r\n\r\n**How to reproduce**\r\n* ClickHouse server version 20.10.1 revision 54440\r\n* Queries to run that lead to unexpected result:\r\n```\r\n:) SET allow_experimental_live_view=1\r\n\r\nSET allow_experimental_live_view = 1\r\n\r\nOk.\r\n\r\n0 rows in set. Elapsed: 0.002 sec.\r\n\r\n:) CREATE LIVE VIEW live0 AS SELECT 1\r\n\r\nCREATE LIVE VIEW live0 AS\r\nSELECT 1\r\n\r\nOk.\r\n\r\n0 rows in set. Elapsed: 0.007 sec.\r\n\r\n:) CREATE LIVE VIEW live1 AS SELECT * FROM live0\r\n\r\nCREATE LIVE VIEW live1 AS\r\nSELECT *\r\nFROM live0\r\n\r\nOk.\r\n\r\n0 rows in set. Elapsed: 0.005 sec.\r\n\r\n:) DROP VIEW live0\r\n\r\nDROP VIEW live0\r\n\r\n\r\nReceived exception from server (version 20.8.2):\r\nCode: 305. DB::Exception: Received from localhost:9000. DB::Exception: Table has dependency default.live1.\r\n\r\n0 rows in set. Elapsed: 0.003 sec.\r\n\r\n:) create view view0 as select 1\r\n\r\nCREATE VIEW view0 AS\r\nSELECT 1\r\n\r\nOk.\r\n\r\n0 rows in set. Elapsed: 0.007 sec.\r\n\r\n:) CREATE LIVE VIEW view1 AS SELECT * FROM view0\r\n\r\nCREATE LIVE VIEW view1 AS\r\nSELECT *\r\nFROM view0\r\n\r\nOk.\r\n\r\n0 rows in set. Elapsed: 0.009 sec.\r\n\r\n:) DROP VIEW view0\r\n\r\nDROP VIEW view0\r\n\r\nOk.\r\n\r\n0 rows in set. Elapsed: 0.002 sec.\r\n\r\n:)","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15004/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/15004/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14980","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14980/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14980/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14980/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/14980","id":704283957,"node_id":"MDU6SXNzdWU3MDQyODM5NTc=","number":14980,"title":"arrayMap in IN operator not recognized as constant","user":{"login":"akuzm","id":36882414,"node_id":"MDQ6VXNlcjM2ODgyNDE0","avatar_url":"https://avatars.githubusercontent.com/u/36882414?v=4","gravatar_id":"","url":"https://api.github.com/users/akuzm","html_url":"https://github.com/akuzm","followers_url":"https://api.github.com/users/akuzm/followers","following_url":"https://api.github.com/users/akuzm/following{/other_user}","gists_url":"https://api.github.com/users/akuzm/gists{/gist_id}","starred_url":"https://api.github.com/users/akuzm/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/akuzm/subscriptions","organizations_url":"https://api.github.com/users/akuzm/orgs","repos_url":"https://api.github.com/users/akuzm/repos","events_url":"https://api.github.com/users/akuzm/events{/privacy}","received_events_url":"https://api.github.com/users/akuzm/received_events","type":"User","site_admin":false},"labels":[{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2020-09-18T10:51:41Z","updated_at":"2020-09-18T10:58:03Z","closed_at":null,"author_association":"COLLABORATOR","active_lock_reason":null,"body":"```\r\nselect 1 in arrayMap(x->x, [1]);\r\n\r\nReceived exception from server (version 20.10.1):\r\nCode: 36. DB::Exception: Received from localhost:9000. DB::Exception: Element of set in IN, VALUES or LIMIT is not a constant expression (result column not found): arrayMap(lambda(tuple(x), x), [1]). Stack trace:\r\n```\r\n\r\nIt is constant though.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14980/reactions","total_count":5,"+1":5,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14980/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14978","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14978/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14978/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14978/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/14978","id":704218787,"node_id":"MDU6SXNzdWU3MDQyMTg3ODc=","number":14978,"title":"Column alias problem - name conflict","user":{"login":"bgranvea","id":1116217,"node_id":"MDQ6VXNlcjExMTYyMTc=","avatar_url":"https://avatars.githubusercontent.com/u/1116217?v=4","gravatar_id":"","url":"https://api.github.com/users/bgranvea","html_url":"https://github.com/bgranvea","followers_url":"https://api.github.com/users/bgranvea/followers","following_url":"https://api.github.com/users/bgranvea/following{/other_user}","gists_url":"https://api.github.com/users/bgranvea/gists{/gist_id}","starred_url":"https://api.github.com/users/bgranvea/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bgranvea/subscriptions","organizations_url":"https://api.github.com/users/bgranvea/orgs","repos_url":"https://api.github.com/users/bgranvea/repos","events_url":"https://api.github.com/users/bgranvea/events{/privacy}","received_events_url":"https://api.github.com/users/bgranvea/received_events","type":"User","site_admin":false},"labels":[{"id":386401505,"node_id":"MDU6TGFiZWwzODY0MDE1MDU=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/bug","name":"bug","color":"ee0701","default":true,"description":"Confirmed user-visible misbehaviour in official release"},{"id":1357578153,"node_id":"MDU6TGFiZWwxMzU3NTc4MTUz","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-joins","name":"comp-joins","color":"b5bcff","default":false,"description":"JOINs"},{"id":1507867504,"node_id":"MDU6TGFiZWwxNTA3ODY3NTA0","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/st-hold","name":"st-hold","color":"e5b890","default":false,"description":"We've paused the work on issue for some reason"},{"id":2132806078,"node_id":"MDU6TGFiZWwyMTMyODA2MDc4","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/v20.5-affected","name":"v20.5-affected","color":"c2bfff","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2020-09-18T09:09:38Z","updated_at":"2021-07-02T23:46:14Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**How to reproduce**\r\n```\r\n# clickhouse-client\r\nClickHouse client version 20.5.4.40 (official build).\r\nConnecting to localhost:9000 as user default.\r\nConnected to ClickHouse server version 20.5.4 revision 54435.\r\n\r\n> create table test1(insid UInt64, insidvalue UInt64) ENGINE=MergeTree ORDER BY tuple();     \r\n> create table test2(insid UInt64, svalue String) ENGINE=MergeTree ORDER BY tuple();     \r\n\r\n> SELECT NULL AS svalue FROM test1 t1 LEFT JOIN (SELECT insid,svalue FROM test2) t2 ON t1.insid=t2.insid WHERE t2.svalue='test'\r\n\r\nCode: 47. DB::Exception: Received from localhost:9000. DB::Exception: Unknown identifier: svalue there are columns: insid.\r\n```\r\n\r\nWorkaround: change column alias in select to avoid name conflict:\r\n\r\n```\r\n> SELECT NULL AS _svalue FROM test1 t1 LEFT JOIN (SELECT insid,svalue FROM test2) t2 ON t1.insid=t2.insid WHERE t2.svalue='test'\r\n=> ok\r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14978/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14978/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14909","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14909/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14909/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14909/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/14909","id":703383186,"node_id":"MDU6SXNzdWU3MDMzODMxODY=","number":14909,"title":"Syntax error on 4.0E-323","user":{"login":"bgranvea","id":1116217,"node_id":"MDQ6VXNlcjExMTYyMTc=","avatar_url":"https://avatars.githubusercontent.com/u/1116217?v=4","gravatar_id":"","url":"https://api.github.com/users/bgranvea","html_url":"https://github.com/bgranvea","followers_url":"https://api.github.com/users/bgranvea/followers","following_url":"https://api.github.com/users/bgranvea/following{/other_user}","gists_url":"https://api.github.com/users/bgranvea/gists{/gist_id}","starred_url":"https://api.github.com/users/bgranvea/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bgranvea/subscriptions","organizations_url":"https://api.github.com/users/bgranvea/orgs","repos_url":"https://api.github.com/users/bgranvea/repos","events_url":"https://api.github.com/users/bgranvea/events{/privacy}","received_events_url":"https://api.github.com/users/bgranvea/received_events","type":"User","site_admin":false},"labels":[{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2020-09-17T08:33:46Z","updated_at":"2020-09-17T15:35:42Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**How to reproduce**\r\nI have issues while manipulating the value 4.0E-323. I can indirectly generate it with toFloat64:\r\n\r\n```\r\nroot@f549d5b3bca6:/# clickhouse-client\r\nClickHouse client version 20.5.4.40 (official build).\r\nConnecting to localhost:9000 as user default.\r\nConnected to ClickHouse server version 20.5.4 revision 54435.\r\n\r\nf549d5b3bca6 :) select 4.0E-323\r\n\r\nSyntax error: failed at position 8:\r\n[...]\r\n\r\nf549d5b3bca6 :) select toFloat64('4.0E-323')\r\n\r\nSELECT toFloat64('4.0E-323')\r\n\r\n┌─toFloat64('4.0E-323')─┐\r\n│                4e-323 │\r\n└───────────────────────┘\r\n```\r\n\r\nThe smallest number which doesn't generate a syntax error seems to be around 3.0E-308 which must correspond to the limit of 2.2250738585072014E-308 that I find on some pages for C++ double type.\r\n\r\nI'm confused by this limit: we manipulate 4.0E-323 in our Java programs with a native 8 bytes double type, so I was expecting the limit to be the same. And why does toFloat64('4.0E-323') seem to work?\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14909/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14909/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14896","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14896/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14896/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14896/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/14896","id":703259699,"node_id":"MDU6SXNzdWU3MDMyNTk2OTk=","number":14896,"title":"Three tables join spend time a lot of time","user":{"login":"chang0391","id":41037089,"node_id":"MDQ6VXNlcjQxMDM3MDg5","avatar_url":"https://avatars.githubusercontent.com/u/41037089?v=4","gravatar_id":"","url":"https://api.github.com/users/chang0391","html_url":"https://github.com/chang0391","followers_url":"https://api.github.com/users/chang0391/followers","following_url":"https://api.github.com/users/chang0391/following{/other_user}","gists_url":"https://api.github.com/users/chang0391/gists{/gist_id}","starred_url":"https://api.github.com/users/chang0391/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/chang0391/subscriptions","organizations_url":"https://api.github.com/users/chang0391/orgs","repos_url":"https://api.github.com/users/chang0391/repos","events_url":"https://api.github.com/users/chang0391/events{/privacy}","received_events_url":"https://api.github.com/users/chang0391/received_events","type":"User","site_admin":false},"labels":[{"id":756395244,"node_id":"MDU6TGFiZWw3NTYzOTUyNDQ=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/performance","name":"performance","color":"c2e0c6","default":false,"description":null},{"id":1357578153,"node_id":"MDU6TGFiZWwxMzU3NTc4MTUz","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-joins","name":"comp-joins","color":"b5bcff","default":false,"description":"JOINs"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":4,"created_at":"2020-09-17T04:42:36Z","updated_at":"2021-04-02T13:24:16Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"**Describe the bug**\r\n  I used two tables with join spend time 55 seconds ,but if the tables reach three one, spend a lot of time about 210 seconds\r\n**How to reproduce**\r\nnsj-op-shorturl2-205-062 :) select count(1) from rp_credit_sms_cmcc a join rp_credit_sms_cmcc b on a.rysecret=b.rysecret\r\nSELECT count(1)\r\nFROM rp_credit_sms_cmcc AS a\r\nINNER JOIN rp_credit_sms_cmcc AS b ON a.rysecret = b.rysecret\r\n┌──count(1)─┐\r\n│ 593111241 │\r\n└───────────┘\r\n1 rows in set. Elapsed: 55.816 sec. Processed 202.71 million rows, 9.12 GB (3.63 million rows/s., 163.43 MB/s.) \r\ncost 55 sec\r\nSELECT count(1)\r\nFROM rp_credit_sms_cmcc AS a\r\n┌───count(1)─┐\r\n│ 4702326615 │credit_sms_cmcc AS c ON b.rysecret = c.rysecret\r\n└────────────┘\r\n1 rows in set. Elapsed: 210.846 sec. Processed 304.07 million rows, 13.68 GB (1.44 million rows/s., 64.90 MB/s.) \r\ncost 210 sec\r\n**Expected behavior**\r\n We hope that CH can improve performace of multiple tables join ,because we have some tables which need join with three or four tables frequently","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14896/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14896/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14778","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14778/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14778/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14778/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/14778","id":700650271,"node_id":"MDU6SXNzdWU3MDA2NTAyNzE=","number":14778,"title":"arrayCompact for array with tuples","user":{"login":"mshpakov","id":33029350,"node_id":"MDQ6VXNlcjMzMDI5MzUw","avatar_url":"https://avatars.githubusercontent.com/u/33029350?v=4","gravatar_id":"","url":"https://api.github.com/users/mshpakov","html_url":"https://github.com/mshpakov","followers_url":"https://api.github.com/users/mshpakov/followers","following_url":"https://api.github.com/users/mshpakov/following{/other_user}","gists_url":"https://api.github.com/users/mshpakov/gists{/gist_id}","starred_url":"https://api.github.com/users/mshpakov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mshpakov/subscriptions","organizations_url":"https://api.github.com/users/mshpakov/orgs","repos_url":"https://api.github.com/users/mshpakov/repos","events_url":"https://api.github.com/users/mshpakov/events{/privacy}","received_events_url":"https://api.github.com/users/mshpakov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2020-09-13T21:20:15Z","updated_at":"2020-09-13T21:20:15Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Currently arrayCompact doesn't work with tuples like other array functions arraySort or arrayFilter.\r\nPlease consider adding such functionality to arrayCompact.\r\nWe need something like this... SELECT arrayCompact( (x,y) -> y, arr1, arr2) AS v\r\n\r\nCurrent behavior:\r\n`SELECT\r\n    [('a', 1), ('a', 2), ('c', 3), ('a', 2)] AS arr,\r\n    arrayCompact(x -> (x.1), arr) AS v,\r\n    [('a', 1), ('c', 3), ('a', 2)] AS expected_v\r\n`\r\n![изображение](https://user-images.githubusercontent.com/33029350/93028896-5fca5e00-f617-11ea-9d55-e0a5d3c36697.png)\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14778/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14778/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14774","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14774/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14774/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14774/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/14774","id":700528056,"node_id":"MDU6SXNzdWU3MDA1MjgwNTY=","number":14774,"title":"Alter delete via replicated MATERIALIZED view table is not working","user":{"login":"Awezome","id":3314334,"node_id":"MDQ6VXNlcjMzMTQzMzQ=","avatar_url":"https://avatars.githubusercontent.com/u/3314334?v=4","gravatar_id":"","url":"https://api.github.com/users/Awezome","html_url":"https://github.com/Awezome","followers_url":"https://api.github.com/users/Awezome/followers","following_url":"https://api.github.com/users/Awezome/following{/other_user}","gists_url":"https://api.github.com/users/Awezome/gists{/gist_id}","starred_url":"https://api.github.com/users/Awezome/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Awezome/subscriptions","organizations_url":"https://api.github.com/users/Awezome/orgs","repos_url":"https://api.github.com/users/Awezome/repos","events_url":"https://api.github.com/users/Awezome/events{/privacy}","received_events_url":"https://api.github.com/users/Awezome/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":5,"created_at":"2020-09-13T08:54:47Z","updated_at":"2020-09-16T01:50:39Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"**Describe the bug**\r\nwhen I want delete some data from MATERIALIZED view engined on ReplicatedAggregatingMergeTree \r\n```\r\nalter TABLE city_view ON cluster ch_cluster_all delete WHERE date=20200910\r\n```\r\nget errors:\r\n```\r\nAn error occurred before execution: Code: 371, e.displayText() = DB::Exception: Table `city_view` isn't replicated, but shard #1 is replicated according to its cluster definition (version 20.8.2.3 (official build))\r\n```\r\n\r\n**How to reproduce**\r\n* clickHouse server version 20.8.2.3 (official build)\r\n* metrika config\r\n```\r\n /etc/clickhouse-server/config.d/metrika.xml\r\n```\r\n```\r\n<?xml version=\"1.0\"?>\r\n<yandex>\r\n    <clickhouse_remote_servers>\r\n        <ch_cluster_all>\r\n            <shard>\r\n                <internal_replication>true</internal_replication>\r\n                <replica>\r\n                    <host>10.145.1.1</host>\r\n                    <port>9090</port>\r\n                    <user>default</user>\r\n                    <password></password>\r\n                </replica>\r\n                <replica>\r\n                    <host>10.145.1.2</host>\r\n                    <port>9090</port>\r\n                    <user>default</user>\r\n                    <password></password>\r\n                </replica>\r\n            </shard>\r\n        </ch_cluster_all>\r\n    </clickhouse_remote_servers>\r\n    <zookeeper-servers>\r\n        <node index=\"1\">\r\n            <host>10.145.1.3</host>\r\n            <port>2181</port>\r\n        </node>\r\n    </zookeeper-servers>\r\n    <macros>\r\n        <replica>test_replica</replica>\r\n    </macros>\r\n</yandex>\r\n```\r\n* Recurrence process\r\n\r\n1.create ReplicatedMergeTree table and it's ok\r\n```\r\nCREATE TABLE city ON cluster ch_cluster_all (date int, city String,number UInt32) \r\nENGINE = ReplicatedMergeTree('/clickhouse/tables/city','{replica}') PARTITION BY date ORDER BY(city);\r\n```\r\n2.create ReplicatedAggregatingMergeTree table and it's ok\r\n```\r\nCREATE MATERIALIZED VIEW city_view ON cluster ch_cluster_all \r\nENGINE = ReplicatedAggregatingMergeTree('/clickhouse/tables/city_view','{replica}') PARTITION BY date ORDER BY (city) \r\nAS SELECT date,city ,sumState(number) AS number FROM city GROUP BY  date,city ; \r\n```\r\n3.delete some rows from ReplicatedAggregatingMergeTree table and get errors\r\n```\r\nalter TABLE city_view ON cluster ch_cluster_all delete WHERE date=20200910; \r\n```\r\n**Error message and/or stacktrace**\r\n```\r\nAn error occurred before execution: Code: 371, e.displayText() = DB::Exception: Table `city_view` isn't replicated, but shard #1 is replicated according to its cluster definition (version 20.8.2.3 (official build))\r\n```\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14774/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14774/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14739","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14739/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14739/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14739/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/14739","id":699316144,"node_id":"MDU6SXNzdWU2OTkzMTYxNDQ=","number":14739,"title":"Field redefinition in subquery behaves inconsistently","user":{"login":"andrea-s","id":9706626,"node_id":"MDQ6VXNlcjk3MDY2MjY=","avatar_url":"https://avatars.githubusercontent.com/u/9706626?v=4","gravatar_id":"","url":"https://api.github.com/users/andrea-s","html_url":"https://github.com/andrea-s","followers_url":"https://api.github.com/users/andrea-s/followers","following_url":"https://api.github.com/users/andrea-s/following{/other_user}","gists_url":"https://api.github.com/users/andrea-s/gists{/gist_id}","starred_url":"https://api.github.com/users/andrea-s/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/andrea-s/subscriptions","organizations_url":"https://api.github.com/users/andrea-s/orgs","repos_url":"https://api.github.com/users/andrea-s/repos","events_url":"https://api.github.com/users/andrea-s/events{/privacy}","received_events_url":"https://api.github.com/users/andrea-s/received_events","type":"User","site_admin":false},"labels":[{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2020-09-11T13:25:01Z","updated_at":"2020-09-11T13:25:12Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"```\r\ndrop table if exists temp.test_subquery;\r\nCREATE TABLE temp.test_subquery\r\nENGINE = Memory AS\r\nSELECT 'base' AS my_field;\r\n\r\n-- query 1\r\nSELECT my_field\r\nFROM\r\n(\r\n    SELECT\r\n        *,\r\n        'redefined' AS my_field\r\n\tfrom temp.test_subquery\r\n);\r\n\r\n-- query 2\r\nSELECT my_field\r\nFROM\r\n(\r\n    SELECT\r\n        'redefined' AS my_field,\r\n        *\r\n\tfrom temp.test_subquery\r\n);\r\n\r\n-- query 3\r\nSELECT my_field\r\nFROM\r\n(\r\n    SELECT\r\n        *,\r\n        'redefined' AS my_field\r\n\tfrom (select * from temp.test_subquery)\r\n);\r\n```\r\n\r\nI would expect all queries to return \"redefined\" - but query 1 returns \"base\" instead. Version 20.8.2.3.\r\n\r\nI have checked on an older version (18.14.11) and all three queries return \"redefined\".","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14739/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14739/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14737","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14737/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14737/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14737/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/14737","id":699190598,"node_id":"MDU6SXNzdWU2OTkxOTA1OTg=","number":14737,"title":"How to check current value of merge_with_ttl_timeout","user":{"login":"ghuname","id":15207713,"node_id":"MDQ6VXNlcjE1MjA3NzEz","avatar_url":"https://avatars.githubusercontent.com/u/15207713?v=4","gravatar_id":"","url":"https://api.github.com/users/ghuname","html_url":"https://github.com/ghuname","followers_url":"https://api.github.com/users/ghuname/followers","following_url":"https://api.github.com/users/ghuname/following{/other_user}","gists_url":"https://api.github.com/users/ghuname/gists{/gist_id}","starred_url":"https://api.github.com/users/ghuname/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ghuname/subscriptions","organizations_url":"https://api.github.com/users/ghuname/orgs","repos_url":"https://api.github.com/users/ghuname/repos","events_url":"https://api.github.com/users/ghuname/events{/privacy}","received_events_url":"https://api.github.com/users/ghuname/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":5,"created_at":"2020-09-11T11:20:00Z","updated_at":"2021-07-29T10:22:11Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Hi,\r\n\r\nI have a problem with deleting old records. I know that I can set table's merge_with_ttl_timeout with:\r\nALTER TABLE [db.]table MODIFY SETTING merge_with_ttl_timeout = 3600\r\n\r\nbut I would like to check table's current value. I red in documentation that it is set as default to 1 day, but I would like to check it.\r\n\r\n1. How to check current value of merge_with_ttl_timeout?\r\n\r\nAt the moment I am inserting \"old\" records in a table that has modify setting merge_with_ttl_timeout set to  60 seconds.\r\n\r\n2. How to check whether ttl for table has been executed?\r\n\r\n3. If something went wrong, how to check it? What events in clickhouse log are relevant for ttl?\r\n\r\n\r\nFurthermore, it is unclear from which clickhouse version merge_with_ttl_timeout exists.\r\nOn https://github.com/ClickHouse/ClickHouse/blob/master/CHANGELOG.md I found mentioning of \"merge_with_ttl_timeout\" once in ClickHouse release v20.7.2.30-stable, 2020-08-31 as \"Corrected merge_with_ttl_timeout logic which did not work well when expiration affected more than one partition over one time interval. (Authored by @excitoon). #12982 (Alexander Kazakov).\"\r\n\r\nRegards.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14737/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14737/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14700","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14700/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14700/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14700/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/14700","id":697946098,"node_id":"MDU6SXNzdWU2OTc5NDYwOTg=","number":14700,"title":"Logical error: Block structure mismatch in Merge Storage: different types","user":{"login":"tavplubix","id":14847450,"node_id":"MDQ6VXNlcjE0ODQ3NDUw","avatar_url":"https://avatars.githubusercontent.com/u/14847450?v=4","gravatar_id":"","url":"https://api.github.com/users/tavplubix","html_url":"https://github.com/tavplubix","followers_url":"https://api.github.com/users/tavplubix/followers","following_url":"https://api.github.com/users/tavplubix/following{/other_user}","gists_url":"https://api.github.com/users/tavplubix/gists{/gist_id}","starred_url":"https://api.github.com/users/tavplubix/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tavplubix/subscriptions","organizations_url":"https://api.github.com/users/tavplubix/orgs","repos_url":"https://api.github.com/users/tavplubix/repos","events_url":"https://api.github.com/users/tavplubix/events{/privacy}","received_events_url":"https://api.github.com/users/tavplubix/received_events","type":"User","site_admin":false},"labels":[{"id":386401505,"node_id":"MDU6TGFiZWwzODY0MDE1MDU=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/bug","name":"bug","color":"ee0701","default":true,"description":"Confirmed user-visible misbehaviour in official release"},{"id":2104602822,"node_id":"MDU6TGFiZWwyMTA0NjAyODIy","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/fuzz","name":"fuzz","color":"abc4ea","default":false,"description":""}],"state":"open","locked":false,"assignee":{"login":"kssenii","id":54203879,"node_id":"MDQ6VXNlcjU0MjAzODc5","avatar_url":"https://avatars.githubusercontent.com/u/54203879?v=4","gravatar_id":"","url":"https://api.github.com/users/kssenii","html_url":"https://github.com/kssenii","followers_url":"https://api.github.com/users/kssenii/followers","following_url":"https://api.github.com/users/kssenii/following{/other_user}","gists_url":"https://api.github.com/users/kssenii/gists{/gist_id}","starred_url":"https://api.github.com/users/kssenii/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kssenii/subscriptions","organizations_url":"https://api.github.com/users/kssenii/orgs","repos_url":"https://api.github.com/users/kssenii/repos","events_url":"https://api.github.com/users/kssenii/events{/privacy}","received_events_url":"https://api.github.com/users/kssenii/received_events","type":"User","site_admin":false},"assignees":[{"login":"kssenii","id":54203879,"node_id":"MDQ6VXNlcjU0MjAzODc5","avatar_url":"https://avatars.githubusercontent.com/u/54203879?v=4","gravatar_id":"","url":"https://api.github.com/users/kssenii","html_url":"https://github.com/kssenii","followers_url":"https://api.github.com/users/kssenii/followers","following_url":"https://api.github.com/users/kssenii/following{/other_user}","gists_url":"https://api.github.com/users/kssenii/gists{/gist_id}","starred_url":"https://api.github.com/users/kssenii/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kssenii/subscriptions","organizations_url":"https://api.github.com/users/kssenii/orgs","repos_url":"https://api.github.com/users/kssenii/repos","events_url":"https://api.github.com/users/kssenii/events{/privacy}","received_events_url":"https://api.github.com/users/kssenii/received_events","type":"User","site_admin":false}],"milestone":null,"comments":3,"created_at":"2020-09-10T13:15:57Z","updated_at":"2021-07-15T09:00:24Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"```\r\nCREATE DATABASE fuzz;\r\nUSE fuzz;\r\n\r\nCREATE TABLE test_s64_local (date Date, value Int64) ENGINE = MergeTree(date, date, 8192);\r\nCREATE TABLE test_u64_local (date Date, value UInt64) ENGINE = MergeTree(date, date, 8192);\r\nCREATE TABLE test_s64_distributed AS test_s64_local ENGINE = Distributed('test_shard_localhost', currentDatabase(), test_s64_local, rand());\r\nCREATE TABLE test_u64_distributed AS test_u64_local ENGINE = Distributed('test_shard_localhost', currentDatabase(), test_u64_local, rand());\r\n\r\nSELECT * FROM merge(currentDatabase(), '') WHERE value = 1048575\r\n\r\n[linux-ubuntu-14-04-trusty] 2020.09.10 15:31:25.858301 [ 201 ] <Fatal> BaseDaemon: ########################################\r\n[linux-ubuntu-14-04-trusty] 2020.09.10 15:31:25.858807 [ 201 ] <Fatal> BaseDaemon: (version 20.10.1.4614, build id: B4A1B0622B6A7D03) (from thread 97) (query_id: 831c8b30-0013-4edb-a43b-abda6845f302) Received signal Aborted (6)\r\n[linux-ubuntu-14-04-trusty] 2020.09.10 15:31:25.859002 [ 201 ] <Fatal> BaseDaemon: \r\n[linux-ubuntu-14-04-trusty] 2020.09.10 15:31:25.859195 [ 201 ] <Fatal> BaseDaemon: Stack trace: 0x7f5573666f47 0x7f55736688b1 0x7f557365842a 0x7f55736584a2 0x2122ba21 0x2c130279 0x2c12f983 0x2c12db5e 0x2cbb95cd 0x2b9a6124 0x2b99aaf3 0x2b99445c 0x2b9939a6 0x2bc9e4e8 0x2bc9e7b6 0x2be59a66 0x2be58a2a 0x2c7a6a26 0x2c7adee8 0x304456bc 0x30445ecc 0x30587cd3 0x30584c0d 0x30583a98 0x7f5573e2c6db 0x7f5573749a3f\r\n[linux-ubuntu-14-04-trusty] 2020.09.10 15:31:25.859566 [ 201 ] <Fatal> BaseDaemon: 4. /build/glibc-2ORdQG/glibc-2.27/signal/../sysdeps/unix/sysv/linux/raise.c:51: raise @ 0x3ef47 in /usr/lib/debug/lib/x86_64-linux-gnu/libc-2.27.so\r\n[linux-ubuntu-14-04-trusty] 2020.09.10 15:31:25.859865 [ 201 ] <Fatal> BaseDaemon: 5. /build/glibc-2ORdQG/glibc-2.27/stdlib/abort.c:81: __GI_abort @ 0x408b1 in /usr/lib/debug/lib/x86_64-linux-gnu/libc-2.27.so\r\n[linux-ubuntu-14-04-trusty] 2020.09.10 15:31:25.860117 [ 201 ] <Fatal> BaseDaemon: 6. /build/glibc-2ORdQG/glibc-2.27/assert/assert.c:89: __assert_fail_base @ 0x3042a in /usr/lib/debug/lib/x86_64-linux-gnu/libc-2.27.so\r\n[linux-ubuntu-14-04-trusty] 2020.09.10 15:31:25.860575 [ 201 ] <Fatal> BaseDaemon: 7. ? @ 0x304a2 in /usr/lib/debug/lib/x86_64-linux-gnu/libc-2.27.so\r\n[linux-ubuntu-14-04-trusty] 2020.09.10 15:31:25.860948 [ 201 ] <Fatal> BaseDaemon: 8. /build/obj-x86_64-linux-gnu/../src/Common/Exception.cpp:48: DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int) @ 0x2122ba21 in /workspace/clickhouse\r\n[linux-ubuntu-14-04-trusty] 2020.09.10 15:31:25.884484 [ 201 ] <Fatal> BaseDaemon: 9. /build/obj-x86_64-linux-gnu/../src/Storages/StorageMerge.cpp:507: DB::StorageMerge::convertingSourceStream(DB::Block const&, std::__1::shared_ptr<DB::StorageInMemoryMetadata const> const&, DB::Context const&, std::__1::shared_ptr<DB::IAST>&, DB::Pipe&, DB::QueryProcessingStage::Enum) @ 0x2c130279 in /workspace/clickhouse\r\n[linux-ubuntu-14-04-trusty] 2020.09.10 15:31:25.907480 [ 201 ] <Fatal> BaseDaemon: 10. /build/obj-x86_64-linux-gnu/../src/Storages/StorageMerge.cpp:331: DB::StorageMerge::createSources(std::__1::shared_ptr<DB::StorageInMemoryMetadata const> const&, DB::SelectQueryInfo const&, DB::QueryProcessingStage::Enum const&, unsigned long, DB::Block const&, std::__1::tuple<std::__1::shared_ptr<DB::IStorage>, std::__1::shared_ptr<DB::RWLockImpl::LockHolderImpl>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > const&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > >&, std::__1::shared_ptr<DB::Context> const&, unsigned long, bool, bool) @ 0x2c12f983 in /workspace/clickhouse\r\n[linux-ubuntu-14-04-trusty] 2020.09.10 15:31:25.931791 [ 201 ] <Fatal> BaseDaemon: 11. /build/obj-x86_64-linux-gnu/../src/Storages/StorageMerge.cpp:234: DB::StorageMerge::read(std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&, std::__1::shared_ptr<DB::StorageInMemoryMetadata const> const&, DB::SelectQueryInfo const&, DB::Context const&, DB::QueryProcessingStage::Enum, unsigned long, unsigned int) @ 0x2c12db5e in /workspace/clickhouse\r\n[linux-ubuntu-14-04-trusty] 2020.09.10 15:31:25.962385 [ 201 ] <Fatal> BaseDaemon: 12. /build/obj-x86_64-linux-gnu/../src/Processors/QueryPlan/ReadFromStorageStep.cpp:39: DB::ReadFromStorageStep::ReadFromStorageStep(std::__1::shared_ptr<DB::RWLockImpl::LockHolderImpl>, std::__1::shared_ptr<DB::StorageInMemoryMetadata const>&, DB::SelectQueryOptions, std::__1::shared_ptr<DB::IStorage>, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&, DB::SelectQueryInfo const&, std::__1::shared_ptr<DB::Context>, DB::QueryProcessingStage::Enum, unsigned long, unsigned long) @ 0x2cbb95cd in /workspace/clickhouse\r\n[linux-ubuntu-14-04-trusty] 2020.09.10 15:31:25.981633 [ 201 ] <Fatal> BaseDaemon: 13. /build/obj-x86_64-linux-gnu/../contrib/libcxx/include/memory:3028: std::__1::__unique_if<DB::ReadFromStorageStep>::__unique_single std::__1::make_unique<DB::ReadFromStorageStep, std::__1::shared_ptr<DB::RWLockImpl::LockHolderImpl>&, std::__1::shared_ptr<DB::StorageInMemoryMetadata const>&, DB::SelectQueryOptions&, std::__1::shared_ptr<DB::IStorage>&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > >&, DB::SelectQueryInfo&, std::__1::shared_ptr<DB::Context>&, DB::QueryProcessingStage::Enum&, unsigned long&, unsigned long&>(std::__1::shared_ptr<DB::RWLockImpl::LockHolderImpl>&, std::__1::shared_ptr<DB::StorageInMemoryMetadata const>&, DB::SelectQueryOptions&, std::__1::shared_ptr<DB::IStorage>&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > >&, DB::SelectQueryInfo&, std::__1::shared_ptr<DB::Context>&, DB::QueryProcessingStage::Enum&, unsigned long&, unsigned long&) @ 0x2b9a6124 in /workspace/clickhouse\r\n[linux-ubuntu-14-04-trusty] 2020.09.10 15:31:26.000202 [ 201 ] <Fatal> BaseDaemon: 14. /build/obj-x86_64-linux-gnu/../src/Interpreters/InterpreterSelectQuery.cpp:1412: DB::InterpreterSelectQuery::executeFetchColumns(DB::QueryProcessingStage::Enum, DB::QueryPlan&, std::__1::shared_ptr<DB::PrewhereInfo> const&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&) @ 0x2b99aaf3 in /workspace/clickhouse\r\n[linux-ubuntu-14-04-trusty] 2020.09.10 15:31:26.019178 [ 201 ] <Fatal> BaseDaemon: 15. /build/obj-x86_64-linux-gnu/../src/Interpreters/InterpreterSelectQuery.cpp:810: DB::InterpreterSelectQuery::executeImpl(DB::QueryPlan&, std::__1::shared_ptr<DB::IBlockInputStream> const&, std::__1::optional<DB::Pipe>) @ 0x2b99445c in /workspace/clickhouse\r\n[linux-ubuntu-14-04-trusty] 2020.09.10 15:31:26.037936 [ 201 ] <Fatal> BaseDaemon: 16. /build/obj-x86_64-linux-gnu/../src/Interpreters/InterpreterSelectQuery.cpp:471: DB::InterpreterSelectQuery::buildQueryPlan(DB::QueryPlan&) @ 0x2b9939a6 in /workspace/clickhouse\r\n[linux-ubuntu-14-04-trusty] 2020.09.10 15:31:26.057048 [ 201 ] <Fatal> BaseDaemon: 17. /build/obj-x86_64-linux-gnu/../src/Interpreters/InterpreterSelectWithUnionQuery.cpp:183: DB::InterpreterSelectWithUnionQuery::buildQueryPlan(DB::QueryPlan&) @ 0x2bc9e4e8 in /workspace/clickhouse\r\n[linux-ubuntu-14-04-trusty] 2020.09.10 15:31:26.075531 [ 201 ] <Fatal> BaseDaemon: 18. /build/obj-x86_64-linux-gnu/../src/Interpreters/InterpreterSelectWithUnionQuery.cpp:206: DB::InterpreterSelectWithUnionQuery::execute() @ 0x2bc9e7b6 in /workspace/clickhouse\r\n[linux-ubuntu-14-04-trusty] 2020.09.10 15:31:26.096688 [ 201 ] <Fatal> BaseDaemon: 19. /build/obj-x86_64-linux-gnu/../src/Interpreters/executeQuery.cpp:392: DB::executeQueryImpl(char const*, char const*, DB::Context&, bool, DB::QueryProcessingStage::Enum, bool, DB::ReadBuffer*) @ 0x2be59a66 in /workspace/clickhouse\r\n[linux-ubuntu-14-04-trusty] 2020.09.10 15:31:26.119308 [ 201 ] <Fatal> BaseDaemon: 20. /build/obj-x86_64-linux-gnu/../src/Interpreters/executeQuery.cpp:679: DB::executeQuery(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, DB::Context&, bool, DB::QueryProcessingStage::Enum, bool) @ 0x2be58a2a in /workspace/clickhouse\r\n[linux-ubuntu-14-04-trusty] 2020.09.10 15:31:26.146743 [ 201 ] <Fatal> BaseDaemon: 21. /build/obj-x86_64-linux-gnu/../src/Server/TCPHandler.cpp:253: DB::TCPHandler::runImpl() @ 0x2c7a6a26 in /workspace/clickhouse\r\n[linux-ubuntu-14-04-trusty] 2020.09.10 15:31:26.174615 [ 201 ] <Fatal> BaseDaemon: 22. /build/obj-x86_64-linux-gnu/../src/Server/TCPHandler.cpp:1217: DB::TCPHandler::run() @ 0x2c7adee8 in /workspace/clickhouse\r\n[linux-ubuntu-14-04-trusty] 2020.09.10 15:31:26.208762 [ 201 ] <Fatal> BaseDaemon: 23. /build/obj-x86_64-linux-gnu/../contrib/poco/Net/src/TCPServerConnection.cpp:43: Poco::Net::TCPServerConnection::start() @ 0x304456bc in /workspace/clickhouse\r\n[linux-ubuntu-14-04-trusty] 2020.09.10 15:31:26.244270 [ 201 ] <Fatal> BaseDaemon: 24. /build/obj-x86_64-linux-gnu/../contrib/poco/Net/src/TCPServerDispatcher.cpp:114: Poco::Net::TCPServerDispatcher::run() @ 0x30445ecc in /workspace/clickhouse\r\n[linux-ubuntu-14-04-trusty] 2020.09.10 15:31:26.278996 [ 201 ] <Fatal> BaseDaemon: 25. /build/obj-x86_64-linux-gnu/../contrib/poco/Foundation/src/ThreadPool.cpp:199: Poco::PooledThread::run() @ 0x30587cd3 in /workspace/clickhouse\r\n[linux-ubuntu-14-04-trusty] 2020.09.10 15:31:26.314520 [ 201 ] <Fatal> BaseDaemon: 26. /build/obj-x86_64-linux-gnu/../contrib/poco/Foundation/src/Thread.cpp:56: Poco::(anonymous namespace)::RunnableHolder::run() @ 0x30584c0d in /workspace/clickhouse\r\n[linux-ubuntu-14-04-trusty] 2020.09.10 15:31:26.350760 [ 201 ] <Fatal> BaseDaemon: 27. /build/obj-x86_64-linux-gnu/../contrib/poco/Foundation/src/Thread_POSIX.cpp:345: Poco::ThreadImpl::runnableEntry(void*) @ 0x30583a98 in /workspace/clickhouse\r\n[linux-ubuntu-14-04-trusty] 2020.09.10 15:31:26.351062 [ 201 ] <Fatal> BaseDaemon: 28. start_thread @ 0x76db in /lib/x86_64-linux-gnu/libpthread-2.27.so\r\n[linux-ubuntu-14-04-trusty] 2020.09.10 15:31:26.351423 [ 201 ] <Fatal> BaseDaemon: 29. /build/glibc-2ORdQG/glibc-2.27/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:97: __clone @ 0x121a3f in /usr/lib/debug/lib/x86_64-linux-gnu/libc-2.27.so\r\nError on processing query 'SELECT * FROM merge(currentDatabase(), '') WHERE value = 1048575': Code: 32, e.displayText() = DB::Exception: Attempt to read after eof: while receiving packet from localhost:9000, Stack trace (when copying this message, always include the lines below):\r\n```\r\n\r\nhttps://clickhouse-test-reports.s3.yandex.net/14563/20b3823770f60feefcd73306141bc25875d87f9a/fuzzer/report.html#fail1","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14700/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14700/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14699","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14699/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14699/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14699/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/14699","id":697939505,"node_id":"MDU6SXNzdWU2OTc5Mzk1MDU=","number":14699,"title":"Missing columns related to ignore(*) pushed with enable_optimize_predicate_expression ","user":{"login":"filimonov","id":1549571,"node_id":"MDQ6VXNlcjE1NDk1NzE=","avatar_url":"https://avatars.githubusercontent.com/u/1549571?v=4","gravatar_id":"","url":"https://api.github.com/users/filimonov","html_url":"https://github.com/filimonov","followers_url":"https://api.github.com/users/filimonov/followers","following_url":"https://api.github.com/users/filimonov/following{/other_user}","gists_url":"https://api.github.com/users/filimonov/gists{/gist_id}","starred_url":"https://api.github.com/users/filimonov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/filimonov/subscriptions","organizations_url":"https://api.github.com/users/filimonov/orgs","repos_url":"https://api.github.com/users/filimonov/repos","events_url":"https://api.github.com/users/filimonov/events{/privacy}","received_events_url":"https://api.github.com/users/filimonov/received_events","type":"User","site_admin":false},"labels":[{"id":386401505,"node_id":"MDU6TGFiZWwzODY0MDE1MDU=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/bug","name":"bug","color":"ee0701","default":true,"description":"Confirmed user-visible misbehaviour in official release"},{"id":1365579236,"node_id":"MDU6TGFiZWwxMzY1NTc5MjM2","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/minor","name":"minor","color":"FFF8F8","default":false,"description":"Priority: minor"},{"id":2104602822,"node_id":"MDU6TGFiZWwyMTA0NjAyODIy","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/fuzz","name":"fuzz","color":"abc4ea","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2020-09-10T13:10:49Z","updated_at":"2021-01-06T02:15:27Z","closed_at":null,"author_association":"COLLABORATOR","active_lock_reason":null,"body":"```\r\nselect * from (select rand() from numbers(1)) where not ignore(*);\r\n```\r\n\r\n```\r\nReceived exception from server (version 20.9.1):\r\nCode: 47. DB::Exception: Received from localhost:9000. DB::Exception: Missing columns: 'rand()' while processing query: 'SELECT rand() FROM numbers(1) WHERE NOT ignore(`rand()`)', required columns: 'rand()', source columns: 'number'. Stack trace:\r\n\r\n0. /build/obj-x86_64-linux-gnu/../contrib/poco/Foundation/src/Exception.cpp:27: Poco::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int) @ 0x18bca170 in /usr/lib/debug/usr/bin/clickhouse\r\n1. /build/obj-x86_64-linux-gnu/../src/Common/Exception.cpp:37: DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int) @ 0xe612dad in /usr/lib/debug/usr/bin/clickhouse\r\n2. /build/obj-x86_64-linux-gnu/../contrib/libcxx/include/string:2134: DB::TreeRewriterResult::collectUsedColumns(std::__1::shared_ptr<DB::IAST> const&, bool) (.cold) @ 0x15b8fedb in /usr/lib/debug/usr/bin/clickhouse\r\n3. /build/obj-x86_64-linux-gnu/../src/Interpreters/TreeRewriter.cpp:619: DB::TreeRewriter::analyzeSelect(std::__1::shared_ptr<DB::IAST>&, DB::TreeRewriterResult&&, DB::SelectQueryOptions const&, std::__1::vector<DB::TableWithColumnNamesAndTypes, std::__1::allocator<DB::TableWithColumnNamesAndTypes> > const&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&, std::__1::shared_ptr<DB::TableJoin>) const @ 0x15b895ec in /usr/lib/debug/usr/bin/clickhouse\r\n4. /build/obj-x86_64-linux-gnu/../src/Interpreters/InterpreterSelectQuery.cpp:313: DB::InterpreterSelectQuery::InterpreterSelectQuery(std::__1::shared_ptr<DB::IAST> const&, DB::Context const&, std::__1::shared_ptr<DB::IBlockInputStream> const&, std::__1::optional<DB::Pipe>, std::__1::shared_ptr<DB::IStorage> const&, DB::SelectQueryOptions const&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&, std::__1::shared_ptr<DB::StorageInMemoryMetadata const> const&)::'lambda'(bool)::operator()(bool) const @ 0x158f5ed1 in /usr/lib/debug/usr/bin/clickhouse\r\n5. /build/obj-x86_64-linux-gnu/../src/Interpreters/InterpreterSelectQuery.cpp:409: DB::InterpreterSelectQuery::InterpreterSelectQuery(std::__1::shared_ptr<DB::IAST> const&, DB::Context const&, std::__1::shared_ptr<DB::IBlockInputStream> const&, std::__1::optional<DB::Pipe>, std::__1::shared_ptr<DB::IStorage> const&, DB::SelectQueryOptions const&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&, std::__1::shared_ptr<DB::StorageInMemoryMetadata const> const&) @ 0x158fe7a4 in /usr/lib/debug/usr/bin/clickhouse\r\n6. /build/obj-x86_64-linux-gnu/../src/Interpreters/InterpreterSelectQuery.cpp:147: DB::InterpreterSelectQuery::InterpreterSelectQuery(std::__1::shared_ptr<DB::IAST> const&, DB::Context const&, DB::SelectQueryOptions const&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&) @ 0x15900239 in /usr/lib/debug/usr/bin/clickhouse\r\n7. /build/obj-x86_64-linux-gnu/../contrib/libcxx/include/vector:1681: DB::InterpreterSelectWithUnionQuery::InterpreterSelectWithUnionQuery(std::__1::shared_ptr<DB::IAST> const&, DB::Context const&, DB::SelectQueryOptions const&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&) @ 0x15a78ed7 in /usr/lib/debug/usr/bin/clickhouse\r\n8. /build/obj-x86_64-linux-gnu/../contrib/libcxx/include/vector:461: DB::JoinedTables::makeLeftTableSubquery(DB::SelectQueryOptions const&) @ 0x15ac5494 in /usr/lib/debug/usr/bin/clickhouse\r\n9. /build/obj-x86_64-linux-gnu/../src/Interpreters/InterpreterSelectQuery.cpp:313: DB::InterpreterSelectQuery::InterpreterSelectQuery(std::__1::shared_ptr<DB::IAST> const&, DB::Context const&, std::__1::shared_ptr<DB::IBlockInputStream> const&, std::__1::optional<DB::Pipe>, std::__1::shared_ptr<DB::IStorage> const&, DB::SelectQueryOptions const&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&, std::__1::shared_ptr<DB::StorageInMemoryMetadata const> const&)::'lambda'(bool)::operator()(bool) const @ 0x158f6772 in /usr/lib/debug/usr/bin/clickhouse\r\n10. /build/obj-x86_64-linux-gnu/../src/Interpreters/InterpreterSelectQuery.cpp:409: DB::InterpreterSelectQuery::InterpreterSelectQuery(std::__1::shared_ptr<DB::IAST> const&, DB::Context const&, std::__1::shared_ptr<DB::IBlockInputStream> const&, std::__1::optional<DB::Pipe>, std::__1::shared_ptr<DB::IStorage> const&, DB::SelectQueryOptions const&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&, std::__1::shared_ptr<DB::StorageInMemoryMetadata const> const&) @ 0x158fe7a4 in /usr/lib/debug/usr/bin/clickhouse\r\n11. /build/obj-x86_64-linux-gnu/../src/Interpreters/InterpreterSelectQuery.cpp:147: DB::InterpreterSelectQuery::InterpreterSelectQuery(std::__1::shared_ptr<DB::IAST> const&, DB::Context const&, DB::SelectQueryOptions const&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&) @ 0x15900239 in /usr/lib/debug/usr/bin/clickhouse\r\n12. /build/obj-x86_64-linux-gnu/../contrib/libcxx/include/vector:1681: DB::InterpreterSelectWithUnionQuery::InterpreterSelectWithUnionQuery(std::__1::shared_ptr<DB::IAST> const&, DB::Context const&, DB::SelectQueryOptions const&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&) @ 0x15a78ed7 in /usr/lib/debug/usr/bin/clickhouse\r\n13. /build/obj-x86_64-linux-gnu/../contrib/libcxx/include/vector:461: DB::InterpreterFactory::get(std::__1::shared_ptr<DB::IAST>&, DB::Context&, DB::QueryProcessingStage::Enum) @ 0x15868f9f in /usr/lib/debug/usr/bin/clickhouse\r\n14. /build/obj-x86_64-linux-gnu/../contrib/libcxx/include/memory:2587: DB::executeQueryImpl(char const*, char const*, DB::Context&, bool, DB::QueryProcessingStage::Enum, bool, DB::ReadBuffer*) @ 0x15bf5918 in /usr/lib/debug/usr/bin/clickhouse\r\n15. /build/obj-x86_64-linux-gnu/../src/Interpreters/executeQuery.cpp:675: DB::executeQuery(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, DB::Context&, bool, DB::QueryProcessingStage::Enum, bool) @ 0x15bf7402 in /usr/lib/debug/usr/bin/clickhouse\r\n16. /build/obj-x86_64-linux-gnu/../src/Server/TCPHandler.cpp:253: DB::TCPHandler::runImpl() @ 0x1628f0d5 in /usr/lib/debug/usr/bin/clickhouse\r\n17. /build/obj-x86_64-linux-gnu/../src/Server/TCPHandler.cpp:1219: DB::TCPHandler::run() @ 0x1628fe40 in /usr/lib/debug/usr/bin/clickhouse\r\n18. /build/obj-x86_64-linux-gnu/../contrib/poco/Net/src/TCPServerConnection.cpp:57: Poco::Net::TCPServerConnection::start() @ 0x18ae7fdb in /usr/lib/debug/usr/bin/clickhouse\r\n19. /build/obj-x86_64-linux-gnu/../contrib/libcxx/include/atomic:856: Poco::Net::TCPServerDispatcher::run() @ 0x18ae846b in /usr/lib/debug/usr/bin/clickhouse\r\n20. /build/obj-x86_64-linux-gnu/../contrib/poco/Foundation/include/Poco/Mutex_POSIX.h:59: Poco::PooledThread::run() @ 0x18c66f46 in /usr/lib/debug/usr/bin/clickhouse\r\n21. /build/obj-x86_64-linux-gnu/../contrib/poco/Foundation/include/Poco/AutoPtr.h:223: Poco::ThreadImpl::runnableEntry(void*) @ 0x18c62340 in /usr/lib/debug/usr/bin/clickhouse\r\n22. start_thread @ 0x9609 in /lib/x86_64-linux-gnu/libpthread-2.31.so\r\n23. /build/glibc-YYA7BZ/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:97: __clone @ 0x122103 in /usr/lib/debug/lib/x86_64-linux-gnu/libc-2.31.so\r\n\r\n0 rows in set. Elapsed: 0.002 sec. \r\n```\r\n\r\nenable_optimize_predicate_expression = 0 resolves the issue. ","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14699/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14699/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14698","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14698/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14698/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14698/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/14698","id":697937142,"node_id":"MDU6SXNzdWU2OTc5MzcxNDI=","number":14698,"title":"Cannot perform a multi-line insert with clickhouse-client","user":{"login":"bgranvea","id":1116217,"node_id":"MDQ6VXNlcjExMTYyMTc=","avatar_url":"https://avatars.githubusercontent.com/u/1116217?v=4","gravatar_id":"","url":"https://api.github.com/users/bgranvea","html_url":"https://github.com/bgranvea","followers_url":"https://api.github.com/users/bgranvea/followers","following_url":"https://api.github.com/users/bgranvea/following{/other_user}","gists_url":"https://api.github.com/users/bgranvea/gists{/gist_id}","starred_url":"https://api.github.com/users/bgranvea/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bgranvea/subscriptions","organizations_url":"https://api.github.com/users/bgranvea/orgs","repos_url":"https://api.github.com/users/bgranvea/repos","events_url":"https://api.github.com/users/bgranvea/events{/privacy}","received_events_url":"https://api.github.com/users/bgranvea/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":5,"created_at":"2020-09-10T13:08:59Z","updated_at":"2020-09-11T07:45:38Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Describe the unexpected behaviour**\r\nException when executing a multi-line insert contained in a SQL file with clickhouse-client.\r\n\r\n**How to reproduce**\r\n\r\n```\r\n# clickhouse-client -n -m\r\nClickHouse client version 20.5.4.40 (official build).\r\nConnecting to localhost:9000 as user default.\r\nConnected to ClickHouse server version 20.5.4 revision 54435.\r\n\r\nchhost1 :) create table test (value Float64) ENGINE=MergeTree ORDER BY tuple();\r\nchhost1 :) insert into test values\r\n:-] (1),\r\n:-] (2);\r\n\r\nOk.\r\n\r\n# cat test.sql\r\ninsert into test values\r\n(1),\r\n(2);\r\n\r\n# clickhouse-client -n -m < test.sql\r\nCode: 62. DB::Exception: Syntax error: failed at position 2 (line 1, col 2): 2);\r\n\r\n. Expected one of: SELECT subquery, SELECT query, SELECT, list of elements, WITH, SELECT query, possibly with UNION, SELECT query, subquery, possibly with UNION\r\n```\r\n\r\nIt is very annoying because refactoring all the INSERT in my SQL script to single line statements would make them very hard to read for a human.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14698/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14698/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14694","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14694/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14694/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14694/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/14694","id":697821903,"node_id":"MDU6SXNzdWU2OTc4MjE5MDM=","number":14694,"title":"Add support for secondary index","user":{"login":"itzikiusa","id":37109688,"node_id":"MDQ6VXNlcjM3MTA5Njg4","avatar_url":"https://avatars.githubusercontent.com/u/37109688?v=4","gravatar_id":"","url":"https://api.github.com/users/itzikiusa","html_url":"https://github.com/itzikiusa","followers_url":"https://api.github.com/users/itzikiusa/followers","following_url":"https://api.github.com/users/itzikiusa/following{/other_user}","gists_url":"https://api.github.com/users/itzikiusa/gists{/gist_id}","starred_url":"https://api.github.com/users/itzikiusa/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/itzikiusa/subscriptions","organizations_url":"https://api.github.com/users/itzikiusa/orgs","repos_url":"https://api.github.com/users/itzikiusa/repos","events_url":"https://api.github.com/users/itzikiusa/events{/privacy}","received_events_url":"https://api.github.com/users/itzikiusa/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2020-09-10T11:38:08Z","updated_at":"2020-09-10T20:13:54Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"**Use case**\r\nI have a table which i need to query by 3 different column, which are not dependent on each other.\r\nwhen querying by the leading index, performance is less then 100 ms,\r\nwhen query by one of the secondary indexes response takes more then 3 seconds\r\n\r\n**Describe the solution you'd like**\r\nA way to add additional index to the table, which will allow us to query by another fields as well as the primary key\r\n\r\n**Describe alternatives you've considered**\r\nUse skipping indexes - improved performance in about 5 percent, still not ideal\r\nreplicated the table 3 times - use 3 different tables(with same data), only different primary keys - query is returned in under 100 ms, however data size has increased from 50GB to around 200GB\r\n\r\n**Additional context**\r\nthis is my main table, any suggestions on how to improve it will be helpful\r\n\r\n```CREATE TABLE example.transactions\r\n(\r\n  event_time DateTime,\r\n  frb Boolean,\r\n  is_test_account Boolean,\r\n  transaction_key String,\r\n  country LowCardinality(String),\r\n  type LowCardinality(String),\r\n  language LowCardinality(String),\r\n  platform LowCardinality(String),\r\n  currency LowCardinality(String),\r\n  game_id String,\r\n  casino_session_id String,\r\n  round_id String,\r\n  trans_id String,\r\n  account_id String,\r\n  casino_id Int32,\r\n  provider_id Int32,\r\n  amount Float64,\r\n  bonus_money Float64,\r\n  real_money Float64,\r\n  ggr Float64,\r\n  ggr_eur Float64,\r\n  ngr Float64,\r\n  ngr_eur Float64,\r\n  amount_eur Float64,\r\n  bonus_money_eur Float64\r\n\r\n)\r\nENGINE = MergeTree()\r\nPARTITION BY toYYYYMM(event_time)\r\nORDER BY (transaction_key, round_id,  event_time, trans_id, game_id, casino_id, type)\r\nSETTINGS index_granularity = 8192`\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14694/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14694/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14674","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14674/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14674/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14674/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/14674","id":697242267,"node_id":"MDU6SXNzdWU2OTcyNDIyNjc=","number":14674,"title":"RBAC Materialized Views - MODIFY QUERY requires less privileges than CREATE MATERIALIZED VIEW","user":{"login":"MyroTk","id":44327070,"node_id":"MDQ6VXNlcjQ0MzI3MDcw","avatar_url":"https://avatars.githubusercontent.com/u/44327070?v=4","gravatar_id":"","url":"https://api.github.com/users/MyroTk","html_url":"https://github.com/MyroTk","followers_url":"https://api.github.com/users/MyroTk/followers","following_url":"https://api.github.com/users/MyroTk/following{/other_user}","gists_url":"https://api.github.com/users/MyroTk/gists{/gist_id}","starred_url":"https://api.github.com/users/MyroTk/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/MyroTk/subscriptions","organizations_url":"https://api.github.com/users/MyroTk/orgs","repos_url":"https://api.github.com/users/MyroTk/repos","events_url":"https://api.github.com/users/MyroTk/events{/privacy}","received_events_url":"https://api.github.com/users/MyroTk/received_events","type":"User","site_admin":false},"labels":[{"id":386401505,"node_id":"MDU6TGFiZWwzODY0MDE1MDU=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/bug","name":"bug","color":"ee0701","default":true,"description":"Confirmed user-visible misbehaviour in official release"},{"id":2011606513,"node_id":"MDU6TGFiZWwyMDExNjA2NTEz","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-rbac","name":"comp-rbac","color":"b5bcff","default":false,"description":"Access control related"}],"state":"open","locked":false,"assignee":{"login":"vitlibar","id":45142681,"node_id":"MDQ6VXNlcjQ1MTQyNjgx","avatar_url":"https://avatars.githubusercontent.com/u/45142681?v=4","gravatar_id":"","url":"https://api.github.com/users/vitlibar","html_url":"https://github.com/vitlibar","followers_url":"https://api.github.com/users/vitlibar/followers","following_url":"https://api.github.com/users/vitlibar/following{/other_user}","gists_url":"https://api.github.com/users/vitlibar/gists{/gist_id}","starred_url":"https://api.github.com/users/vitlibar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vitlibar/subscriptions","organizations_url":"https://api.github.com/users/vitlibar/orgs","repos_url":"https://api.github.com/users/vitlibar/repos","events_url":"https://api.github.com/users/vitlibar/events{/privacy}","received_events_url":"https://api.github.com/users/vitlibar/received_events","type":"User","site_admin":false},"assignees":[{"login":"vitlibar","id":45142681,"node_id":"MDQ6VXNlcjQ1MTQyNjgx","avatar_url":"https://avatars.githubusercontent.com/u/45142681?v=4","gravatar_id":"","url":"https://api.github.com/users/vitlibar","html_url":"https://github.com/vitlibar","followers_url":"https://api.github.com/users/vitlibar/followers","following_url":"https://api.github.com/users/vitlibar/following{/other_user}","gists_url":"https://api.github.com/users/vitlibar/gists{/gist_id}","starred_url":"https://api.github.com/users/vitlibar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vitlibar/subscriptions","organizations_url":"https://api.github.com/users/vitlibar/orgs","repos_url":"https://api.github.com/users/vitlibar/repos","events_url":"https://api.github.com/users/vitlibar/events{/privacy}","received_events_url":"https://api.github.com/users/vitlibar/received_events","type":"User","site_admin":false}],"milestone":null,"comments":0,"created_at":"2020-09-09T23:43:10Z","updated_at":"2021-07-02T23:45:01Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Describe the bug**\r\nIn order to `CREATE MATERIALIZED VIEW` with a source table, the user needs `SELECT` privilege on that source table. When using `ALTER TABLE MODIFY QUERY`, the user is able to successfully execute the command without any `SELECT` privilege.\r\n\r\n**How to reproduce**\r\n* ClickHouse server version 20.9.1 revision 54439\r\n\r\n**Stacktrace**\r\n```\r\nClickHouse client version 20.9.1.4571 (official build).\r\nConnecting to localhost:9000 as user user0.\r\nConnected to ClickHouse server version 20.9.1 revision 54439.\"\r\n\r\nclicktest :) SET allow_experimental_alter_materialized_view_structure = 1\r\nSET allow_experimental_alter_materialized_view_structure = 1\r\nOk.\r\n0 rows in set. Elapsed: 0.002 sec.\r\n\r\nclicktest :) ALTER TABLE mat0 MODIFY QUERY SELECT * FROM table0\r\nALTER TABLE mat0\r\n    MODIFY QUERY\r\n    SELECT *\r\n    FROM table0\r\nOk.\r\n0 rows in set. Elapsed: 0.010 sec.\r\n\r\nclicktest :) q\r\nBye.\r\n\r\n# clickhouse-client\r\nClickHouse client version 20.9.1.4571 (official build).\r\nConnecting to localhost:9000 as user default.\r\nConnected to ClickHouse server version 20.9.1 revision 54439.\r\n\r\nclicktest :) show grants for user0\r\nSHOW GRANTS FOR user0\r\n┌─GRANTS FOR user0───────────────────────────────────────┐\r\n│ GRANT ALTER VIEW MODIFY QUERY ON default.mat0 TO user0 │\r\n└────────────────────────────────────────────────────────┘\r\n1 rows in set. Elapsed: 0.007 sec.\r\n\r\nclicktest :)\r\n```\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14674/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14674/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14634","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14634/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14634/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14634/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/14634","id":696884281,"node_id":"MDU6SXNzdWU2OTY4ODQyODE=","number":14634,"title":"now64() documentation | now with miliseconds","user":{"login":"valentinmk","id":12662946,"node_id":"MDQ6VXNlcjEyNjYyOTQ2","avatar_url":"https://avatars.githubusercontent.com/u/12662946?v=4","gravatar_id":"","url":"https://api.github.com/users/valentinmk","html_url":"https://github.com/valentinmk","followers_url":"https://api.github.com/users/valentinmk/followers","following_url":"https://api.github.com/users/valentinmk/following{/other_user}","gists_url":"https://api.github.com/users/valentinmk/gists{/gist_id}","starred_url":"https://api.github.com/users/valentinmk/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/valentinmk/subscriptions","organizations_url":"https://api.github.com/users/valentinmk/orgs","repos_url":"https://api.github.com/users/valentinmk/repos","events_url":"https://api.github.com/users/valentinmk/events{/privacy}","received_events_url":"https://api.github.com/users/valentinmk/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2020-09-09T14:52:23Z","updated_at":"2021-02-05T09:31:09Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"(you don't have to strictly follow this form)\r\n\r\n**Describe the issue**\r\nNo documentation at all\r\n\r\n**Additional context**\r\nGot answer  at clickhouse_ru telegram chanel\r\n`now64()` return `DateTime64(3)` type value of current time with miliseconds and equals to call of `now64(3)` \r\n\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14634/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14634/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14567","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14567/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14567/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14567/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/14567","id":695520099,"node_id":"MDU6SXNzdWU2OTU1MjAwOTk=","number":14567,"title":"Bad comparison of IPv6 to String: toIPv6('::1') != '::1'","user":{"login":"akuzm","id":36882414,"node_id":"MDQ6VXNlcjM2ODgyNDE0","avatar_url":"https://avatars.githubusercontent.com/u/36882414?v=4","gravatar_id":"","url":"https://api.github.com/users/akuzm","html_url":"https://github.com/akuzm","followers_url":"https://api.github.com/users/akuzm/followers","following_url":"https://api.github.com/users/akuzm/following{/other_user}","gists_url":"https://api.github.com/users/akuzm/gists{/gist_id}","starred_url":"https://api.github.com/users/akuzm/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/akuzm/subscriptions","organizations_url":"https://api.github.com/users/akuzm/orgs","repos_url":"https://api.github.com/users/akuzm/repos","events_url":"https://api.github.com/users/akuzm/events{/privacy}","received_events_url":"https://api.github.com/users/akuzm/received_events","type":"User","site_admin":false},"labels":[{"id":386401505,"node_id":"MDU6TGFiZWwzODY0MDE1MDU=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/bug","name":"bug","color":"ee0701","default":true,"description":"Confirmed user-visible misbehaviour in official release"},{"id":1507867504,"node_id":"MDU6TGFiZWwxNTA3ODY3NTA0","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/st-hold","name":"st-hold","color":"e5b890","default":false,"description":"We've paused the work on issue for some reason"}],"state":"open","locked":false,"assignee":{"login":"Enmk","id":1110183,"node_id":"MDQ6VXNlcjExMTAxODM=","avatar_url":"https://avatars.githubusercontent.com/u/1110183?v=4","gravatar_id":"","url":"https://api.github.com/users/Enmk","html_url":"https://github.com/Enmk","followers_url":"https://api.github.com/users/Enmk/followers","following_url":"https://api.github.com/users/Enmk/following{/other_user}","gists_url":"https://api.github.com/users/Enmk/gists{/gist_id}","starred_url":"https://api.github.com/users/Enmk/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Enmk/subscriptions","organizations_url":"https://api.github.com/users/Enmk/orgs","repos_url":"https://api.github.com/users/Enmk/repos","events_url":"https://api.github.com/users/Enmk/events{/privacy}","received_events_url":"https://api.github.com/users/Enmk/received_events","type":"User","site_admin":false},"assignees":[{"login":"Enmk","id":1110183,"node_id":"MDQ6VXNlcjExMTAxODM=","avatar_url":"https://avatars.githubusercontent.com/u/1110183?v=4","gravatar_id":"","url":"https://api.github.com/users/Enmk","html_url":"https://github.com/Enmk","followers_url":"https://api.github.com/users/Enmk/followers","following_url":"https://api.github.com/users/Enmk/following{/other_user}","gists_url":"https://api.github.com/users/Enmk/gists{/gist_id}","starred_url":"https://api.github.com/users/Enmk/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Enmk/subscriptions","organizations_url":"https://api.github.com/users/Enmk/orgs","repos_url":"https://api.github.com/users/Enmk/repos","events_url":"https://api.github.com/users/Enmk/events{/privacy}","received_events_url":"https://api.github.com/users/Enmk/received_events","type":"User","site_admin":false}],"milestone":null,"comments":4,"created_at":"2020-09-08T03:40:00Z","updated_at":"2021-09-26T01:12:43Z","closed_at":null,"author_association":"COLLABORATOR","active_lock_reason":null,"body":"```\r\n:) select toIPv6('::1') = '::1'\r\n\r\n┌─equals(toIPv6('::1'), '::1')─┐\r\n│                            0 │\r\n└──────────────────────────────┘\r\n```\r\n\r\nNot sure what's going on. It does some implicit cast, but somehow casts to a wrong type? I would expect an error about implicit cast since we don't do them often, or at least that they compare as equal.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14567/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14567/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14542","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14542/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14542/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14542/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/14542","id":695060624,"node_id":"MDU6SXNzdWU2OTUwNjA2MjQ=","number":14542,"title":"whey IN  is slower than GLOBAL IN  with subquery ","user":{"login":"yancheng44","id":24712421,"node_id":"MDQ6VXNlcjI0NzEyNDIx","avatar_url":"https://avatars.githubusercontent.com/u/24712421?v=4","gravatar_id":"","url":"https://api.github.com/users/yancheng44","html_url":"https://github.com/yancheng44","followers_url":"https://api.github.com/users/yancheng44/followers","following_url":"https://api.github.com/users/yancheng44/following{/other_user}","gists_url":"https://api.github.com/users/yancheng44/gists{/gist_id}","starred_url":"https://api.github.com/users/yancheng44/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yancheng44/subscriptions","organizations_url":"https://api.github.com/users/yancheng44/orgs","repos_url":"https://api.github.com/users/yancheng44/repos","events_url":"https://api.github.com/users/yancheng44/events{/privacy}","received_events_url":"https://api.github.com/users/yancheng44/received_events","type":"User","site_admin":false},"labels":[{"id":756395244,"node_id":"MDU6TGFiZWw3NTYzOTUyNDQ=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/performance","name":"performance","color":"c2e0c6","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2020-09-07T12:39:59Z","updated_at":"2020-09-07T12:39:59Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"hello team,\r\n\r\nI am using the  in/global in with subquery  and met some problem.\r\n\r\nMy question is why in  is slower than global in.  Actually I want use the (local)  in clause in clickhouse clusters. \r\n\r\nBelow is the information:\r\n\r\nclickhouse version:  20.3.12.112\r\n\r\nSql trace log:  \r\n\r\nSELECT count(user_id)\r\nFROM stage.dm_push_soc_user_second_category_day_cyan1\r\nWHERE (first_category_name = '游戏') AND (second_category_name = '手游') AND (user_id IN\r\n(\r\n    SELECT user_id\r\n    FROM stage.dm_user_crowd_metrics_day_cyan1 AS a\r\n    WHERE (a.year_old >= 15) AND (a.year_old <= 20)\r\n))\r\n\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:09.881179 [ 44426 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Debug> executeQuery: (from [::1]:21545) SELECT count(user_id) FROM stage.dm_push_soc_user_second_category_day_cyan1 WHERE (first_category_name = '游戏') AND (second_category_name = '手游') AND (user_id IN (SELECT user_id FROM stage.dm_user_crowd_metrics_day_cyan1 AS a WHERE (a.year_old >= 15) AND (a.year_old <= 20)))\r\n↙ Progress: 0.00 rows, 0.00 B (0.00 rows/s., 0.00 B/s.) [hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:09.882204 [ 44426 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Debug> InterpreterSelectQuery: MergeTreeWhereOptimizer: condition \"(year_old >= 15) AND (year_old <= 20)\" moved to PREWHERE\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:09.882408 [ 44426 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> AccessRightsContext (default): Access granted: SELECT(user_id, year_old) ON stage.dm_user_crowd_metrics_day_cyan1\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:09.882581 [ 44426 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Debug> stage.dm_user_crowd_metrics_day_cyan1 (SelectExecutor): Key condition: unknown, unknown, and\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:09.882604 [ 44426 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Debug> stage.dm_user_crowd_metrics_day_cyan1 (SelectExecutor): MinMax index condition: unknown, unknown, and\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:09.882638 [ 44426 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Debug> stage.dm_user_crowd_metrics_day_cyan1 (SelectExecutor): Selected 3 parts by date, 3 parts by key, 27166 marks to read from 3 ranges\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:09.883056 [ 44426 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> stage.dm_user_crowd_metrics_day_cyan1 (SelectExecutor): Reading approx. 147231929 rows with 44 streams\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:09.885444 [ 44426 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:10.821837 [ 44426 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Debug> MemoryTracker: Current memory usage: 1.00 GiB.\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:12.540451 [ 44426 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> UnionBlockInputStream: Waiting for threads to finish\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:12.540515 [ 44426 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> UnionBlockInputStream: Waited for threads to finish\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:12.540584 [ 44426 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> UnionBlockInputStream: Waiting for threads to finish\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:12.540596 [ 44426 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> UnionBlockInputStream: Waited for threads to finish\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:12.541011 [ 44426 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Debug> InterpreterSelectQuery: MergeTreeWhereOptimizer: condition \"second_category_name = '手游'\" moved to PREWHERE\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:12.541896 [ 44426 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Debug> InterpreterSelectQuery: MergeTreeWhereOptimizer: condition \"(year_old >= 15) AND (year_old <= 20)\" moved to PREWHERE\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:12.542073 [ 44426 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> AccessRightsContext (default): Access granted: SELECT(user_id, year_old) ON stage.dm_user_crowd_metrics_day_cyan1\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:12.542242 [ 44426 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Debug> stage.dm_user_crowd_metrics_day_cyan1 (SelectExecutor): Key condition: unknown, unknown, and\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:12.542250 [ 44426 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Debug> stage.dm_user_crowd_metrics_day_cyan1 (SelectExecutor): MinMax index condition: unknown, unknown, and\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:12.542273 [ 44426 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Debug> stage.dm_user_crowd_metrics_day_cyan1 (SelectExecutor): Selected 3 parts by date, 3 parts by key, 27166 marks to read from 3 ranges\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:12.542732 [ 44426 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> stage.dm_user_crowd_metrics_day_cyan1 (SelectExecutor): Reading approx. 147231929 rows with 44 streams\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:12.545151 [ 44426 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:12.553034 [ 16674 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Debug> MemoryTracker: Current memory usage: 2.00 GiB.\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:13.858829 [ 44426 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Debug> MemoryTracker: Current memory usage: 3.28 GiB.\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:15.187455 [ 44426 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> UnionBlockInputStream: Waiting for threads to finish\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:15.187496 [ 44426 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> UnionBlockInputStream: Waited for threads to finish\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:15.187537 [ 44426 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> UnionBlockInputStream: Waiting for threads to finish\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:15.187549 [ 44426 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> UnionBlockInputStream: Waited for threads to finish\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:15.360084 [ 44426 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> AccessRightsContext (default): Access granted: SELECT(user_id, first_category_name, second_category_name) ON stage.dm_push_soc_user_second_category_day_cyan1\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.593051 [ 44426 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Debug> stage.dm_push_soc_user_second_category_day_cyan1 (SelectExecutor): Key condition: (column 1 in ['手游', '手游']), (column 0 in ['游戏', '游戏']), (column 3 in 15685165-element set), and, and, (column 1 in ['手游', '手游']), and\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.593089 [ 44426 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Debug> stage.dm_push_soc_user_second_category_day_cyan1 (SelectExecutor): MinMax index condition: unknown, unknown, unknown, and, and, unknown, and\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.599139 [ 44426 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Debug> stage.dm_push_soc_user_second_category_day_cyan1 (SelectExecutor): Selected 5 parts by date, 5 parts by key, 403 marks to read from 5 ranges\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.599309 [ 44426 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> stage.dm_push_soc_user_second_category_day_cyan1 (SelectExecutor): Reading approx. 3240193 rows with 17 streams\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.652982 [ 44426 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n┌─count(user_id)─┐\r\n│        1034459 │\r\n└────────────────┘\r\n← Progress: 0.00 rows, 0.00 B (0.00 rows/s., 0.00 B/s.) [hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.655266 [ 17160 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> AggregatingTransform: Aggregating\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.655294 [ 17160 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> Aggregator: Aggregation method: without_key\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.655555 [ 17160 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> AggregatingTransform: Aggregated. 199 to 1 rows (from 0.006 MiB) in 0.002 sec. (100655.169 rows/sec., 3.168 MiB/sec.)\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.657534 [ 17085 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> AggregatingTransform: Aggregating\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.657556 [ 17085 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> Aggregator: Aggregation method: without_key\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.657593 [ 16912 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> AggregatingTransform: Aggregating\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.657613 [ 16912 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> Aggregator: Aggregation method: without_key\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.657708 [ 17066 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> AggregatingTransform: Aggregating\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.657728 [ 17066 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> Aggregator: Aggregation method: without_key\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.658044 [ 16819 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> AggregatingTransform: Aggregating\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.658065 [ 16819 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> Aggregator: Aggregation method: without_key\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.658286 [ 44616 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> AggregatingTransform: Aggregating\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.658306 [ 16764 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> AggregatingTransform: Aggregating\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.658324 [ 44616 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> Aggregator: Aggregation method: without_key\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.658353 [ 44607 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> AggregatingTransform: Aggregating\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.658332 [ 16764 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> Aggregator: Aggregation method: without_key\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.658378 [ 44607 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> Aggregator: Aggregation method: without_key\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.658572 [ 44403 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> AggregatingTransform: Aggregating\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.658599 [ 44403 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> Aggregator: Aggregation method: without_key\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.658608 [ 17148 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> AggregatingTransform: Aggregating\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.658640 [ 17148 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> Aggregator: Aggregation method: without_key\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.658705 [ 16897 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> AggregatingTransform: Aggregating\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.658731 [ 16897 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> Aggregator: Aggregation method: without_key\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.658843 [ 17208 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> AggregatingTransform: Aggregating\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.658867 [ 17208 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> Aggregator: Aggregation method: without_key\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.658916 [ 16790 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> AggregatingTransform: Aggregating\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.658953 [ 16790 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> Aggregator: Aggregation method: without_key\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.659375 [ 17130 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> AggregatingTransform: Aggregating\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.659408 [ 17130 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> Aggregator: Aggregation method: without_key\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.659734 [ 16989 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> AggregatingTransform: Aggregating\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.659733 [ 44518 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> AggregatingTransform: Aggregating\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.659769 [ 16989 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> Aggregator: Aggregation method: without_key\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.659770 [ 44518 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> Aggregator: Aggregation method: without_key\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.660142 [ 17292 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> AggregatingTransform: Aggregating\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.660175 [ 17292 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> Aggregator: Aggregation method: without_key\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.684661 [ 16912 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> AggregatingTransform: Aggregated. 66943 to 1 rows (from 2.107 MiB) in 0.031 sec. (2153402.220 rows/sec., 67.770 MiB/sec.)\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.686219 [ 16764 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> AggregatingTransform: Aggregated. 51378 to 1 rows (from 1.617 MiB) in 0.033 sec. (1573452.080 rows/sec., 49.519 MiB/sec.)\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.687934 [ 17066 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> AggregatingTransform: Aggregated. 77322 to 1 rows (from 2.433 MiB) in 0.034 sec. (2249616.612 rows/sec., 70.798 MiB/sec.)\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.689159 [ 44616 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> AggregatingTransform: Aggregated. 78743 to 1 rows (from 2.478 MiB) in 0.036 sec. (2212064.394 rows/sec., 69.616 MiB/sec.)\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.689340 [ 44607 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> AggregatingTransform: Aggregated. 65389 to 1 rows (from 2.058 MiB) in 0.036 sec. (1828035.862 rows/sec., 57.531 MiB/sec.)\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.689323 [ 17085 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> AggregatingTransform: Aggregated. 54599 to 1 rows (from 1.718 MiB) in 0.036 sec. (1525889.552 rows/sec., 48.022 MiB/sec.)\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.689703 [ 17148 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> AggregatingTransform: Aggregated. 61161 to 1 rows (from 1.925 MiB) in 0.036 sec. (1692538.102 rows/sec., 53.266 MiB/sec.)\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.690755 [ 17208 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> AggregatingTransform: Aggregated. 82302 to 1 rows (from 2.590 MiB) in 0.037 sec. (2212362.262 rows/sec., 69.626 MiB/sec.)\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.690890 [ 17130 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> AggregatingTransform: Aggregated. 11251 to 1 rows (from 0.354 MiB) in 0.037 sec. (301299.145 rows/sec., 9.482 MiB/sec.)\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.690976 [ 44403 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> AggregatingTransform: Aggregated. 50878 to 1 rows (from 1.601 MiB) in 0.037 sec. (1359491.680 rows/sec., 42.785 MiB/sec.)\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.697888 [ 16897 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> AggregatingTransform: Aggregated. 72914 to 1 rows (from 2.295 MiB) in 0.044 sec. (1644497.429 rows/sec., 51.754 MiB/sec.)\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.698108 [ 16790 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> AggregatingTransform: Aggregated. 75322 to 1 rows (from 2.370 MiB) in 0.045 sec. (1690113.755 rows/sec., 53.190 MiB/sec.)\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.699481 [ 17292 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> AggregatingTransform: Aggregated. 55725 to 1 rows (from 1.754 MiB) in 0.046 sec. (1213608.699 rows/sec., 38.194 MiB/sec.)\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.700575 [ 16819 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> AggregatingTransform: Aggregated. 85999 to 1 rows (from 2.706 MiB) in 0.047 sec. (1828523.573 rows/sec., 57.546 MiB/sec.)\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.701738 [ 44518 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> AggregatingTransform: Aggregated. 59898 to 1 rows (from 1.885 MiB) in 0.048 sec. (1243640.482 rows/sec., 39.139 MiB/sec.)\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.712857 [ 16989 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> AggregatingTransform: Aggregated. 84436 to 1 rows (from 2.657 MiB) in 0.059 sec. (1423992.911 rows/sec., 44.815 MiB/sec.)\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.712878 [ 16989 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Trace> Aggregator: Merging aggregated data\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.713529 [ 44426 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Information> executeQuery: Read 3240193 rows, 193.90 MiB in 7.832 sec., 413695 rows/sec., 24.76 MiB/sec.\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:26:17.713559 [ 44426 ] {03ce4627-d502-4d46-a2cf-6ae72cfd1b1f} <Debug> MemoryTracker: Peak memory usage (for query): 3.75 GiB.\r\n\r\n1 rows in set. Elapsed: 7.834 sec. Processed 3.24 million rows, 203.31 MB (413.63 thousand rows/s., 25.95 MB/s.)\r\n\r\n\r\n\r\nsql 2 :\r\n\r\nSELECT count(user_id)\r\nFROM stage.dm_push_soc_user_second_category_day_cyan1\r\nWHERE (first_category_name = '游戏') AND (second_category_name = '手游') AND (user_id GLOBAL IN\r\n(\r\n    SELECT user_id\r\n    FROM stage.dm_user_crowd_metrics_day_cyan1 AS a\r\n    WHERE (a.year_old >= 15) AND (a.year_old <= 20)\r\n))\r\n\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:26.492450 [ 44426 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Debug> executeQuery: (from [::1]:21545) SELECT count(user_id) FROM stage.dm_push_soc_user_second_category_day_cyan1 WHERE (first_category_name = '游戏') AND (second_category_name = '手游') AND (user_id GLOBAL IN (SELECT user_id FROM stage.dm_user_crowd_metrics_day_cyan1 AS a WHERE (a.year_old >= 15) AND (a.year_old <= 20)))\r\n↑ Progress: 0.00 rows, 0.00 B (0.00 rows/s., 0.00 B/s.) [hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:26.492752 [ 44426 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Debug> InterpreterSelectQuery: MergeTreeWhereOptimizer: condition \"second_category_name = '手游'\" moved to PREWHERE\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:26.506242 [ 44426 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Debug> InterpreterSelectQuery: MergeTreeWhereOptimizer: condition \"(year_old >= 15) AND (year_old <= 20)\" moved to PREWHERE\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:26.506461 [ 44426 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> AccessRightsContext (default): Access granted: SELECT(user_id, year_old) ON stage.dm_user_crowd_metrics_day_cyan1\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:26.507300 [ 44426 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Debug> InterpreterSelectQuery: MergeTreeWhereOptimizer: condition \"(year_old >= 15) AND (year_old <= 20)\" moved to PREWHERE\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:26.507472 [ 44426 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> AccessRightsContext (default): Access granted: SELECT(user_id, year_old) ON stage.dm_user_crowd_metrics_day_cyan1\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:26.507623 [ 44426 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> AccessRightsContext (default): Access granted: SELECT(user_id, first_category_name, second_category_name) ON stage.dm_push_soc_user_second_category_day_cyan1\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:26.507789 [ 44426 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Debug> stage.dm_push_soc_user_second_category_day_cyan1 (SelectExecutor): Key condition: (column 1 in ['手游', '手游']), (column 0 in ['游戏', '游戏']), unknown, and, and, (column 1 in ['手游', '手游']), and\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:26.507806 [ 44426 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Debug> stage.dm_push_soc_user_second_category_day_cyan1 (SelectExecutor): MinMax index condition: unknown, unknown, unknown, and, and, unknown, and\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:26.508335 [ 44426 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Debug> stage.dm_push_soc_user_second_category_day_cyan1 (SelectExecutor): Selected 5 parts by date, 5 parts by key, 403 marks to read from 5 ranges\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:26.508543 [ 44426 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> stage.dm_push_soc_user_second_category_day_cyan1 (SelectExecutor): Reading approx. 3240193 rows with 17 streams\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:26.508750 [ 44426 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n↗ Progress: 8.14 million rows, 333.60 MB (68.79 million rows/s., 2.82 GB/s.)  5%[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:26.509631 [ 44508 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> CreatingSetsBlockInputStream: Creating set.\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:26.510159 [ 44508 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Debug> stage.dm_user_crowd_metrics_day_cyan1 (SelectExecutor): Key condition: unknown, unknown, and\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:26.510175 [ 44508 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Debug> stage.dm_user_crowd_metrics_day_cyan1 (SelectExecutor): MinMax index condition: unknown, unknown, and\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:26.510193 [ 44508 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Debug> stage.dm_user_crowd_metrics_day_cyan1 (SelectExecutor): Selected 3 parts by date, 3 parts by key, 27166 marks to read from 3 ranges\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:26.511204 [ 44508 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> stage.dm_user_crowd_metrics_day_cyan1 (SelectExecutor): Reading approx. 147231929 rows with 44 streams\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:26.515345 [ 44508 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n→ Progress: 85.63 million rows, 3.51 GB (76.48 million rows/s., 3.14 GB/s.) ████████████████████████████████████████████████████████▊                                          57%[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:27.547711 [ 44508 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Debug> MemoryTracker: Current memory usage: 1.23 GiB.\r\n→ Progress: 150.03 million rows, 6.21 GB (67.55 million rows/s., 2.80 GB/s.) ████████████████████████████████████████████████████████████████████████████████████████████████▋ 98%[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:28.678956 [ 44508 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Debug> CreatingSetsBlockInputStream: Created. Set with 15685165 entries from 15685165 rows. In 2.165 sec.\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:28.681412 [ 16960 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> AggregatingTransform: Aggregating\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:28.681458 [ 16960 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> Aggregator: Aggregation method: without_key\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:28.681835 [ 16960 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> AggregatingTransform: Aggregated. 199 to 1 rows (from 0.006 MiB) in 2.173 sec. (91.597 rows/sec., 0.003 MiB/sec.)\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:28.682244 [ 44508 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> AggregatingTransform: Aggregating\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:28.682265 [ 44508 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> Aggregator: Aggregation method: without_key\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:28.683055 [ 16910 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> AggregatingTransform: Aggregating\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:28.683072 [ 17206 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> AggregatingTransform: Aggregating\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:28.683075 [ 16910 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> Aggregator: Aggregation method: without_key\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:28.683103 [ 17206 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> Aggregator: Aggregation method: without_key\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:28.683342 [ 16739 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> AggregatingTransform: Aggregating\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:28.683363 [ 16739 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> Aggregator: Aggregation method: without_key\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:28.683639 [ 17244 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> AggregatingTransform: Aggregating\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:28.683673 [ 17244 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> Aggregator: Aggregation method: without_key\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:28.683759 [ 44550 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> AggregatingTransform: Aggregating\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:28.683799 [ 44550 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> Aggregator: Aggregation method: without_key\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:28.683810 [ 16996 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> AggregatingTransform: Aggregating\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:28.683830 [ 16996 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> Aggregator: Aggregation method: without_key\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:28.683919 [ 44608 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> AggregatingTransform: Aggregating\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:28.683945 [ 44608 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> Aggregator: Aggregation method: without_key\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:28.684022 [ 17124 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> AggregatingTransform: Aggregating\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:28.684041 [ 17124 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> Aggregator: Aggregation method: without_key\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:28.684219 [ 44413 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> AggregatingTransform: Aggregating\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:28.684242 [ 44413 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> Aggregator: Aggregation method: without_key\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:28.684264 [ 17092 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> AggregatingTransform: Aggregating\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:28.684285 [ 17092 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> Aggregator: Aggregation method: without_key\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:28.684298 [ 44543 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> AggregatingTransform: Aggregating\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:28.684329 [ 44543 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> Aggregator: Aggregation method: without_key\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:28.684763 [ 44599 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> AggregatingTransform: Aggregating\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:28.684794 [ 44599 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> Aggregator: Aggregation method: without_key\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:28.685083 [ 44509 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> AggregatingTransform: Aggregating\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:28.685092 [ 17207 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> AggregatingTransform: Aggregating\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:28.685107 [ 44509 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> Aggregator: Aggregation method: without_key\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:28.685112 [ 17207 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> Aggregator: Aggregation method: without_key\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:28.685114 [ 44432 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> AggregatingTransform: Aggregating\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:28.685138 [ 44432 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> Aggregator: Aggregation method: without_key\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:28.708605 [ 17124 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> AggregatingTransform: Aggregated. 66943 to 1 rows (from 2.107 MiB) in 2.199 sec. (30437.940 rows/sec., 0.958 MiB/sec.)\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:28.708842 [ 16739 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> AggregatingTransform: Aggregated. 72490 to 1 rows (from 2.281 MiB) in 2.200 sec. (32956.253 rows/sec., 1.037 MiB/sec.)\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:28.709098 [ 44413 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> AggregatingTransform: Aggregated. 61190 to 1 rows (from 1.926 MiB) in 2.200 sec. (27815.663 rows/sec., 0.875 MiB/sec.)\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:28.710447 [ 16910 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> AggregatingTransform: Aggregated. 61161 to 1 rows (from 1.925 MiB) in 2.201 sec. (27785.564 rows/sec., 0.874 MiB/sec.)\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:28.710616 [ 17206 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> AggregatingTransform: Aggregated. 72468 to 1 rows (from 2.281 MiB) in 2.201 sec. (32919.416 rows/sec., 1.036 MiB/sec.)\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:28.711179 [ 17244 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> AggregatingTransform: Aggregated. 14105 to 1 rows (from 0.444 MiB) in 2.202 sec. (6405.755 rows/sec., 0.202 MiB/sec.)\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:28.712670 [ 16996 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> AggregatingTransform: Aggregated. 65389 to 1 rows (from 2.058 MiB) in 2.203 sec. (29676.408 rows/sec., 0.934 MiB/sec.)\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:28.712693 [ 44508 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> AggregatingTransform: Aggregated. 52473 to 1 rows (from 1.651 MiB) in 2.203 sec. (23813.959 rows/sec., 0.749 MiB/sec.)\r\n┌─count(user_id)─┐\r\n│        1034459 │\r\n└────────────────┘\r\n↘ Progress: 150.03 million rows, 6.21 GB (66.82 million rows/s., 2.77 GB/s.) ████████████████████████████████████████████████████████████████████████████████████████████████▋ 98%[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:28.713598 [ 17092 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> AggregatingTransform: Aggregated. 76569 to 1 rows (from 2.410 MiB) in 2.204 sec. (34735.740 rows/sec., 1.093 MiB/sec.)\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:28.714315 [ 44550 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> AggregatingTransform: Aggregated. 50878 to 1 rows (from 1.601 MiB) in 2.205 sec. (23073.222 rows/sec., 0.726 MiB/sec.)\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:28.722845 [ 44543 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> AggregatingTransform: Aggregated. 60025 to 1 rows (from 1.889 MiB) in 2.214 sec. (27116.752 rows/sec., 0.853 MiB/sec.)\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:28.725667 [ 44509 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> AggregatingTransform: Aggregated. 77322 to 1 rows (from 2.433 MiB) in 2.216 sec. (34886.117 rows/sec., 1.098 MiB/sec.)\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:28.726279 [ 44432 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> AggregatingTransform: Aggregated. 60743 to 1 rows (from 1.912 MiB) in 2.217 sec. (27398.594 rows/sec., 0.862 MiB/sec.)\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:28.726350 [ 44599 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> AggregatingTransform: Aggregated. 72914 to 1 rows (from 2.295 MiB) in 2.217 sec. (32887.067 rows/sec., 1.035 MiB/sec.)\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:28.734739 [ 17207 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> AggregatingTransform: Aggregated. 83591 to 1 rows (from 2.631 MiB) in 2.225 sec. (37561.114 rows/sec., 1.182 MiB/sec.)\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:28.736300 [ 44608 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> AggregatingTransform: Aggregated. 85999 to 1 rows (from 2.706 MiB) in 2.227 sec. (38615.510 rows/sec., 1.215 MiB/sec.)\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:28.736317 [ 44608 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Trace> Aggregator: Merging aggregated data\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:28.736766 [ 44426 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Information> executeQuery: Read 150472122 rows, 5.81 GiB in 2.244 sec., 67047493 rows/sec., 2.59 GiB/sec.\r\n[hw-sh2-prod-dt-etl-p1-ck02] 2020.09.07 20:29:28.736802 [ 44426 ] {2c52dce7-5d70-4fc3-a3c9-40d721f7bf34} <Debug> MemoryTracker: Peak memory usage (for query): 1.36 GiB.\r\n\r\n1 rows in set. Elapsed: 2.246 sec. Processed 150.47 million rows, 6.24 GB (67.01 million rows/s., 2.78 GB/s.)\r\n\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14542/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14542/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14511","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14511/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14511/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14511/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/14511","id":694030664,"node_id":"MDU6SXNzdWU2OTQwMzA2NjQ=","number":14511,"title":"users_config and/or access_control_path together with entries from user_directories may produce duplicate access info storages","user":{"login":"traceon","id":10261534,"node_id":"MDQ6VXNlcjEwMjYxNTM0","avatar_url":"https://avatars.githubusercontent.com/u/10261534?v=4","gravatar_id":"","url":"https://api.github.com/users/traceon","html_url":"https://github.com/traceon","followers_url":"https://api.github.com/users/traceon/followers","following_url":"https://api.github.com/users/traceon/following{/other_user}","gists_url":"https://api.github.com/users/traceon/gists{/gist_id}","starred_url":"https://api.github.com/users/traceon/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/traceon/subscriptions","organizations_url":"https://api.github.com/users/traceon/orgs","repos_url":"https://api.github.com/users/traceon/repos","events_url":"https://api.github.com/users/traceon/events{/privacy}","received_events_url":"https://api.github.com/users/traceon/received_events","type":"User","site_admin":false},"labels":[{"id":386401508,"node_id":"MDU6TGFiZWwzODY0MDE1MDg=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/help%20wanted","name":"help wanted","color":"128A0C","default":true,"description":null},{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""},{"id":2011606513,"node_id":"MDU6TGFiZWwyMDExNjA2NTEz","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-rbac","name":"comp-rbac","color":"b5bcff","default":false,"description":"Access control related"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":4,"created_at":"2020-09-05T08:07:18Z","updated_at":"2021-04-17T15:57:15Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"Discovered during testing of #12736\r\n\r\nWhen `config.xml` contains both (or one of) `users_config` and `access_control_path`, together with the corresponding entries in `user_directories`, and when the paths/values in those sections are the same, duplicate access storage are created in memory.\r\n\r\nThis leads to unexpected behavior, e.g., when a role is removed - it will be removed in one of `access_control_path`/`local_directory` duplicate and will be preserved in another, effectively making that role still available.\r\n\r\n`SHOW ROLES`, for example, before the deletion, will show duplicate roles.\r\n\r\nPotential solution would be avoiding creating duplicate storage when old and new corresponding config sections point to the same actual file/path.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14511/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14511/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14403","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14403/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14403/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14403/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/14403","id":690886584,"node_id":"MDU6SXNzdWU2OTA4ODY1ODQ=","number":14403,"title":"InActive part are not getting deleted in one of the MergeTree replicas","user":{"login":"shantam04","id":5487221,"node_id":"MDQ6VXNlcjU0ODcyMjE=","avatar_url":"https://avatars.githubusercontent.com/u/5487221?v=4","gravatar_id":"","url":"https://api.github.com/users/shantam04","html_url":"https://github.com/shantam04","followers_url":"https://api.github.com/users/shantam04/followers","following_url":"https://api.github.com/users/shantam04/following{/other_user}","gists_url":"https://api.github.com/users/shantam04/gists{/gist_id}","starred_url":"https://api.github.com/users/shantam04/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/shantam04/subscriptions","organizations_url":"https://api.github.com/users/shantam04/orgs","repos_url":"https://api.github.com/users/shantam04/repos","events_url":"https://api.github.com/users/shantam04/events{/privacy}","received_events_url":"https://api.github.com/users/shantam04/received_events","type":"User","site_admin":false},"labels":[{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":8,"created_at":"2020-09-02T09:58:10Z","updated_at":"2020-10-02T21:49:08Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"**Issue description**\r\nInActive part are not getting deleted in one of the merge tree replicas, even though I have setup old_parts_lifetime to 180 seconds inactive part are not getting deleted for hours and inactive part count is reaching in thousands. \r\nIs there any way to debug this further as to why inactive parts are getting deleted with this much delay ? \r\n\r\n**Merge tree part removal settings**\r\n```\r\nSELECT \r\n    name, \r\n    value, \r\n    changed\r\nFROM system.merge_tree_settings\r\nWHERE name IN ('old_parts_lifetime', 'max_part_removal_threads')\r\n\r\n┌─name─────────────────────┬─value─┬─changed─┐\r\n│ old_parts_lifetime       │ 180   │       1 │\r\n│ max_part_removal_threads │ 10    │       1 │\r\n└──────────────────────────┴───────┴─────────┘\r\n2 rows in set. Elapsed: 0.002 sec. \r\n```\r\n\r\n\r\n**Table create query**\r\n```\r\nCREATE TABLE \r\nevents.incident_task_events_new (`csIncident` String, `partnerVendor` Nullable(String), `lastActionTaken` Nullable(String), `formStatus` Nullable(String), `issueName` LowCardinality(String), `partnerVertical` Nullable(String), `createdOn` DateTime, `lastActionTakenBy` Nullable(String), `lastUpdatedOn` Nullable(DateTime), `formResponseDataValue4` Nullable(String), `partnerCourierPartner` Nullable(String), `mpsDetails` Nullable(String), `formCreatedOn` Nullable(String), `formResponseDataType1` Nullable(String), `partnerStatus` Nullable(String), `partnerCurrentPartner` Nullable(String), `partnerOrder_id` Nullable(String), `formResponseDataName1` Nullable(String), `firstActionDeadline` Nullable(DateTime), `lastActionTakenAt` Nullable(DateTime), `globalTrackingId` Nullable(String), `partnerAddress` Nullable(String), `formResponseDataValue2` Nullable(String), `allocationAssignedAgentOn` Nullable(DateTime), `partnerId` Nullable(String), `formTaskId` Nullable(String), `taskOrderItemIds` Nullable(String), `allocationLastSolvedBy` Nullable(String), `lastActionDeadline` Nullable(DateTime), `formResponseDataType2` Nullable(String), `formResponseDataValue1` Nullable(String), `partnerSeller_id` Nullable(String), `partnerHubName` Nullable(String), `taskOrderItemUnitIds` Nullable(String), `formResponseDataType3` Nullable(String), `taskSellerIds` Nullable(String), `lastUpdatedBy` Nullable(String), `formResponseDataName3` Nullable(String), `taskOrderIds` Nullable(String), `formRequestAgentId` Nullable(String), `formRequestDataName1` Nullable(String), `issueId` LowCardinality(String), `formRequestDataType1` Nullable(String), `taskStatus` LowCardinality(Nullable(String)), `taskIncidentId` String, `partnerType` LowCardinality(String), `partnerService` Nullable(String), `partnerEklIssueId` Nullable(String), `taskTrackingIds` Nullable(String), `csIncidentStatus` Nullable(String), `partnerPinCode` Nullable(String), `partnerModel` Nullable(String), `partnerCustomer_name` Nullable(String), `allocationAssignedTo` Nullable(String), `incidentPriority` Nullable(String), `formRequestDataValue1` Nullable(String), `partnerBrand` Nullable(String), `formRequestPartnerType` Nullable(String), `formResponseDataName4` Nullable(String), `partnerPhone` Nullable(String), `allocationQueueName` Nullable(String), `allocationAddedToQueueAt` Nullable(DateTime), `formRequestData` Nullable(String), `allocationReadyOrQueueChangeAt` Nullable(DateTime), `formResponseDataValue3` Nullable(String), `fromUpdatedOn` Nullable(String), `formResponseDataName2` Nullable(String), `formResponseDataType4` Nullable(String), `partnerEmail_id` Nullable(String), `eventTime` DateTime) \r\nENGINE = ReplicatedMergeTree('/clickhouse/tables/{shard}/events.incident_task_events_new', '{replica}') \r\nPARTITION BY toYYYYMMDD(eventTime) \r\nORDER BY (partnerType, createdOn) \r\nTTL eventTime + toIntervalMonth(1) \r\nSETTINGS index_granularity = 8192\r\n```\r\n\r\n\r\n**Part count**\r\n```\r\nSELECT \r\n    count(), \r\n    table, \r\n    active\r\nFROM system.parts\r\nWHERE table = 'incident_task_events_new'\r\nGROUP BY (database, table, active)\r\nORDER BY (active, table) ASC\r\n\r\n┌─count()─┬─table────────────────────┬─active─┐\r\n│    8209 │ incident_task_events_new │      0 │\r\n│      11 │ incident_task_events_new │      1 │\r\n└─────────┴──────────────────────────┴────────┘\r\n2 rows in set. Elapsed: 6.113 sec. Processed 8.22 thousand rows, 4.00 MB (1.34 thousand rows/s., 655.09 KB/s.) \r\n```\r\n\r\n\r\n**Last part removal time for the table**\r\nHere last parts where deleted few hours from the current time even though  old_parts_lifetime is 180 seconds, not sure whats causing this delay and will there be any unexpected issues on clickhouse sever that's running.\r\n```\r\nSELECT \r\n    partition, \r\n    name, \r\n    active, \r\n    remove_time, \r\n    rows, \r\n    toDateTime(now()) AS currentTime\r\nFROM system.parts\r\nWHERE (database = 'events') AND (table = 'incident_task_events_new') AND (active = 0)\r\nORDER BY remove_time ASC\r\nLIMIT 10\r\n\r\n┌─partition─┬─name────────────────────┬─active─┬─────────remove_time─┬─rows─┬─────────currentTime─┐\r\n│ 20200902  │ 20200902_13819_13819_0  │      0 │ 2020-09-02 09:38:45 │    1 │ 2020-09-02 14:01:23 │\r\n│ 20200902  │ 20200902_13821_13821_0  │      0 │ 2020-09-02 09:38:45 │    2 │ 2020-09-02 14:01:23 │\r\n│ 20200902  │ 20200902_13820_13820_0  │      0 │ 2020-09-02 09:38:45 │    4 │ 2020-09-02 14:01:23 │\r\n│ 20200902  │ 20200902_13823_13823_0  │      0 │ 2020-09-02 09:38:45 │    2 │ 2020-09-02 14:01:23 │\r\n│ 20200902  │ 20200902_13822_13822_0  │      0 │ 2020-09-02 09:38:45 │    1 │ 2020-09-02 14:01:23 │\r\n│ 20200902  │ 20200902_13605_13818_18 │      0 │ 2020-09-02 09:38:45 │ 1891 │ 2020-09-02 14:01:23 │\r\n│ 20200902  │ 20200902_13826_13826_0  │      0 │ 2020-09-02 09:38:56 │   13 │ 2020-09-02 14:01:23 │\r\n│ 20200902  │ 20200902_13825_13825_0  │      0 │ 2020-09-02 09:38:56 │    2 │ 2020-09-02 14:01:23 │\r\n│ 20200902  │ 20200902_13827_13827_0  │      0 │ 2020-09-02 09:38:56 │   80 │ 2020-09-02 14:01:23 │\r\n│ 20200902  │ 20200902_13824_13824_0  │      0 │ 2020-09-02 09:38:56 │    9 │ 2020-09-02 14:01:23 │\r\n└───────────┴─────────────────────────┴────────┴─────────────────────┴──────┴─────────────────────┘\r\n10 rows in set. Elapsed: 2.436 sec. Processed 8.29 thousand rows, 4.04 MB (3.40 thousand rows/s., 1.66 MB/s.) \r\n```\r\n\r\n**Cluster stats**\r\n```\r\nNodes - 3\r\nCores - 20 per node\r\nRam - 94G\r\n\r\nTop command state on the server :\r\n15:26:07 up 130 days,  5:52,  1 user,  load average: 27.06, 24.55, 24.13\r\nTasks: 334 total,   1 running, 333 sleeping,   0 stopped,   0 zombie\r\n%Cpu(s):  0.4 us,  0.2 sy,  0.0 ni, 94.4 id,  4.9 wa,  0.0 hi,  0.0 si,  0.0 st\r\nKiB Mem : 99009592 total,  1386144 free, 19366152 used, 78257296 buff/cache\r\nKiB Swap:        0 total,        0 free,        0 used. 78540672 avail Mem \r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14403/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14403/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14347","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14347/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14347/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14347/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/14347","id":690276949,"node_id":"MDU6SXNzdWU2OTAyNzY5NDk=","number":14347,"title":"No WITH ROLLUP description in the docs","user":{"login":"reflechant","id":5537648,"node_id":"MDQ6VXNlcjU1Mzc2NDg=","avatar_url":"https://avatars.githubusercontent.com/u/5537648?v=4","gravatar_id":"","url":"https://api.github.com/users/reflechant","html_url":"https://github.com/reflechant","followers_url":"https://api.github.com/users/reflechant/followers","following_url":"https://api.github.com/users/reflechant/following{/other_user}","gists_url":"https://api.github.com/users/reflechant/gists{/gist_id}","starred_url":"https://api.github.com/users/reflechant/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/reflechant/subscriptions","organizations_url":"https://api.github.com/users/reflechant/orgs","repos_url":"https://api.github.com/users/reflechant/repos","events_url":"https://api.github.com/users/reflechant/events{/privacy}","received_events_url":"https://api.github.com/users/reflechant/received_events","type":"User","site_admin":false},"labels":[{"id":785082162,"node_id":"MDU6TGFiZWw3ODUwODIxNjI=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-documentation","name":"comp-documentation","color":"b5bcff","default":false,"description":"Used to run automatic builds of the documentation"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":5,"created_at":"2020-09-01T16:17:18Z","updated_at":"2021-02-05T09:31:09Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"In version 18.12.13 Clickhouse got `WITH ROLLUP` support in `SELECT` queries. It's still not in the docs.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14347/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14347/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14266","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14266/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14266/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14266/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/14266","id":689095011,"node_id":"MDU6SXNzdWU2ODkwOTUwMTE=","number":14266,"title":"Calculating per second peak values after summing up individual values in a distributed and replicated table","user":{"login":"keerthana-kannan-ch","id":68999933,"node_id":"MDQ6VXNlcjY4OTk5OTMz","avatar_url":"https://avatars.githubusercontent.com/u/68999933?v=4","gravatar_id":"","url":"https://api.github.com/users/keerthana-kannan-ch","html_url":"https://github.com/keerthana-kannan-ch","followers_url":"https://api.github.com/users/keerthana-kannan-ch/followers","following_url":"https://api.github.com/users/keerthana-kannan-ch/following{/other_user}","gists_url":"https://api.github.com/users/keerthana-kannan-ch/gists{/gist_id}","starred_url":"https://api.github.com/users/keerthana-kannan-ch/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/keerthana-kannan-ch/subscriptions","organizations_url":"https://api.github.com/users/keerthana-kannan-ch/orgs","repos_url":"https://api.github.com/users/keerthana-kannan-ch/repos","events_url":"https://api.github.com/users/keerthana-kannan-ch/events{/privacy}","received_events_url":"https://api.github.com/users/keerthana-kannan-ch/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":8,"created_at":"2020-08-31T10:25:56Z","updated_at":"2020-09-21T11:09:04Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"I am currently using Clickhouse cluster (2 shards, 2 replicas) to read transaction logs from my server. The log contains fields like timestamp, bytes delivered, ttms, etc. The structure of my table is as below:\r\n\r\n```\r\nCREATE TABLE db.log_data_local ON CLUSTER '{cluster}' (\r\n  timestamp DateTime,\r\n  bytes UInt64,\r\n  /*lots of other fields */\r\n  ) ENGINE = ReplicatedMergeTree('/clickhouse/{cluster}/db/tables/logs/{shard}','{replica}')\r\nPARTITION BY toYYYYMMDD(timestamp)\r\nORDER BY timestamp\r\nTTL timestamp + INTERVAL 1 MONTH;\r\n\r\nCREATE TABLE db.log_data ON CLUSTER '{cluster}'\r\nAS cdn_data.http_access_data_local\r\nENGINE = Distributed('{cluster}','db','log_data_local',rand());\r\n```\r\n\r\nI am ingesting data from Kafka and using materialized view to populate this table. Now I need to calculate the peak throughput per second from this table. So basically I need to sum up the bytes field per second and then find the max value for a 5 minute period.\r\n\r\nI tried using ReplicatedAggregatingMergeTree with aggregate functions for the throughput, but the peak value I get is much less compared to the value I get when I directly query the raw table.\r\n\r\nThe problem is, while creating the material view to populate the peak values, querying the distributed table directly is not giving any results but if I query the local table then only partial data set is considered. I tried using an intermediary table to compute the per-second total and then to create the materialized but I faced the same issue.\r\n\r\nThis is the schema for my peaks table and the materialized view I am trying to create:\r\n\r\n```\r\nCREATE TABLE db.peak_metrics_5m_local ON CLUSTER '{cluster}'\r\n(\r\n  timestamp DateTime,\r\n  peak_throughput AggregateFunction(max,UInt64),\r\n)\r\nENGINE=ReplicatedAggregatingMergeTree('/clickhouse/{cluster}/db/tables/peak_metrics_5m_local/{shard}','{replica}')\r\nPARTITION BY toYYYYMMDD(timestamp)\r\nORDER BY (timestamp)\r\nTTL timestamp + toIntervalDay(90);\r\n\r\n\r\nCREATE TABLE db.peak_metrics_5m ON CLUSTER '{cluster}'\r\nAS cdn_data.peak_metrics_5m_local\r\nENGINE = Distributed('{cluster}','db','peak_metrics_5m_local',rand());\r\n\r\nCREATE MATERIALIZED VIEW db.peak_metrics_5m_mv ON CLUSTER '{cluster}'\r\nTO db.peak_metrics_5m_local\r\nAS SELECT\r\n        toStartOfFiveMinute(timestamp) as timestamp,\r\n        maxState(bytes)*8 as peak_throughput,\r\n    FROM (\r\n        SELECT \r\n            timestamp,\r\n            sum(bytes) as bytes,\r\n        FROM db.log_data_local\r\n        GROUP BY timestamp\r\n    )\r\n    GROUP BY timestamp;\r\n```\r\nPlease help me out with a solution to this.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14266/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14266/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14200","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14200/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14200/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14200/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/14200","id":687622535,"node_id":"MDU6SXNzdWU2ODc2MjI1MzU=","number":14200,"title":"Secondary index performance expectation","user":{"login":"iameugenejo","id":1054824,"node_id":"MDQ6VXNlcjEwNTQ4MjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1054824?v=4","gravatar_id":"","url":"https://api.github.com/users/iameugenejo","html_url":"https://github.com/iameugenejo","followers_url":"https://api.github.com/users/iameugenejo/followers","following_url":"https://api.github.com/users/iameugenejo/following{/other_user}","gists_url":"https://api.github.com/users/iameugenejo/gists{/gist_id}","starred_url":"https://api.github.com/users/iameugenejo/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/iameugenejo/subscriptions","organizations_url":"https://api.github.com/users/iameugenejo/orgs","repos_url":"https://api.github.com/users/iameugenejo/repos","events_url":"https://api.github.com/users/iameugenejo/events{/privacy}","received_events_url":"https://api.github.com/users/iameugenejo/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""},{"id":1357507723,"node_id":"MDU6TGFiZWwxMzU3NTA3NzIz","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-skipidx","name":"comp-skipidx","color":"b5bcff","default":false,"description":"Data skipping indices"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2020-08-28T00:21:17Z","updated_at":"2020-11-25T09:14:34Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Hello,\r\n\r\nI'm testing out the secondary index feature, and I'd like to know what to expect.\r\n\r\nI have this Replicated Materialized View (obfuscated irrelevant field names) - \r\n```sql\r\nCREATE MATERIALIZED VIEW sample_1d.logs\r\n(\r\n    `a` UInt64 DEFAULT CAST(0, 'UInt64'),\r\n    `b` UInt64 DEFAULT CAST(0, 'UInt64'),\r\n    `c` UInt64,\r\n    `d` LowCardinality(String),\r\n    `e` UInt8 DEFAULT 1,\r\n    `f` Date DEFAULT toDate(toStartOfDay(timestamp)),\r\n    `timestamp` DateTime,\r\n    `partition_code` String,\r\n    `h` LowCardinality(String),\r\n    `i` LowCardinality(String) DEFAULT CAST('', 'LowCardinality(String)'),\r\n    `j` LowCardinality(String),\r\n    `k` LowCardinality(String),\r\n    `l` LowCardinality(String) DEFAULT CAST('', 'LowCardinality(String)'),\r\n    `m` LowCardinality(String),\r\n    `n` UInt32,\r\n    `o` LowCardinality(String),\r\n    `p` String,\r\n    `q` String,\r\n    `r` String,\r\n    `user_agent` LowCardinality(String),\r\n    `s` LowCardinality(String) DEFAULT CAST('', 'LowCardinality(String)'),\r\n    `asn` UInt32 DEFAULT 0,\r\n    `as_org` LowCardinality(String) DEFAULT CAST('', 'LowCardinality(String)'),\r\n    `isp` LowCardinality(String) DEFAULT CAST('', 'LowCardinality(String)'),\r\n    `region_name` LowCardinality(String) DEFAULT CAST('', 'LowCardinality(String)'),\r\n    `city_name` LowCardinality(String) DEFAULT CAST('', 'LowCardinality(String)'),\r\n    `t` String,\r\n    `u` String,\r\n    `v` String,\r\n    `cnt` UInt64\r\n)\r\nENGINE = ReplicatedSummingMergeTree('/clickhouse/tables/{layer}-{shard}/sample_1d.logs', '{replica}')\r\nPARTITION BY partition_code\r\nORDER BY (a, b, c, d, e, f, timestamp, h, i, j, k, l, m, n, o, p, q, r, user_agent, s, asn, as_org, isp, region_name, city_name, t, u, v)\r\nTTL timestamp + toIntervalDay(94)\r\nSETTINGS index_granularity = 8192 AS\r\nSELECT\r\n    a,\r\n    b,\r\n    c,\r\n    d,\r\n    e,\r\n    f,\r\n    toStartOfDay(timestamp) AS timestamp,\r\n    substring(partition_code, 1, 10) AS partition_code,\r\n    h,\r\n    i,\r\n    j,\r\n    k,\r\n    l,\r\n    m,\r\n    n,\r\n    o,\r\n    p,\r\n    q,\r\n    r,\r\n    user_agent,\r\n    s,\r\n    asn,\r\n    as_org,\r\n    isp,\r\n    region_name,\r\n    city_name,\r\n    t,\r\n    u,\r\n    v,\r\n    sum(cnt) AS cnt\r\nFROM sample.logs\r\nGROUP BY\r\n    a,\r\n    n,\r\n    c,\r\n    d,\r\n    e,\r\n    f,\r\n    timestamp,\r\n    partition_code,\r\n    h,\r\n    i,\r\n    j,\r\n    k,\r\n    l,\r\n    m,\r\n    n,\r\n    o,\r\n    p,\r\n    q,\r\n    r,\r\n    user_agent,\r\n    s,\r\n    asn,\r\n    as_org,\r\n    isp,\r\n    region_name,\r\n    city_name,\r\n    t,\r\n    u,\r\n    v\r\n```\r\n\r\nI ran the following query before adding a secondary index - \r\n```sql\r\n     select timestamp, city_name, count() \r\n       from sample_1d.logs \r\n     where timestamp >= '2020-08-01 00:00:00' and timestamp < '2020-08-25 00:00:00' \r\n         and user_agent = '' \r\ngroup by timestamp, city_name \r\norder by timestamp\r\n```\r\n\r\nAnd produced the following stats -\r\n```bash\r\n1611707 rows in set. Elapsed: 7.318 sec. Processed 223.95 million rows, 2.00 GB (30.60 million rows/s., 273.84 MB/s.)\r\n```\r\n\r\nNumber of rows with `user_agent = \"\"` within the time range is 107393773\r\n\r\nTotal number of rows within the time range is 293180409\r\n\r\nAbout **63%** of the data within the range is what I'm filtering out with the query.\r\n\r\nI ran the following to add an index on `user_agent` - \r\n```sql\r\nALTER TABLE sample_1d.`.inner.logs` ADD INDEX idx_user_agent user_agent TYPE set(0) GRANULARITY 1\r\nOPTIMIZE TABLE sample_1d.`.inner.logs` FINAL\r\n```\r\n\r\nAfter that, I ran the same query and that produced the following stats -\r\n```\r\n1611707 rows in set. Elapsed: 6.084 sec. Processed 202.48 million rows, 1.80 GB (33.28 million rows/s., 295.56 MB/s.)\r\n```\r\n\r\nI'm only seeing 10% improvement with this index.\r\n\r\nWhat are the variables that cause such little improvement?\r\n\r\nIs it possible the optimization to finish creating the index didn't work?\r\n\r\nI tried `MATERIALIZE INDEX idx_user_agent` and it didn't do anything.\r\n\r\nThat command is even stuck in `system.mutations` for days, with error -\r\n```Code: 49, e.displayText() = DB::Exception: Part a83fd13795ab07f06fd6504529d5d912_2239_9526_32_14698 intersects previous part a83fd13795ab07f06fd6504529d5d912_2228_2243_3 (state Committed). It is a bug. (version 20.5.4.40 (official build))```\r\n\r\nI tried `MATERIALIZE INDEX idx_user_agent ON PARTITION {PARTITION_CODE}` for all the partitions the above query is supposed to touch, and all of those commands are stuck like above.\r\n\r\nPlease advise.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14200/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14200/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14178","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14178/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14178/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14178/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/14178","id":687208567,"node_id":"MDU6SXNzdWU2ODcyMDg1Njc=","number":14178,"title":"internal_replication auto","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":1507886722,"node_id":"MDU6TGFiZWwxNTA3ODg2NzIy","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/st-discussion","name":"st-discussion","color":"e5b890","default":false,"description":"The story requires discussion /research / expert help / design & decomposition before will be taken"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2020-08-27T12:37:15Z","updated_at":"2020-08-27T12:37:45Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"Distributed table has `internal_replication` setting for shard, see https://github.com/ClickHouse/ClickHouse/issues/5829\r\n\r\nIf it's true, the data will be sent to one of replicas assuming that the destination table will replicate it by itself.\r\nIf it's false, the table will be sent to all replicas assuming that the destination table is not replicated (imagine it as Distributed table doing replication by itself).\r\n\r\nLet's add the new option `auto` and make it default.\r\nWith this option, Distributed table will query one replica and if it has Replicated table engine, set `internal_replication` to true, otherwise to false.\r\n\r\nThe only question is where and how to query replica.\r\nVariants:\r\n- before first insert; then cache the value in memory forever (until server restart).","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14178/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14178/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14149","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14149/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14149/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14149/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/14149","id":686809404,"node_id":"MDU6SXNzdWU2ODY4MDk0MDQ=","number":14149,"title":"RBAC: User is able to SELECT FROM VIEW without full source table privilege.","user":{"login":"MyroTk","id":44327070,"node_id":"MDQ6VXNlcjQ0MzI3MDcw","avatar_url":"https://avatars.githubusercontent.com/u/44327070?v=4","gravatar_id":"","url":"https://api.github.com/users/MyroTk","html_url":"https://github.com/MyroTk","followers_url":"https://api.github.com/users/MyroTk/followers","following_url":"https://api.github.com/users/MyroTk/following{/other_user}","gists_url":"https://api.github.com/users/MyroTk/gists{/gist_id}","starred_url":"https://api.github.com/users/MyroTk/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/MyroTk/subscriptions","organizations_url":"https://api.github.com/users/MyroTk/orgs","repos_url":"https://api.github.com/users/MyroTk/repos","events_url":"https://api.github.com/users/MyroTk/events{/privacy}","received_events_url":"https://api.github.com/users/MyroTk/received_events","type":"User","site_admin":false},"labels":[{"id":386401505,"node_id":"MDU6TGFiZWwzODY0MDE1MDU=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/bug","name":"bug","color":"ee0701","default":true,"description":"Confirmed user-visible misbehaviour in official release"},{"id":2011606513,"node_id":"MDU6TGFiZWwyMDExNjA2NTEz","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-rbac","name":"comp-rbac","color":"b5bcff","default":false,"description":"Access control related"}],"state":"open","locked":false,"assignee":{"login":"vitlibar","id":45142681,"node_id":"MDQ6VXNlcjQ1MTQyNjgx","avatar_url":"https://avatars.githubusercontent.com/u/45142681?v=4","gravatar_id":"","url":"https://api.github.com/users/vitlibar","html_url":"https://github.com/vitlibar","followers_url":"https://api.github.com/users/vitlibar/followers","following_url":"https://api.github.com/users/vitlibar/following{/other_user}","gists_url":"https://api.github.com/users/vitlibar/gists{/gist_id}","starred_url":"https://api.github.com/users/vitlibar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vitlibar/subscriptions","organizations_url":"https://api.github.com/users/vitlibar/orgs","repos_url":"https://api.github.com/users/vitlibar/repos","events_url":"https://api.github.com/users/vitlibar/events{/privacy}","received_events_url":"https://api.github.com/users/vitlibar/received_events","type":"User","site_admin":false},"assignees":[{"login":"vitlibar","id":45142681,"node_id":"MDQ6VXNlcjQ1MTQyNjgx","avatar_url":"https://avatars.githubusercontent.com/u/45142681?v=4","gravatar_id":"","url":"https://api.github.com/users/vitlibar","html_url":"https://github.com/vitlibar","followers_url":"https://api.github.com/users/vitlibar/followers","following_url":"https://api.github.com/users/vitlibar/following{/other_user}","gists_url":"https://api.github.com/users/vitlibar/gists{/gist_id}","starred_url":"https://api.github.com/users/vitlibar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vitlibar/subscriptions","organizations_url":"https://api.github.com/users/vitlibar/orgs","repos_url":"https://api.github.com/users/vitlibar/repos","events_url":"https://api.github.com/users/vitlibar/events{/privacy}","received_events_url":"https://api.github.com/users/vitlibar/received_events","type":"User","site_admin":false}],"milestone":null,"comments":1,"created_at":"2020-08-26T23:35:12Z","updated_at":"2020-11-24T15:26:22Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Describe the bug**\r\nUser is able to SELECT FROM VIEW that includes a `JOIN` statement only having select privilege on one of the source tables.\r\n\r\n**How to reproduce**\r\n* ClickHouse server version 20.8.1 revision 54438.\r\n* `CREATE TABLE` statements for all tables involved\r\n```\r\nclicktest :) show create table table0\r\n\r\nSHOW CREATE TABLE table0\r\n\r\n┌─statement─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\r\n│ CREATE TABLE default.table0\r\n(\r\n    `d` Date,\r\n    `a` String,\r\n    `b` UInt8,\r\n    `x` String,\r\n    `y` Int8\r\n)\r\nENGINE = MergeTree()\r\nORDER BY d\r\nSETTINGS index_granularity = 8192 │\r\n└───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\r\n\r\n1 rows in set. Elapsed: 0.007 sec.\r\n\r\nclicktest :) show create table table1\r\n\r\nSHOW CREATE TABLE table1\r\n\r\n┌─statement─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\r\n│ CREATE TABLE default.table1\r\n(\r\n    `d` Date,\r\n    `a` String,\r\n    `b` UInt8,\r\n    `x` String,\r\n    `y` Int8\r\n)\r\nENGINE = MergeTree()\r\nORDER BY d\r\nSETTINGS index_granularity = 8192 │\r\n└───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\r\n\r\n1 rows in set. Elapsed: 0.005 sec.\r\n\r\nclicktest :) show create view0\r\n\r\nSHOW CREATE TABLE view0\r\n\r\n┌─statement──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\r\n│ CREATE VIEW default.view0\r\n(\r\n    `d` Date,\r\n    `a` String,\r\n    `b` UInt8,\r\n    `x` String,\r\n    `y` Int8,\r\n    `table1.a` String,\r\n    `table1.b` UInt8,\r\n    `table1.x` String,\r\n    `table1.y` Int8\r\n) AS\r\nSELECT *\r\nFROM default.table0\r\nINNER JOIN default.table1 USING (d) │\r\n└────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\r\n\r\n1 rows in set. Elapsed: 0.005 sec.\r\n```\r\n\r\n* Queries to run that lead to unexpected result\r\n```\r\nClickHouse client version 20.8.1.4447 (official build).\r\nConnecting to localhost:9000 as user user0.\r\nConnected to ClickHouse server version 20.8.1 revision 54438.\r\n\r\nclicktest :) select * from view0\r\n\r\nSELECT *\r\nFROM view0\r\n\r\nOk.\r\n\r\n0 rows in set. Elapsed: 0.017 sec.\r\n```\r\n\r\n**Expected behavior**\r\nUser should be unable to select from a view without full select privelege.\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14149/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14149/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14106","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14106/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14106/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14106/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/14106","id":686264733,"node_id":"MDU6SXNzdWU2ODYyNjQ3MzM=","number":14106,"title":"Reload interserver credentials dynamically","user":{"login":"johnskopis","id":1578524,"node_id":"MDQ6VXNlcjE1Nzg1MjQ=","avatar_url":"https://avatars.githubusercontent.com/u/1578524?v=4","gravatar_id":"","url":"https://api.github.com/users/johnskopis","html_url":"https://github.com/johnskopis","followers_url":"https://api.github.com/users/johnskopis/followers","following_url":"https://api.github.com/users/johnskopis/following{/other_user}","gists_url":"https://api.github.com/users/johnskopis/gists{/gist_id}","starred_url":"https://api.github.com/users/johnskopis/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/johnskopis/subscriptions","organizations_url":"https://api.github.com/users/johnskopis/orgs","repos_url":"https://api.github.com/users/johnskopis/repos","events_url":"https://api.github.com/users/johnskopis/events{/privacy}","received_events_url":"https://api.github.com/users/johnskopis/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2020-08-26T12:05:23Z","updated_at":"2020-08-26T12:05:23Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"(you don't have to strictly follow this form)\r\n\r\n**Use case**\r\nCurrently, changing the interserver credentials requires a full restart of the daemon.\r\nWith more than a few nodes this means downtime or inconsistent replicas for some period of time.\r\n\r\n**Describe the solution you'd like**\r\nInterserver credentials should dynamically reload. ClickHouse server should support more than one interserver credential, i.e. to support changing passwords seamlessly.\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14106/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14106/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14097","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14097/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14097/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14097/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/14097","id":686111894,"node_id":"MDU6SXNzdWU2ODYxMTE4OTQ=","number":14097,"title":"Cannot reach Amazon AWS s3 cloud store when clickhouse server is behind proxy","user":{"login":"macEar","id":47277788,"node_id":"MDQ6VXNlcjQ3Mjc3Nzg4","avatar_url":"https://avatars.githubusercontent.com/u/47277788?v=4","gravatar_id":"","url":"https://api.github.com/users/macEar","html_url":"https://github.com/macEar","followers_url":"https://api.github.com/users/macEar/followers","following_url":"https://api.github.com/users/macEar/following{/other_user}","gists_url":"https://api.github.com/users/macEar/gists{/gist_id}","starred_url":"https://api.github.com/users/macEar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/macEar/subscriptions","organizations_url":"https://api.github.com/users/macEar/orgs","repos_url":"https://api.github.com/users/macEar/repos","events_url":"https://api.github.com/users/macEar/events{/privacy}","received_events_url":"https://api.github.com/users/macEar/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""},{"id":2020016497,"node_id":"MDU6TGFiZWwyMDIwMDE2NDk3","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-s3","name":"comp-s3","color":"b5bcff","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":5,"created_at":"2020-08-26T08:12:47Z","updated_at":"2020-08-31T18:19:16Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"## Question\r\n\r\nIs there any option to set to make Clickhouse server reach external web-sites (e.g. AWS) if Clickhouse is located behind proxy.\r\n\r\n## Description\r\n\r\nI have clickhouse server running in docker. The shortened docker-compose I used for clickhouse is:\r\n\r\n```yml\r\nversion: '3.7'\r\n\r\nnetworks:\r\n  clickhouse-network:\r\n    ipam:\r\n      driver: default\r\n      config:\r\n        - subnet: 10.6.26.0/24\r\n\r\n  clickhouse-server:\r\n    container_name: clickhouse-server\r\n    image: yandex/clickhouse-server:20.5.3.27\r\n    restart: always\r\n    environment:\r\n      - http_proxy=http://myproxy:3128\r\n      - https_proxy=http://myproxy:3128\r\n      - noproxy=127.0.0.1,localhost\r\n    volumes: ...\r\n    networks:\r\n      - clickhouse-network\r\n```\r\n\r\nAfter I ran the container, I try:\r\n\r\n```\r\n$ docker exec -it clickhouse-server bash\r\nroot@5b9784b9113b:/# clickhouse-client --user \"XXXXX\" --password \"XXXXX\" --query \"INSERT INTO FUNCTION s3('https://s3.us-east-1.amazonaws.com/ch-backup1/test.csv', 'XXXXXXXXX', 'XXXXXXXXXXXXXXXXX', 'CSV', 'key String, value String') VALUES ('color','red'),('size','10')\"\r\n\r\nCode: 499. DB::Exception: Received from clickhouse-server:9000. DB::Exception: Poco::Exception. Code: 1000, e.code() = 0, e.displayText() = Timeout: connect timed out: 52.216.76.254:443 (version 20.5.3.27 (official build)).\r\n```\r\n\r\nIf I do the same on another machine which has direct access to Internet, it works.\r\n\r\nSo, is there any option to set or should I make feature request?\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14097/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14097/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14091","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14091/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14091/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14091/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/14091","id":685961354,"node_id":"MDU6SXNzdWU2ODU5NjEzNTQ=","number":14091,"title":"RBAC: CREATE VIEW executes successfully when user doesn't have full RBAC privileges.","user":{"login":"MyroTk","id":44327070,"node_id":"MDQ6VXNlcjQ0MzI3MDcw","avatar_url":"https://avatars.githubusercontent.com/u/44327070?v=4","gravatar_id":"","url":"https://api.github.com/users/MyroTk","html_url":"https://github.com/MyroTk","followers_url":"https://api.github.com/users/MyroTk/followers","following_url":"https://api.github.com/users/MyroTk/following{/other_user}","gists_url":"https://api.github.com/users/MyroTk/gists{/gist_id}","starred_url":"https://api.github.com/users/MyroTk/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/MyroTk/subscriptions","organizations_url":"https://api.github.com/users/MyroTk/orgs","repos_url":"https://api.github.com/users/MyroTk/repos","events_url":"https://api.github.com/users/MyroTk/events{/privacy}","received_events_url":"https://api.github.com/users/MyroTk/received_events","type":"User","site_admin":false},"labels":[{"id":386401505,"node_id":"MDU6TGFiZWwzODY0MDE1MDU=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/bug","name":"bug","color":"ee0701","default":true,"description":"Confirmed user-visible misbehaviour in official release"},{"id":2011606513,"node_id":"MDU6TGFiZWwyMDExNjA2NTEz","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-rbac","name":"comp-rbac","color":"b5bcff","default":false,"description":"Access control related"}],"state":"open","locked":false,"assignee":{"login":"vitlibar","id":45142681,"node_id":"MDQ6VXNlcjQ1MTQyNjgx","avatar_url":"https://avatars.githubusercontent.com/u/45142681?v=4","gravatar_id":"","url":"https://api.github.com/users/vitlibar","html_url":"https://github.com/vitlibar","followers_url":"https://api.github.com/users/vitlibar/followers","following_url":"https://api.github.com/users/vitlibar/following{/other_user}","gists_url":"https://api.github.com/users/vitlibar/gists{/gist_id}","starred_url":"https://api.github.com/users/vitlibar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vitlibar/subscriptions","organizations_url":"https://api.github.com/users/vitlibar/orgs","repos_url":"https://api.github.com/users/vitlibar/repos","events_url":"https://api.github.com/users/vitlibar/events{/privacy}","received_events_url":"https://api.github.com/users/vitlibar/received_events","type":"User","site_admin":false},"assignees":[{"login":"vitlibar","id":45142681,"node_id":"MDQ6VXNlcjQ1MTQyNjgx","avatar_url":"https://avatars.githubusercontent.com/u/45142681?v=4","gravatar_id":"","url":"https://api.github.com/users/vitlibar","html_url":"https://github.com/vitlibar","followers_url":"https://api.github.com/users/vitlibar/followers","following_url":"https://api.github.com/users/vitlibar/following{/other_user}","gists_url":"https://api.github.com/users/vitlibar/gists{/gist_id}","starred_url":"https://api.github.com/users/vitlibar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vitlibar/subscriptions","organizations_url":"https://api.github.com/users/vitlibar/orgs","repos_url":"https://api.github.com/users/vitlibar/repos","events_url":"https://api.github.com/users/vitlibar/events{/privacy}","received_events_url":"https://api.github.com/users/vitlibar/received_events","type":"User","site_admin":false}],"milestone":null,"comments":1,"created_at":"2020-08-26T02:45:37Z","updated_at":"2021-07-02T23:45:01Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Describe the bug**\r\nA user is required to have select privilege on a table in order to create a view using that table as the source table, however a user is able to create a view that uses three tables only having select privilege on one of the three tables.\r\n\r\n**How to reproduce**\r\n* ClickHouse server version 20.8.1 revision 54438.\r\n* `CREATE TABLE` statements\r\n```\r\nclicktest :) show create table table0\r\n\r\nSHOW CREATE TABLE table0\r\n\r\n┌─statement─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\r\n│ CREATE TABLE default.table0\r\n(\r\n    `d` Date,\r\n    `a` String,\r\n    `b` UInt8,\r\n    `x` String,\r\n    `y` Int8\r\n)\r\nENGINE = MergeTree()\r\nORDER BY d\r\nSETTINGS index_granularity = 8192 │\r\n└───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\r\n\r\n1 rows in set. Elapsed: 0.007 sec.\r\n\r\nclicktest :) show create table table1\r\n\r\nSHOW CREATE TABLE table1\r\n\r\n┌─statement─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\r\n│ CREATE TABLE default.table1\r\n(\r\n    `d` Date,\r\n    `a` String,\r\n    `b` UInt8,\r\n    `x` String,\r\n    `y` Int8\r\n)\r\nENGINE = MergeTree()\r\nORDER BY d\r\nSETTINGS index_granularity = 8192 │\r\n└───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\r\n\r\n1 rows in set. Elapsed: 0.005 sec.\r\n\r\nclicktest :) show create table table2\r\n\r\nSHOW CREATE TABLE table2\r\n\r\n┌─statement─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\r\n│ CREATE TABLE default.table2\r\n(\r\n    `d` Date,\r\n    `a` String,\r\n    `b` UInt8,\r\n    `x` String,\r\n    `y` Int8\r\n)\r\nENGINE = MergeTree()\r\nORDER BY d\r\nSETTINGS index_granularity = 8192 │\r\n└───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\r\n\r\n1 rows in set. Elapsed: 0.004 sec.\r\n```\r\n* Queries to run that lead to unexpected result\r\n```\r\nClickHouse client version 20.8.1.4447 (official build).\r\nConnecting to localhost:9000 as user user0.\r\nConnected to ClickHouse server version 20.8.1 revision 54438.\r\n\r\nclicktest :) CREATE VIEW view0 AS SELECT * FROM table0 WHERE y IN (SELECT y FROM table1 WHERE y IN (SELECT y FROM table2 WHERE y<2))\r\n\r\nCREATE VIEW view0 AS\r\nSELECT *\r\nFROM table0\r\nWHERE y IN\r\n(\r\n    SELECT y\r\n    FROM table1\r\n    WHERE y IN\r\n    (\r\n        SELECT y\r\n        FROM table2\r\n        WHERE y < 2\r\n    )\r\n)\r\n\r\nOk.\r\n\r\n0 rows in set. Elapsed: 0.012 sec.\r\n\r\nclicktest :) q\r\nBye.\r\n/home/myrotk/rbac# clickhouse-client\r\nClickHouse client version 20.8.1.4447 (official build).\r\nConnecting to localhost:9000 as user default.\r\nConnected to ClickHouse server version 20.8.1 revision 54438.\r\n\r\nclicktest :) show grants for user0\r\n\r\nSHOW GRANTS FOR user0\r\n\r\n┌─GRANTS FOR user0────────────────────────────┐\r\n│ GRANT SELECT ON default.table0 TO user0     │\r\n│ GRANT CREATE VIEW ON default.view0 TO user0 │\r\n└─────────────────────────────────────────────┘\r\n\r\n2 rows in set. Elapsed: 0.004 sec.\r\n```\r\n\r\n**Expected behavior**\r\nUser is required to have select privilege on all of the tables in order to create a view that uses them.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14091/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14091/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14004","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14004/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14004/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14004/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/14004","id":684611915,"node_id":"MDU6SXNzdWU2ODQ2MTE5MTU=","number":14004,"title":"SHOW CREATE TABLE and DESCRIBE TABLE are inconsistent with respect to TEMPORARY tables","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2020-08-24T12:04:40Z","updated_at":"2020-08-25T22:37:06Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"**Use case**\r\n```\r\nmilovidov-desktop :) CREATE TABLE t (hello String) ENGINE = StripeLog\r\n\r\nCREATE TABLE t\r\n(\r\n    `hello` String\r\n)\r\nENGINE = StripeLog\r\n\r\nOk.\r\n\r\n0 rows in set. Elapsed: 0.002 sec. \r\n\r\nmilovidov-desktop :) CREATE TEMPORARY TABLE t (world UInt64)\r\n\r\nCREATE TEMPORARY TABLE t\r\n(\r\n    `world` UInt64\r\n)\r\n\r\nOk.\r\n\r\n0 rows in set. Elapsed: 0.001 sec. \r\n\r\nmilovidov-desktop :) SHOW CREATE TABLE t\r\n\r\nSHOW CREATE TABLE t\r\n\r\n┌─statement────────────────────────────────────────────────────┐\r\n│ CREATE TABLE default.t\r\n(\r\n    `hello` String\r\n)\r\nENGINE = StripeLog │\r\n└──────────────────────────────────────────────────────────────┘\r\n\r\n1 rows in set. Elapsed: 0.001 sec. \r\n\r\nmilovidov-desktop :) DESCRIBE TABLE t\r\n\r\nDESCRIBE TABLE t\r\n\r\n┌─name──┬─type───┬─default_type─┬─default_expression─┬─comment─┬─codec_expression─┬─ttl_expression─┐\r\n│ world │ UInt64 │              │                    │         │                  │                │\r\n└───────┴────────┴──────────────┴────────────────────┴─────────┴──────────────────┴────────────────┘\r\n\r\n1 rows in set. Elapsed: 0.001 sec. \r\n\r\nmilovidov-desktop :) SHOW CREATE TEMPORARY TABLE t\r\n\r\nSHOW CREATE TEMPORARY TABLE t\r\n\r\n┌─statement───────────────────────────────────────────────────┐\r\n│ CREATE TEMPORARY TABLE t\r\n(\r\n    `world` UInt64\r\n)\r\nENGINE = Memory │\r\n└─────────────────────────────────────────────────────────────┘\r\n\r\n1 rows in set. Elapsed: 0.001 sec. \r\n\r\nmilovidov-desktop :) DESCRIBE TEMPORARY TABLE t\r\n\r\nSyntax error: failed at position 26 ('t'):\r\n\r\nDESCRIBE TEMPORARY TABLE t\r\n\r\nExpected one of: SAMPLE, INTO OUTFILE, SETTINGS, FORMAT, FINAL\r\n```\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14004/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14004/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14003","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14003/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14003/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14003/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/14003","id":684610167,"node_id":"MDU6SXNzdWU2ODQ2MTAxNjc=","number":14003,"title":"Natural / version sort","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2020-08-24T12:02:01Z","updated_at":"2020-08-28T06:17:14Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"**Use case**\r\nProvide a way to sort strings in the following order:\r\n\r\n```\r\nhello4world5\r\nhello4world10\r\nhello30\r\nhello123\r\n```\r\n\r\nIt's in question what is better - maybe add a function that will map string to some value that will have the desired order (array of components) or implement it as a modifier to ORDER BY element.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14003/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/14003/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13999","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13999/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13999/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13999/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/13999","id":684567272,"node_id":"MDU6SXNzdWU2ODQ1NjcyNzI=","number":13999,"title":"Support DictJoin optimisation for COMPLEX_KEY_HASHED","user":{"login":"4ertus2","id":8061274,"node_id":"MDQ6VXNlcjgwNjEyNzQ=","avatar_url":"https://avatars.githubusercontent.com/u/8061274?v=4","gravatar_id":"","url":"https://api.github.com/users/4ertus2","html_url":"https://github.com/4ertus2","followers_url":"https://api.github.com/users/4ertus2/followers","following_url":"https://api.github.com/users/4ertus2/following{/other_user}","gists_url":"https://api.github.com/users/4ertus2/gists{/gist_id}","starred_url":"https://api.github.com/users/4ertus2/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/4ertus2/subscriptions","organizations_url":"https://api.github.com/users/4ertus2/orgs","repos_url":"https://api.github.com/users/4ertus2/repos","events_url":"https://api.github.com/users/4ertus2/events{/privacy}","received_events_url":"https://api.github.com/users/4ertus2/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":1357578153,"node_id":"MDU6TGFiZWwxMzU3NTc4MTUz","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-joins","name":"comp-joins","color":"b5bcff","default":false,"description":"JOINs"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2020-08-24T10:49:13Z","updated_at":"2021-11-25T08:13:23Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"JOIN over dictionary has optimisation for UInt64 layouts. It's possible to add COMPLEX_KEY_HASHED layout too.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13999/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13999/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13997","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13997/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13997/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13997/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/13997","id":684561494,"node_id":"MDU6SXNzdWU2ODQ1NjE0OTQ=","number":13997,"title":"Better subquery optimizations (and their introspection)","user":{"login":"UnamedRus","id":9449405,"node_id":"MDQ6VXNlcjk0NDk0MDU=","avatar_url":"https://avatars.githubusercontent.com/u/9449405?v=4","gravatar_id":"","url":"https://api.github.com/users/UnamedRus","html_url":"https://github.com/UnamedRus","followers_url":"https://api.github.com/users/UnamedRus/followers","following_url":"https://api.github.com/users/UnamedRus/following{/other_user}","gists_url":"https://api.github.com/users/UnamedRus/gists{/gist_id}","starred_url":"https://api.github.com/users/UnamedRus/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/UnamedRus/subscriptions","organizations_url":"https://api.github.com/users/UnamedRus/orgs","repos_url":"https://api.github.com/users/UnamedRus/repos","events_url":"https://api.github.com/users/UnamedRus/events{/privacy}","received_events_url":"https://api.github.com/users/UnamedRus/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":756395244,"node_id":"MDU6TGFiZWw3NTYzOTUyNDQ=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/performance","name":"performance","color":"c2e0c6","default":false,"description":null},{"id":1401777979,"node_id":"MDU6TGFiZWwxNDAxNzc3OTc5","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-optimizers","name":"comp-optimizers","color":"b5bcff","default":false,"description":"Query optimizations"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2020-08-24T10:38:32Z","updated_at":"2020-09-25T09:14:26Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Use case**\r\nImprove performance of multiple joins by implementing some optimizations to multiple join rewriters.\r\n\r\n**Describe the solution you'd like**\r\nWe have an query 1:\r\n```\r\nSELECT \r\n    toYear(LO_ORDERDATE) AS year, \r\n    C_NATION, \r\n    SUM(LO_REVENUE - LO_SUPPLYCOST) AS profit\r\nFROM lineorder\r\nINNER JOIN customer ON C_CUSTKEY = LO_CUSTKEY\r\nINNER JOIN supplier ON LO_SUPPKEY = S_SUPPKEY\r\nINNER JOIN part ON P_PARTKEY = LO_PARTKEY\r\nWHERE (C_REGION = 'AMERICA') AND (S_REGION = 'AMERICA') AND ((P_MFGR = 'MFGR#1') OR (P_MFGR = 'MFGR#2'))\r\nGROUP BY \r\n    year, \r\n    C_NATION\r\nORDER BY \r\n    year ASC, \r\n    C_NATION ASC\r\n```\r\nWith set multiple_join_rewriter = 2; clickhouse rewrites it's to this:\r\n```\r\nSELECT\r\n    toYear(LO_ORDERDATE) AS year,\r\n    C_NATION,\r\n    SUM(LO_REVENUE - LO_SUPPLYCOST) AS profit\r\nFROM\r\n(\r\n    SELECT\r\n        LO_PARTKEY,\r\n        LO_ORDERDATE,\r\n        LO_SUPPLYCOST,\r\n        LO_CUSTKEY,\r\n        LO_SUPPKEY,\r\n        LO_REVENUE,\r\n        C_CUSTKEY,\r\n        C_REGION,\r\n        C_NATION,\r\n        S_SUPPKEY,\r\n        S_REGION\r\n    FROM\r\n    (\r\n        SELECT\r\n            LO_PARTKEY,\r\n            LO_ORDERDATE,\r\n            LO_SUPPLYCOST,\r\n            LO_CUSTKEY,\r\n            LO_SUPPKEY,\r\n            LO_REVENUE,\r\n            C_CUSTKEY,\r\n            C_REGION,\r\n            C_NATION\r\n        FROM lineorder\r\n        ALL INNER JOIN\r\n        (\r\n            SELECT\r\n                C_CUSTKEY,\r\n                C_NATION,\r\n                C_REGION\r\n            FROM customer\r\n            WHERE C_REGION = 'AMERICA'\r\n        ) AS customer ON C_CUSTKEY = LO_CUSTKEY\r\n        WHERE C_REGION = 'AMERICA'\r\n    ) AS `--.s`\r\n    ALL INNER JOIN\r\n    (\r\n        SELECT\r\n            S_SUPPKEY,\r\n            S_REGION\r\n        FROM supplier\r\n        WHERE S_REGION = 'AMERICA'\r\n    ) AS supplier ON LO_SUPPKEY = S_SUPPKEY\r\n    WHERE (S_REGION = 'AMERICA') AND (C_REGION = 'AMERICA')\r\n) AS `--.s`\r\nALL INNER JOIN\r\n(\r\n    SELECT\r\n        P_PARTKEY,\r\n        P_MFGR\r\n    FROM part\r\n    WHERE (P_MFGR = 'MFGR#1') OR (P_MFGR = 'MFGR#2')\r\n) AS part ON P_PARTKEY = LO_PARTKEY\r\nWHERE (C_REGION = 'AMERICA') AND (S_REGION = 'AMERICA') AND ((P_MFGR = 'MFGR#1') OR (P_MFGR = 'MFGR#2'))\r\nGROUP BY\r\n    year,\r\n    C_NATION\r\nORDER BY\r\n    year ASC,\r\n    C_NATION ASC \r\n```\r\nBut more optimal variant is this:\r\n```\r\nSELECT\r\n    toYear(LO_ORDERDATE) AS year,\r\n    C_NATION,\r\n    SUM(LO_REVENUE - LO_SUPPLYCOST) AS profit\r\nFROM\r\n(\r\n    SELECT\r\n        LO_PARTKEY,\r\n        LO_ORDERDATE,\r\n        LO_SUPPLYCOST,\r\n        LO_REVENUE,\r\n        C_NATION\r\n    FROM\r\n    (\r\n        SELECT\r\n            LO_PARTKEY,\r\n            LO_ORDERDATE,\r\n            LO_SUPPLYCOST,\r\n            LO_SUPPKEY,\r\n            LO_REVENUE,\r\n            C_NATION\r\n        FROM lineorder\r\n        ALL INNER JOIN\r\n        (\r\n            SELECT\r\n                C_CUSTKEY,\r\n                C_NATION\r\n            FROM customer\r\n            WHERE C_REGION = 'AMERICA'\r\n        ) AS customer ON C_CUSTKEY = LO_CUSTKEY\r\n    ) AS `--.s`\r\n    ALL INNER JOIN\r\n    (\r\n        SELECT\r\n            S_SUPPKEY\r\n        FROM supplier\r\n        WHERE S_REGION = 'AMERICA'\r\n    ) AS supplier ON LO_SUPPKEY = S_SUPPKEY\r\n) AS `--.s`\r\nALL INNER JOIN\r\n(\r\n    SELECT\r\n        P_PARTKEY\r\n    FROM part\r\n    WHERE (P_MFGR = 'MFGR#1') OR (P_MFGR = 'MFGR#2')\r\n) AS part ON P_PARTKEY = LO_PARTKEY\r\nGROUP BY\r\n    year,\r\n    C_NATION\r\nORDER BY\r\n    year ASC,\r\n    C_NATION ASC\r\n```\r\n We have an query 2:\r\n```\r\nSELECT\r\n  C_NATION,\r\n  S_NATION,\r\n toYear(LO_ORDERDATE) AS year,\r\n   SUM(LO_REVENUE) AS revenue\r\nFROM lineorder\r\nINNER JOIN customer ON C_CUSTKEY = LO_CUSTKEY\r\nINNER JOIN supplier ON LO_SUPPKEY = S_SUPPKEY\r\nWHERE  C_REGION = 'ASIA'\r\n  AND S_REGION = 'ASIA'\r\n  AND year  >= 1992\r\n  AND year  <= 1997\r\nGROUP BY\r\n  C_NATION,\r\n  S_NATION,\r\n  year\r\nORDER BY\r\n  year ASC,\r\n  revenue DESC;\r\n```\r\nWith set multiple_join_rewriter = 2; clickhouse rewrites it's to this:\r\n```\r\nSELECT\r\n    C_NATION,\r\n    S_NATION,\r\n    toYear(LO_ORDERDATE) AS year,\r\n    SUM(LO_REVENUE) AS revenue\r\nFROM\r\n(\r\n    SELECT\r\n        LO_SUPPKEY,\r\n        LO_CUSTKEY,\r\n        LO_REVENUE,\r\n        LO_ORDERDATE,\r\n        C_CUSTKEY,\r\n        C_REGION,\r\n        C_NATION\r\n    FROM lineorder\r\n    ALL INNER JOIN\r\n    (\r\n        SELECT\r\n            C_CUSTKEY,\r\n            C_NATION,\r\n            C_REGION\r\n        FROM customer\r\n        WHERE C_REGION = 'ASIA'\r\n    ) AS customer ON C_CUSTKEY = LO_CUSTKEY\r\n    WHERE ((toYear(LO_ORDERDATE) <= 1997) AND (toYear(LO_ORDERDATE) >= 1992)) AND (C_REGION = 'ASIA')\r\n) AS `--.s`\r\nALL INNER JOIN\r\n(\r\n    SELECT\r\n        S_SUPPKEY,\r\n        S_NATION,\r\n        S_REGION\r\n    FROM supplier\r\n    WHERE S_REGION = 'ASIA'\r\n) AS supplier ON LO_SUPPKEY = S_SUPPKEY\r\nWHERE (C_REGION = 'ASIA') AND (S_REGION = 'ASIA') AND (year >= 1992) AND (year <= 1997)\r\nGROUP BY\r\n    C_NATION,\r\n    S_NATION,\r\n    year\r\nORDER BY\r\n    year ASC,\r\n    revenue DESC\r\n```\r\nBut more optimal variant is this:\r\n```\r\nSELECT\r\n    C_NATION,\r\n    S_NATION,\r\n    year,\r\n    SUM(LO_REVENUE) AS revenue\r\nFROM\r\n(\r\n    SELECT\r\n        LO_SUPPKEY,\r\n        LO_REVENUE,\r\n\t\ttoYear(LO_ORDERDATE) AS year,\r\n        C_NATION\r\n    FROM lineorder\r\n    ALL INNER JOIN\r\n    (\r\n        SELECT\r\n            C_CUSTKEY,\r\n            C_NATION\r\n        FROM customer\r\n        WHERE C_REGION = 'ASIA'\r\n    ) AS customer ON C_CUSTKEY = LO_CUSTKEY\r\n    WHERE ((year <= 1997) AND (year >= 1992))\r\n) AS `--.s`\r\nALL INNER JOIN\r\n(\r\n    SELECT\r\n        S_SUPPKEY,\r\n        S_NATION\r\n    FROM supplier\r\n    WHERE S_REGION = 'ASIA'\r\n) AS supplier ON LO_SUPPKEY = S_SUPPKEY\r\nGROUP BY\r\n    C_NATION,\r\n    S_NATION,\r\n    year\r\nORDER BY\r\n    year ASC,\r\n    revenue DESC\r\n```\r\n\r\n1. remove unneeded columns from right table subquery.\r\n2. remove unneeded columns from subqueries.\r\n3. remove unnecessary repetitions of WHERE clause (probably will work only for certain join types)\r\n4. move evaluation of expressions to subqueries. (if they were already executed in subqueries)\r\n\r\n**Describe alternatives you've considered**\r\nRewrite the query by hand, but it's isn't practical and not all clickhouse users will do that.\r\n\r\n**Additional context**\r\nPerfomance difference is\r\nFor query 1\r\nclickhouse rewritten query:\r\n35 rows in set. Elapsed: 269.492 sec. Processed 15.08 billion rows, 330.49 GB (55.97 million rows/s., 1.23 GB/s.) ~ 1440% cpu usage\r\nby hand rewritten query:\r\n35 rows in set. Elapsed: 215.259 sec. Processed 15.08 billion rows, 330.49 GB (70.07 million rows/s., 1.54 GB/s.) ~ 1390% cpu usage\r\n\r\nFor query 2\r\nclickhouse rewritten query:\r\n150 rows in set. Elapsed: 219.746 sec. Processed 13.75 billion rows, 191.80 GB (62.55 million rows/s., 872.84 MB/s.)\r\nby hand rewritten query:\r\n150 rows in set. Elapsed: 163.690 sec. Processed 13.75 billion rows, 191.80 GB (83.97 million rows/s., 1.17 GB/s.)\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13997/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13997/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13996","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13996/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13996/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13996/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/13996","id":684555085,"node_id":"MDU6SXNzdWU2ODQ1NTUwODU=","number":13996,"title":"Multiple DROP PARTITION in single ALTER query doesn't work if partitions bigger than max_partition_size_to_drop ","user":{"login":"UnamedRus","id":9449405,"node_id":"MDQ6VXNlcjk0NDk0MDU=","avatar_url":"https://avatars.githubusercontent.com/u/9449405?v=4","gravatar_id":"","url":"https://api.github.com/users/UnamedRus","html_url":"https://github.com/UnamedRus","followers_url":"https://api.github.com/users/UnamedRus/followers","following_url":"https://api.github.com/users/UnamedRus/following{/other_user}","gists_url":"https://api.github.com/users/UnamedRus/gists{/gist_id}","starred_url":"https://api.github.com/users/UnamedRus/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/UnamedRus/subscriptions","organizations_url":"https://api.github.com/users/UnamedRus/orgs","repos_url":"https://api.github.com/users/UnamedRus/repos","events_url":"https://api.github.com/users/UnamedRus/events{/privacy}","received_events_url":"https://api.github.com/users/UnamedRus/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2020-08-24T10:27:55Z","updated_at":"2020-08-24T10:27:55Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Use case**\r\nClickhouse allows us to execute multiple statements in ALTER TABLE query, but we can't drop multiple partitions at once if they are bigger than max_partition_size_to_drop threshold.\r\n\r\n**Describe the solution you'd like**\r\nGive the ability to set a flag  once for a single ALTER query.\r\n`touch '/var/lib/clickhouse/flags/force_drop_table' && chmod 666 '/var/lib/clickhouse/flags/force_drop_table'`\r\n**Describe alternatives you've considered**\r\nDon't use multiple DROP PARTITION statements in ALTER TABLE query.\r\nAdjust max_partition_size_to_drop  setting to ignore those partitions, but it's necessary to restart the clickhouse server to do that.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13996/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13996/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13978","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13978/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13978/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13978/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/13978","id":684240724,"node_id":"MDU6SXNzdWU2ODQyNDA3MjQ=","number":13978,"title":"Simplify ReplicatedMergeTree (RFC)","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":1478073551,"node_id":"MDU6TGFiZWwxNDc4MDczNTUx","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-replication","name":"comp-replication","color":"b5bcff","default":false,"description":"Replicated tables"},{"id":1507886722,"node_id":"MDU6TGFiZWwxNTA3ODg2NzIy","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/st-discussion","name":"st-discussion","color":"e5b890","default":false,"description":"The story requires discussion /research / expert help / design & decomposition before will be taken"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":7,"created_at":"2020-08-23T19:18:48Z","updated_at":"2021-04-07T16:05:35Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"Goals:\r\n\r\nLower the number of nodes and amount of coordination in ZooKeeper. Simplify coordination as much as possible.\r\n\r\nAllow (under specific setting) inserts to replicas even if they are disconnected from ZooKeeper.\r\n\r\nPrefer to use internal requests between replicas for notifications and querying state instead of using ZooKeeper requests or watches.\r\n\r\nParallel quorum inserts.\r\n\r\nManual duplicate inserts to different replicas should work seamlessly - as if data is replicated.\r\n    \r\n    \r\nLoosely related goals:\r\n\r\nAtomic inserts in multiple partitions.\r\n\r\nAtomic inserts of more than one block.\r\n\r\nAllow implementation of point update/delete.\r\n\r\nParallel download of parts from multiple replicas.\r\nBandwidth control while downloading parts.\r\nStop and resume unfinished merging or fetching.\r\nLarge merges/fetches should not prevent small merges/fetches to work.\r\n\r\nOpen up the possibility to move parts between shards.\r\n   \r\n   \r\nProposal:\r\n\r\nGet rid of separate \"parts\" set of different replicas. There will be only one, common set of parts and all replicas will converge to that set.\r\n\r\nGet rid of \"log\" and \"queue\". Simple inserts, merges and drops will appear implicitly as modifications to common set of \"parts\". Specific merge instructions: mutations, optimize deduplicate - will be written to smaller \"logs\" inside parts (instructions on how the larger part should be created).\r\n   \r\n   \r\nImplementation:\r\n\r\n`table_path/parts/partition_id/part_name`\r\n\\- set of parts common to all replicas.\r\n`table_path/parts/partition_id/deduplication/checksum`\r\n\\- checksums for deduplication of last blocks.\r\n\r\nPartitions should be separate directories for slightly better scalability.\r\n\r\nPart can be represented by persistent or ephemeral nodes.\r\nEphemeral node is an intent to create part. It used when:\r\n\\- part is being written by INSERT but not committed yet;\r\n\\- part should be written with quorum but it's not satisfied yet.\r\nMerge intent is created as persistent node, so all replicas can start merging and the intent won't disappear if first replica become offline.\r\n\r\nPart may contain or may not contain checksum. It does not contain checksum if it represents merge intent but no replicas has been finish this merge. When first replica will finish merging, it will update node with checksum. Other replicas will validate checksums.\r\n\r\nIf part is created with merge/mutation, it will contain: - the list of parts from which it's merged along with their checksums; - instruction of what's specific about this merge (deduplicate, update/delete). TODO (what depth of merges we should store?)\r\n\r\nMerge or mutation may fail. When exception is thrown during merge or mutation and no replicas has finished merging (checksum is unavailable), we can delete the node and restore previous nodes in its place. If other replicas finish merging but the node is deleted, merged part is also deleted locally.\r\n\r\nAlong with checksum, part contains refcount - the number of replicas successfully written this part (or: the list of all replicas successfully written this part). It is used for quorum inserts. This refcount does not guarantee that replica has the specific part at this moment of time because replica may become unavailable or lose this part on local filesystem (it only indicates that the part has been successfully written once). When the refcount for part that is written with quorum, becomes large enough, part is converted from ephemeral to persistent.\r\n\r\nThe node for partition contains sequential block number. When we create a node for new (inserted) part, we increment block number in the same transaction. Note: block numbers can contain holes.\r\n\r\nWhen ZooKeeper is unavailable, we can still do INSERTs but cannot allocate common sequential block numbers. We can allocate local block numbers, write parts to separate \"uncommitted\" (or: \"offline\") directory - these parts will be available for SELECTs and merges and can be committed as new parts later, when ZooKeeper will become available.\r\n \r\n \r\nHow to do INSERT:\r\n\r\n\\- split block by partitions;\r\nFor each partition:\r\n\\- allocate local block number;\r\n\\- write part to temporary directory in \"uncommitted\", obtain checksum;\r\n\\- create partition node in ZooKeeper if it looks like the first insert in that partition;\r\nFor all written parts in partitions at once:\r\n\\- commit parts in memory and rename directories in local filesystem;\r\n\\- atomically: allocate block numbers in ZooKeeper; create new nodes in `parts` - either persistent or ephemeral for quorum inserts; create deduplication nodes (if duplicate, remove some elements from transaction or find existing nodes and update refcounts for them, and repeat modified transaction);\r\n\\- if zookeeper is unavailable and offline inserts are not permitted, rollback commits on local filesystem and memory (if server will die, it will rollback on restart; parts on local filesystem should contain info if they were written with offline inserts allowed);\r\n\\- add information to notification queue for other replicas so they will be notified about insert.\r\n\r\nSimilar logic is applied for: ATTACH or REPLACE partition, committing of uncommitted parts that were written offline.\r\n   \r\n   \r\nHow to do merge:\r\n\r\nEvery replica can select parts to merge either from uncommitted parts or from committed parts that are available in local filesystem. Replica will obtain a set of parts in relevant partition from ZooKeeper, keep the version of partition node, and only select parts to merge that does not contain ephemeral parts or unwritten parts (parts without checksums) in the middle. Then it atomically: - checks that the version of partition node did not change; deletes source nodes and creates merged node with instructions on how to merge.\r\n\r\nIf replica has all parts to perform merge (e.g. it has initiated merge) it will perform it. Otherwise it will either download required parts or download already merged part or just wait for merge to be performed by other replica.\r\n\r\nIf merged part appeared to be empty (all rows are deleted during merge), we still keep it as empty part in ZooKeeper but should not keep empty part in local dataset (and should not report the part in system.parts).\r\n\r\nVariants: maybe keep old parts in ZK before merge is finished by one/a few replicas?\r\n   \r\n   \r\nHow to fetch data from replicas:\r\n\r\nEvery replica subscribes to changes of common set of parts in ZooKeeper with watches (TODO what if there are too many partitions?) or being notified by other replicas about changes and requests current state from ZooKeeper after being notified (or simply use these changes?).\r\n\r\nIt compares common set of data parts with local set of data parts (we assume relatively small number of data parts but it's tricky because it still implies O(n^2) actions) or being notified only about changes by other replicas and figures out: what data parts should be fetched or merged and what data parts should be deleted.\r\n\r\nMerge or download is performed, checksums are compared, refcounts updated, quorum parts changed from ephemeral to persistent, etc...\r\n\r\nWhen data part should be deleted, replica shouldn't delete local data immediately but keep it as inactive parts for a while.\r\n   \r\n   \r\nHow to drop partition:\r\n\r\nImplement it as a special merge operation that will delete all data instead of merge. Deleted parts will be replaced to single merged part (with instruction that it's delete). It will be processed in the same way as a merge/mutation that has deleted all the records.\r\n\r\nWe should not store empty part in local dataset but should keep it in ZooKeeper for a while. We can delete the empty part from ZooKeeper if all replicas have processed the corresponding merge operation.\r\n\r\nAdditionally, we should delete all the deduplication info that is related to the block numbers in a range of delete operation (part name is stored in deduplication info).\r\n\r\nDelete old empty partitions from ZK in background thread. Partitions will be recreated implicitly on next INSERT if there will be any.\r\n\r\nBonus: now we can safely drop single parts or part range.\r\n\r\nIf there is no part in ZooKeeper but there is covered parts in local dataset - replica should move them to `unexpected` directory or throw an exception as a safety measure if amount of data is large.\r\n   \r\n   \r\nHow to perform mutations:\r\n\r\nTwo variants.\r\n\r\nOld: write mutations to special path in ZooKeeper. Choose mutations to process in order and assign special merges of all parts.\r\n\r\nNew: mutation is represented as data part and mutation instruction is written to special data part. Whenever merge is assigned it should also do all mutations that are after the corresponding data parts according to their block numbers. Mutation part can participate in merge (and vanish) if all older parts are already mutated.\r\n\r\nSpecial data part may contain mutation instruction as a simple expression. Or it may also contain precalculated mutation data - the data that should be deleted in a form of: row numbers in data parts (1); values of primary keys and index of row within rows with the same primary key (2); and data that should be inserted.\r\n\r\nThis mutation data may be applied on SELECTs.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13978/reactions","total_count":13,"+1":8,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":5},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13978/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13961","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13961/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13961/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13961/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/13961","id":683912336,"node_id":"MDU6SXNzdWU2ODM5MTIzMzY=","number":13961,"title":"Distributed table in Distibuted table spend double time ","user":{"login":"yancheng44","id":24712421,"node_id":"MDQ6VXNlcjI0NzEyNDIx","avatar_url":"https://avatars.githubusercontent.com/u/24712421?v=4","gravatar_id":"","url":"https://api.github.com/users/yancheng44","html_url":"https://github.com/yancheng44","followers_url":"https://api.github.com/users/yancheng44/followers","following_url":"https://api.github.com/users/yancheng44/following{/other_user}","gists_url":"https://api.github.com/users/yancheng44/gists{/gist_id}","starred_url":"https://api.github.com/users/yancheng44/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yancheng44/subscriptions","organizations_url":"https://api.github.com/users/yancheng44/orgs","repos_url":"https://api.github.com/users/yancheng44/repos","events_url":"https://api.github.com/users/yancheng44/events{/privacy}","received_events_url":"https://api.github.com/users/yancheng44/received_events","type":"User","site_admin":false},"labels":[{"id":756395244,"node_id":"MDU6TGFiZWw3NTYzOTUyNDQ=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/performance","name":"performance","color":"c2e0c6","default":false,"description":null},{"id":1634829961,"node_id":"MDU6TGFiZWwxNjM0ODI5OTYx","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-distributed","name":"comp-distributed","color":"b5bcff","default":false,"description":"Distributed tables"},{"id":1907525265,"node_id":"MDU6TGFiZWwxOTA3NTI1MjY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/v20.3-affected","name":"v20.3-affected","color":"c2bfff","default":false,"description":"This issue affects some releases of v20.3"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":7,"created_at":"2020-08-22T02:49:12Z","updated_at":"2020-09-08T22:05:52Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Hello Team,\r\n\r\nWe are using two distributed table with in function to filter the users we want 。\r\n\r\nExample Sql: \r\n```\r\n    set distributed_product_mode='local';\r\n    SET distributed_group_by_no_merge =1; \r\n\r\nSELECT count(user_id)\r\nFROM reddm.dm_push_soc_user_second_category_day_cyan1\r\nWHERE (first_category_name = 'game') AND (second_category_name = 'phonegame')\r\nand user_id in (\r\nselect user_id from reddm.dm_user_crowd_metrics_day_cyan1 a\r\nwhere a.year_old between 15 and 20 \r\n) \r\n\r\n┌─count(user_id)─┐\r\n│        1034129 │\r\n└────────────────┘\r\n┌─count(user_id)─┐\r\n│        1031505 │\r\n└────────────────┘\r\n┌─count(user_id)─┐\r\n│        1033392 │\r\n└────────────────┘\r\n┌─count(user_id)─┐\r\n│        1034383 │\r\n└────────────────┘\r\n┌─count(user_id)─┐\r\n│        1034459 │\r\n└────────────────┘\r\n\r\n5 rows in set. Elapsed: 16.142 sec. Processed 16.31 million rows, 1.02 GB (1.01 million rows/s., 63.13 MB/s.)\r\n```\r\n\r\nThis query take 16 seconds 。 and the fist  result  takes  8second , then others  takes 16 seconds。  \r\n\r\nSql 2:  \r\n\r\nI have test the sql using local table on every node。they take  8 seconds。 \r\n```\r\nSELECT count(user_id)\r\nFROM local.dm_push_soc_user_second_category_day_cyan1\r\nWHERE (first_category_name = 'game') AND (second_category_name = 'phonegame')\r\nand user_id in (\r\nselect user_id from local.dm_user_crowd_metrics_day_cyan1 a\r\nwhere a.year_old between 15 and 20 \r\n)\r\n```\r\n\r\nVersion :20.3.12.112 \r\n\r\nI am confused about  that. please help me. \r\n\r\nIf you want any other information, just let me know. I will update .\r\n\r\nThanks  \r\nJohnny ","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13961/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13961/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13959","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13959/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13959/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13959/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/13959","id":683812162,"node_id":"MDU6SXNzdWU2ODM4MTIxNjI=","number":13959,"title":"Table engine \"VersionedCollapsingMergeTree\": confusion about columns that have to be replicated as part of the \"cancel\"-row","user":{"login":"heyciao","id":14062695,"node_id":"MDQ6VXNlcjE0MDYyNjk1","avatar_url":"https://avatars.githubusercontent.com/u/14062695?v=4","gravatar_id":"","url":"https://api.github.com/users/heyciao","html_url":"https://github.com/heyciao","followers_url":"https://api.github.com/users/heyciao/followers","following_url":"https://api.github.com/users/heyciao/following{/other_user}","gists_url":"https://api.github.com/users/heyciao/gists{/gist_id}","starred_url":"https://api.github.com/users/heyciao/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/heyciao/subscriptions","organizations_url":"https://api.github.com/users/heyciao/orgs","repos_url":"https://api.github.com/users/heyciao/repos","events_url":"https://api.github.com/users/heyciao/events{/privacy}","received_events_url":"https://api.github.com/users/heyciao/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2020-08-21T20:30:28Z","updated_at":"2021-02-05T09:31:08Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"**Problem:**\r\nThe documentation of the table engine \"VersionedCollapsingMergeTree\" currently states the following:\r\n\r\n> The program that writes the data should remember the state of an object in order to cancel it. The “cancel” string should be a copy of the “state” string with the opposite Sign.\r\n> ...\r\n> When ClickHouse merges data parts, it deletes each pair of rows that have the same primary key and version and different Sign.\r\n\r\nIn my opinion the two sentences conflict a little bit with each other:\r\n1. I interpret the first statement as \"_the \"cancel\"-line_ (not a \"string\" but a \"line/row\", right?) _should replicate the contents of **all table columns of the \"state\"-row**, with the exception of the \"sign\"-column having the opposite value._\"\r\n2. The second statement seems to focus **only on the columns that are in the table's primary key** (and the \"version\"-column, which is anyway added automatically to the primary key if not explicitly already present).\r\n\r\nBased on the experiments that I did the second statement seems to be the correct one (therefore if I have some column which is not part of the primary key and that contains in the \"state\"-row some MBs of data, I don't have to re-add those MBs in the \"cancel\"-row, which lowers the I/O needed to perform the deletion of the \"state\"-row), but I'm not sure if my tests were correct - I might have just been lucky.\r\nIn general I would tend to think that merging ops are done by taking into account only the primary key, therefore I would tend to think as well in this case that the second statement is more correct, but I didn't check the source code.\r\n\r\n**Proposed change:**\r\nIf the second statement is the one that is correct, then the first statement could perhaps be rewritten from...\r\n\r\n> The program that writes the data should remember the state of an object in order to cancel it. The “cancel” string should be a copy of the “state” string with the opposite Sign.\r\n\r\n...to something like this...\r\n\r\n> The program that writes the data should remember the state of an object in order to cancel it. The “cancel”-row should be a copy of the row's “state” primary keys but using the opposite Sign.\r\n\r\n...(as I mentioned above I think that \"string\" actually refers to \"row\"?)?\r\nThank you and kind regards.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13959/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13959/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13955","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13955/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13955/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13955/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/13955","id":683686097,"node_id":"MDU6SXNzdWU2ODM2ODYwOTc=","number":13955,"title":"Readonly error when declaring setting (connect_timeout) and querying distributed table","user":{"login":"JClement57","id":25063179,"node_id":"MDQ6VXNlcjI1MDYzMTc5","avatar_url":"https://avatars.githubusercontent.com/u/25063179?v=4","gravatar_id":"","url":"https://api.github.com/users/JClement57","html_url":"https://github.com/JClement57","followers_url":"https://api.github.com/users/JClement57/followers","following_url":"https://api.github.com/users/JClement57/following{/other_user}","gists_url":"https://api.github.com/users/JClement57/gists{/gist_id}","starred_url":"https://api.github.com/users/JClement57/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/JClement57/subscriptions","organizations_url":"https://api.github.com/users/JClement57/orgs","repos_url":"https://api.github.com/users/JClement57/repos","events_url":"https://api.github.com/users/JClement57/events{/privacy}","received_events_url":"https://api.github.com/users/JClement57/received_events","type":"User","site_admin":false},"labels":[{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""},{"id":1634829961,"node_id":"MDU6TGFiZWwxNjM0ODI5OTYx","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-distributed","name":"comp-distributed","color":"b5bcff","default":false,"description":"Distributed tables"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2020-08-21T16:47:04Z","updated_at":"2020-08-24T10:20:47Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"**Describe the unexpected behaviour**\r\nI'm trying to modify the connect_timeout within my session as I'm running benchmarks for concurrent queries and have been hitting the 10 second cap. Trying to raise to 20 seconds. It works when running a query on the current node, but when I try and run a SELECT query on a distributed table I receive a readonly error.\r\n\r\n```\r\n$ clickhouse-server --version\r\nClickHouse server version 19.17.6.36 (official build).\r\n\r\n$ clickhouse-client --version\r\nClickHouse client version 20.4.5.36 (official build).\r\n\r\n$ clickhouse-client --user admin --password PASSWORD --connect_timeout=20 --query \"select count(*) from regular_table\"\r\n3481975\r\n$ clickhouse-client --user admin --password PASSWORD --connect_timeout=20 --query \"select count(*) from distributed_table\"\r\nReceived exception from server (version 19.17.6):\r\nCode: 164. DB::Exception: Received from <server_address>:9000. DB::Exception: Received from <server_address>:9000. DB::Exception: Cannot modify 'connect_timeout' setting in readonly mode. \r\n```\r\n\r\n**Expected behavior**\r\nI would expect to not be in readonly mode since I am using admin credentials to connect to the server, and thus shouldn't be in readonly mode. Not sure if this is a flawed assumption. I would then expect the query to execute properly with a connect_timeout of 20 seconds","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13955/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13955/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13953","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13953/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13953/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13953/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/13953","id":683610867,"node_id":"MDU6SXNzdWU2ODM2MTA4Njc=","number":13953,"title":"Backups","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":{"login":"vitlibar","id":45142681,"node_id":"MDQ6VXNlcjQ1MTQyNjgx","avatar_url":"https://avatars.githubusercontent.com/u/45142681?v=4","gravatar_id":"","url":"https://api.github.com/users/vitlibar","html_url":"https://github.com/vitlibar","followers_url":"https://api.github.com/users/vitlibar/followers","following_url":"https://api.github.com/users/vitlibar/following{/other_user}","gists_url":"https://api.github.com/users/vitlibar/gists{/gist_id}","starred_url":"https://api.github.com/users/vitlibar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vitlibar/subscriptions","organizations_url":"https://api.github.com/users/vitlibar/orgs","repos_url":"https://api.github.com/users/vitlibar/repos","events_url":"https://api.github.com/users/vitlibar/events{/privacy}","received_events_url":"https://api.github.com/users/vitlibar/received_events","type":"User","site_admin":false},"assignees":[{"login":"vitlibar","id":45142681,"node_id":"MDQ6VXNlcjQ1MTQyNjgx","avatar_url":"https://avatars.githubusercontent.com/u/45142681?v=4","gravatar_id":"","url":"https://api.github.com/users/vitlibar","html_url":"https://github.com/vitlibar","followers_url":"https://api.github.com/users/vitlibar/followers","following_url":"https://api.github.com/users/vitlibar/following{/other_user}","gists_url":"https://api.github.com/users/vitlibar/gists{/gist_id}","starred_url":"https://api.github.com/users/vitlibar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vitlibar/subscriptions","organizations_url":"https://api.github.com/users/vitlibar/orgs","repos_url":"https://api.github.com/users/vitlibar/repos","events_url":"https://api.github.com/users/vitlibar/events{/privacy}","received_events_url":"https://api.github.com/users/vitlibar/received_events","type":"User","site_admin":false}],"milestone":null,"comments":5,"created_at":"2020-08-21T14:41:51Z","updated_at":"2021-11-12T07:32:14Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"Details of what's proposed here: #8841\r\n\r\nRequirements:\r\n- physical backup for almost all cases - backup of binary data without deserialization;\r\n- allow to backup any kind of tables;\r\n- allow to backup subset of partitions of MergeTree tables;\r\n- allow to backup whole databases or all server data;\r\n- support for incremental backups;\r\n- support for tables on remote storage;\r\n- support for tables with symlinks or hardlinks;\r\n- backup and restore of replicated tables;\r\n- backups are performed in streaming fashion, so +100% space is not required;\r\n- support for parallel writing of backup data to destination storage in multiple streams;\r\n- backup process should not consume too much memory while performed;\r\n- incremental backups should be optimized so reading the whole data is not necessarily if checksums can be quickly compared;\r\n- consistent snapshot whenever possible (for MergeTree tables), best effort when not possible;\r\n- support for different storage options via VFS;\r\n- restore with partial replace (single partition, subset of tables);\r\n- backups should be also useful for distribution of public datasets;\r\n- changing of db/table/replica path on restore;\r\n- allow to restore into different kind of database or table in some cases (Atomic database to Ordinary; ReplicatedMergeTree to MergeTree);\r\n- support for backups and restore of a cluster;\r\n\r\nOut of scope:\r\n- point in time recovery;\r\n- restore is not necessarily atomic, the client may see partially restored data if the server is not closed for connections.\r\n\r\nImplementation proposal:\r\n\r\nBackup is represented by a set of blobs and metadata.\r\n\r\nBackup mechanism is implemented with the following:\r\n- add a method to iterate over snapshot of the database in a form of entries consisting blobs;\r\n- add an interface to consume these entries and write a backup;\r\n- add a method to read the backup and iterate over its entries;\r\n- add a method of catalog/database/table to consume backup entries and restore the data;\r\n\r\nMore details:\r\n\r\nIStorage, IDatabase and DatabaseCatalog should provide `backup` method, returning IBakupIterator.\r\nIBakupIterator acquires (consistent if possible but not necessarily) snapshot of table or database or catalog and provides a method to iterate through it.\r\nIteration over backup iterator returns `BackupEntry` struct that contains:\r\n- virtual path: it's relative path if data is stored in local filesystem or something similar otherwise - it's enough to identify this entry;\r\n- optional ReadBuffer to read the data (blob); it also should hold the corresponding data, so we can read it;\r\n- optional checksum - if already available or empty if it must be calculated from file data (ready available checksums are useful when we do incremental backups to skip reading);\r\n- information about file metadata needed for tables - if it's symlink or hardlink, etc.\r\n\r\nBackups can be written to various destinations with `IBackupWriter`. IBackupWriter will consume `BackupEntry` objects to write blobs somewhere and build metadata info. It's also responsible to skip blobs for incremental backups.\r\n\r\nBackups can be read back in a form of `IBackupIterator`.\r\nIStorage, IDatabase and DatabaseCatalog should provide `restore` method taking `IBackupIterator` and various options (partial restore, restore with different names...)\r\n\r\nExamples:\r\n\r\n> physical backup for almost all cases - backup of binary data without deserialization\r\n> backup any kind of tables\r\n\r\nThe table may provide a ReadBuffer to read some file directly (MergeTree, Log tables) or to generate some stream of serialized data (Memory table).\r\nThe only requirement for this stream (blob) is to allow data restore. It's even possible that some table may provide logical dump as a blob, but it's not intended.\r\n\r\nPhysical backup allows to restore the same set of data parts. Data parts don't have to be re-merged after restore, in contrast to table dump.\r\n\r\nTables that don't store data should not provide any blobs - for example, backup of a table with URL or S3 engine will be shallow.\r\nIn contrast, if MergeTree table is stored on S3 (in development), backup will consist blobs of data equal if they are stored locally.\r\n\r\nThe process of physical backup is similar to simply copying the files... but is more generic to account for all the details.\r\n\r\nThere are different variants possible if we want to backup Distributed tables, but for first implementation it will be shallow backup.\r\n\r\n> allow to backup subset of partitions of MergeTree tables;\r\n> allow to backup whole databases or all server data;\r\n\r\nThe BACKUP query should allow these options.\r\n\r\nWhen we backup tables, the metadata (.sql) files will be enumerated by BackupInterator of Database.\r\nBackupIterator of Database will also iterate over BackupIterators for tables.\r\n\r\n> support for incremental backups\r\n\r\nBACKUP query will allow to specify previous backup (its location and total checksum).\r\nBackupWriter will write information about previous backup to metadata of current backup, check the contents of previous backup and don't write blobs that are identical.\r\n\r\n> support for tables on remote storage\r\n\r\nTables on remote storage will simply read remote data to provide blobs for backup.\r\nIt's appreciated if the contents of a backup for MergeTree table will be independent of the used VFS, and this table can be restored as a table on another VFS.\r\n\r\n> support for tables with symlinks or hardlinks\r\n\r\nJust write info in backup entry and skip writing blobs.\r\n\r\n> backup and restore of replicated tables\r\n\r\nSimply choose arbitrary replica for backup. When restore, use commands that will replicate and replace restored data.\r\n\r\n> backups are performed in streaming fashion, so +100% space is not required\r\n> backup process should not consume too much memory while performed\r\n\r\nBackupIterator only acquires snapshot of data. Blobs are enumerated and read in streaming fashion.\r\n\r\n> support for parallel writing of backup data to destination storage in multiple streams\r\n\r\nIt's Ok to get multiple entries from BackupIterator and read/write blobs in parallel. So, previous entry is not invalidated on iteration.\r\n\r\n> incremental backups should be optimized so reading the whole data is not necessarily if checksums can be quickly compared.\r\n\r\nWe have to store checksums of blobs in backup. When we do incremental backup, we have to compare checksums.\r\nFor MergeTree tables we already have checksums in most cases and we can compare them without reading blobs.\r\n\r\n> consistent snapshot whenever possible (for MergeTree tables), best effort when not possible\r\n\r\nWhen backup multiple tables, it's not currently possible to ensure that their state correspond to the single point of time.\r\nBackup will be partially consistent for now, but improvements will be possible.\r\n\r\n> support for different storage options via VFS\r\n\r\nBACKUP query should allow to provide path on filesystem along with disk for VFS or URL-like interface.\r\n\r\n> backups should be also useful for distribution of public datasets\r\n\r\nUse case: quickly obtain famous datasets from public s3 URL for testing.\r\nBackup will be restored as physically the same set of partitions - it's good for performance testing.\r\n\r\n> restore with partial replace (single partition, subset of tables);\r\n> changing of db/table/replica path on restore;\r\n\r\nRESTORE query should have these options.\r\n\r\n> allow to restore into different kind of database or table in some cases (Atomic database to Ordinary; ReplicatedMergeTree to MergeTree);\r\n\r\nBackup of Atomic database may mimic the structure of Ordinary database. So, the backups will look identical and can be restored into different kind of database.\r\nIt's also important to allow to restore e.g. ReplicatedMergeTree over S3 into MergeTree on local filesystem.\r\n\r\n> support for backups and restore of a cluster;\r\n\r\nIt should be out of scope in first implementation but it should be possible by:\r\n- iterating over all servers of a cluster;\r\n- processing only metadata for Distributed tables;\r\n- putting info about shard/replica number into backup.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13953/reactions","total_count":18,"+1":13,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":5,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13953/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13924","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13924/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13924/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13924/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/13924","id":682874626,"node_id":"MDU6SXNzdWU2ODI4NzQ2MjY=","number":13924,"title":"Create system table with server parameters","user":{"login":"qoega","id":2159081,"node_id":"MDQ6VXNlcjIxNTkwODE=","avatar_url":"https://avatars.githubusercontent.com/u/2159081?v=4","gravatar_id":"","url":"https://api.github.com/users/qoega","html_url":"https://github.com/qoega","followers_url":"https://api.github.com/users/qoega/followers","following_url":"https://api.github.com/users/qoega/following{/other_user}","gists_url":"https://api.github.com/users/qoega/gists{/gist_id}","starred_url":"https://api.github.com/users/qoega/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/qoega/subscriptions","organizations_url":"https://api.github.com/users/qoega/orgs","repos_url":"https://api.github.com/users/qoega/repos","events_url":"https://api.github.com/users/qoega/events{/privacy}","received_events_url":"https://api.github.com/users/qoega/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":845247686,"node_id":"MDU6TGFiZWw4NDUyNDc2ODY=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/usability","name":"usability","color":"ebf28c","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2020-08-20T16:24:31Z","updated_at":"2020-11-07T14:48:52Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"**Use case**\r\nWe want to read sever settings like `dns_cache_update_period` from SQL.\r\n\r\n**Describe the solution you'd like**\r\nCreate a wrapper that reads setting value and registers it in system table when used.\r\nFor example instead of \r\n``` c++\r\nconfig().getInt(\"dns_cache_update_period\", 15)\r\n```\r\n\r\nWe can have ConfigReader class with interface like \r\n``` c++\r\ngetInt(std::string path, int32 default, std::string description, bool hide_value, std::string scope)\r\n```\r\nWhen we call it we can add data to system table on startup.\r\nDescription can be used as one in system.settings. \r\n\r\n`scope` can be used to debug which parts of server use this setting if we don't want to ban usage of same setting from different server parts.\r\n\r\nWe may need to hide credentials.\r\n\r\nThere could be settings available in config but not used in server - we will not see them. It should be OK.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13924/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13924/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13907","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13907/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13907/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13907/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/13907","id":682444275,"node_id":"MDU6SXNzdWU2ODI0NDQyNzU=","number":13907,"title":"toColumnTypeName(toLowCardinality(...)) does not work","user":{"login":"hczhcz","id":3832986,"node_id":"MDQ6VXNlcjM4MzI5ODY=","avatar_url":"https://avatars.githubusercontent.com/u/3832986?v=4","gravatar_id":"","url":"https://api.github.com/users/hczhcz","html_url":"https://github.com/hczhcz","followers_url":"https://api.github.com/users/hczhcz/followers","following_url":"https://api.github.com/users/hczhcz/following{/other_user}","gists_url":"https://api.github.com/users/hczhcz/gists{/gist_id}","starred_url":"https://api.github.com/users/hczhcz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/hczhcz/subscriptions","organizations_url":"https://api.github.com/users/hczhcz/orgs","repos_url":"https://api.github.com/users/hczhcz/repos","events_url":"https://api.github.com/users/hczhcz/events{/privacy}","received_events_url":"https://api.github.com/users/hczhcz/received_events","type":"User","site_admin":false},"labels":[{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2020-08-20T06:11:54Z","updated_at":"2020-08-20T06:11:54Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Describe the unexpected behaviour**\r\nClickHouse reports an error on `toColumnTypeName(toLowCardinality(...))`.\r\n\r\n**How to reproduce**\r\n```sql\r\nSELECT toColumnTypeName(toLowCardinality(1))\r\n\r\nReceived exception from server (version 20.7.1):\r\nCode: 44. DB::Exception: Received from localhost:9000. DB::Exception: Cannot convert column `toColumnTypeName(toLowCardinality(1))` because it is non constant in source stream but must be constant in result. \r\n```\r\n\r\n**Additional context**\r\nI am not sure if it is unexpected. In comparison, `select toColumnTypeName(toNullable(1))` has no problem.\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13907/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13907/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13889","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13889/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13889/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13889/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/13889","id":681896700,"node_id":"MDU6SXNzdWU2ODE4OTY3MDA=","number":13889,"title":" A large array array join easily overflow memory","user":{"login":"melin","id":1145830,"node_id":"MDQ6VXNlcjExNDU4MzA=","avatar_url":"https://avatars.githubusercontent.com/u/1145830?v=4","gravatar_id":"","url":"https://api.github.com/users/melin","html_url":"https://github.com/melin","followers_url":"https://api.github.com/users/melin/followers","following_url":"https://api.github.com/users/melin/following{/other_user}","gists_url":"https://api.github.com/users/melin/gists{/gist_id}","starred_url":"https://api.github.com/users/melin/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/melin/subscriptions","organizations_url":"https://api.github.com/users/melin/orgs","repos_url":"https://api.github.com/users/melin/repos","events_url":"https://api.github.com/users/melin/events{/privacy}","received_events_url":"https://api.github.com/users/melin/received_events","type":"User","site_admin":false},"labels":[{"id":756395244,"node_id":"MDU6TGFiZWw3NTYzOTUyNDQ=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/performance","name":"performance","color":"c2e0c6","default":false,"description":null},{"id":1532016596,"node_id":"MDU6TGFiZWwxNTMyMDE2NTk2","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/memory","name":"memory","color":"e99695","default":false,"description":"When memory usage is higher than expected"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2020-08-19T14:41:40Z","updated_at":"2021-04-14T04:16:40Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":" A large array array join easily OOM，parameter settings to avoid memory overflow?\r\n```sql\r\nCREATE TABLE feature.join_1038_data_table\r\n(\r\n    `eventid` String,\r\n    `Rulename` String,\r\n    `time_time` UInt32,\r\n    `time_date` String,\r\n    `groupData` Array(Tuple(String, String, UInt32, String, UInt8, String))\r\n)\r\nENGINE = MergeTree()\r\nPRIMARY KEY eventid\r\nORDER BY eventid\r\nSETTINGS index_granularity = 8192 \r\n\r\n┌─column─────────────┬─any(type)───────────────────────────────────────────────────┬─compressed─┬─uncompressed─┬─sum(rows)─┐\r\n│ Rulename           │ String                                                      │ 479.00 B   │ 609.00 B     │        23 │\r\n│ groupData          │ Array(Tuple(String, String, UInt32, String, UInt8, String)) │ 2.56 MiB   │ 5.87 MiB     │        23 │\r\n│ group_field_concat │ String                                                      │ 479.00 B   │ 609.00 B     │        23 │\r\n└────────────────────┴─────────────────────────────────────────────────────────────┴────────────┴──────────────┴───────────┘\r\n\r\ndatainsight-d-006053.te.td :) select Rulename, length(groupData) as num from feature.group_1038_data_table order by num desc;\r\n\r\nSELECT\r\n    Rulename,\r\n    length(groupData) AS num\r\nFROM feature.group_1038_data_table\r\nORDER BY num DESC\r\n\r\n┌─Rulename────────────────────────────────┬───num─┐\r\n│ Custom Violation                        │ 72550 │\r\n│ Unknown Parameter                       │   848 │\r\n│ Parameter Type Violation                │   162 │\r\n│ Unauthorized Method for Known URL       │    71 │\r\n│ Unauthorized Content Type for Known URL │    69 │\r\n│ Parameter Value Length Violation        │    47 │\r\n│ Post Request - Missing Content Type     │    45 │\r\n│ HTTP Signature Violation                │    35 │\r\n│ Malformed JSON Message                  │    25 │\r\n│ SQL injection                           │    20 │\r\n│ Malformed URL                           │     8 │\r\n│ NULL Character in Parameter Value       │     8 │\r\n│ HTTP WebSocket Violation                │     6 │\r\n│ Unknown HTTP Request Method             │     5 │\r\n│ Required Parameter Not Found            │     4 │\r\n│ Cookie Tampering                        │     3 │\r\n│ Illegal Byte Code Character in URL      │     2 │\r\n│ NULL Character in Header Value          │     2 │\r\n│ Redundant UTF-8 Encoding                │     2 │\r\n│ URL is Above Root Directory             │     2 │\r\n└─────────────────────────────────────────┴───────┘\r\n┌─Rulename──────────────────────────┬─num─┐\r\n│ Cross-site scripting              │   1 │\r\n│ Redundant HTTP Headers            │   1 │\r\n│ Reuse of Expired Session's Cookie │   1 │\r\n└───────────────────────────────────┴─────┘\r\n\r\n23 rows in set. Elapsed: 0.027 sec.\r\n\r\ndatainsight-d-006053.te.td :) CREATE TABLE feature.join_1038_data_table      ENGINE = MergeTree()      PRIMARY KEY eventid      ORDER BY eventid AS        SELECT            tuple.1 AS eventid,            Rulename,            tuple.3 AS time_time,            tuple.4 AS time_date,            groupData AS groupData        FROM feature.group_1038_data_table       LEFT ARRAY JOIN groupData AS tuple\r\n\r\nCREATE TABLE feature.join_1038_data_table\r\nENGINE = MergeTree()\r\nPRIMARY KEY eventid\r\nORDER BY eventid AS\r\nSELECT\r\n    tuple.1 AS eventid,\r\n    Rulename,\r\n    tuple.3 AS time_time,\r\n    tuple.4 AS time_date,\r\n    groupData AS groupData\r\nFROM feature.group_1038_data_table\r\nLEFT ARRAY JOIN groupData AS tuple\r\n\r\n→ Progress: 20.00 rows, 8.41 MB (154.16 rows/s., 64.79 MB/s.)  70%\r\nReceived exception from server (version 20.6.3):\r\nCode: 241. DB::Exception: Received from localhost:9000. DB::Exception: Memory limit (for query) exceeded: would use 142.99 GiB (attempt to allocate chunk of 68719476736 bytes), maximum: 111.76 GiB.\r\n\r\n0 rows in set. Elapsed: 55.921 sec.\r\n\r\ndatainsight-d-006053.te.td :) show create table feature.join_1038_data_table;\r\n\r\nSHOW CREATE TABLE feature.join_1038_data_table\r\n```\r\n\r\n```\r\n            <max_block_size>20</max_block_size>\r\n            <max_insert_block_size>20</max_insert_block_size>\r\n            <log_queries>1</log_queries>\r\n            <log_query_threads>1</log_query_threads>\r\n            <max_threads>24</max_threads>\r\n            <max_bytes_before_external_group_by>40000000000</max_bytes_before_external_group_by>\r\n            <load_balancing>random</load_balancing>\r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13889/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13889/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13879","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13879/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13879/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13879/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/13879","id":681680117,"node_id":"MDU6SXNzdWU2ODE2ODAxMTc=","number":13879,"title":"ANN (Approximate Nearest Neighbor) search","user":{"login":"ZonghaoWang","id":11403656,"node_id":"MDQ6VXNlcjExNDAzNjU2","avatar_url":"https://avatars.githubusercontent.com/u/11403656?v=4","gravatar_id":"","url":"https://api.github.com/users/ZonghaoWang","html_url":"https://github.com/ZonghaoWang","followers_url":"https://api.github.com/users/ZonghaoWang/followers","following_url":"https://api.github.com/users/ZonghaoWang/following{/other_user}","gists_url":"https://api.github.com/users/ZonghaoWang/gists{/gist_id}","starred_url":"https://api.github.com/users/ZonghaoWang/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ZonghaoWang/subscriptions","organizations_url":"https://api.github.com/users/ZonghaoWang/orgs","repos_url":"https://api.github.com/users/ZonghaoWang/repos","events_url":"https://api.github.com/users/ZonghaoWang/events{/privacy}","received_events_url":"https://api.github.com/users/ZonghaoWang/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":1369940711,"node_id":"MDU6TGFiZWwxMzY5OTQwNzEx","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-ml","name":"comp-ml","color":"b5bcff","default":false,"description":"Machine Learning"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2020-08-19T09:14:01Z","updated_at":"2020-08-31T06:41:56Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"hi\r\n\r\nI am very impressive on the speed of Clickhouse, greet job\r\n\r\nNow, I want to add the feature search to clickhouse, search the nearest feature by euclidean distance. Oue feature is 512d float32, cost 2kB Spcae. It like this,\r\n![image](https://user-images.githubusercontent.com/11403656/90614601-78746d80-e23d-11ea-8531-c6006d7980f7.png)\r\n\r\nI use `featureNorm2 + queryNorm2 - 2 * arrayReduce('sum', arrayReduce(x, y -> feature, [queryArry]))` to calculate the distance .I mount the data dir to a Nvme(30Gbps), Clickhouse can use it up to 100%, process 1.5M rows per second, It is very fast.\r\n\r\nThere is a [PQalgrithm](https://hal.inria.fr/inria-00514462v2/document). It can make the 512d float32 to 32d UInt8, whose space decrease to 1/64.  But the query will become very large, for we will use a  LoopUpTable(32*256 float32), each numer in the 32duint8Array will search the recording 256d table. The sql like this\r\n\r\n```\r\nselect arrayReduce('sum', arrayMap(i, j -> [very long array 256 * 32 float]\r\n[i + (j * 256) + 1], pq_index, array(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31))) dis FROM FeatureInt8Merged order by dis limit 100\r\n```\r\n\r\nWhat I want ask is, the sql above can not use the IO up to 100%, theoretically，this sql will process 90M rows per second, but In fact it can only process 30M rows per second. How I can improve this","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13879/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13879/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13851","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13851/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13851/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13851/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/13851","id":680926385,"node_id":"MDU6SXNzdWU2ODA5MjYzODU=","number":13851,"title":"Close connections to MySQL source, add mysql connection timeout","user":{"login":"Artemeey","id":4234863,"node_id":"MDQ6VXNlcjQyMzQ4NjM=","avatar_url":"https://avatars.githubusercontent.com/u/4234863?v=4","gravatar_id":"","url":"https://api.github.com/users/Artemeey","html_url":"https://github.com/Artemeey","followers_url":"https://api.github.com/users/Artemeey/followers","following_url":"https://api.github.com/users/Artemeey/following{/other_user}","gists_url":"https://api.github.com/users/Artemeey/gists{/gist_id}","starred_url":"https://api.github.com/users/Artemeey/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Artemeey/subscriptions","organizations_url":"https://api.github.com/users/Artemeey/orgs","repos_url":"https://api.github.com/users/Artemeey/repos","events_url":"https://api.github.com/users/Artemeey/events{/privacy}","received_events_url":"https://api.github.com/users/Artemeey/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":2121263626,"node_id":"MDU6TGFiZWwyMTIxMjYzNjI2","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-mysql","name":"comp-mysql","color":"b5bcff","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2020-08-18T10:47:27Z","updated_at":"2020-08-19T11:42:03Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"Сейчас clickhouse не закрывает соединения, после обращения к движку MySQL.\r\nВ случае нечастых обращений к MySQL или при отсутствии постоянного использования всех открытых соединений, часть соединений будет закрываться сервером MySQL при превышении wait timeout.\r\n\r\nПри этом в лог ошибок MySQL поступает подообная информация:\r\n`[Warning] Aborted connection 21856569 to db: 'default' user: 'clickhouse' host: '172.20.0.2' (Got timeout reading communication packets)`\r\n\r\nВместе с этим растут показатели MySQL Aborted clients и Aborted connects, это мешает адекватному анализу работы MySQL.\r\n\r\nПохожее : https://github.com/ClickHouse/ClickHouse/issues/893","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13851/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13851/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13843","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13843/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13843/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13843/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/13843","id":680497507,"node_id":"MDU6SXNzdWU2ODA0OTc1MDc=","number":13843,"title":"numbers(N) doesn't work with WITH Caluse","user":{"login":"yamrzou","id":40591511,"node_id":"MDQ6VXNlcjQwNTkxNTEx","avatar_url":"https://avatars.githubusercontent.com/u/40591511?v=4","gravatar_id":"","url":"https://api.github.com/users/yamrzou","html_url":"https://github.com/yamrzou","followers_url":"https://api.github.com/users/yamrzou/followers","following_url":"https://api.github.com/users/yamrzou/following{/other_user}","gists_url":"https://api.github.com/users/yamrzou/gists{/gist_id}","starred_url":"https://api.github.com/users/yamrzou/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yamrzou/subscriptions","organizations_url":"https://api.github.com/users/yamrzou/orgs","repos_url":"https://api.github.com/users/yamrzou/repos","events_url":"https://api.github.com/users/yamrzou/events{/privacy}","received_events_url":"https://api.github.com/users/yamrzou/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2020-08-17T20:12:10Z","updated_at":"2020-08-17T20:30:50Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"This query:\r\n```\r\nWITH 10 AS n\r\nSELECT *\r\nFROM numbers(n)\r\n```\r\nOr this query:\r\n```\r\nWITH cast(10, 'UInt64') AS n\r\nSELECT *\r\nFROM numbers(n)\r\n```\r\n\r\nReturns:\r\n```\r\nReceived exception from server (version 20.6.3):\r\nCode: 170. DB::Exception: Received from localhost:9000. DB::Exception: Bad get: has String, requested UInt64.\r\n```\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13843/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13843/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13838","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13838/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13838/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13838/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/13838","id":680291214,"node_id":"MDU6SXNzdWU2ODAyOTEyMTQ=","number":13838,"title":"MV uses columns positions during populate, and columns names otherwise","user":{"login":"den-crane","id":19737682,"node_id":"MDQ6VXNlcjE5NzM3Njgy","avatar_url":"https://avatars.githubusercontent.com/u/19737682?v=4","gravatar_id":"","url":"https://api.github.com/users/den-crane","html_url":"https://github.com/den-crane","followers_url":"https://api.github.com/users/den-crane/followers","following_url":"https://api.github.com/users/den-crane/following{/other_user}","gists_url":"https://api.github.com/users/den-crane/gists{/gist_id}","starred_url":"https://api.github.com/users/den-crane/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/den-crane/subscriptions","organizations_url":"https://api.github.com/users/den-crane/orgs","repos_url":"https://api.github.com/users/den-crane/repos","events_url":"https://api.github.com/users/den-crane/events{/privacy}","received_events_url":"https://api.github.com/users/den-crane/received_events","type":"User","site_admin":false},"labels":[{"id":845247686,"node_id":"MDU6TGFiZWw4NDUyNDc2ODY=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/usability","name":"usability","color":"ebf28c","default":false,"description":""},{"id":1350221495,"node_id":"MDU6TGFiZWwxMzUwMjIxNDk1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-matview","name":"comp-matview","color":"b5bcff","default":false,"description":"Materialized views"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2020-08-17T14:44:29Z","updated_at":"2020-08-18T09:54:07Z","closed_at":null,"author_association":"COLLABORATOR","active_lock_reason":null,"body":"20.7.1.4189\r\n```\r\n\r\ncreate table test1(a Int64, b Float64) Engine=MergeTree order by a\r\n\r\ninsert into test1 values(1,1);\r\n\r\ncreate materialized view test1MV(a Int64, b Float64) Engine=SummingMergeTree order by (a) \r\npopulate as select a, sum(b) from test1 group by a;\r\n\r\nselect * from test1MV;\r\n\r\n┌─a─┬─b─┐\r\n│ 1 │ 1 │\r\n└───┴───┘\r\n\r\ninsert into test1 values(1,1),(2,1);\r\n\r\nselect * from test1MV;\r\n\r\n┌─a─┬─b─┐\r\n│ 1 │ 1 │\r\n└───┴───┘\r\n┌─a─┬─b─┐\r\n│ 1 │ 0 │\r\n│ 2 │ 0 │\r\n└───┴───┘\r\n```\r\n\r\n\r\n\r\nEXPECTED \r\n```\r\ncreate table test1(a Int64, b Float64) Engine=MergeTree order by a\r\n\r\ninsert into test1 values(1,1);\r\n\r\ncreate materialized view test1MV(a Int64, b Float64) Engine=SummingMergeTree order by (a) \r\npopulate as select a, sum(b) from test1 group by a;\r\n\r\nselect * from test1MV;\r\n\r\n┌─a─┬─b─┐\r\n│ 1 │ 0 │\r\n└───┴───┘\r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13838/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13838/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13826","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13826/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13826/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13826/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/13826","id":680073467,"node_id":"MDU6SXNzdWU2ODAwNzM0Njc=","number":13826,"title":"Allow to attach a part/partition from a table with more granular partitioning.","user":{"login":"filimonov","id":1549571,"node_id":"MDQ6VXNlcjE1NDk1NzE=","avatar_url":"https://avatars.githubusercontent.com/u/1549571?v=4","gravatar_id":"","url":"https://api.github.com/users/filimonov","html_url":"https://github.com/filimonov","followers_url":"https://api.github.com/users/filimonov/followers","following_url":"https://api.github.com/users/filimonov/following{/other_user}","gists_url":"https://api.github.com/users/filimonov/gists{/gist_id}","starred_url":"https://api.github.com/users/filimonov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/filimonov/subscriptions","organizations_url":"https://api.github.com/users/filimonov/orgs","repos_url":"https://api.github.com/users/filimonov/repos","events_url":"https://api.github.com/users/filimonov/events{/privacy}","received_events_url":"https://api.github.com/users/filimonov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":1507888214,"node_id":"MDU6TGFiZWwxNTA3ODg4MjE0","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/st-accepted","name":"st-accepted","color":"e5b890","default":false,"description":"The issue is in our backlog, ready to take"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":4,"created_at":"2020-08-17T09:08:16Z","updated_at":"2021-04-20T18:27:46Z","closed_at":null,"author_association":"COLLABORATOR","active_lock_reason":null,"body":"if there are 2 table which differs only in the partitioning key and the part from source table matches single partition in target table - allow that (may be with setting like 'allow_attaching_compatible_partitioning_key_parts`).\r\n\r\n```\r\ncreate table source engine=MergeTree ORDER BY tuple() PARTITION BY toYYYYMMDD(timestamp) AS SELECT number, toDateTime('2010-01-01 00:00:00') as timestamp from numbers(100);\r\n\r\ncreate table target engine=MergeTree ORDER BY tuple() PARTITION BY toYYYYMM(timestamp) AS SELECT number, toDateTime('2010-01-01 00:00:00') as timestamp from numbers(100);\r\n\r\nALTER TABLE target ATTACH PARTITION ID '20100101' FROM source;\r\n```\r\n\r\n```\r\nCode: 36, e.displayText() = DB::Exception: Tables have different partition key (version 20.7.1.4186 (official build)) (from 127.0.0.1:39986) (in query: ALTER TABLE target ATTACH PARTITION ID '20100101' FROM source;), Stack trace (when copying this message, always include the lines below):\r\n\r\n0. /build/obj-x86_64-linux-gnu/../contrib/poco/Foundation/src/Exception.cpp:27: Poco::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int) @ 0x123b04c0 in /usr/lib/debug/usr/bin/clickhouse\r\n1. /build/obj-x86_64-linux-gnu/../src/Common/Exception.cpp:37: DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int) @ 0xa2a02bd in /usr/lib/debug/usr/bin/clickhouse\r\n2. /build/obj-x86_64-linux-gnu/../contrib/libcxx/include/string:2134: DB::MergeTreeData::checkStructureAndGetMergeTreeData(DB::IStorage&, std::__1::shared_ptr<DB::StorageInMemoryMetadata const> const&, std::__1::shared_ptr<DB::StorageInMemoryMetadata const> const&) const (.cold) @ 0xf8a32f9 in /usr/lib/debug/usr/bin/clickhouse\r\n3. /build/obj-x86_64-linux-gnu/../src/Storages/StorageMergeTree.cpp:1146: DB::StorageMergeTree::replacePartitionFrom(std::__1::shared_ptr<DB::IStorage> const&, std::__1::shared_ptr<DB::IAST> const&, bool, DB::Context const&) @ 0xf6a7100 in /usr/lib/debug/usr/bin/clickhouse\r\n4. /build/obj-x86_64-linux-gnu/../src/Storages/StorageMergeTree.cpp:1057: DB::StorageMergeTree::alterPartition(std::__1::shared_ptr<DB::IAST> const&, std::__1::shared_ptr<DB::StorageInMemoryMetadata const> const&, std::__1::vector<DB::PartitionCommand, std::__1::allocator<DB::PartitionCommand> > const&, DB::Context const&) @ 0xf6aa4bf in /usr/lib/debug/usr/bin/clickhouse\r\n5. /build/obj-x86_64-linux-gnu/../contrib/libcxx/include/vector:662: DB::InterpreterAlterQuery::execute() @ 0xf169433 in /usr/lib/debug/usr/bin/clickhouse\r\n6. /build/obj-x86_64-linux-gnu/../src/Interpreters/executeQuery.cpp:386: DB::executeQueryImpl(char const*, char const*, DB::Context&, bool, DB::QueryProcessingStage::Enum, bool, DB::ReadBuffer*) @ 0xf4d1bc2 in /usr/lib/debug/usr/bin/clickhouse\r\n7. /build/obj-x86_64-linux-gnu/../src/Interpreters/executeQuery.cpp:655: DB::executeQuery(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, DB::Context&, bool, DB::QueryProcessingStage::Enum, bool) @ 0xf4d5405 in /usr/lib/debug/usr/bin/clickhouse\r\n8. /build/obj-x86_64-linux-gnu/../src/Server/TCPHandler.cpp:253: DB::TCPHandler::runImpl() @ 0xfb39ba3 in /usr/lib/debug/usr/bin/clickhouse\r\n9. /build/obj-x86_64-linux-gnu/../src/Server/TCPHandler.cpp:1215: DB::TCPHandler::run() @ 0xfb3a99e in /usr/lib/debug/usr/bin/clickhouse\r\n10. /build/obj-x86_64-linux-gnu/../contrib/poco/Net/src/TCPServerConnection.cpp:57: Poco::Net::TCPServerConnection::start() @ 0x122ce2eb in /usr/lib/debug/usr/bin/clickhouse\r\n11. /build/obj-x86_64-linux-gnu/../contrib/libcxx/include/atomic:856: Poco::Net::TCPServerDispatcher::run() @ 0x122ce77b in /usr/lib/debug/usr/bin/clickhouse\r\n12. /build/obj-x86_64-linux-gnu/../contrib/poco/Foundation/include/Poco/Mutex_POSIX.h:59: Poco::PooledThread::run() @ 0x1244d2a6 in /usr/lib/debug/usr/bin/clickhouse\r\n13. /build/obj-x86_64-linux-gnu/../contrib/poco/Foundation/include/Poco/AutoPtr.h:223: Poco::ThreadImpl::runnableEntry(void*) @ 0x124486a0 in /usr/lib/debug/usr/bin/clickhouse\r\n14. start_thread @ 0x9609 in /lib/x86_64-linux-gnu/libpthread-2.31.so\r\n15. /build/glibc-YYA7BZ/glibc-2.31/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:97: __clone @ 0x122103 in /usr/lib/debug/lib/x86_64-linux-gnu/libc-2.31.so\r\n\r\n\r\nReceived exception from server (version 20.7.1):\r\nCode: 36. DB::Exception: Received from localhost:9000. DB::Exception: Tables have different partition key. \r\n```\r\n\r\nInternally what should happen:\r\n1) we copy (by hardlinks) the part (as now)\r\n2) we recalculate min/max for the column used in partitioning key if it ends up with different partitions - fail with exception, if it's a single partitions - write new minmax file (see IMergeTreeDataPart::MinMaxIndex)\r\n3) recalc checksum file\r\n4) do rest as usual\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13826/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13826/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13815","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13815/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13815/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13815/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/13815","id":679793059,"node_id":"MDU6SXNzdWU2Nzk3OTMwNTk=","number":13815,"title":"The setting 'merge_tree_min_bytes_for_concurrent_read' may be suboptimal.","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":756395244,"node_id":"MDU6TGFiZWw3NTYzOTUyNDQ=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/performance","name":"performance","color":"c2e0c6","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2020-08-16T17:30:28Z","updated_at":"2021-11-30T02:16:41Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"I've created a table with queries `CREATE TABLE queries (query String) ENGINE = MergeTree ORDER BY query`, total 829 481 rows. The average string size is 1300 bytes. Compression rate is 14 times.\r\n\r\nWhen I run a query\r\n```\r\nSELECT uniq(normalizeQuery(query)) FROM queries\r\n```\r\n\r\n(the `normalizeQuery` function is not available yet, I develop it in my peaceful evening)\r\n\r\nIt is using 4 threads. But I have 16 physical cores on my machine.\r\n\r\nWhen I run it with lower values of the following settings:\r\n```\r\nclickhouse-benchmark --merge_tree_min_rows_for_concurrent_read 1 --merge_tree_min_bytes_for_concurrent_read 1 <<< \"SELECT uniq(normalizeQuery(query)) FROM queries\"\r\n```\r\n\r\nIt is using 16 threads and runs ~3.5 times faster.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13815/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13815/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13655","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13655/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13655/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13655/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/13655","id":677857903,"node_id":"MDU6SXNzdWU2Nzc4NTc5MDM=","number":13655,"title":"insert into engine join (and memory) with select from itself hangs forever","user":{"login":"den-crane","id":19737682,"node_id":"MDQ6VXNlcjE5NzM3Njgy","avatar_url":"https://avatars.githubusercontent.com/u/19737682?v=4","gravatar_id":"","url":"https://api.github.com/users/den-crane","html_url":"https://github.com/den-crane","followers_url":"https://api.github.com/users/den-crane/followers","following_url":"https://api.github.com/users/den-crane/following{/other_user}","gists_url":"https://api.github.com/users/den-crane/gists{/gist_id}","starred_url":"https://api.github.com/users/den-crane/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/den-crane/subscriptions","organizations_url":"https://api.github.com/users/den-crane/orgs","repos_url":"https://api.github.com/users/den-crane/repos","events_url":"https://api.github.com/users/den-crane/events{/privacy}","received_events_url":"https://api.github.com/users/den-crane/received_events","type":"User","site_admin":false},"labels":[{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2020-08-12T17:26:52Z","updated_at":"2020-08-12T17:26:52Z","closed_at":null,"author_association":"COLLABORATOR","active_lock_reason":null,"body":"```\r\nCREATE TABLE test(\r\n id UInt64 MATERIALIZED farmHash64(val1),\r\n val1 String,\r\n val2 String\r\n) \r\nENGINE=Join(ANY, LEFT, id)\r\nSETTINGS join_any_take_last_row = 1\r\n\r\nINSERT INTO TABLE test (val1, val2) VALUES ('a', 'b')\r\n\r\nINSERT INTO test (val1, val2)\r\nSELECT val1, 'c' \r\nFROM test \r\nWHERE val1='a'\r\n\r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13655/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13655/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13653","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13653/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13653/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13653/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/13653","id":677808987,"node_id":"MDU6SXNzdWU2Nzc4MDg5ODc=","number":13653,"title":"Unexpected type inequality","user":{"login":"greenbergjosh","id":18703777,"node_id":"MDQ6VXNlcjE4NzAzNzc3","avatar_url":"https://avatars.githubusercontent.com/u/18703777?v=4","gravatar_id":"","url":"https://api.github.com/users/greenbergjosh","html_url":"https://github.com/greenbergjosh","followers_url":"https://api.github.com/users/greenbergjosh/followers","following_url":"https://api.github.com/users/greenbergjosh/following{/other_user}","gists_url":"https://api.github.com/users/greenbergjosh/gists{/gist_id}","starred_url":"https://api.github.com/users/greenbergjosh/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/greenbergjosh/subscriptions","organizations_url":"https://api.github.com/users/greenbergjosh/orgs","repos_url":"https://api.github.com/users/greenbergjosh/repos","events_url":"https://api.github.com/users/greenbergjosh/events{/privacy}","received_events_url":"https://api.github.com/users/greenbergjosh/received_events","type":"User","site_admin":false},"labels":[{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2020-08-12T16:04:15Z","updated_at":"2020-10-09T16:35:10Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"select [(toUInt8(3), toUInt8(3))] = [(toInt16(3), toInt16(3))]  -- true\r\n\r\nselect hasAny([(toInt16(3), toInt16(3))],[(toInt16(3), toInt16(3))])  -- true\r\n\r\nselect arrayFilter(x -> x = (toInt16(3), toInt16(3)), arrayZip([toUInt8(3)], [toUInt8(3)]))  -- [(3,3)]\r\n\r\nselect hasAny([(toUInt8(3), toUInt8(3))],[(toInt16(3), toInt16(3))])  -- false, odd man out\r\n\r\nI would have expected the last one to return true (1).  I am being explicit with types to show the issue.  This actually came up when doing something more like:\r\n\r\n-- x.a and x.b are columns of type array(Int16)\r\n\r\n-- clickhouse makes the constant literal 3 have type UInt8\r\n\r\nselect hasAny(arrayZip(x.a, x.b), (3,3)) from table \r\n\r\nThe query above never returns true (1).  I can make it work with explicit casting.\r\n\r\nselect hasAny(arrayZip(x.a, x.b), (toInt16(3),toInt16(3))) from table \r\n\r\nBut, that feels a bit heavy and inconsistent.\r\n\r\nIs this maybe related to covariant typing for clickhouse functions?  Is it expected behavior?  Is there a better workaround than the explicit casting.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13653/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13653/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13621","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13621/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13621/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13621/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/13621","id":677096503,"node_id":"MDU6SXNzdWU2NzcwOTY1MDM=","number":13621,"title":"Tips about database schema.","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2020-08-11T18:25:22Z","updated_at":"2020-08-11T18:25:22Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"Implement some heuristics to detect suboptimal database schema.\r\nExample: huge number of tables with similar structure.\r\n\r\nThese heuristics should be implemented in very lightweight and independent manner, so anyone can add/remove them in non-intrusive way.\r\n\r\nClickHouse can run them on server startup and generate \"tips\".\r\n\r\nTips can be displayed in log, or with special command or in clickhouse-client (in unobtrusive way).","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13621/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13621/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13592","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13592/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13592/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13592/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/13592","id":676551996,"node_id":"MDU6SXNzdWU2NzY1NTE5OTY=","number":13592,"title":"DB::Exception: Newly added column B has a default expression, so adding expressions that use it to the sorting key is forbidden.","user":{"login":"den-crane","id":19737682,"node_id":"MDQ6VXNlcjE5NzM3Njgy","avatar_url":"https://avatars.githubusercontent.com/u/19737682?v=4","gravatar_id":"","url":"https://api.github.com/users/den-crane","html_url":"https://github.com/den-crane","followers_url":"https://api.github.com/users/den-crane/followers","following_url":"https://api.github.com/users/den-crane/following{/other_user}","gists_url":"https://api.github.com/users/den-crane/gists{/gist_id}","starred_url":"https://api.github.com/users/den-crane/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/den-crane/subscriptions","organizations_url":"https://api.github.com/users/den-crane/orgs","repos_url":"https://api.github.com/users/den-crane/repos","events_url":"https://api.github.com/users/den-crane/events{/privacy}","received_events_url":"https://api.github.com/users/den-crane/received_events","type":"User","site_admin":false},"labels":[{"id":845247686,"node_id":"MDU6TGFiZWw4NDUyNDc2ODY=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/usability","name":"usability","color":"ebf28c","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2020-08-11T03:31:09Z","updated_at":"2020-11-20T22:41:50Z","closed_at":null,"author_association":"COLLABORATOR","active_lock_reason":null,"body":"```\r\ncreate table mx(A Int64) Engine=MergeTree order by A;\r\n\r\nalter table mx add column B Int64 default 111, modify order by (A,B);\r\n\r\nDB::Exception: Newly added column B has a default expression, so adding expressions that use it to the sorting key is forbidden.\r\n\r\n```\r\nThis behaviour has no sense. I don't see a reason why it's forbidden.\r\n\r\nMoreover there is a workaround:  \r\n\r\n```\r\nalter table mx add column B Int64 , modify order by (A,B);\r\nalter table mx modify column B default 111;\r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13592/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13592/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13574","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13574/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13574/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13574/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/13574","id":676083394,"node_id":"MDU6SXNzdWU2NzYwODMzOTQ=","number":13574,"title":"Self-balancing architecture: Moving parts between shards","user":{"login":"xjewer","id":922743,"node_id":"MDQ6VXNlcjkyMjc0Mw==","avatar_url":"https://avatars.githubusercontent.com/u/922743?v=4","gravatar_id":"","url":"https://api.github.com/users/xjewer","html_url":"https://github.com/xjewer","followers_url":"https://api.github.com/users/xjewer/followers","following_url":"https://api.github.com/users/xjewer/following{/other_user}","gists_url":"https://api.github.com/users/xjewer/gists{/gist_id}","starred_url":"https://api.github.com/users/xjewer/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/xjewer/subscriptions","organizations_url":"https://api.github.com/users/xjewer/orgs","repos_url":"https://api.github.com/users/xjewer/repos","events_url":"https://api.github.com/users/xjewer/events{/privacy}","received_events_url":"https://api.github.com/users/xjewer/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":12,"created_at":"2020-08-10T12:03:10Z","updated_at":"2021-02-24T00:02:16Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"## Issue:\r\n\r\nSo far ClickHouse as a data store shifts the responsibility of the balancing to an operator to provide inbound data flow in\r\na balanced manner - that is to say, once data is written to any of shards, it's hard to move it around involving manual interventions \r\neither tricking read pipeline by building a table with MergeEngine on top and copying partitions around or manually move parts with \r\ninevitable maintenance windows with partial response. Needless to say, it's cumbersome and exausting.\r\n\r\n## Proposal:\r\n\r\nThe proposal doesn’t cover entire self-balancing architecture, rather suggests an extension of `ALTER TABLE table MOVE PARTITION|PART`\r\nto be able to move parts between shards seamless.\r\n\r\nSimilar to `MOVING PARTITION|PART to a disk|volume to DISK|VOLUME,` proposed syntax is:\r\n\r\n```\r\nALTER TABLE table_name MOVE PARTITION|PART partition_expr TO SHARD 'shard_id'\r\n```\r\n\r\nThe process is sketchy explained as follows:\r\n1. ClickHouse won't include in upcoming merges or stops running merges with moving parts\r\n2. Copy data to a designated shard (all live replica) to detached directory\r\n3. When the copy is done, initiate a part attachment on a new node:\r\n    a. mark moving parts on an old node as OLD, during SELECTs return to a root executor all OLD part ids that were processed during query\r\n    b. mark moving parts on a new node as NEW and ATTACH part locally on replicas, during SELECTs return to a root executor all NEW part ids that were processed during a query\r\n    c. remove part from an old node\r\n    d. remove NEW mark from parts on a new node.\r\nDuring SELECTS against the cluster, root executor (a node that gets initial query from the client) will retry query to an old leaf node, if the result from the cluster has intersections between OLD and NEW part ids,  e.g. using virtual columns:\r\n```\r\nwhere _part != '202007_7145_7145_0\r\n```\r\n\r\nThis is a pessimistic scenario when a SELECT hits both parts in old and new nodes during steps 3.b - 3.c. Depending on the data access pattern it's possible to consider a further optimization where OLD node can precompute both results with and without OLD parts.\r\n\r\nUPDATE:\r\n\r\nIRL @nvartolomei raised a few concerns regarding the concept:\r\n1. Parts don’t necessary have the same names between shards\r\n2. Re-attaching a part changes it’s name by renumbering a block_id suffix.\r\n\r\nBoth of those can be covered by extending a metadata of a part during movement: \r\nnot only add an OLD/NEW marker, but also uniq identifier, that can be discarded later when the movement is complete.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13574/reactions","total_count":3,"+1":3,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13574/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13544","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13544/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13544/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13544/events","html_url":"https://github.com/ClickHouse/ClickHouse/pull/13544","id":675686917,"node_id":"MDExOlB1bGxSZXF1ZXN0NDY1MTQyNjUy","number":13544,"title":"Multi-Disk auto-recovery.","user":{"login":"amosbird","id":5085485,"node_id":"MDQ6VXNlcjUwODU0ODU=","avatar_url":"https://avatars.githubusercontent.com/u/5085485?v=4","gravatar_id":"","url":"https://api.github.com/users/amosbird","html_url":"https://github.com/amosbird","followers_url":"https://api.github.com/users/amosbird/followers","following_url":"https://api.github.com/users/amosbird/following{/other_user}","gists_url":"https://api.github.com/users/amosbird/gists{/gist_id}","starred_url":"https://api.github.com/users/amosbird/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/amosbird/subscriptions","organizations_url":"https://api.github.com/users/amosbird/orgs","repos_url":"https://api.github.com/users/amosbird/repos","events_url":"https://api.github.com/users/amosbird/events{/privacy}","received_events_url":"https://api.github.com/users/amosbird/received_events","type":"User","site_admin":false},"labels":[{"id":1304141686,"node_id":"MDU6TGFiZWwxMzA0MTQxNjg2","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/pr-improvement","name":"pr-improvement","color":"007700","default":false,"description":"Pull request with some product improvements"},{"id":1807683251,"node_id":"MDU6TGFiZWwxODA3NjgzMjUx","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/doc-alert","name":"doc-alert","color":"e51068","default":false,"description":"PR where any documentation work is needed or proceeded"}],"state":"open","locked":false,"assignee":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"assignees":[{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false}],"milestone":null,"comments":9,"created_at":"2020-08-09T11:54:44Z","updated_at":"2022-01-30T00:26:48Z","closed_at":null,"author_association":"COLLABORATOR","active_lock_reason":null,"draft":false,"pull_request":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/pulls/13544","html_url":"https://github.com/ClickHouse/ClickHouse/pull/13544","diff_url":"https://github.com/ClickHouse/ClickHouse/pull/13544.diff","patch_url":"https://github.com/ClickHouse/ClickHouse/pull/13544.patch","merged_at":null},"body":"I hereby agree to the terms of the CLA available at: https://yandex.ru/legal/cla/?lang=en\r\n\r\nChangelog category (leave one):\r\n- Improvement\r\n\r\nChangelog entry (a user-readable short description of the changes that goes to CHANGELOG.md):\r\n\r\nNow ReplicatedMergeTree can recover data when some of its disks are broken.\r\n\r\nDetailed description / Documentation draft:\r\n\r\n~~This PR can be viewed as semi-WIP. It works fine but lacks thorough tests (Also I don't know good ways of constructing CI tests for it).~~\r\n\r\nNOTE, if all disks are broken, the instance is still alive but will not recover data after some disks become alive. Manual `SYSTEM REPLICA SYNC` command is needed.\r\n\r\n### update\r\n\r\nThis PR has been used more than half year in production and has recovered hundreds of disks. I'll start making reasonable CI test for it.\r\n\r\n### update 2\r\n\r\nCI tests are added.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13544/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13544/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13541","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13541/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13541/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13541/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/13541","id":675646122,"node_id":"MDU6SXNzdWU2NzU2NDYxMjI=","number":13541,"title":"Ability to write Parquet with configured compression / codec (snappy, gzip etc) ","user":{"login":"alanpaulkwan","id":8321252,"node_id":"MDQ6VXNlcjgzMjEyNTI=","avatar_url":"https://avatars.githubusercontent.com/u/8321252?v=4","gravatar_id":"","url":"https://api.github.com/users/alanpaulkwan","html_url":"https://github.com/alanpaulkwan","followers_url":"https://api.github.com/users/alanpaulkwan/followers","following_url":"https://api.github.com/users/alanpaulkwan/following{/other_user}","gists_url":"https://api.github.com/users/alanpaulkwan/gists{/gist_id}","starred_url":"https://api.github.com/users/alanpaulkwan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alanpaulkwan/subscriptions","organizations_url":"https://api.github.com/users/alanpaulkwan/orgs","repos_url":"https://api.github.com/users/alanpaulkwan/repos","events_url":"https://api.github.com/users/alanpaulkwan/events{/privacy}","received_events_url":"https://api.github.com/users/alanpaulkwan/received_events","type":"User","site_admin":false},"labels":[{"id":386401508,"node_id":"MDU6TGFiZWwzODY0MDE1MDg=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/help%20wanted","name":"help wanted","color":"128A0C","default":true,"description":null},{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":1401255404,"node_id":"MDU6TGFiZWwxNDAxMjU1NDA0","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-formats","name":"comp-formats","color":"b5bcff","default":false,"description":"Input / output formats"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2020-08-09T06:26:53Z","updated_at":"2020-12-03T13:16:41Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"It'd be great to be able to specify the Parquet codec for compression. SNAPPY for example has different properties than GZIP. It's not clear to me what Clickhouse currently uses. \r\n\r\nThanks.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13541/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13541/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13493","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13493/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13493/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13493/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/13493","id":675105105,"node_id":"MDU6SXNzdWU2NzUxMDUxMDU=","number":13493,"title":"'-Resample' combinator limitations","user":{"login":"RikeVoltz","id":23209943,"node_id":"MDQ6VXNlcjIzMjA5OTQz","avatar_url":"https://avatars.githubusercontent.com/u/23209943?v=4","gravatar_id":"","url":"https://api.github.com/users/RikeVoltz","html_url":"https://github.com/RikeVoltz","followers_url":"https://api.github.com/users/RikeVoltz/followers","following_url":"https://api.github.com/users/RikeVoltz/following{/other_user}","gists_url":"https://api.github.com/users/RikeVoltz/gists{/gist_id}","starred_url":"https://api.github.com/users/RikeVoltz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/RikeVoltz/subscriptions","organizations_url":"https://api.github.com/users/RikeVoltz/orgs","repos_url":"https://api.github.com/users/RikeVoltz/repos","events_url":"https://api.github.com/users/RikeVoltz/events{/privacy}","received_events_url":"https://api.github.com/users/RikeVoltz/received_events","type":"User","site_admin":false},"labels":[{"id":845247686,"node_id":"MDU6TGFiZWw4NDUyNDc2ODY=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/usability","name":"usability","color":"ebf28c","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":16,"created_at":"2020-08-07T15:53:29Z","updated_at":"2020-08-12T11:30:36Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"**Describe the issue**\r\nAggregate functions with -Resample combinator don't work with some expressions that can be pre-evaluated and converted to constants.\r\n\r\n**How to reproduce**\r\n```sql\r\nCREATE TABLE IF NOT EXISTS Test\r\n(\r\n    `time` DateTime, \r\n    `id` Int32\r\n)\r\nENGINE = Memory();\r\nINSERT INTO Test VALUES ('2020-08-07 01:03:05',1), ('2020-08-07 01:03:06',2), \r\n                        ('2020-08-07 04:08:12',3), ('2020-08-07 15:06:13',4), \r\n                        ('2020-08-07 15:06:14',5), ('2020-08-07 15:06:15',6);\r\n```\r\nFollowing queries give the same exception:\r\n```sql\r\nSELECT countResample(toDateTime('2020-08-07 00:00:00'), toDateTime('2020-08-08 00:00:00'), INTERVAL 1 HOUR)(id, time) FROM Test;\r\nSELECT countResample(toUnixTimestamp('2020-08-07 00:00:00'), toUnixTimestamp('2020-08-08 00:00:00'), INTERVAL 1 HOUR)(id, time) FROM Test;\r\nSELECT countResample(toUnixTimestamp('2020-08-07 00:00:00'), toUnixTimestamp('2020-08-08 00:00:00'), 3600)(id, time) FROM Test;\r\nSELECT countResample(1596747600, 1596834000, INTERVAL 1 HOUR)(id, time) FROM Test;\r\n```\r\n**Expected behavior**\r\n```sql\r\nSELECT countResample(1596747600, 1596834000, 3600)(id, time) FROM Test;\r\n\r\n┌─countResample(1596747600, 1596834000, 3600)(id, time)─┐\r\n│ [0,2,0,0,1,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0]     │\r\n└───────────────────────────────────────────────────────┘\r\n\r\n```\r\n\r\n\r\n**Error message and/or stacktrace**\r\n`Code: 134. DB::Exception: Received from localhost:19019. DB::Exception: Parameters to aggregate functions must be literals.`\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13493/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13493/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13453","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13453/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13453/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13453/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/13453","id":674938619,"node_id":"MDU6SXNzdWU2NzQ5Mzg2MTk=","number":13453,"title":"SELECT * from subqueries with repeated columns return only unique columns","user":{"login":"jrogov","id":9301440,"node_id":"MDQ6VXNlcjkzMDE0NDA=","avatar_url":"https://avatars.githubusercontent.com/u/9301440?v=4","gravatar_id":"","url":"https://api.github.com/users/jrogov","html_url":"https://github.com/jrogov","followers_url":"https://api.github.com/users/jrogov/followers","following_url":"https://api.github.com/users/jrogov/following{/other_user}","gists_url":"https://api.github.com/users/jrogov/gists{/gist_id}","starred_url":"https://api.github.com/users/jrogov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jrogov/subscriptions","organizations_url":"https://api.github.com/users/jrogov/orgs","repos_url":"https://api.github.com/users/jrogov/repos","events_url":"https://api.github.com/users/jrogov/events{/privacy}","received_events_url":"https://api.github.com/users/jrogov/received_events","type":"User","site_admin":false},"labels":[{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2020-08-07T11:00:39Z","updated_at":"2020-08-07T11:29:57Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"**Describe the unexpected behaviour**\r\nCurrently Clickhouse interpretes `SELECT *` from subqueries as \"select all unique columns from this subquery\", although saving the order, but stripping repeated columns.\r\n\r\nIt's best demonstrated with queries below\r\n\r\n**How to reproduce**\r\n* Tested on Clickhouse 19+\r\n* Any interface\r\n* Default settings\r\n* No tables\r\n* No data\r\n* Queries to run that lead to unexpected result\r\n```\r\n90be848025f1 :) select sum(number), sum(number) from numbers(10)\r\n\r\nSELECT\r\n    sum(number),\r\n    sum(number)\r\nFROM numbers(10)\r\n\r\n┌─sum(number)─┬─sum(number)─┐\r\n│          45 │          45 │\r\n└─────────────┴─────────────┘\r\n\r\n1 rows in set. Elapsed: 0.007 sec.\r\n\r\n90be848025f1 :) select * from (select sum(number), sum(number) from numbers(10))\r\n\r\nSELECT *\r\nFROM\r\n(\r\n    SELECT\r\n        sum(number),\r\n        sum(number)\r\n    FROM numbers(10)\r\n)\r\n\r\n┌─sum(number)─┐\r\n│          45 │\r\n└─────────────┘\r\n```\r\n\r\n**Expected behavior**\r\nOrder for such queries, for both unique and repeated columns, must be preserved.\r\n\r\n**Error message and/or stacktrace**\r\nNone\r\n\r\n**Additional context**\r\nNone\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13453/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13453/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13452","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13452/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13452/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13452/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/13452","id":674917645,"node_id":"MDU6SXNzdWU2NzQ5MTc2NDU=","number":13452,"title":"Expose action locks and SYSTEM commands in metrics/events","user":{"login":"filimonov","id":1549571,"node_id":"MDQ6VXNlcjE1NDk1NzE=","avatar_url":"https://avatars.githubusercontent.com/u/1549571?v=4","gravatar_id":"","url":"https://api.github.com/users/filimonov","html_url":"https://github.com/filimonov","followers_url":"https://api.github.com/users/filimonov/followers","following_url":"https://api.github.com/users/filimonov/following{/other_user}","gists_url":"https://api.github.com/users/filimonov/gists{/gist_id}","starred_url":"https://api.github.com/users/filimonov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/filimonov/subscriptions","organizations_url":"https://api.github.com/users/filimonov/orgs","repos_url":"https://api.github.com/users/filimonov/repos","events_url":"https://api.github.com/users/filimonov/events{/privacy}","received_events_url":"https://api.github.com/users/filimonov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":3086255531,"node_id":"MDU6TGFiZWwzMDg2MjU1NTMx","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/warmup%20task","name":"warmup task","color":"FBCA04","default":false,"description":"The task for new ClickHouse team members. Low risk, moderate complexity, no urgency."}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2020-08-07T10:20:00Z","updated_at":"2021-06-18T00:11:02Z","closed_at":null,"author_association":"COLLABORATOR","active_lock_reason":null,"body":"Really hard to understand that merges not happening due to SYSTEM STOP merges, or that user did fire some other SYSTEM command which can affect the normal server behavior. ","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13452/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13452/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13401","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13401/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13401/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13401/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/13401","id":674125521,"node_id":"MDU6SXNzdWU2NzQxMjU1MjE=","number":13401,"title":"Increase the search conditions to achieve the purpose of narrowing the search scope, but the result is that more data is parsed, and the query becomes slower","user":{"login":"MrSsunlight","id":32731294,"node_id":"MDQ6VXNlcjMyNzMxMjk0","avatar_url":"https://avatars.githubusercontent.com/u/32731294?v=4","gravatar_id":"","url":"https://api.github.com/users/MrSsunlight","html_url":"https://github.com/MrSsunlight","followers_url":"https://api.github.com/users/MrSsunlight/followers","following_url":"https://api.github.com/users/MrSsunlight/following{/other_user}","gists_url":"https://api.github.com/users/MrSsunlight/gists{/gist_id}","starred_url":"https://api.github.com/users/MrSsunlight/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/MrSsunlight/subscriptions","organizations_url":"https://api.github.com/users/MrSsunlight/orgs","repos_url":"https://api.github.com/users/MrSsunlight/repos","events_url":"https://api.github.com/users/MrSsunlight/events{/privacy}","received_events_url":"https://api.github.com/users/MrSsunlight/received_events","type":"User","site_admin":false},"labels":[{"id":756395244,"node_id":"MDU6TGFiZWw3NTYzOTUyNDQ=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/performance","name":"performance","color":"c2e0c6","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2020-08-06T08:27:41Z","updated_at":"2020-08-06T08:27:41Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"system: centos7\r\nversion: 20.3.11.97\r\n\r\nThe default.test_log table is a MergeTree() table, \r\nThe default.rule table is the Dictionary() table.\r\n\r\n**Query sql statement：**\r\n```\r\nWITH \r\n\ttoDateTime('2020-08-05 00:00:00') As start_time, \r\n\ttoDateTime('2020-08-05 23:59:59') As end_time \r\nSELECT \r\n\ttnow, \r\n\tif(ipType = 0, IPv4NumToString(ipv4), IPv6NumToString(ipv6)) AS ip \r\nFROM default.test_log cl \r\nWHERE \r\n\tcl.tnow >= start_time AND \r\n\tcl.tnow <= end_time AND \r\n\tip in (\r\n\t\tSELECT \r\n\t\t\tra.addr \r\n\t\tFROM default.rule ra \r\n\t\tWHERE \r\n\t\t\t(ra.is_deleted == 0 or ra.is_deleted == 1) and (ra.name = 'test')\r\n\t)\r\nLIMIT 0, 10\r\n```\r\nThe difference between the two query sql is that one more condition **(ra.name ='test')** is added；\r\n\r\n`set send_logs_level='trace'`\r\n\r\n**A:** Filter condition does not contain (ra.name='test')：\r\n\r\n```\r\n<Debug> InterpreterSelectQuery: MergeTreeWhereOptimizer: condition \"(if(ipType = 0, IPv4NumToString(ipv4), IPv6NumToString(ipv6)) AS ip) IN ((SELECT ra.addr FROM default.rule AS ra WHERE (ra.is_deleted = 0) OR (ra.is_deleted = 1)) AS _subquery9)\" moved to PREWHERE\r\n<Trace> AccessRightsContext (admin): Access granted: SELECT(addr, is_deleted) ON default.rule\r\n<Trace> AccessRightsContext (admin): Access granted: SELECT(addr, is_deleted) ON default.rule\r\n<Trace> AccessRightsContext (admin): Access granted: SELECT(tnow, ipType, ipv4, ipv6) ON default.test_log\r\n<Debug> default.test_log (SelectExecutor): Key condition: unknown, (column 0 in [1596556800, +inf)), (column 0 in (-inf, 1596643199]), and, and, unknown, and\r\n<Debug> default.test_log (SelectExecutor): MinMax index condition: unknown, (column 0 in [1596556800, +inf)), (column 0 in (-inf, 1596643199]), and, and, unknown, and\r\n<Debug> default.test_log (SelectExecutor): Selected 4 parts by date, 4 parts by key, 87898 marks to read from 4 ranges\r\n<Trace> default.test_log (SelectExecutor): Reading approx. 1437378474 rows with 12 streams\r\n<Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n<Trace> CreatingSetsBlockInputStream: Creating set. \r\n<Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n<Debug> CreatingSetsBlockInputStream: Created. Set with 477382 entries from 477382 rows. In 0.497 sec.\r\n<Information> executeQuery: Read 903366 rows, 20.78 MiB in 1.300 sec., 695092 rows/sec., 15.99 MiB/sec.\r\n<Debug> MemoryTracker: Peak memory usage (for query): 146.56 MiB.\r\n```\r\n\r\n**B:** Filter conditions include (ra.name ='test'):\r\n```\r\n<Debug> InterpreterSelectQuery: MergeTreeWhereOptimizer: condition \"(if(ipType = 0, IPv4NumToString(ipv4), IPv6NumToString(ipv6)) AS ip) IN ((SELECT ra.addr FROM default.rule AS ra WHERE ((ra.is_deleted = 0) OR (ra.is_deleted = 1)) AND (ra.name = 'test')) AS _subquery10)\" moved to PREWHERE\r\n<Trace> AccessRightsContext (admin): Access granted: SELECT(addr, name, is_deleted) ON default.rule\r\n<Trace> AccessRightsContext (admin): Access granted: SELECT(addr, name, is_deleted) ON default.rule\r\n<Trace> AccessRightsContext (admin): Access granted: SELECT(tnow, ipType, ipv4, ipv6) ON default.test_log\r\n<Debug> default.test_log (SelectExecutor): Key condition: unknown, (column 0 in [1596556800, +inf)), (column 0 in (-inf, 1596643199]), and, and, unknown, and\r\n<Debug> default.test_log (SelectExecutor): MinMax index condition: unknown, (column 0 in [1596556800, +inf)), (column 0 in (-inf, 1596643199]), and, and, unknown, and\r\n<Debug> default.test_log (SelectExecutor): Selected 4 parts by date, 4 parts by key, 87898 marks to read from 4 ranges\r\n<Trace> default.test_log (SelectExecutor): Reading approx. 1437378474 rows with 12 streams\r\n<Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n<Trace> CreatingSetsBlockInputStream: Creating set. \r\n<Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n<Debug> CreatingSetsBlockInputStream: Created. Set with 1 entries from 1 rows. In 0.644 sec.\r\n<Debug> MergeTreeReadPool: Slow read, event №1: read 1048576 bytes in 1.081 sec., 0.970 MB/s.\r\n<Debug> MergeTreeReadPool: Slow read, event №2: read 1048576 bytes in 1.687 sec., 0.622 MB/s.\r\n<Debug> MergeTreeReadPool: Will lower number of threads to 11\r\n<Information> executeQuery: Read 1412403247 rows, 27.63 GiB in 34.523 sec., 40912481 rows/sec., 819.54 MiB/sec.\r\n<Debug> MemoryTracker: Peak memory usage (for query): 126.37 MiB.\r\n```\r\n\r\nThe difference between A and B is <Debug> CreatingSetsBlockInputStream: Created. Set with * entries from * rows ；\r\n\r\nThe number of results of `'(ra.is_deleted == 0 or ra.is_deleted == 1) and (ra.name = 'test')'` is much smaller than that of `'(ra.is_deleted == 0 or ra.is_deleted == 1)'`, But the 'Created. Set entries' of A needs more than the query of B.`<Debug> CreatingSetsBlockInputStream: Created. Set with 477382 entries from 477382 rows. In 0.497 sec` and `<Debug> CreatingSetsBlockInputStream: Created. Set with 1 entries from 1 rows. In 0.644 sec`；\r\n\r\nWhat is the logic of `CreatingSetsBlockInputStream: Created. Set with 1 entrie` ?  Why I added a conditional restriction but got more data?\r\n\r\n\r\n\r\n\r\n\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13401/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13401/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13398","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13398/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13398/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13398/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/13398","id":673991802,"node_id":"MDU6SXNzdWU2NzM5OTE4MDI=","number":13398,"title":"Change MySQL engine configuration when the mysql is not accessable","user":{"login":"shwangdev","id":702829,"node_id":"MDQ6VXNlcjcwMjgyOQ==","avatar_url":"https://avatars.githubusercontent.com/u/702829?v=4","gravatar_id":"","url":"https://api.github.com/users/shwangdev","html_url":"https://github.com/shwangdev","followers_url":"https://api.github.com/users/shwangdev/followers","following_url":"https://api.github.com/users/shwangdev/following{/other_user}","gists_url":"https://api.github.com/users/shwangdev/gists{/gist_id}","starred_url":"https://api.github.com/users/shwangdev/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/shwangdev/subscriptions","organizations_url":"https://api.github.com/users/shwangdev/orgs","repos_url":"https://api.github.com/users/shwangdev/repos","events_url":"https://api.github.com/users/shwangdev/events{/privacy}","received_events_url":"https://api.github.com/users/shwangdev/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""}],"state":"open","locked":false,"assignee":{"login":"kssenii","id":54203879,"node_id":"MDQ6VXNlcjU0MjAzODc5","avatar_url":"https://avatars.githubusercontent.com/u/54203879?v=4","gravatar_id":"","url":"https://api.github.com/users/kssenii","html_url":"https://github.com/kssenii","followers_url":"https://api.github.com/users/kssenii/followers","following_url":"https://api.github.com/users/kssenii/following{/other_user}","gists_url":"https://api.github.com/users/kssenii/gists{/gist_id}","starred_url":"https://api.github.com/users/kssenii/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kssenii/subscriptions","organizations_url":"https://api.github.com/users/kssenii/orgs","repos_url":"https://api.github.com/users/kssenii/repos","events_url":"https://api.github.com/users/kssenii/events{/privacy}","received_events_url":"https://api.github.com/users/kssenii/received_events","type":"User","site_admin":false},"assignees":[{"login":"kssenii","id":54203879,"node_id":"MDQ6VXNlcjU0MjAzODc5","avatar_url":"https://avatars.githubusercontent.com/u/54203879?v=4","gravatar_id":"","url":"https://api.github.com/users/kssenii","html_url":"https://github.com/kssenii","followers_url":"https://api.github.com/users/kssenii/followers","following_url":"https://api.github.com/users/kssenii/following{/other_user}","gists_url":"https://api.github.com/users/kssenii/gists{/gist_id}","starred_url":"https://api.github.com/users/kssenii/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kssenii/subscriptions","organizations_url":"https://api.github.com/users/kssenii/orgs","repos_url":"https://api.github.com/users/kssenii/repos","events_url":"https://api.github.com/users/kssenii/events{/privacy}","received_events_url":"https://api.github.com/users/kssenii/received_events","type":"User","site_admin":false}],"milestone":null,"comments":1,"created_at":"2020-08-06T03:46:35Z","updated_at":"2021-09-08T15:40:08Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"I have a database in clickhouse which is using MySQL engine. However, for some reason the IP of that mysql server was changed.  I can not drop the db in clickhouse , cause it reports can not access the old mysql ip.\r\nSo, how can I change the db engine configuration in clickhouse?","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13398/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13398/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13320","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13320/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13320/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13320/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/13320","id":672469596,"node_id":"MDU6SXNzdWU2NzI0Njk1OTY=","number":13320,"title":"Method optimize is not supported by storage Join","user":{"login":"templarzq","id":18200917,"node_id":"MDQ6VXNlcjE4MjAwOTE3","avatar_url":"https://avatars.githubusercontent.com/u/18200917?v=4","gravatar_id":"","url":"https://api.github.com/users/templarzq","html_url":"https://github.com/templarzq","followers_url":"https://api.github.com/users/templarzq/followers","following_url":"https://api.github.com/users/templarzq/following{/other_user}","gists_url":"https://api.github.com/users/templarzq/gists{/gist_id}","starred_url":"https://api.github.com/users/templarzq/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/templarzq/subscriptions","organizations_url":"https://api.github.com/users/templarzq/orgs","repos_url":"https://api.github.com/users/templarzq/repos","events_url":"https://api.github.com/users/templarzq/events{/privacy}","received_events_url":"https://api.github.com/users/templarzq/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2020-08-04T03:04:11Z","updated_at":"2020-08-28T06:32:22Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"(you don't have to strictly follow this form)\r\n\r\n**Use case**\r\n optimize table t.\r\n(table t  use  storage join)\r\n**Describe the solution you'd like**\r\n\r\n**Describe alternatives you've considered**\r\nif  many update & insert operations happend,does storage join table need  optimize?  or system merge data on backend？\r\n\r\n**Additional context**\r\nAdd any other context or screenshots about the feature request here.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13320/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13320/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13210","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13210/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13210/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13210/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/13210","id":671022648,"node_id":"MDU6SXNzdWU2NzEwMjI2NDg=","number":13210,"title":"Alias hides right table column in join","user":{"login":"euyuil","id":1539596,"node_id":"MDQ6VXNlcjE1Mzk1OTY=","avatar_url":"https://avatars.githubusercontent.com/u/1539596?v=4","gravatar_id":"","url":"https://api.github.com/users/euyuil","html_url":"https://github.com/euyuil","followers_url":"https://api.github.com/users/euyuil/followers","following_url":"https://api.github.com/users/euyuil/following{/other_user}","gists_url":"https://api.github.com/users/euyuil/gists{/gist_id}","starred_url":"https://api.github.com/users/euyuil/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/euyuil/subscriptions","organizations_url":"https://api.github.com/users/euyuil/orgs","repos_url":"https://api.github.com/users/euyuil/repos","events_url":"https://api.github.com/users/euyuil/events{/privacy}","received_events_url":"https://api.github.com/users/euyuil/received_events","type":"User","site_admin":false},"labels":[{"id":386401505,"node_id":"MDU6TGFiZWwzODY0MDE1MDU=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/bug","name":"bug","color":"ee0701","default":true,"description":"Confirmed user-visible misbehaviour in official release"},{"id":1357578153,"node_id":"MDU6TGFiZWwxMzU3NTc4MTUz","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-joins","name":"comp-joins","color":"b5bcff","default":false,"description":"JOINs"},{"id":1507867504,"node_id":"MDU6TGFiZWwxNTA3ODY3NTA0","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/st-hold","name":"st-hold","color":"e5b890","default":false,"description":"We've paused the work on issue for some reason"},{"id":1907525265,"node_id":"MDU6TGFiZWwxOTA3NTI1MjY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/v20.3-affected","name":"v20.3-affected","color":"c2bfff","default":false,"description":"This issue affects some releases of v20.3"},{"id":2121848770,"node_id":"MDU6TGFiZWwyMTIxODQ4Nzcw","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-sql","name":"comp-sql","color":"b5bcff","default":false,"description":"General SQL support"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2020-08-01T16:54:33Z","updated_at":"2021-08-15T03:02:28Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"**Describe the bug**\r\n\r\nFailure happens when selecting a constant renaming to the same name with an existing column of a joined table which is also in where clause.\r\n\r\n**How to reproduce**\r\n\r\n* Which ClickHouse server version to use: version 20.3.12.112 (official build)\r\n* Which interface to use, if matters: No matter.\r\n* Non-default settings, if any: Not any.\r\n\r\n* `CREATE TABLE` statements for all tables involved\r\n\r\n```\r\nCREATE TABLE test_a_table (\r\n    name String,\r\n    a_col String\r\n)\r\nEngine = MergeTree()\r\nORDER BY name;\r\n\r\nCREATE TABLE test_b_table (\r\n    name String,\r\n    b_col String,\r\n    some_val String\r\n)\r\nEngine = MergeTree()\r\nORDER BY name;\r\n```\r\n\r\n* Sample data for all these tables, use [clickhouse-obfuscator](https://github.com/ClickHouse/ClickHouse/blob/master/programs/obfuscator/Obfuscator.cpp#L42-L80) if necessary\r\n\r\nNo data is needed to reproduce the error.\r\n\r\n* Queries to run that lead to unexpected result\r\n\r\n```\r\nSELECT\r\n    b.name name,\r\n    a.a_col a_col,\r\n    b.b_col b_col,\r\n    'N' some_val\r\nfrom test_a_table a\r\njoin test_b_table b on a.name = b.name\r\nwhere b.some_val = 'Y';\r\n```\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\nThe query is expected to be successful.\r\n\r\n**Error message and/or stacktrace**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n```\r\nCode: 47, e.displayText() = DB::Exception: Unknown identifier: some_val there are columns: name, a_col, b.name, b_col (version 20.3.12.112 (official build))\r\n```\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n\r\nThese queries are successful:\r\n\r\n```\r\nSELECT\r\n    b.name name,\r\n    a.a_col a_col,\r\n    b.b_col b_col   -- some_val not selected\r\nfrom test_a_table a\r\njoin test_b_table b on a.name = b.name\r\nwhere b.some_val = 'Y';\r\n\r\nSELECT\r\n    b.name name,\r\n    a.a_col a_col,\r\n    b.b_col b_col,\r\n    b.some_val some_val   -- use b.some_val instead of a constant\r\nfrom test_a_table a\r\njoin test_b_table b on a.name = b.name\r\nwhere b.some_val = 'Y';\r\n\r\nSELECT\r\n    b.name name,\r\n    a.a_col a_col,\r\n    b.b_col b_col,\r\n    'N' some_val2   -- do not rename to some_val\r\nfrom test_a_table a\r\njoin test_b_table b on a.name = b.name\r\nwhere b.some_val = 'Y';\r\n\r\nSELECT\r\n    b.name name,\r\n    a.a_col a_col,\r\n    b.b_col b_col,\r\n    'N' some_val\r\nfrom test_a_table a\r\njoin test_b_table b on a.name = b.name;   -- no where clause\r\n\r\nSELECT\r\n    b.name name,\r\n    a.a_col a_col,\r\n    b.b_col b_col,\r\n    if(b.some_val='','N','N') some_val   -- an interesting workaround...\r\nfrom test_a_table a\r\njoin test_b_table b on a.name = b.name\r\nwhere b.some_val = 'Y';\r\n```\r\n\r\nHowever, this won't work either:\r\n\r\n```\r\nSELECT\r\n    b.name name,\r\n    a.a_col a_col,\r\n    b.b_col b_col,\r\n    if(1,'N',b.some_val) some_val   -- b.some_val is not actually evaluated\r\nfrom test_a_table a\r\njoin test_b_table b on a.name = b.name\r\nwhere b.some_val = 'Y';\r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13210/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13210/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13077","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13077/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13077/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13077/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/13077","id":667928450,"node_id":"MDU6SXNzdWU2Njc5Mjg0NTA=","number":13077,"title":"Do not lose stderr/stdout from clickhouse-odbc-bridge","user":{"login":"qoega","id":2159081,"node_id":"MDQ6VXNlcjIxNTkwODE=","avatar_url":"https://avatars.githubusercontent.com/u/2159081?v=4","gravatar_id":"","url":"https://api.github.com/users/qoega","html_url":"https://github.com/qoega","followers_url":"https://api.github.com/users/qoega/followers","following_url":"https://api.github.com/users/qoega/following{/other_user}","gists_url":"https://api.github.com/users/qoega/gists{/gist_id}","starred_url":"https://api.github.com/users/qoega/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/qoega/subscriptions","organizations_url":"https://api.github.com/users/qoega/orgs","repos_url":"https://api.github.com/users/qoega/repos","events_url":"https://api.github.com/users/qoega/events{/privacy}","received_events_url":"https://api.github.com/users/qoega/received_events","type":"User","site_admin":false},"labels":[{"id":845247686,"node_id":"MDU6TGFiZWw4NDUyNDc2ODY=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/usability","name":"usability","color":"ebf28c","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2020-07-29T15:19:18Z","updated_at":"2020-07-29T15:19:18Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"**Describe the issue**\r\nWe store only logs for odbc_bridge\r\n\r\nHere we do not forward stderr/out somewhere.\r\nhttps://github.com/ClickHouse/ClickHouse/blob/be85f9f98ab3d9c5450be967f7fed646d0ce3129/src/Common/XDBCBridgeHelper.h#L340\r\nIt can lead to hang","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13077/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13077/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13057","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13057/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13057/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13057/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/13057","id":667552649,"node_id":"MDU6SXNzdWU2Njc1NTI2NDk=","number":13057,"title":"user `default` doesn't have enough grants for creating another user \\ role \\ row policy for 20.4 and 20.5","user":{"login":"Slach","id":105560,"node_id":"MDQ6VXNlcjEwNTU2MA==","avatar_url":"https://avatars.githubusercontent.com/u/105560?v=4","gravatar_id":"","url":"https://api.github.com/users/Slach","html_url":"https://github.com/Slach","followers_url":"https://api.github.com/users/Slach/followers","following_url":"https://api.github.com/users/Slach/following{/other_user}","gists_url":"https://api.github.com/users/Slach/gists{/gist_id}","starred_url":"https://api.github.com/users/Slach/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Slach/subscriptions","organizations_url":"https://api.github.com/users/Slach/orgs","repos_url":"https://api.github.com/users/Slach/repos","events_url":"https://api.github.com/users/Slach/events{/privacy}","received_events_url":"https://api.github.com/users/Slach/received_events","type":"User","site_admin":false},"labels":[{"id":845247686,"node_id":"MDU6TGFiZWw4NDUyNDc2ODY=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/usability","name":"usability","color":"ebf28c","default":false,"description":""},{"id":2011606513,"node_id":"MDU6TGFiZWwyMDExNjA2NTEz","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-rbac","name":"comp-rbac","color":"b5bcff","default":false,"description":"Access control related"}],"state":"open","locked":false,"assignee":{"login":"vitlibar","id":45142681,"node_id":"MDQ6VXNlcjQ1MTQyNjgx","avatar_url":"https://avatars.githubusercontent.com/u/45142681?v=4","gravatar_id":"","url":"https://api.github.com/users/vitlibar","html_url":"https://github.com/vitlibar","followers_url":"https://api.github.com/users/vitlibar/followers","following_url":"https://api.github.com/users/vitlibar/following{/other_user}","gists_url":"https://api.github.com/users/vitlibar/gists{/gist_id}","starred_url":"https://api.github.com/users/vitlibar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vitlibar/subscriptions","organizations_url":"https://api.github.com/users/vitlibar/orgs","repos_url":"https://api.github.com/users/vitlibar/repos","events_url":"https://api.github.com/users/vitlibar/events{/privacy}","received_events_url":"https://api.github.com/users/vitlibar/received_events","type":"User","site_admin":false},"assignees":[{"login":"vitlibar","id":45142681,"node_id":"MDQ6VXNlcjQ1MTQyNjgx","avatar_url":"https://avatars.githubusercontent.com/u/45142681?v=4","gravatar_id":"","url":"https://api.github.com/users/vitlibar","html_url":"https://github.com/vitlibar","followers_url":"https://api.github.com/users/vitlibar/followers","following_url":"https://api.github.com/users/vitlibar/following{/other_user}","gists_url":"https://api.github.com/users/vitlibar/gists{/gist_id}","starred_url":"https://api.github.com/users/vitlibar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vitlibar/subscriptions","organizations_url":"https://api.github.com/users/vitlibar/orgs","repos_url":"https://api.github.com/users/vitlibar/repos","events_url":"https://api.github.com/users/vitlibar/events{/privacy}","received_events_url":"https://api.github.com/users/vitlibar/received_events","type":"User","site_admin":false}],"milestone":null,"comments":9,"created_at":"2020-07-29T05:08:44Z","updated_at":"2021-11-19T18:23:18Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Describe the bug**\r\nuser `default` doesn't have enough grants for creating another user \\ role \\ row policy for 20.4 and 20.5\r\n\r\n**How to reproduce**\r\nI use following docker-compose.yaml\r\n```\r\nversion: '3'\r\n\r\nservices:\r\n  clickhouse:\r\n    image: docker.io/yandex/clickhouse-server:latest\r\n    ports:\r\n      - 8123:8123\r\n      - 8443:8443\r\n      - 9000:9000\r\n      - 9009:9009\r\n```\r\n\r\n```bash\r\ndocker-compose up -d clickhouse\r\ndocker-compose exec clickhouse clickhouse-client\r\n```\r\n\r\n```sql\r\nSHOW GRANTS;\r\n```\r\n\r\n```\r\n┌─GRANTS─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\r\n│ GRANT SHOW, SELECT, INSERT, ALTER, CREATE, DROP, TRUNCATE, OPTIMIZE, KILL QUERY, SYSTEM, dictGet, INTROSPECTION, SOURCES ON *.* TO default │\r\n└────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\r\n```\r\n\r\naccording to documentation https://clickhouse.tech/docs/en/sql-reference/statements/grant/#grant-privileges \r\nlook like `default` user lost \"ACCESS MANAGEMENT\" grant groups in 20.4 and 20.5 version\r\n\r\ncause\r\n```sql\r\nCREATE USER OR REPLACE monitoring IDENTIFIED WITH NO_PASSWORD HOST ANY SETTINGS PROFILE 'default';\r\n```\r\nreturn\r\n```\r\nCode: 497. DB::Exception: Received from localhost:9000. DB::Exception: default: Not enough privileges. To execute this query it's necessary to have the grant CREATE USER ON *.*.\r\n```\r\n\r\n\r\n* Which ClickHouse server version to use\r\n20.5.3\r\n20.4.7\r\n\r\nfor 20.3\r\nall works fine\r\n```sql\r\nSHOW GRANTS;\r\n```\r\nreturn\r\n```\r\n┌─GRANTS────────────────────────────────────────┐\r\n│ GRANT ALL ON *.* TO default WITH GRANT OPTION │\r\n└───────────────────────────────────────────────┘\r\n```\r\nand\r\n```sql\r\nCREATE USER OR REPLACE monitoring PROFILE 'default';\r\n```\r\nreturn\r\n```\r\nOk.\r\n0 rows in set. Elapsed: 0.002 sec.\r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13057/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13057/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13014","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13014/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13014/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13014/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/13014","id":667129254,"node_id":"MDU6SXNzdWU2NjcxMjkyNTQ=","number":13014,"title":"Engine=Set with multiple columns enforces reversed column order","user":{"login":"filimonov","id":1549571,"node_id":"MDQ6VXNlcjE1NDk1NzE=","avatar_url":"https://avatars.githubusercontent.com/u/1549571?v=4","gravatar_id":"","url":"https://api.github.com/users/filimonov","html_url":"https://github.com/filimonov","followers_url":"https://api.github.com/users/filimonov/followers","following_url":"https://api.github.com/users/filimonov/following{/other_user}","gists_url":"https://api.github.com/users/filimonov/gists{/gist_id}","starred_url":"https://api.github.com/users/filimonov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/filimonov/subscriptions","organizations_url":"https://api.github.com/users/filimonov/orgs","repos_url":"https://api.github.com/users/filimonov/repos","events_url":"https://api.github.com/users/filimonov/events{/privacy}","received_events_url":"https://api.github.com/users/filimonov/received_events","type":"User","site_admin":false},"labels":[{"id":386401505,"node_id":"MDU6TGFiZWwzODY0MDE1MDU=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/bug","name":"bug","color":"ee0701","default":true,"description":"Confirmed user-visible misbehaviour in official release"},{"id":1507888214,"node_id":"MDU6TGFiZWwxNTA3ODg4MjE0","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/st-accepted","name":"st-accepted","color":"e5b890","default":false,"description":"The issue is in our backlog, ready to take"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2020-07-28T14:40:17Z","updated_at":"2021-08-04T10:56:26Z","closed_at":null,"author_association":"COLLABORATOR","active_lock_reason":null,"body":"2 columns sample\r\n\r\n```sql\r\nCREATE TABLE userid_set(userid UInt64, name String) ENGINE = Set;\r\nINSERT INTO userid_set VALUES (1, 'Mary'),(2, 'Jane'),(3, 'Mary'),(4, 'Jack');\r\n\r\nCREATE TABLE userid_test (userid UInt64, name String) ENGINE = MergeTree() PARTITION BY (intDiv(userid, 500)) ORDER BY (userid) SETTINGS index_granularity = 8192;\r\nINSERT INTO userid_test VALUES (1, 'Jack'),(2, 'Mary'),(3, 'Mary'),(4, 'John'),(5, 'Mary');\r\n\r\nSELECT * FROM userid_test WHERE (userid, name) IN (userid_set); -- fails\r\n\r\nSELECT * FROM userid_test WHERE (name, userid) IN (userid_set); -- works, but order of columns is reversed.\r\n\r\n```\r\n\r\n3 columns sample\r\n```sql\r\nCREATE TABLE userid_set2(userid UInt64, name String, birthdate Date) ENGINE = Set;\r\n insert into userid_set2 values (1,'John', '1990-01-01');\r\n\r\nWITH  'John' AS name,  toDate('1990-01-01') AS birthdate\r\nSELECT * FROM numbers(10)\r\nWHERE (number, name, birthdate) IN (userid_set2); -- fails\r\n\r\nWITH  'John' AS name,  toDate('1990-01-01') AS birthdate\r\nSELECT * FROM numbers(10)\r\nWHERE (birthdate, name, number) IN (userid_set2); -- works, but order of column is reversed\r\n```\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13014/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13014/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13012","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13012/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13012/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13012/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/13012","id":667118656,"node_id":"MDU6SXNzdWU2NjcxMTg2NTY=","number":13012,"title":"Add support for a positive settings constraints model (as opposed to negative)","user":{"login":"nvartolomei","id":543193,"node_id":"MDQ6VXNlcjU0MzE5Mw==","avatar_url":"https://avatars.githubusercontent.com/u/543193?v=4","gravatar_id":"","url":"https://api.github.com/users/nvartolomei","html_url":"https://github.com/nvartolomei","followers_url":"https://api.github.com/users/nvartolomei/followers","following_url":"https://api.github.com/users/nvartolomei/following{/other_user}","gists_url":"https://api.github.com/users/nvartolomei/gists{/gist_id}","starred_url":"https://api.github.com/users/nvartolomei/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nvartolomei/subscriptions","organizations_url":"https://api.github.com/users/nvartolomei/orgs","repos_url":"https://api.github.com/users/nvartolomei/repos","events_url":"https://api.github.com/users/nvartolomei/events{/privacy}","received_events_url":"https://api.github.com/users/nvartolomei/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":{"login":"vitlibar","id":45142681,"node_id":"MDQ6VXNlcjQ1MTQyNjgx","avatar_url":"https://avatars.githubusercontent.com/u/45142681?v=4","gravatar_id":"","url":"https://api.github.com/users/vitlibar","html_url":"https://github.com/vitlibar","followers_url":"https://api.github.com/users/vitlibar/followers","following_url":"https://api.github.com/users/vitlibar/following{/other_user}","gists_url":"https://api.github.com/users/vitlibar/gists{/gist_id}","starred_url":"https://api.github.com/users/vitlibar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vitlibar/subscriptions","organizations_url":"https://api.github.com/users/vitlibar/orgs","repos_url":"https://api.github.com/users/vitlibar/repos","events_url":"https://api.github.com/users/vitlibar/events{/privacy}","received_events_url":"https://api.github.com/users/vitlibar/received_events","type":"User","site_admin":false},"assignees":[{"login":"vitlibar","id":45142681,"node_id":"MDQ6VXNlcjQ1MTQyNjgx","avatar_url":"https://avatars.githubusercontent.com/u/45142681?v=4","gravatar_id":"","url":"https://api.github.com/users/vitlibar","html_url":"https://github.com/vitlibar","followers_url":"https://api.github.com/users/vitlibar/followers","following_url":"https://api.github.com/users/vitlibar/following{/other_user}","gists_url":"https://api.github.com/users/vitlibar/gists{/gist_id}","starred_url":"https://api.github.com/users/vitlibar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vitlibar/subscriptions","organizations_url":"https://api.github.com/users/vitlibar/orgs","repos_url":"https://api.github.com/users/vitlibar/repos","events_url":"https://api.github.com/users/vitlibar/events{/privacy}","received_events_url":"https://api.github.com/users/vitlibar/received_events","type":"User","site_admin":false}],"milestone":null,"comments":2,"created_at":"2020-07-28T14:26:22Z","updated_at":"2020-10-21T23:15:29Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"Today it is possible to configure constraints for settings on user profiles (https://clickhouse.tech/docs/en/operations/settings/constraints-on-settings/).\r\n\r\nThe problem with this feature is that the number of settings a user can change is ~400. I have a use-case where I want to prevent users modifying settings except a few allowed ones, ie timeout and max_execution_speed_bytes. In order to do this I would have to first configure *~400*-2 constraints on all the other settings to mark them as readonly.\r\n\r\nThe proposal is to allow constraints to work in opposite way.\r\n\r\nIe defining a profile as ~\r\n\r\n```xml\r\n<analyst>\r\n  <readonly>1</readonly>\r\n\r\n  <constraints>\r\n    <max_execution_speed_bytes>\r\n      <min>10000</min>\r\n      <max>500000</max>\r\n    </max_execution_speed_bytes >\r\n  </constraints>\r\n</analyst>\r\n```\r\n\r\nwould allow an analyst user to change only the `max_execution_speed_bytes` as long as it satisfies the constraints.\r\n\r\nAlternatively\r\n\r\n```xml\r\n<analyst>\r\n  <readonly>2</readonly>\r\n\r\n  <constraints default=\"deny\">\r\n    <max_execution_speed_bytes>\r\n      <min>10000</min>\r\n      <max>500000</max>\r\n    </max_execution_speed_bytes >\r\n  </constraints>\r\n</analyst>\r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13012/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/13012/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12974","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12974/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12974/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12974/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/12974","id":666828169,"node_id":"MDU6SXNzdWU2NjY4MjgxNjk=","number":12974,"title":"Add description for ALTER TABLE MODIFY QUERY","user":{"login":"Felixoid","id":3025537,"node_id":"MDQ6VXNlcjMwMjU1Mzc=","avatar_url":"https://avatars.githubusercontent.com/u/3025537?v=4","gravatar_id":"","url":"https://api.github.com/users/Felixoid","html_url":"https://github.com/Felixoid","followers_url":"https://api.github.com/users/Felixoid/followers","following_url":"https://api.github.com/users/Felixoid/following{/other_user}","gists_url":"https://api.github.com/users/Felixoid/gists{/gist_id}","starred_url":"https://api.github.com/users/Felixoid/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Felixoid/subscriptions","organizations_url":"https://api.github.com/users/Felixoid/orgs","repos_url":"https://api.github.com/users/Felixoid/repos","events_url":"https://api.github.com/users/Felixoid/events{/privacy}","received_events_url":"https://api.github.com/users/Felixoid/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2020-07-28T07:16:09Z","updated_at":"2021-02-05T09:31:08Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"**Describe the issue**\r\nThere no documentation for the query currently.\r\n\r\n**Additional context**\r\n```\r\n> git grep 'MODIFY QUERY' -- docs                                                                                                                                                                                              [e:1]\r\ndocs/en/sql-reference/statements/grant.md:        - `ALTER VIEW MODIFY QUERY`\r\ndocs/en/sql-reference/statements/grant.md:        - `ALTER VIEW MODIFY QUERY`. Level: `VIEW`. Aliases: `ALTER TABLE MODIFY QUERY`\r\ndocs/es/sql-reference/statements/grant.md:        -   `ALTER VIEW MODIFY QUERY`\r\ndocs/es/sql-reference/statements/grant.md:        -   `ALTER VIEW MODIFY QUERY`. Nivel: `VIEW`. Apodo: `ALTER TABLE MODIFY QUERY`\r\ndocs/fa/sql-reference/statements/grant.md:        -   `ALTER VIEW MODIFY QUERY`\r\ndocs/fa/sql-reference/statements/grant.md:        -   `ALTER VIEW MODIFY QUERY`. سطح: `VIEW`. نامگردانها: `ALTER TABLE MODIFY QUERY`\r\ndocs/fr/sql-reference/statements/grant.md:        -   `ALTER VIEW MODIFY QUERY`\r\ndocs/fr/sql-reference/statements/grant.md:        -   `ALTER VIEW MODIFY QUERY`. Niveau: `VIEW`. Alias: `ALTER TABLE MODIFY QUERY`\r\ndocs/ru/sql-reference/statements/grant.md:        - `ALTER VIEW MODIFY QUERY`\r\ndocs/ru/sql-reference/statements/grant.md:        - `ALTER VIEW MODIFY QUERY`. Уровень: `VIEW`. Алиасы: `ALTER TABLE MODIFY QUERY`\r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12974/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12974/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12743","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12743/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12743/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12743/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/12743","id":664886581,"node_id":"MDU6SXNzdWU2NjQ4ODY1ODE=","number":12743,"title":"why doesn't my ngrambf_v1 index  work well","user":{"login":"weiyongyuan","id":20318636,"node_id":"MDQ6VXNlcjIwMzE4NjM2","avatar_url":"https://avatars.githubusercontent.com/u/20318636?v=4","gravatar_id":"","url":"https://api.github.com/users/weiyongyuan","html_url":"https://github.com/weiyongyuan","followers_url":"https://api.github.com/users/weiyongyuan/followers","following_url":"https://api.github.com/users/weiyongyuan/following{/other_user}","gists_url":"https://api.github.com/users/weiyongyuan/gists{/gist_id}","starred_url":"https://api.github.com/users/weiyongyuan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/weiyongyuan/subscriptions","organizations_url":"https://api.github.com/users/weiyongyuan/orgs","repos_url":"https://api.github.com/users/weiyongyuan/repos","events_url":"https://api.github.com/users/weiyongyuan/events{/privacy}","received_events_url":"https://api.github.com/users/weiyongyuan/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""},{"id":1357507723,"node_id":"MDU6TGFiZWwxMzU3NTA3NzIz","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-skipidx","name":"comp-skipidx","color":"b5bcff","default":false,"description":"Data skipping indices"},{"id":1798569135,"node_id":"MDU6TGFiZWwxNzk4NTY5MTM1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/v20.1","name":"v20.1","color":"510a75","default":false,"description":"Issue affects version 20.1.* or PR was manually backported to related stable branch"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2020-07-24T03:11:01Z","updated_at":"2020-08-03T09:26:21Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"###  1.my clickhouse version is 20.1.6.30\r\n ### 2.table ddl\r\n CREATE TABLE default.ip_test2\r\n(\r\n    `found_time` UInt32,\r\n    `d_ip` String,\r\n    INDEX d_ip_bl_idx d_ip TYPE bloom_filter(0.001) GRANULARITY 1,\r\n    INDEX d_ip_idx2 d_ip TYPE ngrambf_v1(3, 315119, 6, 0) GRANULARITY 1\r\n)\r\nENGINE = MergeTree()\r\nPARTITION BY toRelativeHourNum(toDateTime(found_time))\r\nORDER BY found_time\r\nSETTINGS index_granularity = 8192;\r\n### 3.the data count is 10000000. the sample data like below\r\n┌─found_time─┬─d_ip────────────────────────────────────┐\r\n│ 1592591894 │ 3200:1010:1100:0100:0110:1110:1100:0001 │\r\n│ 1592591894 │ 8010:1100:1010:0100:0000:1010:1010:2031 │\r\n│ 1592591894 │ 102.171.195.13                          │\r\n│ 1592591894 │ d110:1100:0100:1000:0100:0010:1100:1310 │\r\n│ 1592591894 │ 3110:0010:0000:0110:1100:0110:1100:0012 │\r\n│ 1592591894 │ a300:0100:1110:1000:0000:0010:1110:0000 │\r\n│ 1592591894 │ 2200:1000:0000:0100:1110:0100:1000:3131 │\r\n│ 1592591894 │ 5210:0110:0100:0100:1000:1000:1000:0001 │\r\n│ 1592591894 │ 3001:1000:0110:0000:1010:0110:0100:2320 │\r\n│ 1592591894 │ 116.184.47.2                            │\r\n└────────────┴─────────────────────────────────────────┘\r\n### 4.my query sql:select * from default.ip_test2 where d_ip like '%171.195%' limit 10;the below is query log.My question is why doesn't d_ip_idx2 drop 0 granules?are the prameters i give to the ngrambf_v1 wrong?\r\n>The query result is 10 rows,if every result is in a index_granularity 8192,10 rows locates in 81920 rows,but the query shows that it scan 400million rows!\r\n>\r\n[bd-server-19] 2020.07.24 09:07:18.203411 [ 127961 ] {b5d1900f-6870-4c13-8383-03de0b0f126e} <Debug> InterpreterSelectQuery: MergeTreeWhereOptimizer: condition \"d_ip LIKE '%171.195%'\" moved to PREWHERE\r\n[bd-server-19] 2020.07.24 09:07:18.203639 [ 127961 ] {b5d1900f-6870-4c13-8383-03de0b0f126e} <Trace> ContextAccess (default): Access granted: SELECT(found_time, d_ip) ON default.ip_test2\r\n[bd-server-19] 2020.07.24 09:07:18.203816 [ 127961 ] {b5d1900f-6870-4c13-8383-03de0b0f126e} <Debug> default.ip_test2 (SelectExecutor): Key condition: unknown\r\n[bd-server-19] 2020.07.24 09:07:18.203847 [ 127961 ] {b5d1900f-6870-4c13-8383-03de0b0f126e} <Debug> default.ip_test2 (SelectExecutor): MinMax index condition: unknown\r\n[bd-server-19] 2020.07.24 09:07:18.219786 [ 127961 ] {b5d1900f-6870-4c13-8383-03de0b0f126e} <Debug> default.ip_test2 (SelectExecutor): Index `d_ip_idx2` has dropped 0 granules.\r\n[bd-server-19] 2020.07.24 09:07:18.248175 [ 127961 ] {b5d1900f-6870-4c13-8383-03de0b0f126e} <Debug> default.ip_test2 (SelectExecutor): Index `d_ip_idx2` has dropped 0 granules.\r\n[bd-server-19] 2020.07.24 09:07:18.281673 [ 127961 ] {b5d1900f-6870-4c13-8383-03de0b0f126e} <Debug> default.ip_test2 (SelectExecutor): Index `d_ip_idx2` has dropped 0 granules.\r\n[bd-server-19] 2020.07.24 09:07:18.306771 [ 127961 ] {b5d1900f-6870-4c13-8383-03de0b0f126e} <Debug> default.ip_test2 (SelectExecutor): Index `d_ip_idx2` has dropped 0 granules.\r\n[bd-server-19] 2020.07.24 09:07:18.330602 [ 127961 ] {b5d1900f-6870-4c13-8383-03de0b0f126e} <Debug> default.ip_test2 (SelectExecutor): Index `d_ip_idx2` has dropped 0 granules.\r\n[bd-server-19] 2020.07.24 09:07:18.345376 [ 127961 ] {b5d1900f-6870-4c13-8383-03de0b0f126e} <Debug> default.ip_test2 (SelectExecutor): Index `d_ip_idx2` has dropped 0 granules.\r\n[bd-server-19] 2020.07.24 09:07:18.361686 [ 127961 ] {b5d1900f-6870-4c13-8383-03de0b0f126e} <Debug> default.ip_test2 (SelectExecutor): Index `d_ip_idx2` has dropped 0 granules.\r\n[bd-server-19] 2020.07.24 09:07:18.377417 [ 127961 ] {b5d1900f-6870-4c13-8383-03de0b0f126e} <Debug> default.ip_test2 (SelectExecutor): Index `d_ip_idx2` has dropped 0 granules.\r\n[bd-server-19] 2020.07.24 09:07:18.384960 [ 127961 ] {b5d1900f-6870-4c13-8383-03de0b0f126e} <Debug> default.ip_test2 (SelectExecutor): Index `d_ip_idx2` has dropped 0 granules.\r\n[bd-server-19] 2020.07.24 09:07:18.392819 [ 127961 ] {b5d1900f-6870-4c13-8383-03de0b0f126e} <Debug> default.ip_test2 (SelectExecutor): Index `d_ip_idx2` has dropped 0 granules.\r\n[bd-server-19] 2020.07.24 09:07:18.401857 [ 127961 ] {b5d1900f-6870-4c13-8383-03de0b0f126e} <Debug> default.ip_test2 (SelectExecutor): Index `d_ip_idx2` has dropped 0 granules.\r\n[bd-server-19] 2020.07.24 09:07:18.409763 [ 127961 ] {b5d1900f-6870-4c13-8383-03de0b0f126e} <Debug> default.ip_test2 (SelectExecutor): Index `d_ip_idx2` has dropped 0 granules.\r\n[bd-server-19] 2020.07.24 09:07:18.418204 [ 127961 ] {b5d1900f-6870-4c13-8383-03de0b0f126e} <Debug> default.ip_test2 (SelectExecutor): Index `d_ip_idx2` has dropped 0 granules.\r\n[bd-server-19] 2020.07.24 09:07:18.426288 [ 127961 ] {b5d1900f-6870-4c13-8383-03de0b0f126e} <Debug> default.ip_test2 (SelectExecutor): Index `d_ip_idx2` has dropped 0 granules.\r\n[bd-server-19] 2020.07.24 09:07:18.434560 [ 127961 ] {b5d1900f-6870-4c13-8383-03de0b0f126e} <Debug> default.ip_test2 (SelectExecutor): Index `d_ip_idx2` has dropped 0 granules.\r\n[bd-server-19] 2020.07.24 09:07:18.441925 [ 127961 ] {b5d1900f-6870-4c13-8383-03de0b0f126e} <Debug> default.ip_test2 (SelectExecutor): Index `d_ip_idx2` has dropped 0 granules.\r\n[bd-server-19] 2020.07.24 09:07:18.457873 [ 127961 ] {b5d1900f-6870-4c13-8383-03de0b0f126e} <Debug> default.ip_test2 (SelectExecutor): Index `d_ip_idx2` has dropped 0 granules.\r\n[bd-server-19] 2020.07.24 09:07:18.457909 [ 127961 ] {b5d1900f-6870-4c13-8383-03de0b0f126e} <Debug> default.ip_test2 (SelectExecutor): Selected 17 parts by date, 17 parts by key, 1230 marks to read from 17 ranges\r\n[bd-server-19] 2020.07.24 09:07:18.458151 [ 127961 ] {b5d1900f-6870-4c13-8383-03de0b0f126e} <Trace> default.ip_test2 (SelectExecutor): Reading approx. 10076160 rows with 28 streams\r\n\r\nthe resultis :\r\n┌─found_time─┬─d_ip───────────┐\r\n│ 1592601429 │ 46.171.195.198 │\r\n└────────────┴────────────────┘\r\n┌─found_time─┬─d_ip───────────┐\r\n│ 1592633446 │ 90.180.171.195 │\r\n└────────────┴────────────────┘\r\n┌─found_time─┬─d_ip──────────┐\r\n│ 1592613116 │ 122.171.195.5 │\r\n└────────────┴───────────────┘\r\n┌─found_time─┬─d_ip─────────┐\r\n│ 1592593924 │ 76.171.195.1 │\r\n└────────────┴──────────────┘\r\n┌─found_time─┬─d_ip───────────┐\r\n│ 1592623000 │ 184.171.195.78 │\r\n└────────────┴────────────────┘\r\n┌─found_time─┬─d_ip─────────┐\r\n│ 1592597161 │ 17.171.195.3 │\r\n└────────────┴──────────────┘\r\n┌─found_time─┬─d_ip───────────┐\r\n│ 1592643661 │ 171.195.229.10 │\r\n│ 1592643661 │ 213.171.195.8  │\r\n└────────────┴────────────────┘\r\n┌─found_time─┬─d_ip──────────┐\r\n│ 1592601429 │ 171.195.231.7 │\r\n└────────────┴───────────────┘\r\n┌─found_time─┬─d_ip───────────┐\r\n│ 1592625726 │ 78.218.171.195 │\r\n└────────────┴────────────────┘\r\n\r\n**_10 rows in set. Elapsed: 0.334 sec. Processed 4.00 million rows,_** 139.73 MB (11.97 million rows/s., 418.41 MB/s.) \r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12743/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12743/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12738","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12738/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12738/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12738/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/12738","id":664708007,"node_id":"MDU6SXNzdWU2NjQ3MDgwMDc=","number":12738,"title":"system.query_log and similar - apply LowCardinality whenever necessarily.","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":756395244,"node_id":"MDU6TGFiZWw3NTYzOTUyNDQ=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/performance","name":"performance","color":"c2e0c6","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2020-07-23T19:16:03Z","updated_at":"2020-07-23T19:19:10Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12738/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12738/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12616","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12616/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12616/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12616/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/12616","id":662800191,"node_id":"MDU6SXNzdWU2NjI4MDAxOTE=","number":12616,"title":"Shuffle / Redistribution based join / aggregation","user":{"login":"ilovesoup","id":3347719,"node_id":"MDQ6VXNlcjMzNDc3MTk=","avatar_url":"https://avatars.githubusercontent.com/u/3347719?v=4","gravatar_id":"","url":"https://api.github.com/users/ilovesoup","html_url":"https://github.com/ilovesoup","followers_url":"https://api.github.com/users/ilovesoup/followers","following_url":"https://api.github.com/users/ilovesoup/following{/other_user}","gists_url":"https://api.github.com/users/ilovesoup/gists{/gist_id}","starred_url":"https://api.github.com/users/ilovesoup/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ilovesoup/subscriptions","organizations_url":"https://api.github.com/users/ilovesoup/orgs","repos_url":"https://api.github.com/users/ilovesoup/repos","events_url":"https://api.github.com/users/ilovesoup/events{/privacy}","received_events_url":"https://api.github.com/users/ilovesoup/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2020-07-21T09:30:29Z","updated_at":"2021-11-10T07:08:25Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"**Use case**\r\nThis will be a good bonus for data warehousing or adhoc analytics use cases and will making ClickHouse a more general analytics database.\r\n\r\nI saw ClickHouse roadmap 2020 Q3/Q4 have such a plan. But is there anymore information about this, say, schedule or development design. We like to contribute to this. If possible, any chance we can find such information and cooperate?\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12616/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12616/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12601","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12601/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12601/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12601/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/12601","id":661803067,"node_id":"MDU6SXNzdWU2NjE4MDMwNjc=","number":12601,"title":"GROUP BY over _shard_num doesn't work in distributed tables.","user":{"login":"CurtizJ","id":20361854,"node_id":"MDQ6VXNlcjIwMzYxODU0","avatar_url":"https://avatars.githubusercontent.com/u/20361854?v=4","gravatar_id":"","url":"https://api.github.com/users/CurtizJ","html_url":"https://github.com/CurtizJ","followers_url":"https://api.github.com/users/CurtizJ/followers","following_url":"https://api.github.com/users/CurtizJ/following{/other_user}","gists_url":"https://api.github.com/users/CurtizJ/gists{/gist_id}","starred_url":"https://api.github.com/users/CurtizJ/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/CurtizJ/subscriptions","organizations_url":"https://api.github.com/users/CurtizJ/orgs","repos_url":"https://api.github.com/users/CurtizJ/repos","events_url":"https://api.github.com/users/CurtizJ/events{/privacy}","received_events_url":"https://api.github.com/users/CurtizJ/received_events","type":"User","site_admin":false},"labels":[{"id":1397894054,"node_id":"MDU6TGFiZWwxMzk3ODk0MDU0","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unfinished%20code","name":"unfinished code","color":"ff8800","default":false,"description":""}],"state":"open","locked":false,"assignee":{"login":"azat","id":430798,"node_id":"MDQ6VXNlcjQzMDc5OA==","avatar_url":"https://avatars.githubusercontent.com/u/430798?v=4","gravatar_id":"","url":"https://api.github.com/users/azat","html_url":"https://github.com/azat","followers_url":"https://api.github.com/users/azat/followers","following_url":"https://api.github.com/users/azat/following{/other_user}","gists_url":"https://api.github.com/users/azat/gists{/gist_id}","starred_url":"https://api.github.com/users/azat/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/azat/subscriptions","organizations_url":"https://api.github.com/users/azat/orgs","repos_url":"https://api.github.com/users/azat/repos","events_url":"https://api.github.com/users/azat/events{/privacy}","received_events_url":"https://api.github.com/users/azat/received_events","type":"User","site_admin":false},"assignees":[{"login":"azat","id":430798,"node_id":"MDQ6VXNlcjQzMDc5OA==","avatar_url":"https://avatars.githubusercontent.com/u/430798?v=4","gravatar_id":"","url":"https://api.github.com/users/azat","html_url":"https://github.com/azat","followers_url":"https://api.github.com/users/azat/followers","following_url":"https://api.github.com/users/azat/following{/other_user}","gists_url":"https://api.github.com/users/azat/gists{/gist_id}","starred_url":"https://api.github.com/users/azat/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/azat/subscriptions","organizations_url":"https://api.github.com/users/azat/orgs","repos_url":"https://api.github.com/users/azat/repos","events_url":"https://api.github.com/users/azat/events{/privacy}","received_events_url":"https://api.github.com/users/azat/received_events","type":"User","site_admin":false}],"milestone":null,"comments":3,"created_at":"2020-07-20T13:08:00Z","updated_at":"2021-05-20T12:02:16Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"```\r\nSELECT \r\n    _shard_num,\r\n    count()\r\nFROM remote('127.0.0.{1,2}', system.one)\r\nGROUP BY _shard_num\r\n\r\n↙ Progress: 0.00 rows, 0.00 B (0.00 rows/s., 0.00 B/s.) \r\nReceived exception from server (version 20.7.1):\r\nCode: 10. DB::Exception: Received from localhost:9000. DB::Exception: Not found column _shard_num in block. There are only columns: count(): While executing Remote. \r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12601/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12601/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12594","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12594/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12594/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12594/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/12594","id":661575512,"node_id":"MDU6SXNzdWU2NjE1NzU1MTI=","number":12594,"title":"`remote()` and a database name with a dot","user":{"login":"hczhcz","id":3832986,"node_id":"MDQ6VXNlcjM4MzI5ODY=","avatar_url":"https://avatars.githubusercontent.com/u/3832986?v=4","gravatar_id":"","url":"https://api.github.com/users/hczhcz","html_url":"https://github.com/hczhcz","followers_url":"https://api.github.com/users/hczhcz/followers","following_url":"https://api.github.com/users/hczhcz/following{/other_user}","gists_url":"https://api.github.com/users/hczhcz/gists{/gist_id}","starred_url":"https://api.github.com/users/hczhcz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/hczhcz/subscriptions","organizations_url":"https://api.github.com/users/hczhcz/orgs","repos_url":"https://api.github.com/users/hczhcz/repos","events_url":"https://api.github.com/users/hczhcz/events{/privacy}","received_events_url":"https://api.github.com/users/hczhcz/received_events","type":"User","site_admin":false},"labels":[{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2020-07-20T09:13:12Z","updated_at":"2020-07-21T12:19:38Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Describe the unexpected behaviour**\r\nWe can not access database with a name like `a.b` using `remote()` function\r\n\r\n**How to reproduce**\r\n```sql\r\ncreate database `x.x`;\r\ncreate table `x.x`.`x` ...;\r\nselect * from remote('localhost', 'x.x', 'x'); -- case 1: fail\r\nselect * from remote('localhost', 'x.x.x'); -- case 2: fail\r\nselect * from remote('localhost', '`x.x`.x'); -- case 3: fail\r\n```\r\n\r\n**Expected behavior**\r\nCase 1 is expected to work. It will be good if case 3 could work too.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12594/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12594/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12575","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12575/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12575/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12575/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/12575","id":660420282,"node_id":"MDU6SXNzdWU2NjA0MjAyODI=","number":12575,"title":"ALTER USER renaming to default allowed","user":{"login":"ritaank","id":47439507,"node_id":"MDQ6VXNlcjQ3NDM5NTA3","avatar_url":"https://avatars.githubusercontent.com/u/47439507?v=4","gravatar_id":"","url":"https://api.github.com/users/ritaank","html_url":"https://github.com/ritaank","followers_url":"https://api.github.com/users/ritaank/followers","following_url":"https://api.github.com/users/ritaank/following{/other_user}","gists_url":"https://api.github.com/users/ritaank/gists{/gist_id}","starred_url":"https://api.github.com/users/ritaank/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ritaank/subscriptions","organizations_url":"https://api.github.com/users/ritaank/orgs","repos_url":"https://api.github.com/users/ritaank/repos","events_url":"https://api.github.com/users/ritaank/events{/privacy}","received_events_url":"https://api.github.com/users/ritaank/received_events","type":"User","site_admin":false},"labels":[{"id":845247686,"node_id":"MDU6TGFiZWw4NDUyNDc2ODY=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/usability","name":"usability","color":"ebf28c","default":false,"description":""},{"id":2011606513,"node_id":"MDU6TGFiZWwyMDExNjA2NTEz","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-rbac","name":"comp-rbac","color":"b5bcff","default":false,"description":"Access control related"}],"state":"open","locked":false,"assignee":{"login":"vitlibar","id":45142681,"node_id":"MDQ6VXNlcjQ1MTQyNjgx","avatar_url":"https://avatars.githubusercontent.com/u/45142681?v=4","gravatar_id":"","url":"https://api.github.com/users/vitlibar","html_url":"https://github.com/vitlibar","followers_url":"https://api.github.com/users/vitlibar/followers","following_url":"https://api.github.com/users/vitlibar/following{/other_user}","gists_url":"https://api.github.com/users/vitlibar/gists{/gist_id}","starred_url":"https://api.github.com/users/vitlibar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vitlibar/subscriptions","organizations_url":"https://api.github.com/users/vitlibar/orgs","repos_url":"https://api.github.com/users/vitlibar/repos","events_url":"https://api.github.com/users/vitlibar/events{/privacy}","received_events_url":"https://api.github.com/users/vitlibar/received_events","type":"User","site_admin":false},"assignees":[{"login":"vitlibar","id":45142681,"node_id":"MDQ6VXNlcjQ1MTQyNjgx","avatar_url":"https://avatars.githubusercontent.com/u/45142681?v=4","gravatar_id":"","url":"https://api.github.com/users/vitlibar","html_url":"https://github.com/vitlibar","followers_url":"https://api.github.com/users/vitlibar/followers","following_url":"https://api.github.com/users/vitlibar/following{/other_user}","gists_url":"https://api.github.com/users/vitlibar/gists{/gist_id}","starred_url":"https://api.github.com/users/vitlibar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vitlibar/subscriptions","organizations_url":"https://api.github.com/users/vitlibar/orgs","repos_url":"https://api.github.com/users/vitlibar/repos","events_url":"https://api.github.com/users/vitlibar/events{/privacy}","received_events_url":"https://api.github.com/users/vitlibar/received_events","type":"User","site_admin":false}],"milestone":null,"comments":1,"created_at":"2020-07-18T22:29:15Z","updated_at":"2021-02-01T09:01:12Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Describe the bug**\r\nIf I have some existing {user, quota, settings profile}, and I run the ALTER command to rename that object to `default`, ClickHouse will not throw an error, and will leave me with two items named `default`, causing problems. See below.\r\n\r\n**How to reproduce**\r\n\r\nRenaming user default2 to default: command is accepted, but prevents client from working afterwards:\r\n```\r\nClickHouse client version 20.6.1.4066 (official build).\r\nConnecting to localhost:9000 as user default.\r\nConnected to ClickHouse server version 20.6.1 revision 54436.\r\n\r\nclicktest :) create user default2\r\nCREATE USER default2\r\nOk.\r\n0 rows in set. Elapsed: 0.001 sec.\r\n\r\nclicktest :) alter user default2 rename to default\r\nALTER USER default2 RENAME TO 'default'\r\nOk.\r\n0 rows in set. Elapsed: 0.001 sec.\r\n\r\nclicktest :) create user default2\r\nCREATE USER default2\r\nOk.\r\n0 rows in set. Elapsed: 0.001 sec.\r\n\r\nclicktest :) alter user default rename to default2\r\nALTER USER default RENAME TO 'default2'\r\nReceived exception from server (version 20.6.1):\r\nCode: 494. DB::Exception: Received from localhost:9000. DB::Exception: Found user `default` in 2 storages [disk, users.xml].\r\n0 rows in set. Elapsed: 0.002 sec.\r\n\r\nclicktest :) exit\r\nBye.\r\n\r\nuser@node:~/$ clickhouse-client\r\nClickHouse client version 20.6.1.4066 (official build).\r\nConnecting to localhost:9000 as user default.\r\nCode: 494. DB::Exception: Received from localhost:9000. DB::Exception: Found user `default` in 2 storages [disk, users.xml].\r\n```\r\nIn this particular case, with two users named `default`, I was unable to log back in to the `clickhouse-client`. The only thing that worked was a complete uninstall and wiping of data before reinstalling. Would not recommend trying this unless there is an easier way to undo it.\r\n\r\nSimilar behavior happens after renaming some quota to `default`:\r\n```\r\nclicktest :) show quotas\r\n\r\nSHOW QUOTAS\r\n\r\n┌─name────┐\r\n│ default │\r\n│ default │\r\n└─────────┘\r\n\r\n2 rows in set. Elapsed: 0.002 sec.\r\n```\r\nAfter which, it is impossible to use either quota (similar error as above with user):\r\n```\r\nclicktest :) alter quota default\r\nALTER QUOTA default\r\n\r\nReceived exception from server (version 20.7.1):\r\nCode: 494. DB::Exception: Received from localhost:9000. DB::Exception: Found quota `default` in 2 storages [disk, users.xml].\r\n0 rows in set. Elapsed: 0.001 sec.\r\n```\r\n\r\nI imagine the same will occur when dealing with the default settings profile. As far as I know, these 3 {user, quota, settings profile} are the only object types with a built in default version.\r\n\r\n**Expected behavior**\r\nI imagine renaming to default should be not allowed in these cases.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12575/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12575/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12571","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12571/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12571/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12571/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/12571","id":659701499,"node_id":"MDU6SXNzdWU2NTk3MDE0OTk=","number":12571,"title":"CROSS JOIN using unexpectedly large amount of memory","user":{"login":"gkristic","id":3846692,"node_id":"MDQ6VXNlcjM4NDY2OTI=","avatar_url":"https://avatars.githubusercontent.com/u/3846692?v=4","gravatar_id":"","url":"https://api.github.com/users/gkristic","html_url":"https://github.com/gkristic","followers_url":"https://api.github.com/users/gkristic/followers","following_url":"https://api.github.com/users/gkristic/following{/other_user}","gists_url":"https://api.github.com/users/gkristic/gists{/gist_id}","starred_url":"https://api.github.com/users/gkristic/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/gkristic/subscriptions","organizations_url":"https://api.github.com/users/gkristic/orgs","repos_url":"https://api.github.com/users/gkristic/repos","events_url":"https://api.github.com/users/gkristic/events{/privacy}","received_events_url":"https://api.github.com/users/gkristic/received_events","type":"User","site_admin":false},"labels":[{"id":1365579236,"node_id":"MDU6TGFiZWwxMzY1NTc5MjM2","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/minor","name":"minor","color":"FFF8F8","default":false,"description":"Priority: minor"},{"id":1507867504,"node_id":"MDU6TGFiZWwxNTA3ODY3NTA0","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/st-hold","name":"st-hold","color":"e5b890","default":false,"description":"We've paused the work on issue for some reason"},{"id":1532016596,"node_id":"MDU6TGFiZWwxNTMyMDE2NTk2","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/memory","name":"memory","color":"e99695","default":false,"description":"When memory usage is higher than expected"},{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":14,"created_at":"2020-07-17T22:40:50Z","updated_at":"2021-02-22T16:32:26Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"I've been having issues trying to find prefix relationships between strings in a table, using `startsWith` on top of a cross join. Although the dataset is about 20GiB uncompressed, ClickHouse keeps trying to allocate memory well past the mark where the entire table would fit in it. I tried in a box with 512GiB of RAM (running ClickHouse exclusively) and the query still aborts due of memory limits. My original query was more complicated and involved aggregation functions, that I blamed at first. But as I simplified the case, I noticed that the problem persists even without aggregation of any kind. In this scenario I'd expect ClickHouse to loop over the data and stream the results right away, but queries still abort instead.\r\n\r\n**Setup:** I'm using ClickHouse in Docker. It's almost exactly the standard yandex/clickhouse-server image in Docker Hub (20.5.2.7), except that I changed the max memory for queries to take advantage of the extra memory in the instance I'm using. Specifically, here's my Dockerfile:\r\n\r\n```Dockerfile\r\nFROM yandex/clickhouse-server:20.5.2.7\r\nRUN sed -i '/max_memory_usage/s/[[:digit:]]\\+/494000000000/' /etc/clickhouse-server/users.xml\r\n```\r\n\r\nThe maximum amount of total memory is set through the 0.9 ratio that comes preset in the standard image.\r\n\r\n**Dataset:** The table I'm using has only two columns: an ID (`UInt64`) and a name (`String`). In my original case the strings are all strictly different and vary in length (average ~2KiB), but I reduced the problem further to a dataset that can be easily generated on demand. In this case all strings are equal and 2KiB long. Here's the exact table structure:\r\n\r\n```\r\nclickhouse-client -q 'create database testdb'\r\nclickhouse-client -q 'create table testdb.xs (id UInt64, name String) engine=MergeTree() order by id'\r\n```\r\n\r\nYou can populate the data with:\r\n\r\n```\r\nX=\"$(dd if=/dev/zero bs=2048 count=1 status=none | tr '\\0' X)\"\r\nseq 10000000 | sed \"s/\\$/,$X/\" | clickhouse-client -q 'insert into testdb.xs format CSV'\r\n```\r\n\r\n**Query:** Here's the query I run:\r\n\r\n```sql\r\nselect q.id, p.id\r\nfrom xs q, xs p\r\nwhere startsWith(q.name, p.name);\r\n```\r\n\r\nThe problem seems to be related to the presence of `startsWith`. If I remove it and go for the full cross join, or change it to avoid the reflexive cases (`q.id != p.id`), ClickHouse starts returning results immdiately. However, the experience with this query is that it blocks until it aborts due to memory. It doesn't print even a single result. I set `send_logs_level` to `trace` to have a better perspective, and here's what I got (summarized below for brevity; full output [here](https://github.com/ClickHouse/ClickHouse/files/4940628/ch-trace.txt)).\r\n\r\n```\r\n8c0c3408045c :) select q.id, p.id\r\n:-] from xs q, xs p\r\n:-] where startsWith(q.name, p.name);\r\n\r\nSELECT\r\n    q.id,\r\n    p.id\r\nFROM xs AS q\r\n, xs AS p\r\nWHERE startsWith(q.name, p.name)\r\n\r\n[8c0c3408045c] 2020.07.17 20:13:04.317559 [ 91 ] {927d1881-3b29-4a59-8725-92f1f8a453ac} <Debug> executeQuery: (from 172.17.0.3:58310) select q.id, p.id from xs q, xs p where startsWith(q.name, p.name);\r\n↙ Progress: 0.00 rows, 0.00 B (0.00 rows/s., 0.00 B/s.)\r\n← Progress: 71.38 thousand rows, 147.40 MB (641.09 thousand rows/s., 1.32 GB/s.)  0%\r\n  . . .\r\n[8c0c3408045c] 2020.07.17 20:13:04.504685 [ 155 ] {927d1881-3b29-4a59-8725-92f1f8a453ac} <Debug> MemoryTracker: Current memory usage (total): 1.01 GiB.\r\n[8c0c3408045c] 2020.07.17 20:13:04.507148 [ 137 ] {927d1881-3b29-4a59-8725-92f1f8a453ac} <Debug> MemoryTracker: Current memory usage (for query): 2.00 GiB.\r\n↑ Progress: 1.14 million rows, 2.35 GB (3.64 million rows/s., 7.52 GB/s.)  11%\r\n  . . .\r\n[8c0c3408045c] 2020.07.17 20:13:06.040223 [ 105 ] {927d1881-3b29-4a59-8725-92f1f8a453ac} <Debug> CreatingSetsBlockInputStream: Created Join with 10000000 entries from 10000000 rows in 1.709907685 sec.\r\n[8c0c3408045c] 2020.07.17 20:13:06.101276 [ 101 ] {927d1881-3b29-4a59-8725-92f1f8a453ac} <Debug> MemoryTracker: Current memory usage (total): 16.00 GiB.\r\n[8c0c3408045c] 2020.07.17 20:13:06.109714 [ 104 ] {927d1881-3b29-4a59-8725-92f1f8a453ac} <Debug> MemoryTracker: Current memory usage (for query): 32.01 GiB.\r\n  . . .\r\n[8c0c3408045c] 2020.07.17 20:13:21.054537 [ 123 ] {927d1881-3b29-4a59-8725-92f1f8a453ac} <Debug> MemoryTracker: Current memory usage (total): 420.67 GiB.\r\n[8c0c3408045c] 2020.07.17 20:13:21.112827 [ 123 ] {927d1881-3b29-4a59-8725-92f1f8a453ac} <Debug> MemoryTracker: Current memory usage (for query): 459.00 GiB.\r\n[8c0c3408045c] 2020.07.17 20:13:21.113220 [ 123 ] {927d1881-3b29-4a59-8725-92f1f8a453ac} <Debug> MemoryTracker: Current memory usage (total): 424.73 GiB.\r\n[8c0c3408045c] 2020.07.17 20:13:21.132869 [ 105 ] {927d1881-3b29-4a59-8725-92f1f8a453ac} <Debug> MemoryTracker: Current memory usage (for query): 459.01 GiB.\r\n[8c0c3408045c] 2020.07.17 20:14:16.628530 [ 91 ] {927d1881-3b29-4a59-8725-92f1f8a453ac} <Error> executeQuery: Code: 241, e.displayText() = DB::Exception: Memory limit (for query) exceeded: would use 463.01 GiB (attempt to allocate chunk of 4294967296 bytes), maximum: 460.07 GiB (version 20.5.2.7 (official build)) (from 172.17.0.3:58310) (in query: select q.id, p.id from xs q, xs p where startsWith(q.name, p.name);), Stack trace (when copying this message, always include the lines below):\r\n\r\n0. Poco::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int) @ 0x10ed0da0 in /usr/bin/clickhouse\r\n1. DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int) @ 0x95c923d in /usr/bin/clickhouse\r\n2. ? @ 0x95c8228 in /usr/bin/clickhouse\r\n3. MemoryTracker::alloc(long) @ 0x95c6724 in /usr/bin/clickhouse\r\n4. Allocator<false, false>::realloc(void*, unsigned long, unsigned long, unsigned long) @ 0x96118fb in /usr/bin/clickhouse\r\n5. ? @ 0xe10356c in /usr/bin/clickhouse\r\n6. DB::ColumnString::insertFrom(DB::IColumn const&, unsigned long) @ 0xe10ceec in /usr/bin/clickhouse\r\n7. DB::HashJoin::joinBlockImplCross(DB::Block&, std::__1::shared_ptr<DB::ExtraBlock>&) const @ 0xdbd7784 in /usr/bin/clickhouse\r\n8. DB::HashJoin::joinBlock(DB::Block&, std::__1::shared_ptr<DB::ExtraBlock>&) @ 0xdc15c1f in /usr/bin/clickhouse\r\n9. DB::ExpressionAction::execute(DB::Block&, bool, std::__1::shared_ptr<DB::ExtraBlock>&) const @ 0xdd46de3 in /usr/bin/clickhouse\r\n10. DB::ExpressionActions::execute(DB::Block&, std::__1::shared_ptr<DB::ExtraBlock>&, unsigned long&) const @ 0xdd4980e in /usr/bin/clickhouse\r\n11. DB::InflatingExpressionTransform::readExecute(DB::Chunk&) @ 0xe991b3d in /usr/bin/clickhouse\r\n12. DB::InflatingExpressionTransform::transform(DB::Chunk&) @ 0xe992539 in /usr/bin/clickhouse\r\n13. DB::ISimpleTransform::work() @ 0xe6d7b50 in /usr/bin/clickhouse\r\n14. ? @ 0xe70aa21 in /usr/bin/clickhouse\r\n15. ? @ 0xe70f1a6 in /usr/bin/clickhouse\r\n16. ? @ 0xe70f7f2 in /usr/bin/clickhouse\r\n17. ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) @ 0x95f6e97 in /usr/bin/clickhouse\r\n18. ? @ 0x95f5383 in /usr/bin/clickhouse\r\n19. start_thread @ 0x76db in /lib/x86_64-linux-gnu/libpthread-2.27.so\r\n20. clone @ 0x12188f in /lib/x86_64-linux-gnu/libc-2.27.so\r\n\r\n\r\nReceived exception from server (version 20.5.2):\r\nCode: 241. DB::Exception: Received from server:9000. DB::Exception: Memory limit (for query) exceeded: would use 463.01 GiB (attempt to allocate chunk of 4294967296 bytes), maximum: 460.07 GiB.\r\n\r\n0 rows in set. Elapsed: 72.313 sec. Processed 10.16 million rows, 20.99 GB (140.54 thousand rows/s., 290.22 MB/s.)\r\n```\r\n\r\nI tried with the standard [Yandex.Metrica](https://clickhouse.tech/docs/en/getting-started/example-datasets/metrica/) dataset, using the URL field in kind of the same way:\r\n\r\n```sql\r\nselect q.URL, p.URL\r\nfrom hits_v1 q, hits_v1 p\r\nwhere startsWith(q.URL, p.URL);\r\n```\r\n\r\nIn this case it sent ~10K results almost immediately (for URL `http://public_search`) and then kept processing silently. I didn't let it finish because I had to shutdown the instance. But I let it run for at least 10 minutes and memory use seemed pretty stable; most of the time between 30 to 40GiB, peaking at ~50GiB. It still seems extremely high, though, considering that the uncompressed dataset is 6GiB. Also, in my case above the string is 2KiB for all rows, whereas in this dataset the `URL` column is empty for most of them (more than 7 out of 8 million), and most of those that are non-empty are shorter than 200 bytes.\r\n\r\nFor contrast:\r\n\r\n```\r\nSELECT\r\n    database,\r\n    formatReadableSize(sum(bytes_on_disk)) AS on_disk,\r\n    formatReadableSize(sum(data_compressed_bytes)) AS data_compressed,\r\n    formatReadableSize(sum(data_uncompressed_bytes)) AS data_uncompressed\r\nFROM parts\r\nWHERE database IN ('testdb', 'datasets')\r\nGROUP BY database\r\n\r\n┌─database─┬─on_disk────┬─data_compressed─┬─data_uncompressed─┐\r\n│ testdb   │ 115.80 MiB │ 115.70 MiB      │ 19.17 GiB         │\r\n│ datasets │ 1.18 GiB   │ 1.18 GiB        │ 5.73 GiB          │\r\n└──────────┴────────────┴─────────────────┴───────────────────┘\r\n\r\n2 rows in set. Elapsed: 0.006 sec.\r\n```\r\n\r\nLet me know if there's anything I can help with.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12571/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12571/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12544","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12544/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12544/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12544/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/12544","id":658031154,"node_id":"MDU6SXNzdWU2NTgwMzExNTQ=","number":12544,"title":"After malformed row policy clickhouse wouldn't parse following row policies","user":{"login":"UnamedRus","id":9449405,"node_id":"MDQ6VXNlcjk0NDk0MDU=","avatar_url":"https://avatars.githubusercontent.com/u/9449405?v=4","gravatar_id":"","url":"https://api.github.com/users/UnamedRus","html_url":"https://github.com/UnamedRus","followers_url":"https://api.github.com/users/UnamedRus/followers","following_url":"https://api.github.com/users/UnamedRus/following{/other_user}","gists_url":"https://api.github.com/users/UnamedRus/gists{/gist_id}","starred_url":"https://api.github.com/users/UnamedRus/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/UnamedRus/subscriptions","organizations_url":"https://api.github.com/users/UnamedRus/orgs","repos_url":"https://api.github.com/users/UnamedRus/repos","events_url":"https://api.github.com/users/UnamedRus/events{/privacy}","received_events_url":"https://api.github.com/users/UnamedRus/received_events","type":"User","site_admin":false},"labels":[{"id":386401505,"node_id":"MDU6TGFiZWwzODY0MDE1MDU=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/bug","name":"bug","color":"ee0701","default":true,"description":"Confirmed user-visible misbehaviour in official release"}],"state":"open","locked":false,"assignee":{"login":"vitlibar","id":45142681,"node_id":"MDQ6VXNlcjQ1MTQyNjgx","avatar_url":"https://avatars.githubusercontent.com/u/45142681?v=4","gravatar_id":"","url":"https://api.github.com/users/vitlibar","html_url":"https://github.com/vitlibar","followers_url":"https://api.github.com/users/vitlibar/followers","following_url":"https://api.github.com/users/vitlibar/following{/other_user}","gists_url":"https://api.github.com/users/vitlibar/gists{/gist_id}","starred_url":"https://api.github.com/users/vitlibar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vitlibar/subscriptions","organizations_url":"https://api.github.com/users/vitlibar/orgs","repos_url":"https://api.github.com/users/vitlibar/repos","events_url":"https://api.github.com/users/vitlibar/events{/privacy}","received_events_url":"https://api.github.com/users/vitlibar/received_events","type":"User","site_admin":false},"assignees":[{"login":"vitlibar","id":45142681,"node_id":"MDQ6VXNlcjQ1MTQyNjgx","avatar_url":"https://avatars.githubusercontent.com/u/45142681?v=4","gravatar_id":"","url":"https://api.github.com/users/vitlibar","html_url":"https://github.com/vitlibar","followers_url":"https://api.github.com/users/vitlibar/followers","following_url":"https://api.github.com/users/vitlibar/following{/other_user}","gists_url":"https://api.github.com/users/vitlibar/gists{/gist_id}","starred_url":"https://api.github.com/users/vitlibar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vitlibar/subscriptions","organizations_url":"https://api.github.com/users/vitlibar/orgs","repos_url":"https://api.github.com/users/vitlibar/repos","events_url":"https://api.github.com/users/vitlibar/events{/privacy}","received_events_url":"https://api.github.com/users/vitlibar/received_events","type":"User","site_admin":false}],"milestone":null,"comments":3,"created_at":"2020-07-16T09:39:24Z","updated_at":"2020-11-06T16:22:40Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Describe the bug**\r\nWe have multiple users/row policies, some of them working, some is malformed.\r\nOn the next reload config will parse row policies and will stop on the first malformed row policy and wouldn't parse any following row policy, or even next user row policy.\r\n\r\n**How to reproduce**\r\nClickhouse 20.5.2\r\n\r\n* We will create users:a_user,b_user,c_user with defined row_policies.\r\n```\r\ncat /etc/clickhouse-server/users.d/a_user.xml\r\n\r\n<yandex>\r\n  <users>\r\n    <a_user>\r\n      <password></password>\r\n      <networks incl=\"networks\" replace=\"replace\">\r\n        <ip>::/0</ip>\r\n      </networks>\r\n      <profile>default</profile>\r\n      <quota>default</quota>\r\n      <allow_databases>\r\n        <database>default</database>\r\n      </allow_databases>\r\n      <databases>\r\n        <default>\r\n          <test_0>\r\n            <filter>test='a_user'</filter>\r\n          </test_0>\r\n        </default>\r\n      </databases>\r\n    </a_user>\r\n  </users>\r\n</yandex>\r\n\r\ncat /etc/clickhouse-server/users.d/b_user.xml\r\n\r\n<yandex>\r\n  <users>\r\n    <b_user>\r\n      <password></password>\r\n      <networks incl=\"networks\" replace=\"replace\">\r\n        <ip>::/0</ip>\r\n      </networks>\r\n      <profile>default</profile>\r\n      <quota>default</quota>\r\n      <allow_databases>\r\n        <database>default</database>\r\n      </allow_databases>\r\n      <databases>\r\n        <default>\r\n          <test_0>\r\n            <filter>test='b_user'</filter>\r\n          </test_0>\r\n        </default>\r\n      </databases>\r\n    </b_user>\r\n  </users>\r\n</yandex>\r\n\r\ncat /etc/clickhouse-server/users.d/c_user.xml\r\n\r\n<yandex>\r\n  <users>\r\n    <c_user>\r\n      <password></password>\r\n      <networks incl=\"networks\" replace=\"replace\">\r\n        <ip>::/0</ip>\r\n      </networks>\r\n      <profile>default</profile>\r\n      <quota>default</quota>\r\n      <allow_databases>\r\n        <database>default</database>\r\n      </allow_databases>\r\n      <databases>\r\n        <default>\r\n          <test_1>\r\n            <filter>test='c_user'</filter>\r\n          </test_1>\r\n          <test_2>\r\n            <filter>test='c_user'</filter>\r\n          </test_2>\r\n          <test_3>\r\n            <filter>test='c_user'</filter>\r\n          </test_3>\r\n        </default>\r\n      </databases>\r\n    </c_user>\r\n  </users>\r\n</yandex>\r\n```\r\n*  Reload config and check our row policies:\r\n```\r\nSYSTEM RELOAD CONFIG;\r\nSELECT * FROM system.row_policies WHERE short_name LIKE '%user';\r\n12 rows in set. Elapsed: 0.002 sec.\r\n```\r\nAll policies showed up.\r\n\r\n* For user c_user rename table `test_2` in row policies to `test.2`\r\n\r\n*  Reload config and check our row policies:\r\n```\r\nSYSTEM RELOAD CONFIG;\r\nSELECT * FROM system.row_policies WHERE short_name LIKE '%user';\r\n6 rows in set. Elapsed: 0.002 sec.\r\n```\r\nPolicy which is being parsed after malformed policy and malformed policy itself disappears.\r\n\r\n* For user a_user rename table `test_0` in row policies to `test.0`\r\n\r\n*  Reload config and check our row policies:\r\n```\r\nSYSTEM RELOAD CONFIG;\r\nSELECT * FROM system.row_policies WHERE short_name LIKE '%user';\r\n0 rows in set. Elapsed: 0.002 sec.\r\n```\r\nAll policies disappear because malformed policy was first to parse.\r\n\r\n**Expected behavior**\r\nClickhouse will skip any malformed row policy and will parse all of the working policy.\r\n\r\n**Stack Trace**\r\n```\r\n2020.07.16 12:38:33.120736 [ 572 ] {3f2ab9bc-c6c2-4bf7-955c-1e7cfb1423ea} <Error> Access(users.xml): Could not parse row policies: Poco::Exception. Code: 1000, e.code() = 0, e.displayText() = Not found: users.c_user.databases.default.test.2.filter, Stack trace (when copying this message, always include the lines below):\r\n\r\n0. /build/obj-x86_64-linux-gnu/../contrib/poco/Foundation/src/Exception.cpp:27: Poco::NotFoundException::NotFoundException(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int) @ 0x10ed4bb0 in /usr/lib/debug/usr/bin/clickhouse\r\n1. /build/obj-x86_64-linux-gnu/../contrib/poco/Util/src/AbstractConfiguration.cpp:77: Poco::Util::AbstractConfiguration::getString(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) const (.cold) @ 0x10dfa06a in /usr/lib/debug/usr/bin/clickhouse\r\n2. /build/obj-x86_64-linux-gnu/../contrib/libcxx/include/utility:447: DB::(anonymous namespace)::parseRowPolicies(Poco::Util::AbstractConfiguration const&, Poco::Logger*) @ 0xd8afa9d in /usr/lib/debug/usr/bin/clickhouse\r\n3. /build/obj-x86_64-linux-gnu/../contrib/libcxx/include/vector:1532: DB::UsersConfigAccessStorage::setConfiguration(Poco::Util::AbstractConfiguration const&) @ 0xd8b39f7 in /usr/lib/debug/usr/bin/clickhouse\r\n4. /build/obj-x86_64-linux-gnu/../contrib/libcxx/include/__mutex_base:140: DB::Context::setUsersConfig(Poco::AutoPtr<Poco::Util::AbstractConfiguration> const&) @ 0xdb15dd3 in /usr/lib/debug/usr/bin/clickhouse\r\n5. /build/obj-x86_64-linux-gnu/../programs/server/Server.cpp:579: std::__1::__function::__func<DB::Server::main(std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&)::'lambda3'(Poco::AutoPtr<Poco::Util::AbstractConfiguration>), std::__1::allocator<DB::Server::main(std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&)::'lambda3'(Poco::AutoPtr<Poco::Util::AbstractConfiguration>)>, void (Poco::AutoPtr<Poco::Util::AbstractConfiguration>)>::operator()(Poco::AutoPtr<Poco::Util::AbstractConfiguration>&&) @ 0x962421d in /usr/lib/debug/usr/bin/clickhouse\r\n6. /build/obj-x86_64-linux-gnu/../contrib/poco/Foundation/include/Poco/AutoPtr.h:90: DB::ConfigReloader::reloadIfNewer(bool, bool, bool) @ 0xea3cd76 in /usr/lib/debug/usr/bin/clickhouse\r\n7. /build/obj-x86_64-linux-gnu/../src/Interpreters/Context.cpp:1941: DB::Context::reloadConfig() const @ 0xdb19b42 in /usr/lib/debug/usr/bin/clickhouse\r\n8. /build/obj-x86_64-linux-gnu/../src/Interpreters/InterpreterSystemQuery.cpp:244: DB::InterpreterSystemQuery::execute() @ 0xdf2b84a in /usr/lib/debug/usr/bin/clickhouse\r\n9. /build/obj-x86_64-linux-gnu/../src/Interpreters/executeQuery.cpp:384: DB::executeQueryImpl(char const*, char const*, DB::Context&, bool, DB::QueryProcessingStage::Enum, bool, DB::ReadBuffer*) @ 0xe074a59 in /usr/lib/debug/usr/bin/clickhouse\r\n10. /build/obj-x86_64-linux-gnu/../src/Interpreters/executeQuery.cpp:643: DB::executeQuery(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, DB::Context&, bool, DB::QueryProcessingStage::Enum, bool) @ 0xe07811a in /usr/lib/debug/usr/bin/clickhouse\r\n11. /build/obj-x86_64-linux-gnu/../src/Server/TCPHandler.cpp:251: DB::TCPHandler::runImpl() @ 0xe698946 in /usr/lib/debug/usr/bin/clickhouse\r\n12. /build/obj-x86_64-linux-gnu/../src/Server/TCPHandler.cpp:1197: DB::TCPHandler::run() @ 0xe699660 in /usr/lib/debug/usr/bin/clickhouse\r\n13. /build/obj-x86_64-linux-gnu/../contrib/poco/Net/src/TCPServerConnection.cpp:57: Poco::Net::TCPServerConnection::start() @ 0x10deebcb in /usr/lib/debug/usr/bin/clickhouse\r\n14. /build/obj-x86_64-linux-gnu/../contrib/libcxx/include/atomic:856: Poco::Net::TCPServerDispatcher::run() @ 0x10def05b in /usr/lib/debug/usr/bin/clickhouse\r\n15. /build/obj-x86_64-linux-gnu/../contrib/poco/Foundation/include/Poco/Mutex_POSIX.h:59: Poco::PooledThread::run() @ 0x10f6db86 in /usr/lib/debug/usr/bin/clickhouse\r\n16. /build/obj-x86_64-linux-gnu/../contrib/poco/Foundation/include/Poco/AutoPtr.h:223: Poco::ThreadImpl::runnableEntry(void*) @ 0x10f68f80 in /usr/lib/debug/usr/bin/clickhouse\r\n17. start_thread @ 0x9609 in /usr/lib/x86_64-linux-gnu/libpthread-2.31.so\r\n18. clone @ 0x122103 in /usr/lib/x86_64-linux-gnu/libc-2.31.so\r\n (version 20.5.2.7 (official build))\r\n```\r\n```\r\n 2020.07.16 12:37:28.001820 [ 572 ] {3886d573-a4ba-45a0-99de-1c8c2a30f69d} <Error> Access(users.xml): Could not parse row policies: Poco::Exception. Code: 1000, e.code() = 0, e.displayText() = Not found: users.a_user.databases.default.test_0.filter, Stack trace (when copying this message, always include the lines below):\r\n\r\n0. /build/obj-x86_64-linux-gnu/../contrib/poco/Foundation/src/Exception.cpp:27: Poco::NotFoundException::NotFoundException(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int) @ 0x10ed4bb0 in /usr/lib/debug/usr/bin/clickhouse\r\n1. /build/obj-x86_64-linux-gnu/../contrib/poco/Util/src/AbstractConfiguration.cpp:77: Poco::Util::AbstractConfiguration::getString(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) const (.cold) @ 0x10dfa06a in /usr/lib/debug/usr/bin/clickhouse\r\n2. /build/obj-x86_64-linux-gnu/../contrib/libcxx/include/utility:447: DB::(anonymous namespace)::parseRowPolicies(Poco::Util::AbstractConfiguration const&, Poco::Logger*) @ 0xd8afa9d in /usr/lib/debug/usr/bin/clickhouse\r\n3. /build/obj-x86_64-linux-gnu/../contrib/libcxx/include/vector:1532: DB::UsersConfigAccessStorage::setConfiguration(Poco::Util::AbstractConfiguration const&) @ 0xd8b39f7 in /usr/lib/debug/usr/bin/clickhouse\r\n4. /build/obj-x86_64-linux-gnu/../contrib/libcxx/include/__mutex_base:140: DB::Context::setUsersConfig(Poco::AutoPtr<Poco::Util::AbstractConfiguration> const&) @ 0xdb15dd3 in /usr/lib/debug/usr/bin/clickhouse\r\n5. /build/obj-x86_64-linux-gnu/../programs/server/Server.cpp:579: std::__1::__function::__func<DB::Server::main(std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&)::'lambda3'(Poco::AutoPtr<Poco::Util::AbstractConfiguration>), std::__1::allocator<DB::Server::main(std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&)::'lambda3'(Poco::AutoPtr<Poco::Util::AbstractConfiguration>)>, void (Poco::AutoPtr<Poco::Util::AbstractConfiguration>)>::operator()(Poco::AutoPtr<Poco::Util::AbstractConfiguration>&&) @ 0x962421d in /usr/lib/debug/usr/bin/clickhouse\r\n6. /build/obj-x86_64-linux-gnu/../contrib/poco/Foundation/include/Poco/AutoPtr.h:90: DB::ConfigReloader::reloadIfNewer(bool, bool, bool) @ 0xea3cd76 in /usr/lib/debug/usr/bin/clickhouse\r\n7. /build/obj-x86_64-linux-gnu/../src/Interpreters/Context.cpp:1941: DB::Context::reloadConfig() const @ 0xdb19b42 in /usr/lib/debug/usr/bin/clickhouse\r\n8. /build/obj-x86_64-linux-gnu/../src/Interpreters/InterpreterSystemQuery.cpp:244: DB::InterpreterSystemQuery::execute() @ 0xdf2b84a in /usr/lib/debug/usr/bin/clickhouse\r\n9. /build/obj-x86_64-linux-gnu/../src/Interpreters/executeQuery.cpp:384: DB::executeQueryImpl(char const*, char const*, DB::Context&, bool, DB::QueryProcessingStage::Enum, bool, DB::ReadBuffer*) @ 0xe074a59 in /usr/lib/debug/usr/bin/clickhouse\r\n10. /build/obj-x86_64-linux-gnu/../src/Interpreters/executeQuery.cpp:643: DB::executeQuery(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, DB::Context&, bool, DB::QueryProcessingStage::Enum, bool) @ 0xe07811a in /usr/lib/debug/usr/bin/clickhouse\r\n11. /build/obj-x86_64-linux-gnu/../src/Server/TCPHandler.cpp:251: DB::TCPHandler::runImpl() @ 0xe698946 in /usr/lib/debug/usr/bin/clickhouse\r\n12. /build/obj-x86_64-linux-gnu/../src/Server/TCPHandler.cpp:1197: DB::TCPHandler::run() @ 0xe699660 in /usr/lib/debug/usr/bin/clickhouse\r\n13. /build/obj-x86_64-linux-gnu/../contrib/poco/Net/src/TCPServerConnection.cpp:57: Poco::Net::TCPServerConnection::start() @ 0x10deebcb in /usr/lib/debug/usr/bin/clickhouse\r\n14. /build/obj-x86_64-linux-gnu/../contrib/libcxx/include/atomic:856: Poco::Net::TCPServerDispatcher::run() @ 0x10def05b in /usr/lib/debug/usr/bin/clickhouse\r\n15. /build/obj-x86_64-linux-gnu/../contrib/poco/Foundation/include/Poco/Mutex_POSIX.h:59: Poco::PooledThread::run() @ 0x10f6db86 in /usr/lib/debug/usr/bin/clickhouse\r\n16. /build/obj-x86_64-linux-gnu/../contrib/poco/Foundation/include/Poco/AutoPtr.h:223: Poco::ThreadImpl::runnableEntry(void*) @ 0x10f68f80 in /usr/lib/debug/usr/bin/clickhouse\r\n17. start_thread @ 0x9609 in /usr/lib/x86_64-linux-gnu/libpthread-2.31.so\r\n18. clone @ 0x122103 in /usr/lib/x86_64-linux-gnu/libc-2.31.so\r\n (version 20.5.2.7 (official build))\r\n```\r\n\r\n**Additional context**\r\nClickhouse 20.3.11.97 have that issue too.\r\n\r\nPolicies like this:\r\n```\r\n      <databases>\r\n        <default>\r\n          <test_0>\r\n          </test_0>\r\n        </default>\r\n      </databases>\r\n\r\n      <databases>\r\n        <default>\r\n          <test_0/>\r\n        </default>\r\n      </databases>\r\n```\r\nPrevents clickhouse from row policy parsing too.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12544/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12544/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12530","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12530/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12530/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12530/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/12530","id":657398899,"node_id":"MDU6SXNzdWU2NTczOTg4OTk=","number":12530,"title":"Multiple sending data from a distributed table","user":{"login":"EkaterinaAsabina","id":68337152,"node_id":"MDQ6VXNlcjY4MzM3MTUy","avatar_url":"https://avatars.githubusercontent.com/u/68337152?v=4","gravatar_id":"","url":"https://api.github.com/users/EkaterinaAsabina","html_url":"https://github.com/EkaterinaAsabina","followers_url":"https://api.github.com/users/EkaterinaAsabina/followers","following_url":"https://api.github.com/users/EkaterinaAsabina/following{/other_user}","gists_url":"https://api.github.com/users/EkaterinaAsabina/gists{/gist_id}","starred_url":"https://api.github.com/users/EkaterinaAsabina/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/EkaterinaAsabina/subscriptions","organizations_url":"https://api.github.com/users/EkaterinaAsabina/orgs","repos_url":"https://api.github.com/users/EkaterinaAsabina/repos","events_url":"https://api.github.com/users/EkaterinaAsabina/events{/privacy}","received_events_url":"https://api.github.com/users/EkaterinaAsabina/received_events","type":"User","site_admin":false},"labels":[{"id":386401505,"node_id":"MDU6TGFiZWwzODY0MDE1MDU=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/bug","name":"bug","color":"ee0701","default":true,"description":"Confirmed user-visible misbehaviour in official release"},{"id":1507867504,"node_id":"MDU6TGFiZWwxNTA3ODY3NTA0","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/st-hold","name":"st-hold","color":"e5b890","default":false,"description":"We've paused the work on issue for some reason"},{"id":2070999159,"node_id":"MDU6TGFiZWwyMDcwOTk5MTU5","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/v20.4-affected","name":"v20.4-affected","color":"c2bfff","default":false,"description":"This issue affects some releases of v20.4"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2020-07-15T14:33:03Z","updated_at":"2021-02-15T02:32:26Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Two shards without replication, version CH 20.4.5.36.\r\n\r\n1. Create local Main_Tab tables\r\n2. Create a Distributed table for Main_Tab tables - Distr_main_tab\r\n3. Create a MaterializedView - MV and Tab - target tables that select and transform data from local tables Main_Tab  and insert their to Tab.\r\n4. Insert data into Distr_main_tab\r\n5. An error occurred while inserting into the target tables from MV.\r\n6. In Distr_main_tab and Main_Tab, the data that should have been sent to the Main_Tab tables and then through MV in Tab is multiplied.\r\n\r\nOne gets the impression, as if, of a Distributed table, without receiving information that the data block was successfully transferred to the node - trying to send the same block many times, thereby multiplying the data.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12530/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12530/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12511","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12511/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12511/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12511/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/12511","id":657149991,"node_id":"MDU6SXNzdWU2NTcxNDk5OTE=","number":12511,"title":"Update/Delete Issue found","user":{"login":"Crazylearner30","id":45940564,"node_id":"MDQ6VXNlcjQ1OTQwNTY0","avatar_url":"https://avatars.githubusercontent.com/u/45940564?v=4","gravatar_id":"","url":"https://api.github.com/users/Crazylearner30","html_url":"https://github.com/Crazylearner30","followers_url":"https://api.github.com/users/Crazylearner30/followers","following_url":"https://api.github.com/users/Crazylearner30/following{/other_user}","gists_url":"https://api.github.com/users/Crazylearner30/gists{/gist_id}","starred_url":"https://api.github.com/users/Crazylearner30/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Crazylearner30/subscriptions","organizations_url":"https://api.github.com/users/Crazylearner30/orgs","repos_url":"https://api.github.com/users/Crazylearner30/repos","events_url":"https://api.github.com/users/Crazylearner30/events{/privacy}","received_events_url":"https://api.github.com/users/Crazylearner30/received_events","type":"User","site_admin":false},"labels":[{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2020-07-15T08:05:03Z","updated_at":"2020-07-15T14:50:47Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Hi,\r\n\r\nThere is a strange issue found with the below statement.\r\n\r\nalter table test_table update column1=10 where column2 =0\r\nalter table test_table1 delete where column1=2\r\n\r\nabove two alter statements works perfectly fine without any errors, but it doesn't reflect in the table(basically values are not changing at all).\r\nin system.mutations table \"is_done\" is not changed to 1 \r\nClickHouse server version 20.1.11 revision 54431.\r\n\r\nCan somebody please help me to rectify this.\r\n\r\nThanks in advance.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12511/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12511/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12500","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12500/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12500/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12500/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/12500","id":656745227,"node_id":"MDU6SXNzdWU2NTY3NDUyMjc=","number":12500,"title":"Removing and re-adding the same user to users.xml block it from successfully authenticating.","user":{"login":"traceon","id":10261534,"node_id":"MDQ6VXNlcjEwMjYxNTM0","avatar_url":"https://avatars.githubusercontent.com/u/10261534?v=4","gravatar_id":"","url":"https://api.github.com/users/traceon","html_url":"https://github.com/traceon","followers_url":"https://api.github.com/users/traceon/followers","following_url":"https://api.github.com/users/traceon/following{/other_user}","gists_url":"https://api.github.com/users/traceon/gists{/gist_id}","starred_url":"https://api.github.com/users/traceon/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/traceon/subscriptions","organizations_url":"https://api.github.com/users/traceon/orgs","repos_url":"https://api.github.com/users/traceon/repos","events_url":"https://api.github.com/users/traceon/events{/privacy}","received_events_url":"https://api.github.com/users/traceon/received_events","type":"User","site_admin":false},"labels":[{"id":386401505,"node_id":"MDU6TGFiZWwzODY0MDE1MDU=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/bug","name":"bug","color":"ee0701","default":true,"description":"Confirmed user-visible misbehaviour in official release"},{"id":2011606513,"node_id":"MDU6TGFiZWwyMDExNjA2NTEz","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-rbac","name":"comp-rbac","color":"b5bcff","default":false,"description":"Access control related"}],"state":"open","locked":false,"assignee":{"login":"vitlibar","id":45142681,"node_id":"MDQ6VXNlcjQ1MTQyNjgx","avatar_url":"https://avatars.githubusercontent.com/u/45142681?v=4","gravatar_id":"","url":"https://api.github.com/users/vitlibar","html_url":"https://github.com/vitlibar","followers_url":"https://api.github.com/users/vitlibar/followers","following_url":"https://api.github.com/users/vitlibar/following{/other_user}","gists_url":"https://api.github.com/users/vitlibar/gists{/gist_id}","starred_url":"https://api.github.com/users/vitlibar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vitlibar/subscriptions","organizations_url":"https://api.github.com/users/vitlibar/orgs","repos_url":"https://api.github.com/users/vitlibar/repos","events_url":"https://api.github.com/users/vitlibar/events{/privacy}","received_events_url":"https://api.github.com/users/vitlibar/received_events","type":"User","site_admin":false},"assignees":[{"login":"vitlibar","id":45142681,"node_id":"MDQ6VXNlcjQ1MTQyNjgx","avatar_url":"https://avatars.githubusercontent.com/u/45142681?v=4","gravatar_id":"","url":"https://api.github.com/users/vitlibar","html_url":"https://github.com/vitlibar","followers_url":"https://api.github.com/users/vitlibar/followers","following_url":"https://api.github.com/users/vitlibar/following{/other_user}","gists_url":"https://api.github.com/users/vitlibar/gists{/gist_id}","starred_url":"https://api.github.com/users/vitlibar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vitlibar/subscriptions","organizations_url":"https://api.github.com/users/vitlibar/orgs","repos_url":"https://api.github.com/users/vitlibar/repos","events_url":"https://api.github.com/users/vitlibar/events{/privacy}","received_events_url":"https://api.github.com/users/vitlibar/received_events","type":"User","site_admin":false}],"milestone":null,"comments":0,"created_at":"2020-07-14T16:31:54Z","updated_at":"2020-07-15T01:51:13Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"Affected version: `master` branch.\r\n\r\nDiscovered during testing of #11234\r\n\r\nSteps to reproduce:\r\n\r\n1. Stop the clickhouse server.\r\n2. Add some user to `users.xml`:\r\n```\r\n<abc>\r\n    <password>xyz</password>\r\n</abc>\r\n```\r\n3. Start clickhouse server.\r\n4. Execute a query on behalf of this user (expected and actual behavior: success).\r\n5. Without stopping clickhouse remove the user entry added at step 2 from `users.xml` (expected and actual behavior: clickhouse config reloader detects the change and reloads `users.xml`).\r\n6. Execute a query on behalf of this user (expected and actual behavior: auth failure with `DB::Exception: abc: Authentication failed: password is incorrect or there is no user with such name.`).\r\n7. Without stopping clickhouse re-add the **same** user as in step 2 (expected and actual behavior: clickhouse config reloader detects the change and reloads `users.xml`).\r\n8. Execute a query on behalf of this user (expected behavior: success; actual behavior: **auth failure** as during step 6).\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12500/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12500/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12495","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12495/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12495/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12495/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/12495","id":656667995,"node_id":"MDU6SXNzdWU2NTY2Njc5OTU=","number":12495,"title":"SHOW CREATE QUOTA treats CURRENT as a name rather than a different clause","user":{"login":"MyroTk","id":44327070,"node_id":"MDQ6VXNlcjQ0MzI3MDcw","avatar_url":"https://avatars.githubusercontent.com/u/44327070?v=4","gravatar_id":"","url":"https://api.github.com/users/MyroTk","html_url":"https://github.com/MyroTk","followers_url":"https://api.github.com/users/MyroTk/followers","following_url":"https://api.github.com/users/MyroTk/following{/other_user}","gists_url":"https://api.github.com/users/MyroTk/gists{/gist_id}","starred_url":"https://api.github.com/users/MyroTk/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/MyroTk/subscriptions","organizations_url":"https://api.github.com/users/MyroTk/orgs","repos_url":"https://api.github.com/users/MyroTk/repos","events_url":"https://api.github.com/users/MyroTk/events{/privacy}","received_events_url":"https://api.github.com/users/MyroTk/received_events","type":"User","site_admin":false},"labels":[{"id":386401505,"node_id":"MDU6TGFiZWwzODY0MDE1MDU=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/bug","name":"bug","color":"ee0701","default":true,"description":"Confirmed user-visible misbehaviour in official release"},{"id":2011606513,"node_id":"MDU6TGFiZWwyMDExNjA2NTEz","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-rbac","name":"comp-rbac","color":"b5bcff","default":false,"description":"Access control related"}],"state":"open","locked":false,"assignee":{"login":"vitlibar","id":45142681,"node_id":"MDQ6VXNlcjQ1MTQyNjgx","avatar_url":"https://avatars.githubusercontent.com/u/45142681?v=4","gravatar_id":"","url":"https://api.github.com/users/vitlibar","html_url":"https://github.com/vitlibar","followers_url":"https://api.github.com/users/vitlibar/followers","following_url":"https://api.github.com/users/vitlibar/following{/other_user}","gists_url":"https://api.github.com/users/vitlibar/gists{/gist_id}","starred_url":"https://api.github.com/users/vitlibar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vitlibar/subscriptions","organizations_url":"https://api.github.com/users/vitlibar/orgs","repos_url":"https://api.github.com/users/vitlibar/repos","events_url":"https://api.github.com/users/vitlibar/events{/privacy}","received_events_url":"https://api.github.com/users/vitlibar/received_events","type":"User","site_admin":false},"assignees":[{"login":"vitlibar","id":45142681,"node_id":"MDQ6VXNlcjQ1MTQyNjgx","avatar_url":"https://avatars.githubusercontent.com/u/45142681?v=4","gravatar_id":"","url":"https://api.github.com/users/vitlibar","html_url":"https://github.com/vitlibar","followers_url":"https://api.github.com/users/vitlibar/followers","following_url":"https://api.github.com/users/vitlibar/following{/other_user}","gists_url":"https://api.github.com/users/vitlibar/gists{/gist_id}","starred_url":"https://api.github.com/users/vitlibar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vitlibar/subscriptions","organizations_url":"https://api.github.com/users/vitlibar/orgs","repos_url":"https://api.github.com/users/vitlibar/repos","events_url":"https://api.github.com/users/vitlibar/events{/privacy}","received_events_url":"https://api.github.com/users/vitlibar/received_events","type":"User","site_admin":false}],"milestone":null,"comments":0,"created_at":"2020-07-14T14:42:57Z","updated_at":"2020-07-15T01:52:08Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Describe the bug**\r\n`SHOW CREATE QUOTA CURRENT` does not show show create for the current quota, but rather sees `CURRENT` as the name of the quota and produces an exception.\r\n\r\n**How to reproduce**\r\nClickHouse server version 20.6.1 revision 54436.\r\n`SHOW CREATE QUOTA CURRENT`\r\n`SHOW CREATE QUOTA`\r\n\r\n**Expected behavior**\r\nBoth `SHOW CREATE QUOTA CURRENT` and `SHOW CREATE QUOTA` should return the same result.\r\n\r\n**Error message and/or stacktrace**\r\n```\r\nClickHouse client version 20.6.1.4066 (official build).\r\nConnecting to localhost:9000 as user default.\r\nConnected to ClickHouse server version 20.6.1 revision 54436.\r\n\r\nclicktest :) SHOW CREATE QUOTA CURRENT\r\n\r\nSHOW CREATE QUOTA CURRENT\r\n\r\n\r\nReceived exception from server (version 20.6.1):\r\nCode: 199. DB::Exception: Received from localhost:9000. DB::Exception: There is no quota `CURRENT` in [disk, users.xml].\r\n\r\n0 rows in set. Elapsed: 0.008 sec.\r\n\r\nclicktest :) SHOW CREATE QUOTA\r\n\r\nSHOW CREATE QUOTA\r\n\r\n┌─CREATE QUOTA─────────────────────────────────────────────────────────────────────────┐\r\n│ CREATE QUOTA default KEYED BY user_name FOR INTERVAL 1 hour TRACKING ONLY TO default │\r\n└──────────────────────────────────────────────────────────────────────────────────────┘\r\n\r\n1 rows in set. Elapsed: 0.005 sec.\r\n\r\nclicktest :)\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12495/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/12495/timeline","performed_via_github_app":null}]

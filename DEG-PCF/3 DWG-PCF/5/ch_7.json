[{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29777","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29777/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29777/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29777/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29777","id":1016340262,"node_id":"I_kwDOA5dJV848lB8m","number":29777,"title":"Add autoincrement for id field ","user":{"login":"coderj001","id":39460245,"node_id":"MDQ6VXNlcjM5NDYwMjQ1","avatar_url":"https://avatars.githubusercontent.com/u/39460245?v=4","gravatar_id":"","url":"https://api.github.com/users/coderj001","html_url":"https://github.com/coderj001","followers_url":"https://api.github.com/users/coderj001/followers","following_url":"https://api.github.com/users/coderj001/following{/other_user}","gists_url":"https://api.github.com/users/coderj001/gists{/gist_id}","starred_url":"https://api.github.com/users/coderj001/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/coderj001/subscriptions","organizations_url":"https://api.github.com/users/coderj001/orgs","repos_url":"https://api.github.com/users/coderj001/repos","events_url":"https://api.github.com/users/coderj001/events{/privacy}","received_events_url":"https://api.github.com/users/coderj001/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-10-05T13:35:23Z","updated_at":"2021-10-05T13:35:23Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"\r\n**Use case**\r\n\r\n```\r\nALTER TABLE table_name ADD COLUMN id AUTOINCREMENT PRIMARY KEY;\r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29777/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29777/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29769","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29769/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29769/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29769/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29769","id":1016163710,"node_id":"I_kwDOA5dJV848kW1-","number":29769,"title":"Add docs for supported signals ","user":{"login":"qoega","id":2159081,"node_id":"MDQ6VXNlcjIxNTkwODE=","avatar_url":"https://avatars.githubusercontent.com/u/2159081?v=4","gravatar_id":"","url":"https://api.github.com/users/qoega","html_url":"https://github.com/qoega","followers_url":"https://api.github.com/users/qoega/followers","following_url":"https://api.github.com/users/qoega/following{/other_user}","gists_url":"https://api.github.com/users/qoega/gists{/gist_id}","starred_url":"https://api.github.com/users/qoega/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/qoega/subscriptions","organizations_url":"https://api.github.com/users/qoega/orgs","repos_url":"https://api.github.com/users/qoega/repos","events_url":"https://api.github.com/users/qoega/events{/privacy}","received_events_url":"https://api.github.com/users/qoega/received_events","type":"User","site_admin":false},"labels":[{"id":785082162,"node_id":"MDU6TGFiZWw3ODUwODIxNjI=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-documentation","name":"comp-documentation","color":"b5bcff","default":false,"description":"Used to run automatic builds of the documentation"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-10-05T10:39:16Z","updated_at":"2021-10-05T10:40:14Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"For example SIGHUP is used to rotate logs. And some signals are used internally for query profiler.\r\nWe need to add it to logs.\r\nhttps://github.com/ClickHouse/ClickHouse/blob/6abb3d4c6d89d9ae6b8dc090596b3080aca9863b/base/daemon/BaseDaemon.cpp#L804-L817","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29769/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29769/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29761","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29761/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29761/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29761/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29761","id":1015971840,"node_id":"I_kwDOA5dJV848joAA","number":29761,"title":"'alter table delete where' works not for all partitions","user":{"login":"alexsubota","id":4305175,"node_id":"MDQ6VXNlcjQzMDUxNzU=","avatar_url":"https://avatars.githubusercontent.com/u/4305175?v=4","gravatar_id":"","url":"https://api.github.com/users/alexsubota","html_url":"https://github.com/alexsubota","followers_url":"https://api.github.com/users/alexsubota/followers","following_url":"https://api.github.com/users/alexsubota/following{/other_user}","gists_url":"https://api.github.com/users/alexsubota/gists{/gist_id}","starred_url":"https://api.github.com/users/alexsubota/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexsubota/subscriptions","organizations_url":"https://api.github.com/users/alexsubota/orgs","repos_url":"https://api.github.com/users/alexsubota/repos","events_url":"https://api.github.com/users/alexsubota/events{/privacy}","received_events_url":"https://api.github.com/users/alexsubota/received_events","type":"User","site_admin":false},"labels":[{"id":1507860028,"node_id":"MDU6TGFiZWwxNTA3ODYwMDI4","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/st-need-repro","name":"st-need-repro","color":"e5b890","default":false,"description":"We were not able to reproduce the problem, please help us."},{"id":3260776666,"node_id":"MDU6TGFiZWwzMjYwNzc2NjY2","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/potential%20bug","name":"potential bug","color":"ffc080","default":false,"description":"To be reviewed by developers and confirmed/rejected."}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":12,"created_at":"2021-10-05T07:16:40Z","updated_at":"2021-10-11T17:15:16Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"v.21.7.7.47\r\n\r\nSo, i have table with ts column partitioned by toYYYYMM(toDateTime(ts / 1000))\r\ni want to delete some data by condition, and use 'alter table ... delete where ...', and some data deleted, but data from some partitions not deleted.\r\nTry to do this multiple time, same result. Try to do 'alter table ... delete in partition ... where ...' got same result.\r\nTrying to reproduce this on test data, but cant","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29761/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29761/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29759","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29759/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29759/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29759/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29759","id":1015943559,"node_id":"I_kwDOA5dJV848jhGH","number":29759,"title":"Logical error: 'Block structure mismatch in Pipes stream: different types: Received signal 6 Received signal Aborted (6)","user":{"login":"ucasfl","id":22127746,"node_id":"MDQ6VXNlcjIyMTI3NzQ2","avatar_url":"https://avatars.githubusercontent.com/u/22127746?v=4","gravatar_id":"","url":"https://api.github.com/users/ucasfl","html_url":"https://github.com/ucasfl","followers_url":"https://api.github.com/users/ucasfl/followers","following_url":"https://api.github.com/users/ucasfl/following{/other_user}","gists_url":"https://api.github.com/users/ucasfl/gists{/gist_id}","starred_url":"https://api.github.com/users/ucasfl/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ucasfl/subscriptions","organizations_url":"https://api.github.com/users/ucasfl/orgs","repos_url":"https://api.github.com/users/ucasfl/repos","events_url":"https://api.github.com/users/ucasfl/events{/privacy}","received_events_url":"https://api.github.com/users/ucasfl/received_events","type":"User","site_admin":false},"labels":[{"id":1955634273,"node_id":"MDU6TGFiZWwxOTU1NjM0Mjcz","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/testing","name":"testing","color":"c9a224","default":false,"description":"Special issue with list of bugs found by CI"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-10-05T06:38:56Z","updated_at":"2021-10-05T06:38:56Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"<https://clickhouse-test-reports.s3.yandex.net/25969/86d31445fd0dd9bc086432f559d1089c3d4a7700/fuzzer_debug/report.html#fail1>","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29759/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29759/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29758","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29758/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29758/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29758/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29758","id":1015938813,"node_id":"I_kwDOA5dJV848jf79","number":29758,"title":"`heap-use-after-free` in test","user":{"login":"ucasfl","id":22127746,"node_id":"MDQ6VXNlcjIyMTI3NzQ2","avatar_url":"https://avatars.githubusercontent.com/u/22127746?v=4","gravatar_id":"","url":"https://api.github.com/users/ucasfl","html_url":"https://github.com/ucasfl","followers_url":"https://api.github.com/users/ucasfl/followers","following_url":"https://api.github.com/users/ucasfl/following{/other_user}","gists_url":"https://api.github.com/users/ucasfl/gists{/gist_id}","starred_url":"https://api.github.com/users/ucasfl/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ucasfl/subscriptions","organizations_url":"https://api.github.com/users/ucasfl/orgs","repos_url":"https://api.github.com/users/ucasfl/repos","events_url":"https://api.github.com/users/ucasfl/events{/privacy}","received_events_url":"https://api.github.com/users/ucasfl/received_events","type":"User","site_admin":false},"labels":[{"id":2104602822,"node_id":"MDU6TGFiZWwyMTA0NjAyODIy","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/fuzz","name":"fuzz","color":"abc4ea","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-10-05T06:31:21Z","updated_at":"2021-10-05T12:18:22Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"SUMMARY: ThreadSanitizer: heap-use-after-free (/workspace/clickhouse+0xdd21c7c) in DB::FunctionJSONHelpers::Executor::run(std::__1::vector > const&, std::__1::shared_ptr const&, unsigned long)\r\n\r\n<https://clickhouse-test-reports.s3.yandex.net/25969/86d31445fd0dd9bc086432f559d1089c3d4a7700/fuzzer_tsan/report.html#fail1>","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29758/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29758/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29748","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29748/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29748/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29748/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29748","id":1015522085,"node_id":"I_kwDOA5dJV848h6Ml","number":29748,"title":"CTE intermittent failure with two JOINs (?)","user":{"login":"hazzadous","id":128561,"node_id":"MDQ6VXNlcjEyODU2MQ==","avatar_url":"https://avatars.githubusercontent.com/u/128561?v=4","gravatar_id":"","url":"https://api.github.com/users/hazzadous","html_url":"https://github.com/hazzadous","followers_url":"https://api.github.com/users/hazzadous/followers","following_url":"https://api.github.com/users/hazzadous/following{/other_user}","gists_url":"https://api.github.com/users/hazzadous/gists{/gist_id}","starred_url":"https://api.github.com/users/hazzadous/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/hazzadous/subscriptions","organizations_url":"https://api.github.com/users/hazzadous/orgs","repos_url":"https://api.github.com/users/hazzadous/repos","events_url":"https://api.github.com/users/hazzadous/events{/privacy}","received_events_url":"https://api.github.com/users/hazzadous/received_events","type":"User","site_admin":false},"labels":[{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-10-04T18:58:34Z","updated_at":"2022-01-06T09:28:01Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"**Describe the unexpected behaviour**\r\n\r\nI'm trying to run a query:\r\n\r\n```\r\nWITH cte1 as (\r\n    SELECT '1234' as x\r\n ), cte2 as (\r\n    SELECT '1234' as x\r\n   )\r\nSELECT *\r\nFROM events AS events\r\nJOIN cte2 ON cte2.x = events.distinct_id\r\nJOIN cte1 ON cte1.x = cte2.x\r\nlimit 1\r\n```\r\n\r\nThe `events` table is created with `ON CLUSTER` i.e. distributed.\r\n\r\nFor this query I get:\r\n\r\n```\r\nClickHouse exception, code: 60, host: <ip>, port: 8443; Code: 60, e.displayText() = DB::Exception: Received from <host>:9000. DB::Exception: Table <cluster>.cte2 doesn't exist. (version 21.6.5.37 (official build))\r\n```\r\n\r\n\r\nIf I run:\r\n\r\n```\r\nWITH cte1 as (\r\n    SELECT '1234' as x\r\n ), cte2 as (\r\n    SELECT '1234' as x\r\n   )\r\nSELECT events.distinct_id\r\nFROM events AS events\r\nJOIN cte2 ON cte2.x = events.distinct_id\r\n-- JOIN cte1 ON cte1.x = cte2.x\r\nlimit 1\r\n```\r\n\r\nit always works.\r\n\r\nIf I run:\r\n\r\n```\r\nWITH cte1 as (\r\n    SELECT '1234' as x\r\n ), cte2 as (\r\n    SELECT '1234' as x\r\n   )\r\nSELECT events.distinct_id\r\nFROM events AS events\r\nJOIN cte2 ON cte2.x = events.distinct_id\r\nJOIN cte1 ON cte1.x = cte2.x\r\nlimit 1\r\n```\r\n\r\nit intermittently works.\r\n\r\nIf I query with the same pattern with another table I do not get errors.\r\n\r\n**Expected behavior**\r\n\r\nCTE evaluation shouldn't be dependent on specific select fields (?)\r\n\r\n**Error message and/or stacktrace**\r\n\r\nAs specified above.\r\n\r\n**Additional context**\r\n\r\nNone except mainly I'm looking for debug pointers. i.e. sql to run on a specific shard may be appropriate for debugging?","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29748/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29748/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29739","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29739/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29739/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29739/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29739","id":1015402463,"node_id":"I_kwDOA5dJV848hc_f","number":29739,"title":"Empty Avro data in Kafka after insert","user":{"login":"chybz","id":288894,"node_id":"MDQ6VXNlcjI4ODg5NA==","avatar_url":"https://avatars.githubusercontent.com/u/288894?v=4","gravatar_id":"","url":"https://api.github.com/users/chybz","html_url":"https://github.com/chybz","followers_url":"https://api.github.com/users/chybz/followers","following_url":"https://api.github.com/users/chybz/following{/other_user}","gists_url":"https://api.github.com/users/chybz/gists{/gist_id}","starred_url":"https://api.github.com/users/chybz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/chybz/subscriptions","organizations_url":"https://api.github.com/users/chybz/orgs","repos_url":"https://api.github.com/users/chybz/repos","events_url":"https://api.github.com/users/chybz/events{/privacy}","received_events_url":"https://api.github.com/users/chybz/received_events","type":"User","site_admin":false},"labels":[{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-10-04T16:47:57Z","updated_at":"2021-10-04T16:47:57Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"**Describe the unexpected behaviour**\r\nInserting data into Kafka from a ClickHouse table results in empty Avro record and empty Kafka messages.\r\n\r\n**How to reproduce**\r\n* Which ClickHouse server version to use\r\n21.8.5.7\r\n* `CREATE TABLE` statements for all tables involved\r\n```sql\r\nCREATE TABLE out(a UInt64, b String)\r\nENGINE = Kafka()\r\nSETTINGS\r\n    kafka_broker_list='127.0.0.1:9092',\r\n    kafka_format='Avro',\r\n    kafka_topic_list='a_topic',\r\n    kafka_group_name='a_group'\r\n;\r\n```\r\n```sql\r\nCREATE TABLE records(a UInt64, b String)\r\nENGINE=Memory;\r\n```\r\n* Sample data for all these tables, use [clickhouse-obfuscator](https://github.com/ClickHouse/ClickHouse/blob/master/programs/obfuscator/Obfuscator.cpp#L42-L80) if necessary\r\n```sql\r\nINSERT INTO records VALUES(1, 'one');\r\nINSERT INTO records VALUES(2, 'two');\r\nINSERT INTO records VALUES(3, 'three');\r\n```\r\n* Queries to run that lead to unexpected result\r\n```sql\r\nINSERT INTO out SELECT * FROM records;\r\n```\r\n**Expected behavior**\r\nI expect to see in Kafka:\r\n- A Kafka message containing an Avro \"file\" with 3 lines\r\nor\r\n- 3 Kafka messages containing an Avro \"file\" with 1 lines\r\n\r\n**Additional context**\r\nWhat I see is 3 Kafka records:\r\n- First one is an Avro \"file\" with schema only (no rows)\r\n- Second and third are empty Kafka messages\r\n\r\nI must be missing something but can't see what.\r\nThanks for any help !","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29739/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29739/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29736","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29736/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29736/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29736/events","html_url":"https://github.com/ClickHouse/ClickHouse/pull/29736","id":1015263631,"node_id":"PR_kwDOA5dJV84spOwU","number":29736,"title":"Added storage fuzzer to perform fuzzing on server side","user":{"login":"nikitamikhaylov","id":25705399,"node_id":"MDQ6VXNlcjI1NzA1Mzk5","avatar_url":"https://avatars.githubusercontent.com/u/25705399?v=4","gravatar_id":"","url":"https://api.github.com/users/nikitamikhaylov","html_url":"https://github.com/nikitamikhaylov","followers_url":"https://api.github.com/users/nikitamikhaylov/followers","following_url":"https://api.github.com/users/nikitamikhaylov/following{/other_user}","gists_url":"https://api.github.com/users/nikitamikhaylov/gists{/gist_id}","starred_url":"https://api.github.com/users/nikitamikhaylov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nikitamikhaylov/subscriptions","organizations_url":"https://api.github.com/users/nikitamikhaylov/orgs","repos_url":"https://api.github.com/users/nikitamikhaylov/repos","events_url":"https://api.github.com/users/nikitamikhaylov/events{/privacy}","received_events_url":"https://api.github.com/users/nikitamikhaylov/received_events","type":"User","site_admin":false},"labels":[{"id":1876999755,"node_id":"MDU6TGFiZWwxODc2OTk5NzU1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/pr-not-for-changelog","name":"pr-not-for-changelog","color":"007700","default":false,"description":"This PR should not be mentioned in the changelog"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-10-04T14:35:41Z","updated_at":"2021-10-07T10:50:26Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"draft":true,"pull_request":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/pulls/29736","html_url":"https://github.com/ClickHouse/ClickHouse/pull/29736","diff_url":"https://github.com/ClickHouse/ClickHouse/pull/29736.diff","patch_url":"https://github.com/ClickHouse/ClickHouse/pull/29736.patch","merged_at":null},"body":"Changelog category (leave one):\r\n\r\n- Not for changelog (changelog entry is not required)\r\n\r\n\r\nChangelog entry (a user-readable short description of the changes that goes to CHANGELOG.md):\r\n\r\n#28107","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29736/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29736/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29734","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29734/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29734/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29734/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29734","id":1015209892,"node_id":"I_kwDOA5dJV848gt-k","number":29734,"title":"Unexpected results in query with multiple joins","user":{"login":"DimasKovas","id":34828390,"node_id":"MDQ6VXNlcjM0ODI4Mzkw","avatar_url":"https://avatars.githubusercontent.com/u/34828390?v=4","gravatar_id":"","url":"https://api.github.com/users/DimasKovas","html_url":"https://github.com/DimasKovas","followers_url":"https://api.github.com/users/DimasKovas/followers","following_url":"https://api.github.com/users/DimasKovas/following{/other_user}","gists_url":"https://api.github.com/users/DimasKovas/gists{/gist_id}","starred_url":"https://api.github.com/users/DimasKovas/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/DimasKovas/subscriptions","organizations_url":"https://api.github.com/users/DimasKovas/orgs","repos_url":"https://api.github.com/users/DimasKovas/repos","events_url":"https://api.github.com/users/DimasKovas/events{/privacy}","received_events_url":"https://api.github.com/users/DimasKovas/received_events","type":"User","site_admin":false},"labels":[{"id":386401505,"node_id":"MDU6TGFiZWwzODY0MDE1MDU=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/bug","name":"bug","color":"ee0701","default":true,"description":"Confirmed user-visible misbehaviour in official release"},{"id":1357578153,"node_id":"MDU6TGFiZWwxMzU3NTc4MTUz","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-joins","name":"comp-joins","color":"b5bcff","default":false,"description":"JOINs"},{"id":1507867504,"node_id":"MDU6TGFiZWwxNTA3ODY3NTA0","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/st-hold","name":"st-hold","color":"e5b890","default":false,"description":"We've paused the work on issue for some reason"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-10-04T13:50:45Z","updated_at":"2021-10-04T14:37:13Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"\r\n**Describe what's wrong**\r\n\r\nQuery with multiple joins uses non existent column, but it runs without runtime exception.\r\n\r\n**Does it reproduce on recent release?**\r\nYes\r\n\r\n**How to reproduce**\r\n\r\n* Which ClickHouse server version to use\r\n21.10\r\n\r\n* Queries to run that lead to unexpected result\r\nThis query throws proper exception, because there are no column y in first table expression:\r\n```sql\r\n:) select * from (select 1 as x) as a join (select 1 as x, 2 as y) as b on a.x = b.x and a.y=b.y \r\n\r\nSELECT *\r\nFROM\r\n(\r\n    SELECT 1 AS x\r\n) AS a\r\nINNER JOIN\r\n(\r\n    SELECT\r\n        1 AS x,\r\n        2 AS y\r\n) AS b ON (a.x = b.x) AND (a.y = b.y)\r\n\r\nQuery id: 21fbf396-74ee-4cbf-a3e6-7b38ac6b1a20\r\n\r\n\r\n0 rows in set. Elapsed: 0.006 sec. \r\n\r\nReceived exception from server (version 21.10.2):\r\nCode: 47. DB::Exception: Received from localhost:9000. DB::Exception: There's no column 'a.y' in table 'a': While processing a.y: While processing  INNER JOIN ...  ON (x = b.x) AND (a.y = b.y). (UNKNOWN_IDENTIFIER)\r\n\r\n```\r\nBut when there is second join, it runs without any exceptions:\r\n```sql\r\n:) select * from (select 1 as x) as a join (select 1 as x, 2 as y) as b on a.x = b.x and a.y=b.y join (select 3 as x) as c on a.x=c.x\r\n\r\nSELECT *\r\nFROM\r\n(\r\n    SELECT 1 AS x\r\n) AS a\r\nINNER JOIN\r\n(\r\n    SELECT\r\n        1 AS x,\r\n        2 AS y\r\n) AS b ON (a.x = b.x) AND (a.y = b.y)\r\nINNER JOIN\r\n(\r\n    SELECT 3 AS x\r\n) AS c ON a.x = c.x\r\n\r\nQuery id: fa395c0a-fc4f-4035-b4bc-d1cc1603c230\r\n\r\nOk.\r\n\r\n0 rows in set. Elapsed: 0.026 sec. \r\n```\r\nAnother example with `numbers()`:\r\n```sql\r\n:) select * from (select number as x from numbers(10)) as a join (select number as x, number as y from numbers(10)) as b on a.x = b.x and a.y=b.y joinx(select number as x from numbers(10)) as c on a.x=c.x\r\n\r\nSELECT *\r\nFROM\r\n(\r\n    SELECT number AS x\r\n    FROM numbers(10)\r\n) AS a\r\nINNER JOIN\r\n(\r\n    SELECT\r\n        number AS x,\r\n        number AS y\r\n    FROM numbers(10)\r\n) AS b ON (a.x = b.x) AND (a.y = b.y)\r\nINNER JOIN\r\n(\r\n    SELECT number AS x\r\n    FROM numbers(10)\r\n) AS c ON a.x = c.x\r\n\r\nQuery id: 3bf707e2-dc45-43b3-a80f-ee422d773ef3\r\n\r\n┌─a.x─┬─b.x─┬─b.y─┬─c.x─┐\r\n│   0 │   0 │   0 │   0 │\r\n│   1 │   1 │   1 │   1 │\r\n│   2 │   2 │   2 │   2 │\r\n│   3 │   3 │   3 │   3 │\r\n│   4 │   4 │   4 │   4 │\r\n│   5 │   5 │   5 │   5 │\r\n│   6 │   6 │   6 │   6 │\r\n│   7 │   7 │   7 │   7 │\r\n│   8 │   8 │   8 │   8 │\r\n│   9 │   9 │   9 │   9 │\r\n└─────┴─────┴─────┴─────┘\r\n\r\n10 rows in set. Elapsed: 0.027 sec. \r\n```\r\n**Expected behavior**\r\nAll queries should be terminated with error.\r\n\r\n**Additional context**\r\nIt also terminates with `DB::Exception: Not found column model_id in block.` sometimes in our installation of CH, but I could not reproduce it with small and simple queries\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29734/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29734/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29730","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29730/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29730/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29730/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29730","id":1015133576,"node_id":"I_kwDOA5dJV848gbWI","number":29730,"title":"Function transform with decimal type not working or produce incorrect result","user":{"login":"Grian","id":65714,"node_id":"MDQ6VXNlcjY1NzE0","avatar_url":"https://avatars.githubusercontent.com/u/65714?v=4","gravatar_id":"","url":"https://api.github.com/users/Grian","html_url":"https://github.com/Grian","followers_url":"https://api.github.com/users/Grian/followers","following_url":"https://api.github.com/users/Grian/following{/other_user}","gists_url":"https://api.github.com/users/Grian/gists{/gist_id}","starred_url":"https://api.github.com/users/Grian/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Grian/subscriptions","organizations_url":"https://api.github.com/users/Grian/orgs","repos_url":"https://api.github.com/users/Grian/repos","events_url":"https://api.github.com/users/Grian/events{/privacy}","received_events_url":"https://api.github.com/users/Grian/received_events","type":"User","site_admin":false},"labels":[{"id":3086255531,"node_id":"MDU6TGFiZWwzMDg2MjU1NTMx","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/warmup%20task","name":"warmup task","color":"FBCA04","default":false,"description":"The task for new ClickHouse team members. Low risk, moderate complexity, no urgency."},{"id":3260776666,"node_id":"MDU6TGFiZWwzMjYwNzc2NjY2","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/potential%20bug","name":"potential bug","color":"ffc080","default":false,"description":"To be reviewed by developers and confirmed/rejected."}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2021-10-04T12:45:16Z","updated_at":"2021-11-22T12:01:13Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Current stable release and some recent release\r\nClickHouse client version 21.9.4.35\r\nConnected to ClickHouse server version 21.9.4 revision 54449\r\nConnected to ClickHouse server version 21.5.9 revision 54448\r\n\r\nSQL:\r\n```\r\nSELECT  transform(1, [1], [toDecimal32(1, 2)]),    toDecimal32(1, 2)\r\n```\r\nProduces:\r\n```\r\n100 │                 1\r\n```\r\n\r\nExpected 1 == 1\r\n\r\n```\r\nselect transform(1, [1], [toDecimal32(42, 2)]), toDecimal32(42, 2);\r\n```\r\nProduces:\r\n```\r\n 104 │                 42\r\n```\r\n\r\nExpected 42 == 42\r\n\r\nLooks as garbage ...\r\n\r\nSecond case of transform function\r\n```\r\nSELECT transform(1, [1], [toDecimal32(42, 2)], 0)\r\n\r\n-- OR --\r\n\r\nSELECT transform(1, [1], [toDecimal32(42, 2)], toDecimal32(0, 2))\r\n```\r\nProduce error message\r\n```\r\nReceived exception from server (version 21.9.4):\r\nCode: 44. DB::Exception: Received from localhost:9000. DB::Exception: Illegal column UInt8 of elements of array of second argument of function transform: While processing transform(1, [1], [toDecimal32(42, 2)], 0). (ILLEGAL_COLUMN)\r\n```\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29730/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29730/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29721","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29721/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29721/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29721/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29721","id":1014987126,"node_id":"I_kwDOA5dJV848f3l2","number":29721,"title":"member call on address ... which does not point to an object of type 'DB::IExternalLoadable'","user":{"login":"qoega","id":2159081,"node_id":"MDQ6VXNlcjIxNTkwODE=","avatar_url":"https://avatars.githubusercontent.com/u/2159081?v=4","gravatar_id":"","url":"https://api.github.com/users/qoega","html_url":"https://github.com/qoega","followers_url":"https://api.github.com/users/qoega/followers","following_url":"https://api.github.com/users/qoega/following{/other_user}","gists_url":"https://api.github.com/users/qoega/gists{/gist_id}","starred_url":"https://api.github.com/users/qoega/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/qoega/subscriptions","organizations_url":"https://api.github.com/users/qoega/orgs","repos_url":"https://api.github.com/users/qoega/repos","events_url":"https://api.github.com/users/qoega/events{/privacy}","received_events_url":"https://api.github.com/users/qoega/received_events","type":"User","site_admin":false},"labels":[{"id":1955634273,"node_id":"MDU6TGFiZWwxOTU1NjM0Mjcz","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/testing","name":"testing","color":"c9a224","default":false,"description":"Special issue with list of bugs found by CI"}],"state":"open","locked":false,"assignee":{"login":"kitaisreal","id":22458333,"node_id":"MDQ6VXNlcjIyNDU4MzMz","avatar_url":"https://avatars.githubusercontent.com/u/22458333?v=4","gravatar_id":"","url":"https://api.github.com/users/kitaisreal","html_url":"https://github.com/kitaisreal","followers_url":"https://api.github.com/users/kitaisreal/followers","following_url":"https://api.github.com/users/kitaisreal/following{/other_user}","gists_url":"https://api.github.com/users/kitaisreal/gists{/gist_id}","starred_url":"https://api.github.com/users/kitaisreal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kitaisreal/subscriptions","organizations_url":"https://api.github.com/users/kitaisreal/orgs","repos_url":"https://api.github.com/users/kitaisreal/repos","events_url":"https://api.github.com/users/kitaisreal/events{/privacy}","received_events_url":"https://api.github.com/users/kitaisreal/received_events","type":"User","site_admin":false},"assignees":[{"login":"kitaisreal","id":22458333,"node_id":"MDQ6VXNlcjIyNDU4MzMz","avatar_url":"https://avatars.githubusercontent.com/u/22458333?v=4","gravatar_id":"","url":"https://api.github.com/users/kitaisreal","html_url":"https://github.com/kitaisreal","followers_url":"https://api.github.com/users/kitaisreal/followers","following_url":"https://api.github.com/users/kitaisreal/following{/other_user}","gists_url":"https://api.github.com/users/kitaisreal/gists{/gist_id}","starred_url":"https://api.github.com/users/kitaisreal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kitaisreal/subscriptions","organizations_url":"https://api.github.com/users/kitaisreal/orgs","repos_url":"https://api.github.com/users/kitaisreal/repos","events_url":"https://api.github.com/users/kitaisreal/events{/privacy}","received_events_url":"https://api.github.com/users/kitaisreal/received_events","type":"User","site_admin":false}],"milestone":null,"comments":0,"created_at":"2021-10-04T10:13:45Z","updated_at":"2021-10-04T10:15:46Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"UBsan test_catboost_model_reload test\r\n```\r\n../src/Interpreters/ExternalLoader.cpp:1142:33: runtime error: member call on address 0x7f159c20cc00 which does not point to an object of type 'DB::IExternalLoadable'\r\n0x7f159c20cc00: note: object is of type 'DB::CatBoostModel'\r\n 00 00 00 00  e0 64 fc 07 00 00 00 00  00 cc 20 9c 15 7f 00 00  d0 86 11 9c 15 7f 00 00  6d 6f 64 65\r\n              ^~~~~~~~~~~~~~~~~~~~~~~\r\n              vptr for 'DB::CatBoostModel'\r\n    #0 0x1b08e5ce in DB::ExternalLoader::LoadingDispatcher::calculateNextUpdateTime(std::__1::shared_ptr<DB::IExternalLoadable const> const&, unsigned long) const obj-x86_64-linux-gnu/../src/Interpreters/ExternalLoader.cpp:1142:33\r\n    #1 0x1b082550 in DB::ExternalLoader::LoadingDispatcher::saveResultOfLoadingSingleObject(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, unsigned long, std::__1::shared_ptr<DB::IExternalLoadable const>, std::__1::shared_ptr<DB::IExternalLoadable const>, std::exception_ptr, unsigned long, DB::(anonymous namespace)::LoadingGuardForAsyncLoad const&) obj-x86_64-linux-gnu/../src/Interpreters/ExternalLoader.cpp:1058:32\r\n    #2 0x1b08ab87 in DB::ExternalLoader::LoadingDispatcher::doLoading(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, unsigned long, bool, unsigned long, bool, std::__1::shared_ptr<DB::ThreadGroupStatus>) obj-x86_64-linux-gnu/../src/Interpreters/ExternalLoader.cpp:988:17\r\n    #3 0x1b089d8c in DB::ExternalLoader::LoadingDispatcher::startLoading(DB::ExternalLoader::LoadingDispatcher::Info&, bool, unsigned long) obj-x86_64-linux-gnu/../src/Interpreters/ExternalLoader.cpp:919:13\r\n    #4 0x1b0a226e in DB::ExternalLoader::LoadingDispatcher::loadImpl(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::chrono::duration<long long, std::__1::ratio<1l, 1000l> >, bool, std::__1::unique_lock<std::__1::mutex>&)::'lambda'()::operator()() const obj-x86_64-linux-gnu/../src/Interpreters/ExternalLoader.cpp:822:17\r\n    #5 0x1b0a200e in void std::__1::condition_variable::wait<DB::ExternalLoader::LoadingDispatcher::loadImpl(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::chrono::duration<long long, std::__1::ratio<1l, 1000l> >, bool, std::__1::unique_lock<std::__1::mutex>&)::'lambda'()>(std::__1::unique_lock<std::__1::mutex>&, DB::ExternalLoader::LoadingDispatcher::loadImpl(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::chrono::duration<long long, std::__1::ratio<1l, 1000l> >, bool, std::__1::unique_lock<std::__1::mutex>&)::'lambda'()) obj-x86_64-linux-gnu/../contrib/libcxx/include/__mutex_base:405:13\r\n    #6 0x1b0a200e in DB::ExternalLoader::LoadingDispatcher::loadImpl(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::chrono::duration<long long, std::__1::ratio<1l, 1000l> >, bool, std::__1::unique_lock<std::__1::mutex>&) obj-x86_64-linux-gnu/../src/Interpreters/ExternalLoader.cpp:829:19\r\n    #7 0x1b087462 in DB::ExternalLoader::LoadResult DB::ExternalLoader::LoadingDispatcher::tryLoadOrReload<DB::ExternalLoader::LoadResult>(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::chrono::duration<long long, std::__1::ratio<1l, 1000l> >) obj-x86_64-linux-gnu/../src/Interpreters/ExternalLoader.cpp:614:23\r\n    #8 0x1b085afb in std::__1::shared_ptr<DB::IExternalLoadable const> DB::ExternalLoader::loadOrReload<std::__1::shared_ptr<DB::IExternalLoadable const>, void>(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) const obj-x86_64-linux-gnu/../src/Interpreters/ExternalLoader.cpp:1392:39\r\n    #9 0x1b79cd27 in DB::ExternalModelsLoader::reloadModel(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) const obj-x86_64-linux-gnu/../src/Interpreters/ExternalModelsLoader.h:30:9\r\n    #10 0x1b785497 in DB::InterpreterSystemQuery::execute() obj-x86_64-linux-gnu/../src/Interpreters/InterpreterSystemQuery.cpp:319:36\r\n    #11 0x1ba0f310 in DB::executeQueryImpl(char const*, char const*, std::__1::shared_ptr<DB::Context>, bool, DB::QueryProcessingStage::Enum, DB::ReadBuffer*) obj-x86_64-linux-gnu/../src/Interpreters/executeQuery.cpp:635:32\r\n    #12 0x1ba0c929 in DB::executeQuery(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::shared_ptr<DB::Context>, bool, DB::QueryProcessingStage::Enum) obj-x86_64-linux-gnu/../src/Interpreters/executeQuery.cpp:950:30\r\n    #13 0x1c60e0b2 in DB::TCPHandler::runImpl() obj-x86_64-linux-gnu/../src/Server/TCPHandler.cpp:292:24\r\n    #14 0x1c6271b5 in DB::TCPHandler::run() obj-x86_64-linux-gnu/../src/Server/TCPHandler.cpp:1641:9\r\n    #15 0x1d3cf78b in Poco::Net::TCPServerConnection::start() obj-x86_64-linux-gnu/../contrib/poco/Net/src/TCPServerConnection.cpp:43:3\r\n    #16 0x1d3cfc24 in Poco::Net::TCPServerDispatcher::run() obj-x86_64-linux-gnu/../contrib/poco/Net/src/TCPServerDispatcher.cpp:115:20\r\n    #17 0x1d4c01a6 in Poco::PooledThread::run() obj-x86_64-linux-gnu/../contrib/poco/Foundation/src/ThreadPool.cpp:199:14\r\n    #18 0x1d4bda6b in Poco::ThreadImpl::runnableEntry(void*) obj-x86_64-linux-gnu/../contrib/poco/Foundation/src/Thread_POSIX.cpp:345:27\r\n    #19 0x7f1abe834608 in start_thread (/lib/x86_64-linux-gnu/libpthread.so.0+0x9608)\r\n    #20 0x7f1abe75b292 in __clone (/lib/x86_64-linux-gnu/libc.so.6+0x122292)\r\n\r\nSUMMARY: UndefinedBehaviorSanitizer: undefined-behavior ../src/Interpreters/ExternalLoader.cpp:1142:33 in\r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29721/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29721/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29703","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29703/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29703/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29703/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29703","id":1014746250,"node_id":"I_kwDOA5dJV848e8yK","number":29703,"title":"Allow ALTERing of columns with data skipping indices by rebuilding the indices.","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":845247686,"node_id":"MDU6TGFiZWw4NDUyNDc2ODY=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/usability","name":"usability","color":"ebf28c","default":false,"description":""}],"state":"open","locked":false,"assignee":{"login":"kitaisreal","id":22458333,"node_id":"MDQ6VXNlcjIyNDU4MzMz","avatar_url":"https://avatars.githubusercontent.com/u/22458333?v=4","gravatar_id":"","url":"https://api.github.com/users/kitaisreal","html_url":"https://github.com/kitaisreal","followers_url":"https://api.github.com/users/kitaisreal/followers","following_url":"https://api.github.com/users/kitaisreal/following{/other_user}","gists_url":"https://api.github.com/users/kitaisreal/gists{/gist_id}","starred_url":"https://api.github.com/users/kitaisreal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kitaisreal/subscriptions","organizations_url":"https://api.github.com/users/kitaisreal/orgs","repos_url":"https://api.github.com/users/kitaisreal/repos","events_url":"https://api.github.com/users/kitaisreal/events{/privacy}","received_events_url":"https://api.github.com/users/kitaisreal/received_events","type":"User","site_admin":false},"assignees":[{"login":"kitaisreal","id":22458333,"node_id":"MDQ6VXNlcjIyNDU4MzMz","avatar_url":"https://avatars.githubusercontent.com/u/22458333?v=4","gravatar_id":"","url":"https://api.github.com/users/kitaisreal","html_url":"https://github.com/kitaisreal","followers_url":"https://api.github.com/users/kitaisreal/followers","following_url":"https://api.github.com/users/kitaisreal/following{/other_user}","gists_url":"https://api.github.com/users/kitaisreal/gists{/gist_id}","starred_url":"https://api.github.com/users/kitaisreal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kitaisreal/subscriptions","organizations_url":"https://api.github.com/users/kitaisreal/orgs","repos_url":"https://api.github.com/users/kitaisreal/repos","events_url":"https://api.github.com/users/kitaisreal/events{/privacy}","received_events_url":"https://api.github.com/users/kitaisreal/received_events","type":"User","site_admin":false}],"milestone":null,"comments":0,"created_at":"2021-10-04T05:21:39Z","updated_at":"2021-10-04T07:37:46Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"**Use case**\r\n\r\nIf there is an index depending on a column, it's currently forbidden to alter this column.\r\nWhy not to allow it? We just simply need to rewrite the index along with the column.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29703/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29703/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29701","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29701/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29701/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29701/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29701","id":1014738400,"node_id":"I_kwDOA5dJV848e63g","number":29701,"title":"A window function for tree traversal.","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2021-10-04T05:08:00Z","updated_at":"2021-12-27T12:38:34Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"**Use case**\r\n\r\nhttps://github.com/ClickHouse/ClickHouse/issues/29693\r\nA table has child -> parent relationship but does not have \"top_ancestor\" column.\r\nWe want to calculate it on the fly.\r\n\r\n**Describe the solution you'd like**\r\n\r\nA window function `treeTopAncestor(child, parent)` collects a tree in memory for every window and then outputs the most reachable ancestor for every row.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29701/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29701/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29700","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29700/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29700/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29700/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29700","id":1014721620,"node_id":"I_kwDOA5dJV848e2xU","number":29700,"title":"Automatically choose the size of bloom filter index","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":3086255531,"node_id":"MDU6TGFiZWwzMDg2MjU1NTMx","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/warmup%20task","name":"warmup task","color":"FBCA04","default":false,"description":"The task for new ClickHouse team members. Low risk, moderate complexity, no urgency."}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-10-04T04:34:42Z","updated_at":"2022-01-12T18:40:06Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"If there is a bloom filter of size 2^n, then we can obtain a bloom filter of size 2^(n - 1) from it.\r\n\r\nThe idea is that the user can specify max size of the bloom filter and the desired false positive probability.\r\nWe will keep a buffer in memory with the maximum size of the bloom filter. And when it is filled, we will shrink it by power of two times while the false positive probability is still lower than the specified threshold. This is done before writing an index granule to disk.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29700/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29700/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29698","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29698/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29698/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29698/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29698","id":1014706252,"node_id":"I_kwDOA5dJV848ezBM","number":29698,"title":"Name hints should work for data skipping indices.","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":644208617,"node_id":"MDU6TGFiZWw2NDQyMDg2MTc=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/easy%20task","name":"easy task","color":"0e8a16","default":false,"description":"Good for first contributors"},{"id":845247686,"node_id":"MDU6TGFiZWw4NDUyNDc2ODY=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/usability","name":"usability","color":"ebf28c","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2021-10-04T04:08:52Z","updated_at":"2022-01-19T00:01:43Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"**Use case**\r\n\r\n```\r\nReceived exception from server (version 21.11.1):\r\nCode: 36. DB::Exception: Received from localhost:9000. DB::Exception: Wrong index name. Cannot find index `test_pentagram` to drop.. (BAD_ARGUMENTS)\r\n\r\ngithub-explorer.ru-central1.internal :) ALTER TABLE hackernews DROP INDEX text_pentagram\r\n```\r\n\r\nIt did not show me the typo.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29698/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29698/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29694","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29694/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29694/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29694/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29694","id":1014694740,"node_id":"I_kwDOA5dJV848ewNU","number":29694,"title":"Parallel downloading for `URL` engine with ranges.","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":756395244,"node_id":"MDU6TGFiZWw3NTYzOTUyNDQ=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/performance","name":"performance","color":"c2e0c6","default":false,"description":null},{"id":3086255531,"node_id":"MDU6TGFiZWwzMDg2MjU1NTMx","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/warmup%20task","name":"warmup task","color":"FBCA04","default":false,"description":"The task for new ClickHouse team members. Low risk, moderate complexity, no urgency."}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-10-04T03:44:21Z","updated_at":"2021-10-05T12:24:51Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"**Use case**\r\n\r\nSpeedup download of single file using many connections.\r\n\r\n**Describe the solution you'd like**\r\n\r\nThe settings can control the chunk size and the number of threads.\r\nThe chunks will be selected for download by multiple threads in sequential order.\r\nWhenever a chunk is completed *and has been consumed by the caller*, the thread can select the next chunk.\r\nThe result will be present as a single `ReadBuffer` for sequential reading.\r\nThe memory usage will be limited by chunk_size * num_threads.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29694/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29694/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29693","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29693/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29693/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29693/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29693","id":1014630382,"node_id":"I_kwDOA5dJV848egfu","number":29693,"title":"Hacker News Dataset","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":785082162,"node_id":"MDU6TGFiZWw3ODUwODIxNjI=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-documentation","name":"comp-documentation","color":"b5bcff","default":false,"description":"Used to run automatic builds of the documentation"},{"id":3360106261,"node_id":"MDU6TGFiZWwzMzYwMTA2MjYx","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/dataset","name":"dataset","color":"00CCCC","default":false,"description":""}],"state":"open","locked":false,"assignee":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"assignees":[{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false}],"milestone":null,"comments":17,"created_at":"2021-10-04T01:18:58Z","updated_at":"2021-10-16T02:42:33Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"1. Download data from the official API:\r\n\r\nhttps://github.com/HackerNews/API\r\n\r\n```\r\nseq 0 2990 | xargs -P100 -I{} bash -c '\r\n    BEGIN=$(({} * 10000));\r\n    END=$((({} + 1) * 10000 - 1));\r\n    echo $BEGIN $END;\r\n    curl -sS --retry 100 \"https://hacker-news.firebaseio.com/v0/item/[${BEGIN}-${END}].json\" | pv > \"hn{}.json\"'\r\n```\r\n\r\nIt will take about a day. The size of files is 12.8 GB.\r\n\r\nAs an alternative, you can download prepared files from http://files.pushshift.io/hackernews/\r\nBut this source is abandoned and does not update.\r\n\r\n2. Cleanup the download:\r\n\r\n```\r\nsed 's/{/\\n{/g' hn0.json | grep -v -P '^null$' > hn0.json.tmp && mv hn0.json.tmp hn0.json\r\nfind . -size 40000c | xargs rm\r\ngrep -l -o -F '}null' *.json | xargs sed -i -r 's/}(null)+/}/g'\r\n```\r\n\r\n3. Create table:\r\n\r\n```\r\nCREATE TABLE hackernews\r\n(\r\nid UInt32,\r\ndeleted UInt8,\r\ntype Enum('story' = 1, 'comment' = 2, 'poll' = 3, 'pollopt' = 4, 'job' = 5),\r\nby LowCardinality(String),\r\ntime DateTime,\r\ntext String,\r\ndead UInt8,\r\nparent UInt32,\r\npoll UInt32,\r\nkids Array(UInt32),\r\nurl String,\r\nscore Int32,\r\ntitle String,\r\nparts Array(UInt32),\r\ndescendants Int32\r\n)\r\nENGINE = MergeTree ORDER BY id\r\n```\r\n\r\n4. Insert data:\r\n\r\n```\r\nls -1 *.json | xargs -P$(($(nproc) / 4)) -I{} bash -c 'clickhouse-client --query \"INSERT INTO hackernews FORMAT JSONEachRow\" < {}'\r\n```\r\n\r\n24 seconds, 1 202 257 rows/sec.\r\n\r\n\r\n5. The data is available in Playground: https://gh-api.clickhouse.tech/play?user=play#U0VMRUNUIHRvWWVhcih0aW1lKSBBUyBkLCBjb3VudCgpIEFTIGMsIGJhcihjLCAwLCAxMDAwMDAwMCwgMTAwKSBGUk9NIGhhY2tlcm5ld3MgR1JPVVAgQlkgZCBPUkRFUiBCWSBk","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29693/reactions","total_count":4,"+1":0,"-1":0,"laugh":2,"hooray":0,"confused":0,"heart":0,"rocket":2,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29693/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29675","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29675/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29675/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29675/events","html_url":"https://github.com/ClickHouse/ClickHouse/pull/29675","id":1014285584,"node_id":"PR_kwDOA5dJV84smYKC","number":29675,"title":"DOCSUP-14786: Executable and ExecutablePool table engines, executable() table function, settings","user":{"login":"olgarev","id":56617294,"node_id":"MDQ6VXNlcjU2NjE3Mjk0","avatar_url":"https://avatars.githubusercontent.com/u/56617294?v=4","gravatar_id":"","url":"https://api.github.com/users/olgarev","html_url":"https://github.com/olgarev","followers_url":"https://api.github.com/users/olgarev/followers","following_url":"https://api.github.com/users/olgarev/following{/other_user}","gists_url":"https://api.github.com/users/olgarev/gists{/gist_id}","starred_url":"https://api.github.com/users/olgarev/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/olgarev/subscriptions","organizations_url":"https://api.github.com/users/olgarev/orgs","repos_url":"https://api.github.com/users/olgarev/repos","events_url":"https://api.github.com/users/olgarev/events{/privacy}","received_events_url":"https://api.github.com/users/olgarev/received_events","type":"User","site_admin":false},"labels":[{"id":1310920248,"node_id":"MDU6TGFiZWwxMzEwOTIwMjQ4","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/pr-documentation","name":"pr-documentation","color":"007700","default":false,"description":"Documentation PRs for the specific code PR"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2021-10-03T06:45:39Z","updated_at":"2022-01-24T11:50:35Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"draft":true,"pull_request":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/pulls/29675","html_url":"https://github.com/ClickHouse/ClickHouse/pull/29675","diff_url":"https://github.com/ClickHouse/ClickHouse/pull/29675.diff","patch_url":"https://github.com/ClickHouse/ClickHouse/pull/29675.patch","merged_at":null},"body":"Changelog category:\r\n- Documentation for #28518, #28102, #28833","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29675/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29675/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29624","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29624/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29624/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29624/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29624","id":1013367963,"node_id":"I_kwDOA5dJV848ZsSb","number":29624,"title":"DNSError profile event doesn't increment after 21.9 during DNS error failure","user":{"login":"Slach","id":105560,"node_id":"MDQ6VXNlcjEwNTU2MA==","avatar_url":"https://avatars.githubusercontent.com/u/105560?v=4","gravatar_id":"","url":"https://api.github.com/users/Slach","html_url":"https://github.com/Slach","followers_url":"https://api.github.com/users/Slach/followers","following_url":"https://api.github.com/users/Slach/following{/other_user}","gists_url":"https://api.github.com/users/Slach/gists{/gist_id}","starred_url":"https://api.github.com/users/Slach/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Slach/subscriptions","organizations_url":"https://api.github.com/users/Slach/orgs","repos_url":"https://api.github.com/users/Slach/repos","events_url":"https://api.github.com/users/Slach/events{/privacy}","received_events_url":"https://api.github.com/users/Slach/received_events","type":"User","site_admin":false},"labels":[{"id":1365579236,"node_id":"MDU6TGFiZWwxMzY1NTc5MjM2","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/minor","name":"minor","color":"FFF8F8","default":false,"description":"Priority: minor"},{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""},{"id":3167230621,"node_id":"MDU6TGFiZWwzMTY3MjMwNjIx","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/v21.9-affected","name":"v21.9-affected","color":"c2bfff","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-10-01T13:45:18Z","updated_at":"2021-10-02T03:22:08Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Describe what's wrong**\r\n`DNSError` profile event doesn't increment after 21.9 during DNS error failure\r\n\r\n\r\n> A clear and concise description of what works not as it is supposed to.\r\n\r\n**Does it reproduce on recent release?**\r\n\r\nyes, it reproduce on official docker image 21.9, and doesn't reproduce on 21.8\r\n\r\n\r\n**How to reproduce**\r\n- create cluster with 2 nodes which represents by DNS name in system.cluster\r\n- replace /etc/resolv.conf on `node-0-0` (change nameserver for example), and make `node-0-1` is unresolved on `node-0-0`\r\n- run on `node-0-0` \r\n```sql\r\nSYSTEM DROP DNS CACHE; SELECT count() FROM cluster('cluster-name',system.metrics)\r\n```\r\n- run on `node-0-0` \r\n```sql\r\nSELECT sum(ProfileEvent_DNSError) FROM system.metric_log\r\n```\r\n\r\n**Expected behavior**\r\nReturned error, increment DNSError profile event counter and flush it into system.events and system.metric_log\r\n\r\n**Actual behavior**\r\non 21.9, only system.errors code=198 `DNS_ERROR` increments `value`, system.events doesnt' increments\r\n\r\n**Additional context**\r\nthere is our internal e2e monitoring test logs\r\n\r\nSUCCESS from 21.8\r\n```\r\n               179ms              [bash] bash# kubectl exec --namespace=test -n test chi-test-cluster-for-alerts-default-0-0-0 -c clickhouse-pod -- clickhouse-client --echo -mn -q \"SYSTEM DROP DNS CACHE; SELECT count() FROM cluster('all-sharded',system.metrics)\"\r\n               316ms              [bash] SYSTEM DROP DNS CACHE;\r\n            1s 117ms              [bash] SELECT count() FROM cluster('all-sharded',system.metrics)\r\n            1s 934ms              [bash] Received exception from server (version 21.8.8):\r\n            1s 934ms              [bash] Code: 279. DB::Exception: Received from localhost:9000. DB::Exception: All connection tries failed. Log:\r\n            1s 934ms              [bash]\r\n            1s 935ms              [bash] Code: 210, e.displayText() = DB::NetException: Host not found: chi-test-cluster-for-alerts-default-0-1 (chi-test-cluster-for-alerts-default-0-1:9000) (version 21.8.8.29 (official build))\r\n            1s 935ms              [bash] Code: 210, e.displayText() = DB::NetException: Host not found: chi-test-cluster-for-alerts-default-0-1 (chi-test-cluster-for-alerts-default-0-1:9000) (version 21.8.8.29 (official build))\r\n            1s 935ms              [bash] Code: 210, e.displayText() = DB::NetException: Host not found: chi-test-cluster-for-alerts-default-0-1 (chi-test-cluster-for-alerts-default-0-1:9000) (version 21.8.8.29 (official build))\r\n            1s 935ms              [bash]\r\n            1s 935ms              [bash] : While executing Remote.\r\n            1s 939ms              [bash] command terminated with exit code 23\r\n            1s 942ms              [bash] bash# echo $?\r\n            1s 943ms              [bash] 23\r\n            1s 943ms              [bash] bash#\r\n```\r\nthere is non zero counter flueshed\r\n```            \r\n            1s 945ms              [bash] bash# kubectl exec --namespace=test -n test chi-test-cluster-for-alerts-default-0-0-0 -c clickhouse-pod -- clickhouse-client --echo -mn -q \"SELECT sum(ProfileEvent_DNSError) FROM system.metric_log\"\r\n             2s 96ms              [bash] SELECT sum(ProfileEvent_DNSError) FROM system.metric_log\r\n            2s 100ms              [bash] 3\r\n            2s 110ms              [bash] bash# echo $?\r\n            2s 110ms              [bash] 0\r\n```\r\n\r\nFAILED from 21.9\r\ndifferent error code\r\n```\r\n              3m 49s              [bash] bash# kubectl exec --namespace=test -n test chi-test-cluster-for-alerts-default-0-0-0 -c clickhouse-pod -- clickhouse-client --echo -mn -q \"SYSTEM DROP DNS CACHE; SELECT count() FROM cluster('all-sharded',system.metrics)\"\r\n              3m 49s              [bash] SYSTEM DROP DNS CACHE;\r\n              3m 55s              [bash] SELECT count() FROM cluster('all-sharded',system.metrics)\r\n              3m 55s              [bash] Received exception from server (version 21.9.4):\r\n              3m 55s              [bash] Code: 198. DB::Exception: Received from localhost:9000. DB::Exception: Not found address of host: chi-test-cluster-for-alerts-default-0-1: While executing Remote. (DNS_ERROR)\r\n              3m 55s              [bash] command terminated with exit code 198\r\n              3m 55s              [bash] bash# echo $?\r\n              3m 55s              [bash] 198\r\n              3m 55s              [bash] bash#\r\n```\r\n\r\ndifferent  DNSError behavior              \r\n```\r\n              3m 55s              [bash] bash# kubectl exec --namespace=test -n test chi-test-cluster-for-alerts-default-0-0-0 -c clickhouse-pod -- clickhouse-client --echo -mn -q \"SELECT sum(ProfileEvent_DNSError) FROM system.metric_log;SELECT * FROM system.events WHERE event='DNSError' FORMAT Vertical; SELECT * FROM system.errors FORMAT Vertical\"\r\n              3m 55s              [bash] SELECT sum(ProfileEvent_DNSError) FROM system.metric_log;\r\n              3m 55s              [bash] 0\r\n              3m 55s              [bash] SELECT * FROM system.events WHERE event='DNSError' FORMAT Vertical;\r\n              3m 55s              [bash] SELECT * FROM system.errors WHERE name='DNS_ERROR' FORMAT Vertical \r\n              3m 55s              [bash] Row 1:\r\n              3m 55s              [bash] ──────\r\n              3m 55s              [bash] name:               DNS_ERROR\r\n              3m 55s              [bash] code:               198\r\n              3m 55s              [bash] value:              120\r\n              3m 55s              [bash] last_error_time:    2021-10-01 13:40:11\r\n              3m 55s              [bash] last_error_message: Not found address of host: chi-test-cluster-for-alerts-default-0-1\r\n              3m 55s              [bash] last_error_trace:   [154575226,155292345,155295895,155299725,292355997,292470903,292476068,292480622]\r\n              3m 55s              [bash] remote:             0              \r\n```\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29624/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29624/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29622","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29622/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29622/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29622/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29622","id":1013329936,"node_id":"I_kwDOA5dJV848ZjAQ","number":29622,"title":"AggregatingTransform merges temporary files slowly + limit the max number of temporary files ","user":{"login":"filimonov","id":1549571,"node_id":"MDQ6VXNlcjE1NDk1NzE=","avatar_url":"https://avatars.githubusercontent.com/u/1549571?v=4","gravatar_id":"","url":"https://api.github.com/users/filimonov","html_url":"https://github.com/filimonov","followers_url":"https://api.github.com/users/filimonov/followers","following_url":"https://api.github.com/users/filimonov/following{/other_user}","gists_url":"https://api.github.com/users/filimonov/gists{/gist_id}","starred_url":"https://api.github.com/users/filimonov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/filimonov/subscriptions","organizations_url":"https://api.github.com/users/filimonov/orgs","repos_url":"https://api.github.com/users/filimonov/repos","events_url":"https://api.github.com/users/filimonov/events{/privacy}","received_events_url":"https://api.github.com/users/filimonov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":756395244,"node_id":"MDU6TGFiZWw3NTYzOTUyNDQ=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/performance","name":"performance","color":"c2e0c6","default":false,"description":null},{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":{"login":"kitaisreal","id":22458333,"node_id":"MDQ6VXNlcjIyNDU4MzMz","avatar_url":"https://avatars.githubusercontent.com/u/22458333?v=4","gravatar_id":"","url":"https://api.github.com/users/kitaisreal","html_url":"https://github.com/kitaisreal","followers_url":"https://api.github.com/users/kitaisreal/followers","following_url":"https://api.github.com/users/kitaisreal/following{/other_user}","gists_url":"https://api.github.com/users/kitaisreal/gists{/gist_id}","starred_url":"https://api.github.com/users/kitaisreal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kitaisreal/subscriptions","organizations_url":"https://api.github.com/users/kitaisreal/orgs","repos_url":"https://api.github.com/users/kitaisreal/repos","events_url":"https://api.github.com/users/kitaisreal/events{/privacy}","received_events_url":"https://api.github.com/users/kitaisreal/received_events","type":"User","site_admin":false},"assignees":[{"login":"kitaisreal","id":22458333,"node_id":"MDQ6VXNlcjIyNDU4MzMz","avatar_url":"https://avatars.githubusercontent.com/u/22458333?v=4","gravatar_id":"","url":"https://api.github.com/users/kitaisreal","html_url":"https://github.com/kitaisreal","followers_url":"https://api.github.com/users/kitaisreal/followers","following_url":"https://api.github.com/users/kitaisreal/following{/other_user}","gists_url":"https://api.github.com/users/kitaisreal/gists{/gist_id}","starred_url":"https://api.github.com/users/kitaisreal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kitaisreal/subscriptions","organizations_url":"https://api.github.com/users/kitaisreal/orgs","repos_url":"https://api.github.com/users/kitaisreal/repos","events_url":"https://api.github.com/users/kitaisreal/events{/privacy}","received_events_url":"https://api.github.com/users/kitaisreal/received_events","type":"User","site_admin":false}],"milestone":null,"comments":0,"created_at":"2021-10-01T13:10:30Z","updated_at":"2021-10-01T14:46:25Z","closed_at":null,"author_association":"COLLABORATOR","active_lock_reason":null,"body":"Test case:\r\n\r\n```sql\r\nselect \r\n  max(length(s))\r\nfrom numbers_mt(getSetting('max_block_size')*5000) as l\r\nleft join (\r\n   select number, repeat(toString(number),1000000) s from numbers(500)\r\n) as righ_1G_table\r\nusing (number)\r\ngroup by intDiv(number,getSetting('max_block_size')*1000)\r\nSETTINGS max_bytes_before_external_group_by='500M';\r\n```\r\n\r\nHere the JOIN part uses a lot of ram and leads to triggering `max_bytes_before_external_group_by` immediately. (It's actually a bit confusing).\r\n\r\nAfter that GROUP BY creates a lot of temporary files (5000 in that synthetic sample).\r\n\r\nMerging those files takes an enormous amount of time (is it expected?)\r\n\r\nAlso, we need to introduce some limit on a number of temporary files: AggregatingTransform can create  very high number of temporary files - in real life example it was:\r\n```\r\nAggregatingTransform: Will merge 93786 temporary files of size 2.41 GiB compressed, 22.10 GiB uncompressed.\r\n```\r\n\r\nAnd clickhouse was even hitting ulimit nofiles due to that (when few similar queries was started). ","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29622/reactions","total_count":2,"+1":2,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29622/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29618","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29618/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29618/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29618/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29618","id":1013265447,"node_id":"I_kwDOA5dJV848ZTQn","number":29618,"title":"Hedged requests hang in rare cases","user":{"login":"tavplubix","id":14847450,"node_id":"MDQ6VXNlcjE0ODQ3NDUw","avatar_url":"https://avatars.githubusercontent.com/u/14847450?v=4","gravatar_id":"","url":"https://api.github.com/users/tavplubix","html_url":"https://github.com/tavplubix","followers_url":"https://api.github.com/users/tavplubix/followers","following_url":"https://api.github.com/users/tavplubix/following{/other_user}","gists_url":"https://api.github.com/users/tavplubix/gists{/gist_id}","starred_url":"https://api.github.com/users/tavplubix/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tavplubix/subscriptions","organizations_url":"https://api.github.com/users/tavplubix/orgs","repos_url":"https://api.github.com/users/tavplubix/repos","events_url":"https://api.github.com/users/tavplubix/events{/privacy}","received_events_url":"https://api.github.com/users/tavplubix/received_events","type":"User","site_admin":false},"labels":[{"id":386401505,"node_id":"MDU6TGFiZWwzODY0MDE1MDU=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/bug","name":"bug","color":"ee0701","default":true,"description":"Confirmed user-visible misbehaviour in official release"}],"state":"open","locked":false,"assignee":{"login":"Avogar","id":48961922,"node_id":"MDQ6VXNlcjQ4OTYxOTIy","avatar_url":"https://avatars.githubusercontent.com/u/48961922?v=4","gravatar_id":"","url":"https://api.github.com/users/Avogar","html_url":"https://github.com/Avogar","followers_url":"https://api.github.com/users/Avogar/followers","following_url":"https://api.github.com/users/Avogar/following{/other_user}","gists_url":"https://api.github.com/users/Avogar/gists{/gist_id}","starred_url":"https://api.github.com/users/Avogar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Avogar/subscriptions","organizations_url":"https://api.github.com/users/Avogar/orgs","repos_url":"https://api.github.com/users/Avogar/repos","events_url":"https://api.github.com/users/Avogar/events{/privacy}","received_events_url":"https://api.github.com/users/Avogar/received_events","type":"User","site_admin":false},"assignees":[{"login":"Avogar","id":48961922,"node_id":"MDQ6VXNlcjQ4OTYxOTIy","avatar_url":"https://avatars.githubusercontent.com/u/48961922?v=4","gravatar_id":"","url":"https://api.github.com/users/Avogar","html_url":"https://github.com/Avogar","followers_url":"https://api.github.com/users/Avogar/followers","following_url":"https://api.github.com/users/Avogar/following{/other_user}","gists_url":"https://api.github.com/users/Avogar/gists{/gist_id}","starred_url":"https://api.github.com/users/Avogar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Avogar/subscriptions","organizations_url":"https://api.github.com/users/Avogar/orgs","repos_url":"https://api.github.com/users/Avogar/repos","events_url":"https://api.github.com/users/Avogar/events{/privacy}","received_events_url":"https://api.github.com/users/Avogar/received_events","type":"User","site_admin":false}],"milestone":null,"comments":13,"created_at":"2021-10-01T12:04:46Z","updated_at":"2021-12-23T09:35:13Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"https://clickhouse-test-reports.s3.yandex.net/0/2517f70d7532fc6aca4428f8de54aeae8ab1bf7d/stress_test_(debug).html#fail1\r\n\r\n```\r\nFound hung queries in processlist:\r\nRow 1:\r\n──────\r\nis_initial_query:     1\r\nuser:                 default\r\nquery_id:             76d2f16e-5dc9-42cb-895e-2dc8edbe1c08\r\naddress:              ::1\r\nport:                 36112\r\ninitial_user:         default\r\ninitial_query_id:     76d2f16e-5dc9-42cb-895e-2dc8edbe1c08\r\ninitial_address:      ::1\r\ninitial_port:         36112\r\ninterface:            1\r\nos_user:              \r\nclient_hostname:      27c20d53754c\r\nclient_name:          ClickHouse \r\nclient_revision:      54449\r\nclient_version_major: 21\r\nclient_version_minor: 11\r\nclient_version_patch: 1\r\nhttp_method:          0\r\nhttp_user_agent:      \r\nhttp_referer:         \r\nforwarded_for:        \r\nquota_key:            \r\nelapsed:              3884.86343185\r\nis_cancelled:         0\r\nread_rows:            0\r\nread_bytes:           0\r\ntotal_rows_approx:    0\r\nwritten_rows:         0\r\nwritten_bytes:        0\r\nmemory_usage:         158327769\r\npeak_memory_usage:    157278873\r\nquery:                SELECT sum(UserID GLOBAL IN (SELECT UserID FROM remote('127.0.0.{1,2}', test.hits))) FROM remote('127.0.0.{1,2}', test.hits);\r\nthread_ids:           [1045,3287,3074,3061,3126,13797,13985,15448,3279,15447,14006,8032,2684,2695,3259,15450,3121,13791]\r\nProfileEvents:        {'Query':1,'SelectQuery':1,'FileOpen':1,'Seek':15,'ReadBufferFromFileDescriptorRead':17,'ReadBufferFromFileDescriptorReadBytes':16375089,'ReadCompressedBytes':21697578,'CompressedReadBufferBlocks':1226,'CompressedReadBufferBytes':135426010,'IOBufferAllocs':36,'IOBufferAllocBytes':20571045,'TableFunctionExecute':2,'MarkCacheHits':16,'CreatedReadBufferOrdinary':16,'DiskReadElapsedMicroseconds':128000,'NetworkReceiveElapsedMicroseconds':9956,'NetworkSendElapsedMicroseconds':148,'NetworkReceiveBytes':10573432,'NetworkSendBytes':1064,'HedgedRequestsChangeReplica':1,'SelectedParts':1,'SelectedRanges':1,'SelectedMarks':1084,'SelectedRows':25047187,'SelectedBytes':200377496,'ContextLock':334,'RWLockAcquiredReadLocks':4,'RWLockReadersWaitMilliseconds':4,'CannotWriteToWriteBufferDiscard':36408,'QueryProfilerSignalOverruns':2920}\r\nSettings:             {'connect_timeout_with_failover_ms':'2000','connect_timeout_with_failover_secure_ms':'3000','idle_connection_timeout':'36000','replication_wait_for_inactive_replica_timeout':'30','load_balancing':'random','log_queries':'1','insert_quorum_timeout':'60000','http_send_timeout':'60','http_receive_timeout':'60','opentelemetry_start_trace_probability':'0.1','max_memory_usage':'10000000000','max_untracked_memory':'1048576','memory_profiler_step':'1048576','log_comment':'00147_global_in_aggregate_function.sql','send_logs_level':'warning','database_atomic_wait_for_drop_and_detach_synchronously':'1','allow_experimental_database_replicated':'1','async_insert_busy_timeout_ms':'5000'}\r\ncurrent_database:     test_0s7gn7\r\n\r\n\r\nThread 247 (Thread 0x7fc30c2af700 (LWP 1045)):\r\n#0  __syscall () at ../base/glibc-compatibility/musl/x86_64/syscall.s:14\r\n#1  0x0000000026a70a44 in epoll_pwait (fd=1833, ev=0x7fc30c29c920, cnt=1, to=-1, sigs=0x0) at ../base/glibc-compatibility/musl/epoll.c:27\r\n#2  0x0000000026a70ace in epoll_wait (fd=1833, ev=0x7fc30c29c920, cnt=1, to=-1) at ../base/glibc-compatibility/musl/epoll.c:36\r\n#3  0x000000001dd1cca4 in DB::Epoll::getManyReady (this=0x7fc30c29cf18, max_events=1, events_out=0x7fc30c29c920, blocking=true) at ../src/Common/Epoll.cpp:69\r\n#4  0x000000001f91784c in DB::PollingQueue::wait (this=0x7fc30c29cf18, lock=...) at ../src/Processors/Executors/PollingQueue.cpp:73\r\n#5  0x000000001f8fdbdd in DB::PipelineExecutor::executeImpl (this=0x7fc30c29cec0, num_threads=17) at ../src/Processors/Executors/PipelineExecutor.cpp:805\r\n#6  0x000000001f8fd113 in DB::PipelineExecutor::execute (this=0x7fc30c29cec0, num_threads=17) at ../src/Processors/Executors/PipelineExecutor.cpp:407\r\n#7  0x000000001f8f862e in DB::CompletedPipelineExecutor::execute (this=0x7fc30c29d238) at ../src/Processors/Executors/CompletedPipelineExecutor.cpp:99\r\n#8  0x000000001e2674f2 in DB::GlobalSubqueriesMatcher::Data::addExternalStorage (this=0x7fc30c29ddb0, ast=..., set_alias=false) at ../src/Interpreters/GlobalSubqueriesVisitor.h:164\r\n#9  0x000000001e266592 in DB::GlobalSubqueriesMatcher::visit (func=..., data=...) at ../src/Interpreters/GlobalSubqueriesVisitor.h:220\r\n#10 0x000000001e266201 in DB::GlobalSubqueriesMatcher::visit (ast=..., data=...) at ../src/Interpreters/GlobalSubqueriesVisitor.h:184\r\n#11 0x000000001e256ec1 in DB::InDepthNodeVisitor<DB::GlobalSubqueriesMatcher, false, false, std::__1::shared_ptr<DB::IAST> >::visit (this=0x7fc30c29dd78, ast=...) at ../src/Interpreters/InDepthNodeVisitor.h:34\r\n#12 0x000000001e266197 in DB::InDepthNodeVisitor<DB::GlobalSubqueriesMatcher, false, false, std::__1::shared_ptr<DB::IAST> >::visitChildren (this=0x7fc30c29dd78, ast=...) at ../src/Interpreters/InDepthNodeVisitor.h:62\r\n#13 0x000000001e256ea9 in DB::InDepthNodeVisitor<DB::GlobalSubqueriesMatcher, false, false, std::__1::shared_ptr<DB::IAST> >::visit (this=0x7fc30c29dd78, ast=...) at ../src/Interpreters/InDepthNodeVisitor.h:30\r\n#14 0x000000001e266197 in DB::InDepthNodeVisitor<DB::GlobalSubqueriesMatcher, false, false, std::__1::shared_ptr<DB::IAST> >::visitChildren (this=0x7fc30c29dd78, ast=...) at ../src/Interpreters/InDepthNodeVisitor.h:62\r\n#15 0x000000001e256ea9 in DB::InDepthNodeVisitor<DB::GlobalSubqueriesMatcher, false, false, std::__1::shared_ptr<DB::IAST> >::visit (this=0x7fc30c29dd78, ast=...) at ../src/Interpreters/InDepthNodeVisitor.h:30\r\n#16 0x000000001e266197 in DB::InDepthNodeVisitor<DB::GlobalSubqueriesMatcher, false, false, std::__1::shared_ptr<DB::IAST> >::visitChildren (this=0x7fc30c29dd78, ast=...) at ../src/Interpreters/InDepthNodeVisitor.h:62\r\n#17 0x000000001e256ea9 in DB::InDepthNodeVisitor<DB::GlobalSubqueriesMatcher, false, false, std::__1::shared_ptr<DB::IAST> >::visit (this=0x7fc30c29dd78, ast=...) at ../src/Interpreters/InDepthNodeVisitor.h:30\r\n#18 0x000000001e266197 in DB::InDepthNodeVisitor<DB::GlobalSubqueriesMatcher, false, false, std::__1::shared_ptr<DB::IAST> >::visitChildren (this=0x7fc30c29dd78, ast=...) at ../src/Interpreters/InDepthNodeVisitor.h:62\r\n#19 0x000000001e256ea9 in DB::InDepthNodeVisitor<DB::GlobalSubqueriesMatcher, false, false, std::__1::shared_ptr<DB::IAST> >::visit (this=0x7fc30c29dd78, ast=...) at ../src/Interpreters/InDepthNodeVisitor.h:30\r\n#20 0x000000001e245cb4 in DB::ExpressionAnalyzer::initGlobalSubqueriesAndExternalTables (this=0x7fc387c61c00, do_global=true) at ../src/Interpreters/ExpressionAnalyzer.cpp:360\r\n#21 0x000000001e2459a5 in DB::ExpressionAnalyzer::ExpressionAnalyzer (this=0x7fc387c61c00, query_=..., syntax_analyzer_result_=..., context_=..., subquery_depth_=0, do_global=true, subqueries_for_sets_=..., prepared_sets_=...) at ../src/Interpreters/ExpressionAnalyzer.cpp:153\r\n#22 0x000000001e6581f7 in DB::SelectQueryExpressionAnalyzer::SelectQueryExpressionAnalyzer (this=0x7fc387c61c00, query_=..., syntax_analyzer_result_=..., context_=..., metadata_snapshot_=..., required_result_columns_=..., do_global_=true, options_=..., subqueries_for_sets_=..., prepared_sets_=...) at ../src/Interpreters/ExpressionAnalyzer.h:303\r\n#23 0x000000001e6601c1 in std::__1::make_unique<DB::SelectQueryExpressionAnalyzer, std::__1::shared_ptr<DB::IAST>&, std::__1::shared_ptr<DB::TreeRewriterResult const>&, std::__1::shared_ptr<DB::Context>&, std::__1::shared_ptr<DB::StorageInMemoryMetadata const>&, std::__1::unordered_set<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::hash<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::equal_to<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > >, bool, DB::SelectQueryOptions&, std::__1::unordered_map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, DB::SubqueryForSet, std::__1::hash<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::equal_to<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const, DB::SubqueryForSet> > >, std::__1::unordered_map<DB::PreparedSetKey, std::__1::shared_ptr<DB::Set>, DB::PreparedSetKey::Hash, std::__1::equal_to<DB::PreparedSetKey>, std::__1::allocator<std::__1::pair<DB::PreparedSetKey const, std::__1::shared_ptr<DB::Set> > > > > (__args=..., __args=..., __args=..., __args=..., __args=..., __args=..., __args=..., __args=..., __args=...) at ../contrib/libcxx/include/memory:2068\r\n#24 0x000000001e6418fb in DB::InterpreterSelectQuery::InterpreterSelectQuery(std::__1::shared_ptr<DB::IAST> const&, std::__1::shared_ptr<DB::Context const>, std::__1::shared_ptr<DB::IBlockInputStream> const&, std::__1::optional<DB::Pipe>, std::__1::shared_ptr<DB::IStorage> const&, DB::SelectQueryOptions const&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&, std::__1::shared_ptr<DB::StorageInMemoryMetadata const> const&)::$_1::operator()(bool) const (this=0x7fc30c2a0ad8, try_move_to_prewhere=true) at ../src/Interpreters/InterpreterSelectQuery.cpp:439\r\n#25 0x000000001e63ee0d in DB::InterpreterSelectQuery::InterpreterSelectQuery (this=0x7fc380aa2800, query_ptr_=..., context_=..., input_=..., input_pipe_=..., storage_=..., options_=..., required_result_column_names=..., metadata_snapshot_=...) at ../src/Interpreters/InterpreterSelectQuery.cpp:513\r\n#26 0x000000001e63da7f in DB::InterpreterSelectQuery::InterpreterSelectQuery (this=0x7fc380aa2800, query_ptr_=..., context_=..., options_=..., required_result_column_names_=...) at ../src/Interpreters/InterpreterSelectQuery.cpp:160\r\n#27 0x000000001e9a6432 in std::__1::make_unique<DB::InterpreterSelectQuery, std::__1::shared_ptr<DB::IAST> const&, std::__1::shared_ptr<DB::Context>&, DB::SelectQueryOptions&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&> (__args=..., __args=..., __args=..., __args=...) at ../contrib/libcxx/include/memory:2068\r\n#28 0x000000001e9a47e9 in DB::InterpreterSelectWithUnionQuery::buildCurrentChildInterpreter (this=0x7fc330947820, ast_ptr_=..., current_required_result_column_names=...) at ../src/Interpreters/InterpreterSelectWithUnionQuery.cpp:216\r\n#29 0x000000001e9a403d in DB::InterpreterSelectWithUnionQuery::InterpreterSelectWithUnionQuery (this=0x7fc330947820, query_ptr_=..., context_=..., options_=..., required_result_column_names=...) at ../src/Interpreters/InterpreterSelectWithUnionQuery.cpp:138\r\n#30 0x000000001e5a7c7d in std::__1::make_unique<DB::InterpreterSelectWithUnionQuery, std::__1::shared_ptr<DB::IAST>&, std::__1::shared_ptr<DB::Context>&, DB::SelectQueryOptions const&> (__args=..., __args=..., __args=...) at ../contrib/libcxx/include/memory:2068\r\n#31 0x000000001e5a6235 in DB::InterpreterFactory::get (query=..., context=..., options=...) at ../src/Interpreters/InterpreterFactory.cpp:118\r\n#32 0x000000001ec60ae0 in DB::executeQueryImpl (begin=0x7fc3a50c1300 \"SELECT sum(UserID GLOBAL IN (SELECT UserID FROM remote('127.0.0.{1,2}', test.hits))) FROM remote('127.0.0.{1,2}', test.hits);\", end=0x7fc3a50c137d \"\", context=..., internal=false, stage=DB::QueryProcessingStage::Complete, istr=0x0) at ../src/Interpreters/executeQuery.cpp:605\r\n#33 0x000000001ec5ea64 in DB::executeQuery (query=..., context=..., internal=false, stage=DB::QueryProcessingStage::Complete) at ../src/Interpreters/executeQuery.cpp:950\r\n#34 0x000000001f835ca6 in DB::TCPHandler::runImpl (this=0x7fc3a3797000) at ../src/Server/TCPHandler.cpp:292\r\n#35 0x000000001f842f65 in DB::TCPHandler::run (this=0x7fc3a3797000) at ../src/Server/TCPHandler.cpp:1628\r\n#36 0x0000000023c86b59 in Poco::Net::TCPServerConnection::start (this=0x7fc3a3797000) at ../contrib/poco/Net/src/TCPServerConnection.cpp:43\r\n#37 0x0000000023c87368 in Poco::Net::TCPServerDispatcher::run (this=0x7fc3a4ebb700) at ../contrib/poco/Net/src/TCPServerDispatcher.cpp:115\r\n#38 0x0000000023dd5294 in Poco::PooledThread::run (this=0x7fc3a2706180) at ../contrib/poco/Foundation/src/ThreadPool.cpp:199\r\n#39 0x0000000023dd1d7a in Poco::(anonymous namespace)::RunnableHolder::run (this=0x7fc3a26233f0) at ../contrib/poco/Foundation/src/Thread.cpp:55\r\n#40 0x0000000023dd0b5c in Poco::ThreadImpl::runnableEntry (pThread=0x7fc3a27061b8) at ../contrib/poco/Foundation/src/Thread_POSIX.cpp:345\r\n#41 0x00007fc46877e609 in start_thread () from /lib/x86_64-linux-gnu/libpthread.so.0\r\n#42 0x00007fc468694293 in clone () from /lib/x86_64-linux-gnu/libc.so.6\r\n\r\n```\r\n\r\nLabel is 'bug', because similar issues were seen in Yandex.Metrica\r\n\r\ncc: @Avogar ","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29618/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29618/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29617","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29617/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29617/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29617/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29617","id":1013254697,"node_id":"I_kwDOA5dJV848ZQop","number":29617,"title":"Zookeeper load balancing settings","user":{"login":"filimonov","id":1549571,"node_id":"MDQ6VXNlcjE1NDk1NzE=","avatar_url":"https://avatars.githubusercontent.com/u/1549571?v=4","gravatar_id":"","url":"https://api.github.com/users/filimonov","html_url":"https://github.com/filimonov","followers_url":"https://api.github.com/users/filimonov/followers","following_url":"https://api.github.com/users/filimonov/following{/other_user}","gists_url":"https://api.github.com/users/filimonov/gists{/gist_id}","starred_url":"https://api.github.com/users/filimonov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/filimonov/subscriptions","organizations_url":"https://api.github.com/users/filimonov/orgs","repos_url":"https://api.github.com/users/filimonov/repos","events_url":"https://api.github.com/users/filimonov/events{/privacy}","received_events_url":"https://api.github.com/users/filimonov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":1401894928,"node_id":"MDU6TGFiZWwxNDAxODk0OTI4","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-zookeeper","name":"comp-zookeeper","color":"b5bcff","default":false,"description":"Zookeeper"}],"state":"open","locked":false,"assignee":{"login":"nicelulu","id":18606973,"node_id":"MDQ6VXNlcjE4NjA2OTcz","avatar_url":"https://avatars.githubusercontent.com/u/18606973?v=4","gravatar_id":"","url":"https://api.github.com/users/nicelulu","html_url":"https://github.com/nicelulu","followers_url":"https://api.github.com/users/nicelulu/followers","following_url":"https://api.github.com/users/nicelulu/following{/other_user}","gists_url":"https://api.github.com/users/nicelulu/gists{/gist_id}","starred_url":"https://api.github.com/users/nicelulu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nicelulu/subscriptions","organizations_url":"https://api.github.com/users/nicelulu/orgs","repos_url":"https://api.github.com/users/nicelulu/repos","events_url":"https://api.github.com/users/nicelulu/events{/privacy}","received_events_url":"https://api.github.com/users/nicelulu/received_events","type":"User","site_admin":false},"assignees":[{"login":"nicelulu","id":18606973,"node_id":"MDQ6VXNlcjE4NjA2OTcz","avatar_url":"https://avatars.githubusercontent.com/u/18606973?v=4","gravatar_id":"","url":"https://api.github.com/users/nicelulu","html_url":"https://github.com/nicelulu","followers_url":"https://api.github.com/users/nicelulu/followers","following_url":"https://api.github.com/users/nicelulu/following{/other_user}","gists_url":"https://api.github.com/users/nicelulu/gists{/gist_id}","starred_url":"https://api.github.com/users/nicelulu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nicelulu/subscriptions","organizations_url":"https://api.github.com/users/nicelulu/orgs","repos_url":"https://api.github.com/users/nicelulu/repos","events_url":"https://api.github.com/users/nicelulu/events{/privacy}","received_events_url":"https://api.github.com/users/nicelulu/received_events","type":"User","site_admin":false}],"milestone":null,"comments":3,"created_at":"2021-10-01T11:53:54Z","updated_at":"2021-10-13T10:47:28Z","closed_at":null,"author_association":"COLLABORATOR","active_lock_reason":null,"body":"There are use cases when one of the zookeeper nodes is preferred - same AZ in the cloud, or you just to avoid the situations when all the clickhouse nodes will connect accidentally to the same zookeeper node, etc. \r\n\r\nThe proposed solution is a setting \r\n```xml\r\n<zookeeper_load_balancing>random / in_order / nearest_hostname / first_or_random / round_robin</zookeeper_load_balancing>\r\n```\r\n\r\n`random` would be the default","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29617/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29617/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29601","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29601/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29601/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29601/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29601","id":1012805631,"node_id":"I_kwDOA5dJV848Xi__","number":29601,"title":"Intern Tasks 2021/2022","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":14,"created_at":"2021-10-01T02:14:48Z","updated_at":"2022-01-25T03:35:47Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"This is the list of proposed tasks. It is to be extented. You can propose more tasks.\r\nYou can also find the previous lists here:\r\n\r\n2020/2021: https://github.com/ClickHouse/ClickHouse/issues/15065\r\n2019/2020: https://gist.github.com/alexey-milovidov/4251f71275f169d8fd0867e2051715e9\r\n2018/2019: https://gist.github.com/alexey-milovidov/6735d193762cab1ad3b6e6af643e3a43\r\n2017/2018: https://gist.github.com/alexey-milovidov/26cc3862eb87e52869b9dac64ab99156\r\n\r\nThe tasks should be:\r\n\r\n- not too hard (doable within about a month) but usually not less than a week;\r\n- not alter some core components of the system;\r\n- mostly isolated, does not require full knowledge of the system;\r\n- somewhat interesting to implement or have some point of research;\r\n- not in critical path of our roadmap (ok to be throwed away after a year);\r\n- most of them are for C++ developers, but there should be also tasks for frontend developers or tools/research that only require Go/Python/whatever;\r\n- some tasks should allow team work;\r\n- cover various skills, e.g. system programming, algorithm knowledge, etc...\r\n\r\nThis is a draft. Descriptions to be filled.\r\n\r\n\r\n### :gear: Aggregate functions for graph processing\r\n\r\n**Booked by @ElderlyPassionFruit and @Hattonuri**\r\n\r\n#29701\r\n\r\n\r\n### :gear: Aggregate functions for statistical tests\r\n\r\n**Booked by @trenin17**\r\n\r\n#3266\r\n\r\nNormality tests and similar.\r\n\r\n\r\n### :gear: Representation of ZooKeeper data model as a flat table in ClickHouse\r\n\r\n**Booked by @punkmunk**\r\n\r\n#25645 #22130\r\n\r\n\r\n### :gear: Network replay server for testing\r\n\r\n**Booked by @zhukowladimir**\r\n\r\n#11481\r\n\r\n\r\n### :gear: Evaluation and testing of non-cryptographic hash functions in ClickHouse\r\n\r\n**Booked by @olevino**\r\n\r\nIntegrate wyhash, meowhash, aquahash, farsh, t1ha and highwayhash.\r\n\r\n\r\n### :gear: Parallel compression for data export\r\n\r\n**Booked by @kavladst**\r\n\r\nAllow to parallelize data export into gz, xz and bzip2 formats.\r\n\r\n\r\n### :gear: ClickHouse in a web browser with WebAssembly\r\n\r\n**Booked by @Alucardik**\r\n\r\n\r\n### :gear: Implementation of Graphite Carbon API (Graphite Web) in ClickHouse\r\n\r\n**Booked by @qwertBR**\r\n\r\n\r\n### :gear: Implementation of Prometheus querying API in ClickHouse\r\n\r\n**Booked by @gitnabi**\r\n\r\n\r\n### :gear: Minimal plotting capabilities in ClickHouse\r\n\r\n**Booked by @vlerdman**\r\n\r\n\r\n### :gear: Collecting of Linux Perf data in ClickHouse\r\n\r\n**Booked by @rubin-do**\r\n\r\n### :gear: Integration of ClickHouse with MeiliSearch\r\n\r\n**Booked by @Michicosun**\r\n\r\n### :gear: Time series analysis with window functions\r\n\r\n**Booked by @mathalex Alexey Boykov.**\r\n\r\nSimple moving average. Holt-Winters forecast. ARIMA. Discovery of \"shock events\".\r\nA modifier for ORDER BY WITH FILL or similar to fill data with extrapolation.\r\n\r\n\r\n### :gear: API endpoints based on parametrized views in ClickHouse\r\n\r\n**Booked by @Fancy2000**\r\n\r\nManage HTTP handlers (API endpoints) with SQL queries (creating parametrized views a.k.a. table functions).\r\n\r\n\r\n### :gear: Embedded ClickHouse as a Python module\r\n\r\n**Booked by @LGrishin**\r\n\r\n\r\n### :gear: Compilation of expressions to GPU code\r\n\r\n**Preliminarily booked**\r\n\r\n\r\n### :gear: Integrating Rust code into ClickHouse\r\n\r\n**Booked by @BoloniniD**\r\n\r\nWith BLAKE3 hash function as an example.\r\n\r\n\r\n### :gear: Key value data marts in ClickHouse\r\n\r\n**Booked by @dankondr**\r\n\r\n#33581\r\n\r\n\r\n### :gear: Improvements of ClickHouse integration with foreign databases\r\n\r\n**Booked by @aapetrenko and @kate1mag**\r\n\r\nTable functions to access Mongodb, Redis and Cassandra. Integration with ElasticSearch.\r\nUnrestricted reads from ZooKeeper.\r\n\r\n\r\n### :gear: Improvements of ClickHouse integration with data streams\r\n\r\n**Booked by @tchepavel**\r\n\r\nIntegration with Apache Pulsar, Redis Streams, NATS or Kinesis, SQS.\r\n\r\n\r\n### :gear: Integration of ClickHouse with embedded key-value stores\r\n\r\n**Booked by @nautaa**\r\n\r\nIntegration with TerarkDB, libfpta, FASTER.\r\n\r\n\r\n### :gear: Integration of ClickHouse with MADLib\r\n\r\n**Booked by @antikvist, @sabinadayanova**\r\n\r\n#4425\r\n\r\n\r\n### :gear: Schema inference for data formats. Support for new input/output formats in ClickHouse\r\n\r\n**Booked by @Avogar**\r\n\r\nFlatbuffers, HDF5 and sas7bdat.\r\n\r\n\r\n### :gear: Advanced compression methods in ClickHouse\r\n\r\n**Booked by @takashirei**\r\n\r\nbsc, csc and bcm.\r\n\r\n\r\n### :gear: ClickHouse as a backend for Istio Telemetry.\r\n\r\n**Booked by @Romanchenko**\r\n\r\n### :gear: Integration of ClickHouse with Apache Calcite\r\n\r\n**Booked by @darkkeks**\r\n\r\n### :gear: Integration of ClickHouse with MySQL Parser\r\n\r\n**Booked by @mrworker27**\r\n\r\n### :gear: Tamper-proof data storage with blockchain\r\n\r\n**Booked by @Justarone**\r\n\r\n### :gear: Isolation of user-defined functions with Firecracker VM\r\n\r\n**Booked by @ivolff**\r\n\r\n### :gear: Direct import from files inside tar/zip/7z archives\r\n\r\n**Booked by @0442A403**\r\n\r\n### :gear: SQL functions for compatibility with MySQL dialect\r\n\r\n#7320\r\n\r\n**Booked by @Shuba-Buba, @evlampiy-lavrentiev, @psevdoinsaf**\r\n\r\n### :gear: Porting ClickHouse SIMD optimizations to ARM NEON\r\n\r\n**Booked by @chalice19, preliminary**\r\n\r\n### :gear: Limited support for correlated subqueries in ClickHouse\r\n\r\n**Booked by @Amesaru**\r\n\r\n### :gear: User Defined Functions with Julia, R or Scipy\r\n\r\n**Booked by @vvd170501**\r\n\r\n### :gear: Functions to extract data from HTML with CSS selectors\r\n\r\n**Booked by @zdikov**\r\n\r\n### :gear: Improvements of PREWHERE operator in ClickHouse.\r\n\r\n**Booked by @nikvas0**\r\n\r\n### Add support of ClickHouse SQL dialect to Exposed framework for Kotlin.\r\n\r\n### :gear: Large Scale Internet Technologies Survey\r\n\r\n#18842\r\n**Booked by @mariemalysheva**\r\n\r\n### :gear: Implicit user credentials and TOTP for authentication\r\n\r\n**Booked by @kam3nskii**\r\n\r\n### :gear: Grace Hash JOIN in ClickHouse\r\n\r\n**Booked by @TauZer0**\r\n\r\n### :gear: Parallel execution of Distributed DDL queries\r\n\r\n**Booked by @shaprunovk**\r\n\r\n### :gear: Fuzzy GROUP BY for data clustering\r\n\r\n**Booked by @umchemurziev**\r\n\r\n### :gear: Optimization of caching strategies in ClickHouse\r\n\r\n**Booked by @alexX512**\r\n\r\n### :gear: Optimization of queries with ordering by sublinear aggregate functions\r\n\r\n**Booked by @dimarub2000**\r\n\r\n### :gear: Extensions of ZooKeeper protocol for transactions.\r\n\r\n**Booked by @asokol123**\r\n\r\n### :gear: Probablistic data structures for approximate filtering in ClickHouse queries.\r\n\r\n**Booked by @ruct**\r\n\r\n### :gear: Improvements for CASE operator and transform function\r\n\r\n**Booked by @pmimanukyan**\r\n\r\n### :gear: Comparison of Snap, AppImage and Flatpak formats on ClickHouse builds\r\n\r\n**Booked by @TrueAstralpirate**\r\n\r\n### :gear: Integration of ClickHouse with Observable and Falcon\r\n\r\n**Booked by @DotJason**\r\n\r\n### :gear: Implementation of GWP-Asan and comparison of memory allocators in ClickHouse\r\n\r\n**Booked by **\r\n\r\n### :gear: Implementation of aggregate function combinators: TOTAL, BY and ORDER BY.\r\n\r\n**Booked by **\r\n\r\n### :gear: Improvements of ClickHouse fuzzing\r\n\r\n**Booked by @mark-polokhov**\r\n\r\n### :gear: Optimizations of ClickHouse for cloud infrastructure\r\n\r\n**Booked by @nikitamikhaylov**\r\n\r\n### :gear: Extending Date and Time Functions in ClickHouse\r\n\r\n**Booked by @elevankoff**\r\n\r\n### :gear: Extended Temporary Tables in ClickHouse\r\n\r\n**Booked by **\r\n\r\n### :gear: Specialized compression codecs for floating point data\r\n\r\n**Booked by @koloshmet**","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29601/reactions","total_count":17,"+1":17,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29601/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29587","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29587/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29587/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29587/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29587","id":1012582502,"node_id":"I_kwDOA5dJV848Wshm","number":29587,"title":"Support sending user defined tags with sentry crash reports","user":{"login":"nvartolomei","id":543193,"node_id":"MDQ6VXNlcjU0MzE5Mw==","avatar_url":"https://avatars.githubusercontent.com/u/543193?v=4","gravatar_id":"","url":"https://api.github.com/users/nvartolomei","html_url":"https://github.com/nvartolomei","followers_url":"https://api.github.com/users/nvartolomei/followers","following_url":"https://api.github.com/users/nvartolomei/following{/other_user}","gists_url":"https://api.github.com/users/nvartolomei/gists{/gist_id}","starred_url":"https://api.github.com/users/nvartolomei/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nvartolomei/subscriptions","organizations_url":"https://api.github.com/users/nvartolomei/orgs","repos_url":"https://api.github.com/users/nvartolomei/repos","events_url":"https://api.github.com/users/nvartolomei/events{/privacy}","received_events_url":"https://api.github.com/users/nvartolomei/received_events","type":"User","site_admin":false},"labels":[{"id":386401508,"node_id":"MDU6TGFiZWwzODY0MDE1MDg=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/help%20wanted","name":"help wanted","color":"128A0C","default":true,"description":null},{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2021-09-30T20:15:35Z","updated_at":"2021-10-04T09:17:44Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"It would be great to allow sending of additional/arbitrary tags with sentry crash report. These would allow for better filtering and aggregations in the Sentry UI.\r\n\r\nEg hostname would be great to be sent as tag, this would allow seeing % of crashes by hostname (example https://try.sentry-demo.com/organizations/fresh-moccasin/issues/413055/tags/device/?project=147865)\r\n\r\nAdditional ones could be things like physical/logical cluster name, data center and so on.\r\n\r\nAn idea is to extend `send_crash_reports` section with tags, example:\r\n\r\n```xml\r\n<clickhouse>\r\n    <send_crash_reports>\r\n       <tags>\r\n            <hostname>play.clickhouse.tech</hostname>\r\n            <cluster>play</cluster>\r\n            <!-- ... -->\r\n        </tags>\r\n\r\n        <!-- Changing <enabled> to true allows sending crash reports to -->\r\n        <!-- the ClickHouse core developers team via Sentry https://sentry.io -->\r\n        <!-- Doing so at least in pre-production environments is highly appreciated -->\r\n        <enabled>false</enabled>\r\n        <!-- Change <anonymize> to true if you don't feel comfortable attaching the server hostname to the crash report -->\r\n        <anonymize>false</anonymize>\r\n        <!-- Default endpoint should be changed to different Sentry DSN only if you have -->\r\n        <!-- some in-house engineers or hired consultants who're going to debug ClickHouse issues for you -->\r\n        <endpoint>https://6f33034cfe684dd7a3ab9875e57b1c8d@o388870.ingest.sentry.io/5226277</endpoint>\r\n    </send_crash_reports>\r\n</clickhouse>\r\n```\r\n\r\nhttps://github.com/ClickHouse/ClickHouse/blob/3e0d4faa1e652189e7d4efa67e6849aeadefb0c5/programs/server/config.xml#L1195-L1205","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29587/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29587/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29551","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29551/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29551/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29551/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29551","id":1011795474,"node_id":"I_kwDOA5dJV848TsYS","number":29551,"title":"MaterializedPostgresql database and full text search ","user":{"login":"Shohjahon","id":16575814,"node_id":"MDQ6VXNlcjE2NTc1ODE0","avatar_url":"https://avatars.githubusercontent.com/u/16575814?v=4","gravatar_id":"","url":"https://api.github.com/users/Shohjahon","html_url":"https://github.com/Shohjahon","followers_url":"https://api.github.com/users/Shohjahon/followers","following_url":"https://api.github.com/users/Shohjahon/following{/other_user}","gists_url":"https://api.github.com/users/Shohjahon/gists{/gist_id}","starred_url":"https://api.github.com/users/Shohjahon/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Shohjahon/subscriptions","organizations_url":"https://api.github.com/users/Shohjahon/orgs","repos_url":"https://api.github.com/users/Shohjahon/repos","events_url":"https://api.github.com/users/Shohjahon/events{/privacy}","received_events_url":"https://api.github.com/users/Shohjahon/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-09-30T07:03:14Z","updated_at":"2021-10-04T05:49:53Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"How full text search can be implemented on MaterializedPostgresql database? If there is not any feature for this, can apache solr or elasticsearch be integrated with clickhouse in order to create full text search functionality?","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29551/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29551/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29541","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29541/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29541/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29541/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29541","id":1011181594,"node_id":"I_kwDOA5dJV848RWga","number":29541,"title":"Block structure mismatch in function connect between ConvertingTransform and ReplicatedMergeTreeSink stream","user":{"login":"tavplubix","id":14847450,"node_id":"MDQ6VXNlcjE0ODQ3NDUw","avatar_url":"https://avatars.githubusercontent.com/u/14847450?v=4","gravatar_id":"","url":"https://api.github.com/users/tavplubix","html_url":"https://github.com/tavplubix","followers_url":"https://api.github.com/users/tavplubix/followers","following_url":"https://api.github.com/users/tavplubix/following{/other_user}","gists_url":"https://api.github.com/users/tavplubix/gists{/gist_id}","starred_url":"https://api.github.com/users/tavplubix/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tavplubix/subscriptions","organizations_url":"https://api.github.com/users/tavplubix/orgs","repos_url":"https://api.github.com/users/tavplubix/repos","events_url":"https://api.github.com/users/tavplubix/events{/privacy}","received_events_url":"https://api.github.com/users/tavplubix/received_events","type":"User","site_admin":false},"labels":[{"id":2104602822,"node_id":"MDU6TGFiZWwyMTA0NjAyODIy","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/fuzz","name":"fuzz","color":"abc4ea","default":false,"description":""}],"state":"open","locked":false,"assignee":{"login":"KochetovNicolai","id":4092911,"node_id":"MDQ6VXNlcjQwOTI5MTE=","avatar_url":"https://avatars.githubusercontent.com/u/4092911?v=4","gravatar_id":"","url":"https://api.github.com/users/KochetovNicolai","html_url":"https://github.com/KochetovNicolai","followers_url":"https://api.github.com/users/KochetovNicolai/followers","following_url":"https://api.github.com/users/KochetovNicolai/following{/other_user}","gists_url":"https://api.github.com/users/KochetovNicolai/gists{/gist_id}","starred_url":"https://api.github.com/users/KochetovNicolai/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/KochetovNicolai/subscriptions","organizations_url":"https://api.github.com/users/KochetovNicolai/orgs","repos_url":"https://api.github.com/users/KochetovNicolai/repos","events_url":"https://api.github.com/users/KochetovNicolai/events{/privacy}","received_events_url":"https://api.github.com/users/KochetovNicolai/received_events","type":"User","site_admin":false},"assignees":[{"login":"KochetovNicolai","id":4092911,"node_id":"MDQ6VXNlcjQwOTI5MTE=","avatar_url":"https://avatars.githubusercontent.com/u/4092911?v=4","gravatar_id":"","url":"https://api.github.com/users/KochetovNicolai","html_url":"https://github.com/KochetovNicolai","followers_url":"https://api.github.com/users/KochetovNicolai/followers","following_url":"https://api.github.com/users/KochetovNicolai/following{/other_user}","gists_url":"https://api.github.com/users/KochetovNicolai/gists{/gist_id}","starred_url":"https://api.github.com/users/KochetovNicolai/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/KochetovNicolai/subscriptions","organizations_url":"https://api.github.com/users/KochetovNicolai/orgs","repos_url":"https://api.github.com/users/KochetovNicolai/repos","events_url":"https://api.github.com/users/KochetovNicolai/events{/privacy}","received_events_url":"https://api.github.com/users/KochetovNicolai/received_events","type":"User","site_admin":false}],"milestone":null,"comments":1,"created_at":"2021-09-29T16:39:38Z","updated_at":"2021-10-13T17:25:15Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"https://clickhouse-test-reports.s3.yandex.net/0/70dc235287b3e0e93633ba9e7fc0ed17cdb29a02/functional_stateless_tests_(debug).html#fail1\r\n\r\n(also there is double whitespace in the exception message)\r\n\r\n```\r\n2021.09.29 23:46:57.810106 [ 18428 ] {e6fe5752-84da-4734-9015-efa636666d67} <Fatal> : Logical error: 'Block structure mismatch in  function connect between ConvertingTransform and ReplicatedMergeTreeSink stream: different number of columns:\r\n2021.09.29 23:46:57.812360 [ 20899 ] {} <Fatal> BaseDaemon: ########################################\r\n2021.09.29 23:46:57.812996 [ 20899 ] {} <Fatal> BaseDaemon: (version 21.11.1.8246 (official build), build id: 380C8D80C1FF3D22EDF5D27559D997ED95951F4D) (from thread 18428) (query_id: e6fe5752-84da-4734-9015-efa636666d67) Received signal Aborted (6)\r\n2021.09.29 23:46:57.813549 [ 20899 ] {} <Fatal> BaseDaemon: \r\n2021.09.29 23:46:57.814097 [ 20899 ] {} <Fatal> BaseDaemon: Stack trace: 0x7fb32588e18b 0x7fb32586d859 0x13339638 0x13339742 0x1d9ebf31 0x1d9ea69c 0x1d9ea92a 0x1f7ca42c 0x1f799972 0x1e51e67f 0x1e51ffce 0x1eb7b6bb 0x1eb79284 0x1f74fe06 0x1f75d0c5 0x23ba0b19 0x23ba1328 0x23cef254 0x23cebd3a 0x23ceab1c 0x7fb325a54609 0x7fb32596a293\r\n2021.09.29 23:46:57.814838 [ 20899 ] {} <Fatal> BaseDaemon: 4. gsignal @ 0x4618b in /usr/lib/x86_64-linux-gnu/libc-2.31.so\r\n2021.09.29 23:46:57.815053 [ 20899 ] {} <Fatal> BaseDaemon: 5. abort @ 0x25859 in /usr/lib/x86_64-linux-gnu/libc-2.31.so\r\n2021.09.29 23:46:57.917025 [ 20899 ] {} <Fatal> BaseDaemon: 6. ./obj-x86_64-linux-gnu/../src/Common/Exception.cpp:53: DB::handle_error_code(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, bool, std::__1::vector<void*, std::__1::allocator<void*> > const&) @ 0x13339638 in /usr/bin/clickhouse\r\n2021.09.29 23:46:58.005176 [ 20899 ] {} <Fatal> BaseDaemon: 7. ./obj-x86_64-linux-gnu/../src/Common/Exception.cpp:60: DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, bool) @ 0x13339742 in /usr/bin/clickhouse\r\n2021.09.29 23:46:58.253168 [ 20899 ] {} <Fatal> BaseDaemon: 8. ./obj-x86_64-linux-gnu/../src/Core/Block.cpp:32: void DB::onError<void>(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int) @ 0x1d9ebf31 in /usr/bin/clickhouse\r\n2021.09.29 23:46:58.486682 [ 20899 ] {} <Fatal> BaseDaemon: 9. ./obj-x86_64-linux-gnu/../src/Core/Block.cpp:86: void DB::checkBlockStructure<void>(DB::Block const&, DB::Block const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, bool) @ 0x1d9ea69c in /usr/bin/clickhouse\r\n2021.09.29 23:46:58.720603 [ 20899 ] {} <Fatal> BaseDaemon: 10. ./obj-x86_64-linux-gnu/../src/Core/Block.cpp:607: DB::assertCompatibleHeader(DB::Block const&, DB::Block const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) @ 0x1d9ea92a in /usr/bin/clickhouse\r\n2021.09.29 23:46:58.822850 [ 20899 ] {} <Fatal> BaseDaemon: 11. ./obj-x86_64-linux-gnu/../src/Processors/Port.cpp:19: DB::connect(DB::OutputPort&, DB::InputPort&) @ 0x1f7ca42c in /usr/bin/clickhouse\r\n2021.09.29 23:46:58.929410 [ 20899 ] {} <Fatal> BaseDaemon: 12. ./obj-x86_64-linux-gnu/../src/Processors/Chain.cpp:81: DB::Chain::addSource(std::__1::shared_ptr<DB::IProcessor>) @ 0x1f799972 in /usr/bin/clickhouse\r\n2021.09.29 23:46:59.288941 [ 20899 ] {} <Fatal> BaseDaemon: 13. ./obj-x86_64-linux-gnu/../src/Interpreters/InterpreterInsertQuery.cpp:222: DB::InterpreterInsertQuery::buildChainImpl(std::__1::shared_ptr<DB::IStorage> const&, std::__1::shared_ptr<DB::StorageInMemoryMetadata const> const&, DB::Block const&, DB::ThreadStatus*, std::__1::atomic<unsigned long>*) @ 0x1e51e67f in /usr/bin/clickhouse\r\n2021.09.29 23:46:59.627124 [ 20899 ] {} <Fatal> BaseDaemon: 14. ./obj-x86_64-linux-gnu/../src/Interpreters/InterpreterInsertQuery.cpp:368: DB::InterpreterInsertQuery::execute() @ 0x1e51ffce in /usr/bin/clickhouse\r\n2021.09.29 23:46:59.965561 [ 20899 ] {} <Fatal> BaseDaemon: 15. ./obj-x86_64-linux-gnu/../src/Interpreters/executeQuery.cpp:635: DB::executeQueryImpl(char const*, char const*, std::__1::shared_ptr<DB::Context>, bool, DB::QueryProcessingStage::Enum, DB::ReadBuffer*) @ 0x1eb7b6bb in /usr/bin/clickhouse\r\n2021.09.29 23:47:00.327484 [ 20899 ] {} <Fatal> BaseDaemon: 16. ./obj-x86_64-linux-gnu/../src/Interpreters/executeQuery.cpp:950: DB::executeQuery(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::shared_ptr<DB::Context>, bool, DB::QueryProcessingStage::Enum) @ 0x1eb79284 in /usr/bin/clickhouse\r\n2021.09.29 23:47:00.632069 [ 20899 ] {} <Fatal> BaseDaemon: 17. ./obj-x86_64-linux-gnu/../src/Server/TCPHandler.cpp:292: DB::TCPHandler::runImpl() @ 0x1f74fe06 in /usr/bin/clickhouse\r\n2021.09.29 23:47:00.993655 [ 20899 ] {} <Fatal> BaseDaemon: 18. ./obj-x86_64-linux-gnu/../src/Server/TCPHandler.cpp:1628: DB::TCPHandler::run() @ 0x1f75d0c5 in /usr/bin/clickhouse\r\n2021.09.29 23:47:01.075840 [ 20899 ] {} <Fatal> BaseDaemon: 19. ./obj-x86_64-linux-gnu/../contrib/poco/Net/src/TCPServerConnection.cpp:43: Poco::Net::TCPServerConnection::start() @ 0x23ba0b19 in /usr/bin/clickhouse\r\n2021.09.29 23:47:01.177965 [ 20899 ] {} <Fatal> BaseDaemon: 20. ./obj-x86_64-linux-gnu/../contrib/poco/Net/src/TCPServerDispatcher.cpp:115: Poco::Net::TCPServerDispatcher::run() @ 0x23ba1328 in /usr/bin/clickhouse\r\n2021.09.29 23:47:01.287364 [ 20899 ] {} <Fatal> BaseDaemon: 21. ./obj-x86_64-linux-gnu/../contrib/poco/Foundation/src/ThreadPool.cpp:199: Poco::PooledThread::run() @ 0x23cef254 in /usr/bin/clickhouse\r\n2021.09.29 23:47:01.395495 [ 20899 ] {} <Fatal> BaseDaemon: 22. ./obj-x86_64-linux-gnu/../contrib/poco/Foundation/src/Thread.cpp:56: Poco::(anonymous namespace)::RunnableHolder::run() @ 0x23cebd3a in /usr/bin/clickhouse\r\n2021.09.29 23:47:01.501554 [ 20899 ] {} <Fatal> BaseDaemon: 23. ./obj-x86_64-linux-gnu/../contrib/poco/Foundation/src/Thread_POSIX.cpp:345: Poco::ThreadImpl::runnableEntry(void*) @ 0x23ceab1c in /usr/bin/clickhouse\r\n2021.09.29 23:47:01.516965 [ 20899 ] {} <Fatal> BaseDaemon: 24. start_thread @ 0x9609 in /usr/lib/x86_64-linux-gnu/libpthread-2.31.so\r\n2021.09.29 23:47:01.517420 [ 20899 ] {} <Fatal> BaseDaemon: 25. __clone @ 0x122293 in /usr/lib/x86_64-linux-gnu/libc-2.31.so\r\n2021.09.29 23:47:02.946969 [ 20899 ] {} <Fatal> BaseDaemon: Checksum of the binary: F288FB192F04A7536C9D71079D67D6B4, integrity check passed.\r\n2021.09.29 23:47:18.134320 [ 373 ] {} <Fatal> Application: Child process was terminated by signal 6.\r\n```\r\n\r\ncc: @KochetovNicolai ","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29541/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29541/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29532","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29532/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29532/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29532/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29532","id":1010929798,"node_id":"I_kwDOA5dJV848QZCG","number":29532,"title":"Inconsistent behavior working with large arrays","user":{"login":"alesapin","id":3684697,"node_id":"MDQ6VXNlcjM2ODQ2OTc=","avatar_url":"https://avatars.githubusercontent.com/u/3684697?v=4","gravatar_id":"","url":"https://api.github.com/users/alesapin","html_url":"https://github.com/alesapin","followers_url":"https://api.github.com/users/alesapin/followers","following_url":"https://api.github.com/users/alesapin/following{/other_user}","gists_url":"https://api.github.com/users/alesapin/gists{/gist_id}","starred_url":"https://api.github.com/users/alesapin/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alesapin/subscriptions","organizations_url":"https://api.github.com/users/alesapin/orgs","repos_url":"https://api.github.com/users/alesapin/repos","events_url":"https://api.github.com/users/alesapin/events{/privacy}","received_events_url":"https://api.github.com/users/alesapin/received_events","type":"User","site_admin":false},"labels":[{"id":845247686,"node_id":"MDU6TGFiZWw4NDUyNDc2ODY=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/usability","name":"usability","color":"ebf28c","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-09-29T13:01:36Z","updated_at":"2021-09-29T13:02:02Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"We have internal limitation to the maximum array size which can be stored inside `Field` structure -- 1000000. This value is reasonable and we shouldn't allow to have bigger arrays in fields. But we have following inconsistencies:\r\n```\r\n:) SELECT range(1000001) -- expected to fail, 1000001 >  1000000                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \r\n                                                                                                                                                                                                                                                                                                                                                                                              \r\nReceived exception from server (version 21.11.1):                                                                                                                                                                                                                                                                                                                                             \r\nCode: 128. DB::Exception: Received from localhost:9000. DB::Exception: Array of size 1000001 is too large to be manipulated as single field, maximum size 1000000. (TOO_LARGE_ARRAY_SIZE)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \r\n```\r\nBut, semantically same query works:\r\n```\r\n:) SELECT groupArray(number) AS n_array -- array is bigger than 1000000\r\nFROM\r\n(\r\n    SELECT number\r\n    FROM numbers(1000001)\r\n)\r\n\r\n┌─n_array────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\r\n│ [0,1,2,3,4,5,6,7,8,9,⋯│\r\n└────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\r\n```\r\n\r\nAnd again, if we move the array into `WITH` expression query will fail:\r\n```\r\n:) WITH (\r\n        SELECT groupArray(number) AS n_array\r\n        FROM\r\n        (\r\n            SELECT number\r\n            FROM numbers(1000001)\r\n        )\r\n    ) AS A\r\nSELECT\r\n    A\r\n\r\nReceived exception from server (version 21.11.1):\r\nCode: 128. DB::Exception: Received from localhost:9000. DB::Exception: Array of size 1000001 is too large to be manipulated as single field, maximum size 1000000. (TOO_LARGE_ARRAY_SIZE)\r\n```\r\n\r\nThe main reason is that we have `Const` column in case of `range(...)` and `WITH` which tries to convert the value to `Field`, but in case №2 we have Array(UInt64). It's not visible from users size:\r\n```\r\n\r\n:) SELECT toTypeName(range(1000001))\r\n\r\n┌─toTypeName(range(1000001))─┐\r\n│ Array(UInt32)              │\r\n└────────────────────────────┘\r\n\r\n:) SELECT toTypeName(groupArray(number))\r\nFROM\r\n(\r\n    SELECT number\r\n    FROM numbers(1000001)\r\n)\r\n\r\n┌─toTypeName(groupArray(number))─┐\r\n│ Array(UInt64)                  │\r\n└────────────────────────────────┘\r\n\r\n\r\n:) WITH (\r\n        SELECT groupArray(number) AS n_array\r\n        FROM\r\n        (\r\n            SELECT number\r\n            FROM numbers(1000001)\r\n        )\r\n    ) AS A\r\nSELECT toTypeName(A)\r\n\r\n┌─toTypeName(A)─┐\r\n│ Array(UInt64) │\r\n└───────────────┘\r\n```\r\n\r\nSo we have to make this behavior consistent.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29532/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29532/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29505","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29505/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29505/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29505/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29505","id":1010382313,"node_id":"I_kwDOA5dJV848OTXp","number":29505,"title":"system.replication_queue is blocked","user":{"login":"825644691","id":34371864,"node_id":"MDQ6VXNlcjM0MzcxODY0","avatar_url":"https://avatars.githubusercontent.com/u/34371864?v=4","gravatar_id":"","url":"https://api.github.com/users/825644691","html_url":"https://github.com/825644691","followers_url":"https://api.github.com/users/825644691/followers","following_url":"https://api.github.com/users/825644691/following{/other_user}","gists_url":"https://api.github.com/users/825644691/gists{/gist_id}","starred_url":"https://api.github.com/users/825644691/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/825644691/subscriptions","organizations_url":"https://api.github.com/users/825644691/orgs","repos_url":"https://api.github.com/users/825644691/repos","events_url":"https://api.github.com/users/825644691/events{/privacy}","received_events_url":"https://api.github.com/users/825644691/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":11,"created_at":"2021-09-29T01:42:11Z","updated_at":"2021-09-30T09:56:35Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"SELECT type,postpone_reason FROM system.replication_queue WHERE is_currently_executing\r\n\r\n┌─type────────┬─postpone_reason─────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ GET_PART    │                                                                                                                             │\r\n│ GET_PART    │                                                                                                                             │\r\n│ GET_PART    │                                                                                                                             │\r\n│ GET_PART    │                                                                                                                             │\r\n│ GET_PART    │                                                                                                                             │\r\n│ GET_PART    │                                                                                                                             │\r\n│ GET_PART    │                                                                                                                             │\r\n│ GET_PART    │                                                                                                                             │\r\n│ GET_PART    │ Not executing fetch of part 1f92a8a309110cb78af3998adb2fb2df_1503_2997_4 because 100 fetches already executing, max 100.    │\r\n│ GET_PART    │ Not executing fetch of part 21fb30adf1eb403d421aa7d0ec89f2fb_0_1307_4 because 100 fetches already executing, max 100.       │\r\n│ GET_PART    │ Not executing fetch of part 288ddfe71265204f3782e75f2a2572c7_0_1512_4 because 100 fetches already executing, max 100.       │\r\n│ GET_PART    │ Not executing fetch of part 288ddfe71265204f3782e75f2a2572c7_1513_9435_5 because 100 fetches already executing, max 100.    │\r\n│ GET_PART    │ Not executing fetch of part 2a5a060bc8d8346efbf674f3eed17bdf_1297_7386_5 because 100 fetches already executing, max 100.    │\r\n│ GET_PART    │ Not executing fetch of part 2a5a060bc8d8346efbf674f3eed17bdf_38077_38228_11 because 100 fetches already executing, max 100. │\r\n│ GET_PART    │ Not executing fetch of part 2a5a060bc8d8346efbf674f3eed17bdf_38229_38340_12 because 100 fetches already executing, max 100. │\r\n│ GET_PART    │ Not executing fetch of part 2c0e980bbfd1fdb8af4c5d604a1e5e55_0_1531_4 because 100 fetches already executing, max 100.       │\r\n│ GET_PART    │ Not executing fetch of part 2c0e980bbfd1fdb8af4c5d604a1e5e55_1532_9797_5 because 100 fetches already executing, max 100.    │\r\n│ GET_PART    │ Not executing fetch of part 372e3239d8e7762bd0d3fc181280982a_4380_16635_21 because 100 fetches already executing, max 100.  │\r\n│ GET_PART    │ Not executing fetch of part 2c0e980bbfd1fdb8af4c5d604a1e5e55_76753_78918_19 because 100 fetches already executing, max 100. │\r\n│ GET_PART    │ Not executing fetch of part 2c0e980bbfd1fdb8af4c5d604a1e5e55_9798_28812_11 because 100 fetches already executing, max 100.  │\r\n│ GET_PART    │ Not executing fetch of part 2c0e980bbfd1fdb8af4c5d604a1e5e55_28813_38668_14 because 100 fetches already executing, max 100. │\r\n│ GET_PART    │ Not executing fetch of part 5f0c971c5abeed1718ad4ad19680cff6_0_5345_5 because 100 fetches already executing, max 100.       │\r\n│ GET_PART    │ Not executing fetch of part 2c0e980bbfd1fdb8af4c5d604a1e5e55_38669_48569_14 because 100 fetches already executing, max 100. │\r\n│ GET_PART    │ Not executing fetch of part 2c0e980bbfd1fdb8af4c5d604a1e5e55_48570_58349_18 because 100 fetches already executing, max 100. │\r\n│ GET_PART    │ Not executing fetch of part 2c0e980bbfd1fdb8af4c5d604a1e5e55_58350_67365_18 because 100 fetches already executing, max 100. │\r\n│ GET_PART    │ Not executing fetch of part 2c0e980bbfd1fdb8af4c5d604a1e5e55_67366_72557_23 because 100 fetches already executing, max 100. │\r\n│ GET_PART    │ Not executing fetch of part 2c0e980bbfd1fdb8af4c5d604a1e5e55_78919_79011_12 because 100 fetches already executing, max 100. │\r\n│ GET_PART    │ Not executing fetch of part 8c632e3f2c2f614aa76bb171dc3cbd9e_13728_13751_5 because 100 fetches already executing, max 100.  │\r\n│ GET_PART    │ Not executing fetch of part 2c0e980bbfd1fdb8af4c5d604a1e5e55_79012_79079_14 because 100 fetches already executing, max 100. │\r\n│ GET_PART    │ Not executing fetch of part 94c06e95fdd8429401cb9fbe534a191d_83284_83284_0 because 100 fetches already executing, max 100.  │\r\n│ GET_PART    │ Not executing fetch of part 2c0e980bbfd1fdb8af4c5d604a1e5e55_79080_79084_1 because 100 fetches already executing, max 100.  │\r\n│ GET_PART    │ Not executing fetch of part 2c6dc0dcff59357163cb4be83dc5f286_0_3916_6 because 100 fetches already executing, max 100.       │\r\n│ GET_PART    │ Not executing fetch of part cfb4249273daf481870905aae74e24b4_5412_5412_0 because 100 fetches already executing, max 100.    │\r\n│ GET_PART    │ Not executing fetch of part 4f724746b2e005886f8ffc0eb82ada8d_85169_85169_0 because 100 fetches already executing, max 100.  │\r\n│ GET_PART    │ Not executing fetch of part 6bdaf2348020ba98543b409720df4282_82035_87359_20 because 100 fetches already executing, max 100. │\r\n│ GET_PART    │ Not executing fetch of part 2c6dc0dcff59357163cb4be83dc5f286_3917_7752_11 because 100 fetches already executing, max 100.   │\r\n│ GET_PART    │ Not executing fetch of part 2c6dc0dcff59357163cb4be83dc5f286_7753_9618_12 because 100 fetches already executing, max 100.   │\r\n│ GET_PART    │ Not executing fetch of part 57b9dab726e1876e2d23399af8615e01_9684_9684_0 because 100 fetches already executing, max 100.    │\r\n│ GET_PART    │ Not executing fetch of part 2c6dc0dcff59357163cb4be83dc5f286_9619_15211_15 because 100 fetches already executing, max 100.  │\r\n│ GET_PART    │ Not executing fetch of part e38b7ed040737de29a8d8b6e1735531b_0_3657_5 because 100 fetches already executing, max 100.       │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ GET_PART    │ Not executing fetch of part 2c6dc0dcff59357163cb4be83dc5f286_21376_21376_0 because 100 fetches already executing, max 100.  │\r\n│ GET_PART    │ Not executing fetch of part 3a5fb2670d9e5d4b0f5395c5a4bf62eb_6736_8906_4 because 100 fetches already executing, max 100.    │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ GET_PART    │ Not executing fetch of part 2c6dc0dcff59357163cb4be83dc5f286_21377_21377_0 because 100 fetches already executing, max 100.  │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ GET_PART    │ Not executing fetch of part 82ea87233ff8a311f0858f92633580d8_1583_9199_5 because 100 fetches already executing, max 100.    │\r\n│ GET_PART    │ Not executing fetch of part 3a5fb2670d9e5d4b0f5395c5a4bf62eb_10653_19810_8 because 100 fetches already executing, max 100.  │\r\n│ GET_PART    │ Not executing fetch of part 36ef23adec8a77f1a8cedf716e3deeab_9517_23237_10 because 100 fetches already executing, max 100.  │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ GET_PART    │ Not executing fetch of part 6c7b1781be764d6d4de2331da6029577_5436_35308_17 because 100 fetches already executing, max 100.  │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ GET_PART    │ Not executing fetch of part 2c6dc0dcff59357163cb4be83dc5f286_20554_20822_13 because 100 fetches already executing, max 100. │\r\n│ GET_PART    │ Not executing fetch of part 2c6dc0dcff59357163cb4be83dc5f286_20823_21093_15 because 100 fetches already executing, max 100. │\r\n│ GET_PART    │ Not executing fetch of part 2c6dc0dcff59357163cb4be83dc5f286_21094_21352_16 because 100 fetches already executing, max 100. │\r\n│ GET_PART    │ Not executing fetch of part 2f0285e98a4f0452d6ce4b54593ee047_0_3817_5 because 100 fetches already executing, max 100.       │\r\n│ GET_PART    │ Not executing fetch of part 2f0285e98a4f0452d6ce4b54593ee047_19244_47966_27 because 100 fetches already executing, max 100. │\r\n│ GET_PART    │ Not executing fetch of part 2f0285e98a4f0452d6ce4b54593ee047_47967_52740_30 because 100 fetches already executing, max 100. │\r\n│ GET_PART    │ Not executing fetch of part 2f0285e98a4f0452d6ce4b54593ee047_52741_54823_30 because 100 fetches already executing, max 100. │\r\n│ GET_PART    │ Not executing fetch of part 2f0285e98a4f0452d6ce4b54593ee047_54824_55500_30 because 100 fetches already executing, max 100. │\r\n│ GET_PART    │ Not executing fetch of part 2f0285e98a4f0452d6ce4b54593ee047_55501_55566_14 because 100 fetches already executing, max 100. │\r\n│ GET_PART    │ Not executing fetch of part f9794e6454a7ce1de6beff20a1553a54_0_8139_6 because 100 fetches already executing, max 100.       │\r\n│ GET_PART    │ Not executing fetch of part 2f9a26f355b8ff50b8c60744a481e263_246_4547_5 because 100 fetches already executing, max 100.     │\r\n│ GET_PART    │ Not executing fetch of part 2f9a26f355b8ff50b8c60744a481e263_4548_14934_10 because 100 fetches already executing, max 100.  │\r\n│ GET_PART    │ Not executing fetch of part 2f9a26f355b8ff50b8c60744a481e263_14935_19104_10 because 100 fetches already executing, max 100. │\r\n│ GET_PART    │ Not executing fetch of part 2f9a26f355b8ff50b8c60744a481e263_19105_24793_12 because 100 fetches already executing, max 100. │\r\n│ GET_PART    │ Not executing fetch of part 64acf5b9a1c62b58d33479c2149d5cd7_81698_81698_0 because 100 fetches already executing, max 100.  │\r\n│ GET_PART    │ Not executing fetch of part ef3fd12ff4260892498e4a9bb0d29ae9_31811_31811_0 because 100 fetches already executing, max 100.  │\r\n│ GET_PART    │ Not executing fetch of part 2f9a26f355b8ff50b8c60744a481e263_37759_38499_12 because 100 fetches already executing, max 100. │\r\n│ GET_PART    │ Not executing fetch of part 2f9a26f355b8ff50b8c60744a481e263_38500_38803_11 because 100 fetches already executing, max 100. │\r\n│ GET_PART    │ Not executing fetch of part 57b9dab726e1876e2d23399af8615e01_9699_9699_0 because 100 fetches already executing, max 100.    │\r\n│ GET_PART    │ Not executing fetch of part 2f9a26f355b8ff50b8c60744a481e263_38804_39060_11 because 100 fetches already executing, max 100. │\r\n│ GET_PART    │ Not executing fetch of part d4d527ac8de0e37c931204aea3602ddf_39330_39330_0 because 100 fetches already executing, max 100.  │\r\n│ GET_PART    │ Not executing fetch of part 2fb895f242a65ff779f63f049b9f009b_0_7976_5 because 100 fetches already executing, max 100.       │\r\n│ GET_PART    │ Not executing fetch of part 2fb895f242a65ff779f63f049b9f009b_7977_9867_4 because 100 fetches already executing, max 100.    │\r\n│ GET_PART    │ Not executing fetch of part cfb4249273daf481870905aae74e24b4_5736_5736_0 because 100 fetches already executing, max 100.    │\r\n│ GET_PART    │ Not executing fetch of part 14608a93af7bce833dc14b58443b1361_24076_24076_0 because 100 fetches already executing, max 100.  │\r\n│ GET_PART    │ Not executing fetch of part 2a5a060bc8d8346efbf674f3eed17bdf_38351_38351_0 because 100 fetches already executing, max 100.  │\r\n│ GET_PART    │ Not executing fetch of part 2a5a060bc8d8346efbf674f3eed17bdf_38352_38352_0 because 100 fetches already executing, max 100.  │\r\n│ GET_PART    │ Not executing fetch of part 2fb895f242a65ff779f63f049b9f009b_9868_12711_7 because 100 fetches already executing, max 100.   │\r\n│ GET_PART    │ Not executing fetch of part 2fb895f242a65ff779f63f049b9f009b_80526_85287_13 because 100 fetches already executing, max 100. │\r\n│ GET_PART    │ Not executing fetch of part 2fb895f242a65ff779f63f049b9f009b_12712_21871_8 because 100 fetches already executing, max 100.  │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ GET_PART    │ Not executing fetch of part bd6e4d898eed9a29758df70384f708d3_46653_46890_23 because 100 fetches already executing, max 100. │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ GET_PART    │ Not executing fetch of part a142e1fcfa64281b9c98774a2b55a48f_1676_3096_4 because 100 fetches already executing, max 100.    │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ GET_PART    │ Not executing fetch of part 6587072160b5b96ada051399848bd5bc_21597_21599_1 because 100 fetches already executing, max 100.  │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ GET_PART    │ Not executing fetch of part 288ddfe71265204f3782e75f2a2572c7_4845_6804_4 because 100 fetches already executing, max 100.    │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ MERGE_PARTS │                                                                                                                             │\r\n│ GET_PART    │ Not executing fetch of part 6bdaf2348020ba98543b409720df4282_18077_36732_12 because 100 fetches already executing, max 100. │\r\n│ GET_PART    │ Not executing fetch of part 1e4b213a5ba4f34f857500023405abf0_24623_26881_11 because 100 fetches already executing, max 100. │\r\n│ GET_PART    │ Not executing fetch of part 0cf001c9729e7f54d3d6ddc81e41c45b_8379_10352_6 because 100 fetches already executing, max 100.   │\r\n│ GET_PART    │ Not executing fetch of part 5955ab8f84329abba770c1b70eb4c27d_0_1505_4 because 100 fetches already executing, max 100.       │\r\n│ GET_PART    │ Not executing fetch of part f6e9e1e68d07d5ebe29c2f5351e1b775_21806_21806_0 because 100 fetches already executing, max 100.  │\r\n│ GET_PART    │ Not executing fetch of part 21fb30adf1eb403d421aa7d0ec89f2fb_53642_54056_23 because 100 fetches already executing, max 100. │\r\n│ GET_PART    │ Not executing fetch of part 0de2376a776ff37ed7de8f35f207347b_10251_10251_0 because 100 fetches already executing, max 100.  │\r\n│ GET_PART    │ Not executing fetch of part ca338bc7ee39836a2b1d230e64d534f2_48185_51854_21 because 100 fetches already executing, max 100. │\r\n│ GET_PART    │ Not executing fetch of part 57b9dab726e1876e2d23399af8615e01_11430_11430_0 because 100 fetches already executing, max 100.  │\r\n│ GET_PART    │ Not executing fetch of part 64acf5b9a1c62b58d33479c2149d5cd7_44759_50133_17 because 100 fetches already executing, max 100. │\r\n│ GET_PART    │ Not executing fetch of part cfb4249273daf481870905aae74e24b4_6442_6449_1 because 100 fetches already executing, max 100.    │\r\n│ GET_PART    │ Not executing fetch of part 91de3137a1261adbe328293c3993343c_35318_58332_24 because 100 fetches already executing, max 100. │\r\n│ GET_PART    │ Not executing fetch of part 3a5fb2670d9e5d4b0f5395c5a4bf62eb_3090_3413_3 because 100 fetches already executing, max 100.    │\r\n│ GET_PART    │ Not executing fetch of part 13f21c37d149b4e736ea9d6e518e909d_1834_2126_3 because 100 fetches already executing, max 100.    │\r\n│ GET_PART    │ Not executing fetch of part 02850348b657da9d31a0d111e9b782e3_53694_54062_16 because 100 fetches already executing, max 100. │\r\n│ GET_PART    │ Not executing fetch of part 3a5fb2670d9e5d4b0f5395c5a4bf62eb_54758_54758_0 because 100 fetches already executing, max 100.  │\r\n│ GET_PART    │ Not executing fetch of part b63748c8bf324537a977b465409aa65b_63783_64905_18 because 100 fetches already executing, max 100. │\r\n│ GET_PART    │ Not executing fetch of part 94c06e95fdd8429401cb9fbe534a191d_63914_63914_0 because 100 fetches already executing, max 100.  │\r\n│ GET_PART    │ Not executing fetch of part 81bde1dd936ec4269e792db3dbf23693_10327_10327_0 because 100 fetches already executing, max 100.  │\r\n└─────────────┴─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\r\n\r\nhello, I find clickhouse system.replication_queue is blocked\r\nWhat should I do?\r\nplease help me please ...\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29505/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29505/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29504","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29504/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29504/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29504/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29504","id":1010304024,"node_id":"I_kwDOA5dJV848OAQY","number":29504,"title":"Lateral Joins","user":{"login":"thomaspaulgrey","id":77589090,"node_id":"MDQ6VXNlcjc3NTg5MDkw","avatar_url":"https://avatars.githubusercontent.com/u/77589090?v=4","gravatar_id":"","url":"https://api.github.com/users/thomaspaulgrey","html_url":"https://github.com/thomaspaulgrey","followers_url":"https://api.github.com/users/thomaspaulgrey/followers","following_url":"https://api.github.com/users/thomaspaulgrey/following{/other_user}","gists_url":"https://api.github.com/users/thomaspaulgrey/gists{/gist_id}","starred_url":"https://api.github.com/users/thomaspaulgrey/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/thomaspaulgrey/subscriptions","organizations_url":"https://api.github.com/users/thomaspaulgrey/orgs","repos_url":"https://api.github.com/users/thomaspaulgrey/repos","events_url":"https://api.github.com/users/thomaspaulgrey/events{/privacy}","received_events_url":"https://api.github.com/users/thomaspaulgrey/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":1357578153,"node_id":"MDU6TGFiZWwxMzU3NTc4MTUz","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-joins","name":"comp-joins","color":"b5bcff","default":false,"description":"JOINs"},{"id":2121848770,"node_id":"MDU6TGFiZWwyMTIxODQ4Nzcw","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-sql","name":"comp-sql","color":"b5bcff","default":false,"description":"General SQL support"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-09-28T23:23:59Z","updated_at":"2021-09-29T11:57:59Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"> (you don't have to strictly follow this form)\r\n\r\nLateral joins are fantastic for workloads primarily used in ClickHouse environments: time-series/logs/analytics/etc. that trace the history of an object's values throughout time\r\n\r\nin particular, lateral joins make writing correlated subqueries far easier\r\n\r\n```\r\nSELECT * FROM (\r\n  SELECT DISTINCT ON (ID) *\r\n  WHERE ID = ANY($1)\r\n  FROM PRICES \r\n  ORDER BY ID, TIMESTAMP DESC\r\n) PRICE LEFT JOIN LATERAL (\r\n   ..... other info\r\n) LEFT JOIN LATERAL (\r\n   ..... other info\r\n)\r\n```\r\n\r\n> A clear and concise description of what is the intended usage scenario is.\r\n\r\nSupport for lateral joins\r\n\r\nWhy not use normal joins? It will duplicate rows during join process before filtering on distinct at the end, causing major performance degradation ","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29504/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29504/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29496","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29496/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29496/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29496/events","html_url":"https://github.com/ClickHouse/ClickHouse/pull/29496","id":1010107458,"node_id":"PR_kwDOA5dJV84saTAD","number":29496,"title":"Negative LIMIT specification","user":{"login":"Joeywzr","id":37319050,"node_id":"MDQ6VXNlcjM3MzE5MDUw","avatar_url":"https://avatars.githubusercontent.com/u/37319050?v=4","gravatar_id":"","url":"https://api.github.com/users/Joeywzr","html_url":"https://github.com/Joeywzr","followers_url":"https://api.github.com/users/Joeywzr/followers","following_url":"https://api.github.com/users/Joeywzr/following{/other_user}","gists_url":"https://api.github.com/users/Joeywzr/gists{/gist_id}","starred_url":"https://api.github.com/users/Joeywzr/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Joeywzr/subscriptions","organizations_url":"https://api.github.com/users/Joeywzr/orgs","repos_url":"https://api.github.com/users/Joeywzr/repos","events_url":"https://api.github.com/users/Joeywzr/events{/privacy}","received_events_url":"https://api.github.com/users/Joeywzr/received_events","type":"User","site_admin":false},"labels":[{"id":1309674771,"node_id":"MDU6TGFiZWwxMzA5Njc0Nzcx","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/pr-feature","name":"pr-feature","color":"007700","default":false,"description":"Pull request with new product feature"},{"id":1807683251,"node_id":"MDU6TGFiZWwxODA3NjgzMjUx","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/doc-alert","name":"doc-alert","color":"e51068","default":false,"description":"PR where any documentation work is needed or proceeded"}],"state":"open","locked":false,"assignee":{"login":"Avogar","id":48961922,"node_id":"MDQ6VXNlcjQ4OTYxOTIy","avatar_url":"https://avatars.githubusercontent.com/u/48961922?v=4","gravatar_id":"","url":"https://api.github.com/users/Avogar","html_url":"https://github.com/Avogar","followers_url":"https://api.github.com/users/Avogar/followers","following_url":"https://api.github.com/users/Avogar/following{/other_user}","gists_url":"https://api.github.com/users/Avogar/gists{/gist_id}","starred_url":"https://api.github.com/users/Avogar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Avogar/subscriptions","organizations_url":"https://api.github.com/users/Avogar/orgs","repos_url":"https://api.github.com/users/Avogar/repos","events_url":"https://api.github.com/users/Avogar/events{/privacy}","received_events_url":"https://api.github.com/users/Avogar/received_events","type":"User","site_admin":false},"assignees":[{"login":"Avogar","id":48961922,"node_id":"MDQ6VXNlcjQ4OTYxOTIy","avatar_url":"https://avatars.githubusercontent.com/u/48961922?v=4","gravatar_id":"","url":"https://api.github.com/users/Avogar","html_url":"https://github.com/Avogar","followers_url":"https://api.github.com/users/Avogar/followers","following_url":"https://api.github.com/users/Avogar/following{/other_user}","gists_url":"https://api.github.com/users/Avogar/gists{/gist_id}","starred_url":"https://api.github.com/users/Avogar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Avogar/subscriptions","organizations_url":"https://api.github.com/users/Avogar/orgs","repos_url":"https://api.github.com/users/Avogar/repos","events_url":"https://api.github.com/users/Avogar/events{/privacy}","received_events_url":"https://api.github.com/users/Avogar/received_events","type":"User","site_admin":false}],"milestone":null,"comments":5,"created_at":"2021-09-28T19:07:02Z","updated_at":"2021-12-23T04:48:04Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"draft":true,"pull_request":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/pulls/29496","html_url":"https://github.com/ClickHouse/ClickHouse/pull/29496","diff_url":"https://github.com/ClickHouse/ClickHouse/pull/29496.diff","patch_url":"https://github.com/ClickHouse/ClickHouse/pull/29496.patch","merged_at":null},"body":"Changelog category (leave one):\r\n- New Feature\r\n\r\n\r\nChangelog entry (a user-readable short description of the changes that goes to CHANGELOG.md):\r\nAdded Negative LIMIT specification. And it can be combined with negative offset (but not with positive offset).\r\n\r\n\r\nDetailed description / Documentation draft:\r\n#28913\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29496/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29496/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29493","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29493/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29493/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29493/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29493","id":1010036047,"node_id":"I_kwDOA5dJV848M-1P","number":29493,"title":"when does write to s3 happens while perform_ttl_move_on_insert is set to 0?","user":{"login":"gauravphoenix","id":627662,"node_id":"MDQ6VXNlcjYyNzY2Mg==","avatar_url":"https://avatars.githubusercontent.com/u/627662?v=4","gravatar_id":"","url":"https://api.github.com/users/gauravphoenix","html_url":"https://github.com/gauravphoenix","followers_url":"https://api.github.com/users/gauravphoenix/followers","following_url":"https://api.github.com/users/gauravphoenix/following{/other_user}","gists_url":"https://api.github.com/users/gauravphoenix/gists{/gist_id}","starred_url":"https://api.github.com/users/gauravphoenix/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/gauravphoenix/subscriptions","organizations_url":"https://api.github.com/users/gauravphoenix/orgs","repos_url":"https://api.github.com/users/gauravphoenix/repos","events_url":"https://api.github.com/users/gauravphoenix/events{/privacy}","received_events_url":"https://api.github.com/users/gauravphoenix/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-09-28T17:44:24Z","updated_at":"2021-09-28T17:44:24Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Per [this](https://altinity.com/blog/clickhouse-and-s3-compatible-object-storage)  blog, the setting \r\n```xml\r\n<perform_ttl_move_on_insert>0</perform_ttl_move_on_insert>\r\n```\r\ncauses- \r\n> TTL moves to the corresponding volume are executed in the background.\r\n\r\nI would like to know how often (time interval) does CH performs background writes to s3? and is it configurable? \r\nalso, for monitoring purposes, where can I see what all data is pending write to s3? ","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29493/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29493/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29486","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29486/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29486/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29486/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29486","id":1009779378,"node_id":"I_kwDOA5dJV848MAKy","number":29486,"title":"Segfault in SettingsProfilesCache","user":{"login":"tavplubix","id":14847450,"node_id":"MDQ6VXNlcjE0ODQ3NDUw","avatar_url":"https://avatars.githubusercontent.com/u/14847450?v=4","gravatar_id":"","url":"https://api.github.com/users/tavplubix","html_url":"https://github.com/tavplubix","followers_url":"https://api.github.com/users/tavplubix/followers","following_url":"https://api.github.com/users/tavplubix/following{/other_user}","gists_url":"https://api.github.com/users/tavplubix/gists{/gist_id}","starred_url":"https://api.github.com/users/tavplubix/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tavplubix/subscriptions","organizations_url":"https://api.github.com/users/tavplubix/orgs","repos_url":"https://api.github.com/users/tavplubix/repos","events_url":"https://api.github.com/users/tavplubix/events{/privacy}","received_events_url":"https://api.github.com/users/tavplubix/received_events","type":"User","site_admin":false},"labels":[{"id":1955634273,"node_id":"MDU6TGFiZWwxOTU1NjM0Mjcz","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/testing","name":"testing","color":"c9a224","default":false,"description":"Special issue with list of bugs found by CI"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-09-28T13:47:56Z","updated_at":"2021-10-18T10:18:54Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"https://clickhouse-test-reports.s3.yandex.net/0/ddb0849cdefcde31fb2ba5a3e300ff1f6146454f/stress_test_(debug).html#fail1\r\n\r\n```\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.28 13:41:35.083014 [ 17186 ] {} <Fatal> BaseDaemon: ########################################\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.28 13:41:35.097461 [ 17186 ] {} <Fatal> BaseDaemon: (version 21.11.1.8229 (official build), build id: 9455F3E74FB199B35383F5EB50E62FCD6D1F9181) (from thread 15622) (query_id: af8463de-764e-4714-9a4a-e352c356f13d) Received signal Segmentation fault (11)\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.28 13:41:35.108159 [ 17186 ] {} <Fatal> BaseDaemon: Address: 0x168 Access: read. Address not mapped to object.\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.28 13:41:35.119754 [ 17186 ] {} <Fatal> BaseDaemon: Stack trace: 0x1d9b3717 0x1d9b2fa1 0x1d9b1297 0x1d7f5644 0x1d853a32 0x1d858e78 0x1d858e12 0x1d858dd2 0x1d858d8d 0x1d858d55 0x1d8cb3db 0x1d8cb2ad 0x1d8ca04a 0x1d8c9f9d 0x1d8c9f5d 0x1d8c9f35 0x1d8c9f00 0x133846c6 0x133837b5 0x1d801697 0x1d8015d9 0x1d966374 0x1d966cfc 0x1d966c07 0x1d966ba7 0x1d966b42 0x1d966aed 0x1d8f0df0 0x1d8ef282 0x1d8ebd6d 0x1d8a51f8 0x1d8a51bd 0x1d8a2f95 0x1d8a2ec0 0x1d8eacde 0x1d920cfa 0x1d8ee95d 0x1d8eb355 0x1d8eb29b 0x1e4ea7bc 0x1e4ea483\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.28 13:41:36.146492 [ 17186 ] {} <Fatal> BaseDaemon: 4. ./obj-x86_64-linux-gnu/../contrib/libcxx/include/vector:1405: std::__1::vector<DB::SettingsProfileElement, std::__1::allocator<DB::SettingsProfileElement> >::operator=(std::__1::vector<DB::SettingsProfileElement, std::__1::allocator<DB::SettingsProfileElement> > const&) @ 0x1d9b3717 in /usr/bin/clickhouse\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.28 13:41:37.018643 [ 17186 ] {} <Fatal> BaseDaemon: 5. ./obj-x86_64-linux-gnu/../src/Access/SettingsProfileElement.h:49: DB::SettingsProfileElements::operator=(DB::SettingsProfileElements const&) @ 0x1d9b2fa1 in /usr/bin/clickhouse\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.28 13:41:37.666107 [ 17186 ] {} <Fatal> BaseDaemon: 6. ./obj-x86_64-linux-gnu/../src/Access/SettingsProfilesCache.cpp:198: DB::SettingsProfilesCache::getEnabledSettings(StrongTypedef<wide::integer<128ul, unsigned int>, DB::UUIDTag> const&, DB::SettingsProfileElements const&, boost::container::flat_set<StrongTypedef<wide::integer<128ul, unsigned int>, DB::UUIDTag>, std::__1::less<StrongTypedef<wide::integer<128ul, unsigned int>, DB::UUIDTag> >, void> const&, DB::SettingsProfileElements const&) @ 0x1d9b1297 in /usr/bin/clickhouse\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.28 13:41:38.147491 [ 17186 ] {} <Fatal> BaseDaemon: 7. ./obj-x86_64-linux-gnu/../src/Access/AccessControlManager.cpp:511: DB::AccessControlManager::getEnabledSettings(StrongTypedef<wide::integer<128ul, unsigned int>, DB::UUIDTag> const&, DB::SettingsProfileElements const&, boost::container::flat_set<StrongTypedef<wide::integer<128ul, unsigned int>, DB::UUIDTag>, std::__1::less<StrongTypedef<wide::integer<128ul, unsigned int>, DB::UUIDTag> >, void> const&, DB::SettingsProfileElements const&) const @ 0x1d7f5644 in /usr/bin/clickhouse\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.28 13:41:38.887004 [ 17186 ] {} <Fatal> BaseDaemon: 8. ./obj-x86_64-linux-gnu/../src/Access/ContextAccess.cpp:216: DB::ContextAccess::setRolesInfo(std::__1::shared_ptr<DB::EnabledRolesInfo const> const&) const @ 0x1d853a32 in /usr/bin/clickhouse\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.28 13:41:39.792304 [ 17186 ] {} <Fatal> BaseDaemon: 9. ./obj-x86_64-linux-gnu/../src/Access/ContextAccess.cpp:201: DB::ContextAccess::setUser(std::__1::shared_ptr<DB::User const> const&) const::$_1::operator()(std::__1::shared_ptr<DB::EnabledRolesInfo const> const&) const @ 0x1d858e78 in /usr/bin/clickhouse\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.28 13:41:40.568475 [ 17186 ] {} <Fatal> BaseDaemon: 10. ./obj-x86_64-linux-gnu/../contrib/libcxx/include/type_traits:3676: decltype(std::__1::forward<DB::ContextAccess::setUser(std::__1::shared_ptr<DB::User const> const&) const::$_1&>(fp)(std::__1::forward<std::__1::shared_ptr<DB::EnabledRolesInfo const> const&>(fp0))) std::__1::__invoke<DB::ContextAccess::setUser(std::__1::shared_ptr<DB::User const> const&) const::$_1&, std::__1::shared_ptr<DB::EnabledRolesInfo const> const&>(DB::ContextAccess::setUser(std::__1::shared_ptr<DB::User const> const&) const::$_1&, std::__1::shared_ptr<DB::EnabledRolesInfo const> const&) @ 0x1d858e12 in /usr/bin/clickhouse\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.28 13:41:43.076507 [ 17186 ] {} <Fatal> BaseDaemon: 11. ./obj-x86_64-linux-gnu/../contrib/libcxx/include/__functional_base:349: void std::__1::__invoke_void_return_wrapper<void>::__call<DB::ContextAccess::setUser(std::__1::shared_ptr<DB::User const> const&) const::$_1&, std::__1::shared_ptr<DB::EnabledRolesInfo const> const&>(DB::ContextAccess::setUser(std::__1::shared_ptr<DB::User const> const&) const::$_1&, std::__1::shared_ptr<DB::EnabledRolesInfo const> const&) @ 0x1d858dd2 in /usr/bin/clickhouse\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.28 13:41:43.684539 [ 17186 ] {} <Fatal> BaseDaemon: 12. ./obj-x86_64-linux-gnu/../contrib/libcxx/include/functional:1608: std::__1::__function::__default_alloc_func<DB::ContextAccess::setUser(std::__1::shared_ptr<DB::User const> const&) const::$_1, void (std::__1::shared_ptr<DB::EnabledRolesInfo const> const&)>::operator()(std::__1::shared_ptr<DB::EnabledRolesInfo const> const&) @ 0x1d858d8d in /usr/bin/clickhouse\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.28 13:41:44.517152 [ 17186 ] {} <Fatal> BaseDaemon: 13. ./obj-x86_64-linux-gnu/../contrib/libcxx/include/functional:2089: void std::__1::__function::__policy_invoker<void (std::__1::shared_ptr<DB::EnabledRolesInfo const> const&)>::__call_impl<std::__1::__function::__default_alloc_func<DB::ContextAccess::setUser(std::__1::shared_ptr<DB::User const> const&) const::$_1, void (std::__1::shared_ptr<DB::EnabledRolesInfo const> const&)> >(std::__1::__function::__policy_storage const*, std::__1::shared_ptr<DB::EnabledRolesInfo const> const&) @ 0x1d858d55 in /usr/bin/clickhouse\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.28 13:41:44.835258 [ 17186 ] {} <Fatal> BaseDaemon: 14. ./obj-x86_64-linux-gnu/../contrib/libcxx/include/functional:2221: std::__1::__function::__policy_func<void (std::__1::shared_ptr<DB::EnabledRolesInfo const> const&)>::operator()(std::__1::shared_ptr<DB::EnabledRolesInfo const> const&) const @ 0x1d8cb3db in /usr/bin/clickhouse\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.28 13:41:45.199124 [ 17186 ] {} <Fatal> BaseDaemon: 15. ./obj-x86_64-linux-gnu/../contrib/libcxx/include/functional:2560: std::__1::function<void (std::__1::shared_ptr<DB::EnabledRolesInfo const> const&)>::operator()(std::__1::shared_ptr<DB::EnabledRolesInfo const> const&) const @ 0x1d8cb2ad in /usr/bin/clickhouse\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.28 13:41:45.381274 [ 17186 ] {} <Fatal> BaseDaemon: 16. ./obj-x86_64-linux-gnu/../src/Access/EnabledRoles.cpp:51: DB::EnabledRoles::setRolesInfo(std::__1::shared_ptr<DB::EnabledRolesInfo const> const&, basic_scope_guard<std::__1::function<void ()> >&)::$_1::operator()() const @ 0x1d8ca04a in /usr/bin/clickhouse\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.28 13:41:45.675240 [ 17186 ] {} <Fatal> BaseDaemon: 17. ./obj-x86_64-linux-gnu/../contrib/libcxx/include/type_traits:3676: decltype(std::__1::forward<DB::EnabledRoles::setRolesInfo(std::__1::shared_ptr<DB::EnabledRolesInfo const> const&, basic_scope_guard<std::__1::function<void ()> >&)::$_1&>(fp)()) std::__1::__invoke<DB::EnabledRoles::setRolesInfo(std::__1::shared_ptr<DB::EnabledRolesInfo const> const&, basic_scope_guard<std::__1::function<void ()> >&)::$_1&>(DB::EnabledRoles::setRolesInfo(std::__1::shared_ptr<DB::EnabledRolesInfo const> const&, basic_scope_guard<std::__1::function<void ()> >&)::$_1&) @ 0x1d8c9f9d in /usr/bin/clickhouse\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.28 13:41:45.906425 [ 17186 ] {} <Fatal> BaseDaemon: 18. ./obj-x86_64-linux-gnu/../contrib/libcxx/include/__functional_base:349: void std::__1::__invoke_void_return_wrapper<void>::__call<DB::EnabledRoles::setRolesInfo(std::__1::shared_ptr<DB::EnabledRolesInfo const> const&, basic_scope_guard<std::__1::function<void ()> >&)::$_1&>(DB::EnabledRoles::setRolesInfo(std::__1::shared_ptr<DB::EnabledRolesInfo const> const&, basic_scope_guard<std::__1::function<void ()> >&)::$_1&) @ 0x1d8c9f5d in /usr/bin/clickhouse\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.28 13:41:46.129610 [ 17186 ] {} <Fatal> BaseDaemon: 19. ./obj-x86_64-linux-gnu/../contrib/libcxx/include/functional:1608: std::__1::__function::__default_alloc_func<DB::EnabledRoles::setRolesInfo(std::__1::shared_ptr<DB::EnabledRolesInfo const> const&, basic_scope_guard<std::__1::function<void ()> >&)::$_1, void ()>::operator()() @ 0x1d8c9f35 in /usr/bin/clickhouse\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.28 13:41:46.289557 [ 17186 ] {} <Fatal> BaseDaemon: 20. ./obj-x86_64-linux-gnu/../contrib/libcxx/include/functional:2089: void std::__1::__function::__policy_invoker<void ()>::__call_impl<std::__1::__function::__default_alloc_func<DB::EnabledRoles::setRolesInfo(std::__1::shared_ptr<DB::EnabledRolesInfo const> const&, basic_scope_guard<std::__1::function<void ()> >&)::$_1, void ()> >(std::__1::__function::__policy_storage const*) @ 0x1d8c9f00 in /usr/bin/clickhouse\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.28 13:41:46.428923 [ 17186 ] {} <Fatal> BaseDaemon: 21. ./obj-x86_64-linux-gnu/../contrib/libcxx/include/functional:2221: std::__1::__function::__policy_func<void ()>::operator()() const @ 0x133846c6 in /usr/bin/clickhouse\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.28 13:41:46.626952 [ 17186 ] {} <Fatal> BaseDaemon: 22. ./obj-x86_64-linux-gnu/../contrib/libcxx/include/functional:2560: std::__1::function<void ()>::operator()() const @ 0x133837b5 in /usr/bin/clickhouse\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.28 13:41:47.271882 [ 17186 ] {} <Fatal> BaseDaemon: 23. ./obj-x86_64-linux-gnu/../base/common/../common/scope_guard.h:95: basic_scope_guard<std::__1::function<void ()> >::invoke() @ 0x1d801697 in /usr/bin/clickhouse\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.28 13:41:48.042627 [ 17186 ] {} <Fatal> BaseDaemon: 24. ./obj-x86_64-linux-gnu/../base/common/../common/scope_guard.h:44: basic_scope_guard<std::__1::function<void ()> >::~basic_scope_guard() @ 0x1d8015d9 in /usr/bin/clickhouse\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.28 13:41:48.466651 [ 17186 ] {} <Fatal> BaseDaemon: 25. ./obj-x86_64-linux-gnu/../src/Access/RoleCache.cpp:182: DB::RoleCache::roleRemoved(StrongTypedef<wide::integer<128ul, unsigned int>, DB::UUIDTag> const&) @ 0x1d966374 in /usr/bin/clickhouse\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.28 13:41:49.203446 [ 17186 ] {} <Fatal> BaseDaemon: 26. ./obj-x86_64-linux-gnu/../src/Access/RoleCache.cpp:143: DB::RoleCache::getRole(StrongTypedef<wide::integer<128ul, unsigned int>, DB::UUIDTag> const&)::$_1::operator()(StrongTypedef<wide::integer<128ul, unsigned int>, DB::UUIDTag> const&, std::__1::shared_ptr<DB::IAccessEntity const> const&) const @ 0x1d966cfc in /usr/bin/clickhouse\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.28 13:41:49.671487 [ 17186 ] {} <Fatal> BaseDaemon: 27. ./obj-x86_64-linux-gnu/../contrib/libcxx/include/type_traits:3676: decltype(std::__1::forward<DB::RoleCache::getRole(StrongTypedef<wide::integer<128ul, unsigned int>, DB::UUIDTag> const&)::$_1&>(fp)(std::__1::forward<StrongTypedef<wide::integer<128ul, unsigned int>, DB::UUIDTag> const&>(fp0), std::__1::forward<std::__1::shared_ptr<DB::IAccessEntity const> const&>(fp0))) std::__1::__invoke<DB::RoleCache::getRole(StrongTypedef<wide::integer<128ul, unsigned int>, DB::UUIDTag> const&)::$_1&, StrongTypedef<wide::integer<128ul, unsigned int>, DB::UUIDTag> const&, std::__1::shared_ptr<DB::IAccessEntity const> const&>(DB::RoleCache::getRole(StrongTypedef<wide::integer<128ul, unsigned int>, DB::UUIDTag> const&)::$_1&, StrongTypedef<wide::integer<128ul, unsigned int>, DB::UUIDTag> const&, std::__1::shared_ptr<DB::IAccessEntity const> const&) @ 0x1d966c07 in /usr/bin/clickhouse\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.28 13:41:50.353628 [ 17186 ] {} <Fatal> BaseDaemon: 28. ./obj-x86_64-linux-gnu/../contrib/libcxx/include/__functional_base:349: void std::__1::__invoke_void_return_wrapper<void>::__call<DB::RoleCache::getRole(StrongTypedef<wide::integer<128ul, unsigned int>, DB::UUIDTag> const&)::$_1&, StrongTypedef<wide::integer<128ul, unsigned int>, DB::UUIDTag> const&, std::__1::shared_ptr<DB::IAccessEntity const> const&>(DB::RoleCache::getRole(StrongTypedef<wide::integer<128ul, unsigned int>, DB::UUIDTag> const&)::$_1&, StrongTypedef<wide::integer<128ul, unsigned int>, DB::UUIDTag> const&, std::__1::shared_ptr<DB::IAccessEntity const> const&) @ 0x1d966ba7 in /usr/bin/clickhouse\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.28 13:41:50.914661 [ 17186 ] {} <Fatal> BaseDaemon: 29. ./obj-x86_64-linux-gnu/../contrib/libcxx/include/functional:1608: std::__1::__function::__default_alloc_func<DB::RoleCache::getRole(StrongTypedef<wide::integer<128ul, unsigned int>, DB::UUIDTag> const&)::$_1, void (StrongTypedef<wide::integer<128ul, unsigned int>, DB::UUIDTag> const&, std::__1::shared_ptr<DB::IAccessEntity const> const&)>::operator()(StrongTypedef<wide::integer<128ul, unsigned int>, DB::UUIDTag> const&, std::__1::shared_ptr<DB::IAccessEntity const> const&) @ 0x1d966b42 in /usr/bin/clickhouse\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.28 13:41:51.384557 [ 17186 ] {} <Fatal> BaseDaemon: 30. ./obj-x86_64-linux-gnu/../contrib/libcxx/include/functional:2089: void std::__1::__function::__policy_invoker<void (StrongTypedef<wide::integer<128ul, unsigned int>, DB::UUIDTag> const&, std::__1::shared_ptr<DB::IAccessEntity const> const&)>::__call_impl<std::__1::__function::__default_alloc_func<DB::RoleCache::getRole(StrongTypedef<wide::integer<128ul, unsigned int>, DB::UUIDTag> const&)::$_1, void (StrongTypedef<wide::integer<128ul, unsigned int>, DB::UUIDTag> const&, std::__1::shared_ptr<DB::IAccessEntity const> const&)> >(std::__1::__function::__policy_storage const*, StrongTypedef<wide::integer<128ul, unsigned int>, DB::UUIDTag> const&, std::__1::shared_ptr<DB::IAccessEntity const> const&) @ 0x1d966aed in /usr/bin/clickhouse\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.28 13:41:51.738755 [ 17186 ] {} <Fatal> BaseDaemon: 31. ./obj-x86_64-linux-gnu/../contrib/libcxx/include/functional:2221: std::__1::__function::__policy_func<void (StrongTypedef<wide::integer<128ul, unsigned int>, DB::UUIDTag> const&, std::__1::shared_ptr<DB::IAccessEntity const> const&)>::operator()(StrongTypedef<wide::integer<128ul, unsigned int>, DB::UUIDTag> const&, std::__1::shared_ptr<DB::IAccessEntity const> const&) const @ 0x1d8f0df0 in /usr/bin/clickhouse\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.28 13:41:51.908713 [ 17186 ] {} <Fatal> BaseDaemon: 32. ./obj-x86_64-linux-gnu/../contrib/libcxx/include/functional:2560: std::__1::function<void (StrongTypedef<wide::integer<128ul, unsigned int>, DB::UUIDTag> const&, std::__1::shared_ptr<DB::IAccessEntity const> const&)>::operator()(StrongTypedef<wide::integer<128ul, unsigned int>, DB::UUIDTag> const&, std::__1::shared_ptr<DB::IAccessEntity const> const&) const @ 0x1d8ef282 in /usr/bin/clickhouse\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.28 13:41:54.732308 [ 17186 ] {} <Fatal> BaseDaemon: 33. ./obj-x86_64-linux-gnu/../src/Access/IAccessStorage.cpp:438: DB::IAccessStorage::notify(std::__1::vector<std::__1::tuple<std::__1::function<void (StrongTypedef<wide::integer<128ul, unsigned int>, DB::UUIDTag> const&, std::__1::shared_ptr<DB::IAccessEntity const> const&)>, StrongTypedef<wide::integer<128ul, unsigned int>, DB::UUIDTag>, std::__1::shared_ptr<DB::IAccessEntity const> >, std::__1::allocator<std::__1::tuple<std::__1::function<void (StrongTypedef<wide::integer<128ul, unsigned int>, DB::UUIDTag> const&, std::__1::shared_ptr<DB::IAccessEntity const> const&)>, StrongTypedef<wide::integer<128ul, unsigned int>, DB::UUIDTag>, std::__1::shared_ptr<DB::IAccessEntity const> > > > const&) @ 0x1d8ebd6d in /usr/bin/clickhouse\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.28 13:41:56.758918 [ 485 ] {} <Fatal> Application: Child process was terminated by signal 11.\r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29486/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29486/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29457","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29457/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29457/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29457/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29457","id":1008664465,"node_id":"I_kwDOA5dJV848Hv-R","number":29457,"title":"List of lists of datasets","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":785082162,"node_id":"MDU6TGFiZWw3ODUwODIxNjI=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-documentation","name":"comp-documentation","color":"b5bcff","default":false,"description":"Used to run automatic builds of the documentation"},{"id":3360106261,"node_id":"MDU6TGFiZWwzMzYwMTA2MjYx","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/dataset","name":"dataset","color":"00CCCC","default":false,"description":""}],"state":"open","locked":false,"assignee":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"assignees":[{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false}],"milestone":null,"comments":0,"created_at":"2021-09-27T21:49:37Z","updated_at":"2021-09-27T21:50:40Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"Already prepared, ready to use datasets: https://clickhouse.com/docs/en/getting-started/example-datasets/\r\n\r\nDatasets under development to be used in tutorials and research: https://github.com/ClickHouse/ClickHouse/labels/dataset\r\n\r\nhttps://academictorrents.com/\r\n\r\nhttp://files.pushshift.io/\r\n\r\nhttps://zenodo.org/\r\n\r\nhttps://www.dolthub.com/discover\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29457/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29457/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29430","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29430/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29430/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29430/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29430","id":1008114868,"node_id":"I_kwDOA5dJV848Fpy0","number":29430,"title":"Azure Blob Storage Disk support in ClickHouse","user":{"login":"jkuklis","id":23745611,"node_id":"MDQ6VXNlcjIzNzQ1NjEx","avatar_url":"https://avatars.githubusercontent.com/u/23745611?v=4","gravatar_id":"","url":"https://api.github.com/users/jkuklis","html_url":"https://github.com/jkuklis","followers_url":"https://api.github.com/users/jkuklis/followers","following_url":"https://api.github.com/users/jkuklis/following{/other_user}","gists_url":"https://api.github.com/users/jkuklis/gists{/gist_id}","starred_url":"https://api.github.com/users/jkuklis/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jkuklis/subscriptions","organizations_url":"https://api.github.com/users/jkuklis/orgs","repos_url":"https://api.github.com/users/jkuklis/repos","events_url":"https://api.github.com/users/jkuklis/events{/privacy}","received_events_url":"https://api.github.com/users/jkuklis/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2021-09-27T12:55:15Z","updated_at":"2021-09-28T06:44:38Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"Hello!\r\n\r\nWe would like to propose introducing support for Azure Blob Storage Disks in ClickHouse, in a similar way it was done for AWS S3 Disks. At Contentsquare we have already started preliminary work to make sure this is feasible.\r\n\r\n## Context\r\n\r\nWe use S3 Disks in our AWS servers for example for storing raw data or monitoring data loss with certain metadata, for which regular disks would be too expensive. The `DiskS3` approach (and not e.g. `S3Engine` one) is the best for us, as it can be used with `MergeTree`s.\r\n\r\nSoon we will need a similar solution in Azure servers. We decided internally that the best way for us to go would be to develop for Blob Storage Disks the same logic that was developed for S3 Disks.\r\n\r\nNote on alternatives: we considered using DataLake Gen 2, a higher abstraction built on top of Blob Storage to mimic a disk behavior, but it doesn't offer enough flexibility, for example a possibility to do a move operation, which is important for ClickHouse. We also considered using a proxy server to translate commands from S3 to Blob Storage, but it would be too error-prone and inefficient.\r\n\r\n## Work plan\r\n\r\nBelow we present what we think is necessary to add the Blob Storage Disk to ClickHouse:\r\n* Azure SDK dependency\r\n* POCO HTTP wrapper for Azure\r\n* Azure authentication part\r\n* Blob Storage buffer handling\r\n* Blob Storage Disk\r\n* End to end integration tests\r\n\r\n### Azure SDK dependency\r\n\r\nWe managed to add the dependency by:\r\n* adding `azure-sdk-for-cpp` directory and `azure-cmake` directory with custom `CMakeLists.txt` to `contrib`\r\n* linking libraries and adding directories in `src` and `contrib` `CMakeLists.txt` files\r\n* adding Azure Blob Storage `.cmake` to `cmake/find` and including it in the main `CMakeLists.txt` file\r\n* adding a (deprecated) source file to `borignssl-cmake` `CMakeLists.txt`, as one of its functions is used in the Azure SDK\r\n\r\nWe were able to manipulate Blob Storage from within ClickHouse with this configuration.\r\n\r\n### POCO HTTP wrapper for Azure\r\n\r\nThis part is used for communication over the network and interpretation of messages. It would be based on the S3 counterpart, with all its files located in src/IO/S3. The S3 version is quite developed and robust, for the start we could probably implement a simpler solution. We could also extract the common part with S3 and create a parent class for it.\r\n\r\n### Azure authentication part\r\n\r\nFor the start we would like to rely on the role-based authentication, in which authen is granted to an Azure instance as a whole (so there are no credentials or secrets). We have already conducted preliminary tests for this type of authentication, it is an open question whether we can leave it like that for now, as S3 implementation supports more ways to authenticate. For S3, authentication is done in src/IO/S3Common .h and .cpp.\r\n\r\n### Blob Storage buffer handling\r\n\r\nThis part is for actual reading and writing buffers for Blob Storage. For S3, these are implemented in src/IO, in fReadBufferFromS3 and WriteBufferFromS3 .h and .cpp files. It is unclear whether these need to be extracted from the Disk implementation very early on.\r\n\r\n### Blob Storage Disk\r\n\r\nBlob Storage Disk implementation of the IDiskRemote interface, based on the equivalent src/Disk/S3 files. Regarding mutualization of the logic for Blob Storage and S3, on one hand, it might be hard, as the implementations are short and quite Disk-specific, but on the other hand, this part seems to be updated rather frequently, so it might make sense to mutualize the logic to ensure that potential fixes and refactors are applied to both Disks.\r\n\r\n### Integration tests\r\nWe would like to create a couple of end-to-end integration tests on Contentsquare use cases. We aim to run the full Azure pipeline for at least a couple of days to make sure the solution runs smoothly. Functional and unit tests are also considered.\r\n\r\n## Execution\r\n\r\nWe aim to implement this feature on our own at Contentsquare provided that we get a green light from you on the design. We have already started working on this feature and expect it to be ready in the first quarter of 2022.\r\n\r\n## Questions\r\n\r\n* What is your general feeling about adding Azure Disk?\r\n* Can Blob Storage Disk be started in some preliminary form and not be fully announced immediately, or shall it be full-fledged from the very release, in particular:\r\n  + Shall we extract the common part between S3 and Blob Storage in the code?\r\n  + Do we need to provide all authentication methods?\r\n* What kind of tests are we expected to conduct?\r\n* Any suggestions to the dependency part? We are aware of e.g. https://clickhouse.com/docs/en/development/contrib/#adding-third-party-libraries.\r\n* Did we miss any part of the code necessary to be added?\r\n* What is the main reason for having a POCO client for S3 if AWS already provides HTTP clients using e.g. libcurl?\r\n\r\n\\\r\n\\\r\nThanks for attention, let us know what you think!\r\n\r\nJakub Kuklis\r\nContentsquare","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29430/reactions","total_count":2,"+1":2,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29430/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29413","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29413/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29413/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29413/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29413","id":1007983210,"node_id":"I_kwDOA5dJV848FJpq","number":29413,"title":"CI Fest #10","user":{"login":"qoega","id":2159081,"node_id":"MDQ6VXNlcjIxNTkwODE=","avatar_url":"https://avatars.githubusercontent.com/u/2159081?v=4","gravatar_id":"","url":"https://api.github.com/users/qoega","html_url":"https://github.com/qoega","followers_url":"https://api.github.com/users/qoega/followers","following_url":"https://api.github.com/users/qoega/following{/other_user}","gists_url":"https://api.github.com/users/qoega/gists{/gist_id}","starred_url":"https://api.github.com/users/qoega/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/qoega/subscriptions","organizations_url":"https://api.github.com/users/qoega/orgs","repos_url":"https://api.github.com/users/qoega/repos","events_url":"https://api.github.com/users/qoega/events{/privacy}","received_events_url":"https://api.github.com/users/qoega/received_events","type":"User","site_admin":false},"labels":[{"id":1955634273,"node_id":"MDU6TGFiZWwxOTU1NjM0Mjcz","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/testing","name":"testing","color":"c9a224","default":false,"description":"Special issue with list of bugs found by CI"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-09-27T10:36:23Z","updated_at":"2021-10-20T11:43:21Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"Umbrella issue to track flaky tests and other problems with current master branch stability:\r\n\r\nFlaky tests:\r\n- #29327\r\n- #29412\r\n- #29415\r\n- #30399\r\n- #30402\r\n\r\nSanitizer:\r\n- #29416\r\n- #29470\r\n- #30388\r\n- #30446\r\n\r\nFail:\r\n- #30397\r\n- #30321\r\n- #30400","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29413/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29413/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29401","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29401/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29401/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29401/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29401","id":1007772898,"node_id":"I_kwDOA5dJV848EWTi","number":29401,"title":"Issue creating materialized view on table which is replica of the Postgresql, returning error","user":{"login":"Shohjahon","id":16575814,"node_id":"MDQ6VXNlcjE2NTc1ODE0","avatar_url":"https://avatars.githubusercontent.com/u/16575814?v=4","gravatar_id":"","url":"https://api.github.com/users/Shohjahon","html_url":"https://github.com/Shohjahon","followers_url":"https://api.github.com/users/Shohjahon/followers","following_url":"https://api.github.com/users/Shohjahon/following{/other_user}","gists_url":"https://api.github.com/users/Shohjahon/gists{/gist_id}","starred_url":"https://api.github.com/users/Shohjahon/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Shohjahon/subscriptions","organizations_url":"https://api.github.com/users/Shohjahon/orgs","repos_url":"https://api.github.com/users/Shohjahon/repos","events_url":"https://api.github.com/users/Shohjahon/events{/privacy}","received_events_url":"https://api.github.com/users/Shohjahon/received_events","type":"User","site_admin":false},"labels":[{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":6,"created_at":"2021-09-27T07:01:12Z","updated_at":"2021-09-27T10:07:04Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"(you don't have to strictly follow this form)\r\n\r\n**Description**\r\nWhen i try to create materialized view for the table orders(engine: ReplacingMergeTree), clickhouse returning error.\r\nDatabase migrated from Postgresql using MaterializedPostgresql engine\r\n\r\n**Details**\r\n* Clickhouse server version:  21.9.2.17\r\n* Database client: Dbeaver\r\n* `CREATE TABLE shipox.orders\r\n(\r\n\r\n    `id` Int64,\r\n\r\n    `code` Nullable(String),\r\n\r\n    `status` Nullable(String),\r\n\r\n    `pickup_time` Nullable(DateTime64(6)),\r\n\r\n    `pickup_time_now` Nullable(UInt8),\r\n\r\n    `deleted` Nullable(UInt8),\r\n\r\n    `note` Nullable(String),\r\n\r\n    `approximate_distance` Nullable(Int64),\r\n\r\n    `amount` Nullable(Decimal(38,\r\n 4)),\r\n\r\n    `completed` Nullable(DateTime64(6)),\r\n\r\n    `payment_type` Nullable(String),\r\n\r\n    `payment_status` Nullable(UInt8),\r\n\r\n    `if_recipient_not_available` Nullable(String),\r\n\r\n    `payer` Nullable(String),\r\n\r\n    `delivered_to` Nullable(String),\r\n\r\n    `delivered_to_phone` Nullable(String),\r\n\r\n    `driver_id` Nullable(Int64),\r\n\r\n    `customer_id` Nullable(Int64),\r\n\r\n    `order_payment_id` Nullable(Int64),\r\n\r\n    `created_by` String,\r\n\r\n    `created_date` DateTime64(6),\r\n\r\n    `last_modified_by` Nullable(String),\r\n\r\n    `last_modified_date` Nullable(DateTime64(6)),\r\n\r\n    `supplier_id` Nullable(Int64),\r\n\r\n    `actual_delivery_option` Nullable(String),\r\n\r\n    `package_id` Nullable(Int64),\r\n\r\n    `sender_from` Nullable(String),\r\n\r\n    `sender_phone` Nullable(String),\r\n\r\n    `public_id` Nullable(String),\r\n\r\n    `device_details` Nullable(String),\r\n\r\n    `shipment_id` Nullable(String),\r\n\r\n    `recipient_id` Nullable(Int64),\r\n\r\n    `deadline_time` Nullable(DateTime64(6)),\r\n\r\n    `promo_id` Nullable(Int64),\r\n\r\n    `warehouse_id` Nullable(Int64),\r\n\r\n    `fragile` Nullable(UInt8),\r\n\r\n    `is_public` Nullable(UInt8),\r\n\r\n    `size` Nullable(String),\r\n\r\n    `driver_bonus_id` Nullable(Int64),\r\n\r\n    `previous_driver_id` Nullable(Int64),\r\n\r\n    `delivery_attemp_count` Nullable(Int64),\r\n\r\n    `pickup_attemp_count` Nullable(Int64),\r\n\r\n    `cod_status` Nullable(String),\r\n\r\n    `cod_transfer_id` Nullable(Int64),\r\n\r\n    `create_transaction` Nullable(UInt8),\r\n\r\n    `last_mile_driver_id` Nullable(Int64),\r\n\r\n    `withdraw_request_id` Nullable(Int64),\r\n\r\n    `pickup_id` Nullable(String),\r\n\r\n    `last_status_date` Nullable(DateTime64(6)),\r\n\r\n    `last_cod_status_date` Nullable(DateTime64(6)),\r\n\r\n    `is_uae` Nullable(UInt8),\r\n\r\n    `shop_order` Nullable(UInt8),\r\n\r\n    `customer_care_id` Nullable(Int64),\r\n\r\n    `price_id` Nullable(Int64),\r\n\r\n    `estimated_delivery_date_time` Nullable(DateTime64(6)),\r\n\r\n    `estimated_pick_up_time` Nullable(DateTime64(6)),\r\n\r\n    `cancellation_requires_type` Nullable(String),\r\n\r\n    `parent_supplier_id` Nullable(Int64),\r\n\r\n    `drop_timeslot_availability_id` Nullable(Int64),\r\n\r\n    `pickup_timeslot_availability_id` Nullable(Int64),\r\n\r\n    `reference_id` Nullable(String),\r\n\r\n    `value` Nullable(Decimal(38,\r\n 4)),\r\n\r\n    `fetch_item_id` Nullable(Int64),\r\n\r\n    `pick_up_driver_id` Nullable(Int64),\r\n\r\n    `first_delivery_time` Nullable(DateTime64(6)),\r\n\r\n    `first_pick_up_time` Nullable(DateTime64(6)),\r\n\r\n    `allocated_from_warehouse` Nullable(UInt8),\r\n\r\n    `api_supplier_id` Nullable(Int64),\r\n\r\n    `actualdelivery_time` Nullable(DateTime64(6)),\r\n\r\n    `actual_pickup_time` Nullable(DateTime64(6)),\r\n\r\n    `marketplace_id` Nullable(Int64),\r\n\r\n    `currency_id` Nullable(Int64),\r\n\r\n    `rule_id` Nullable(Int64),\r\n\r\n    `unique_id` Nullable(String),\r\n\r\n    `parent_id` Nullable(Int64),\r\n\r\n    `type` Nullable(String),\r\n\r\n    `is_old` Nullable(UInt8),\r\n\r\n    `with_driver` Nullable(UInt8),\r\n\r\n    `with_driver_time` Nullable(DateTime64(6)),\r\n\r\n    `merchant_promise_date` Nullable(DateTime64(6)),\r\n\r\n    `cod_transfer_type` Nullable(String),\r\n\r\n    `internal_promise_date` Nullable(DateTime64(6)),\r\n\r\n    `finance_pick_up_driver_id` Nullable(Int64),\r\n\r\n    `finance_pick_up_supplier_id` Nullable(Int64),\r\n\r\n    `cashier_id` Nullable(Int64),\r\n\r\n    `id_card_required` Nullable(UInt8),\r\n\r\n    `order_count` Nullable(Int32),\r\n\r\n    `weight` Nullable(Float64),\r\n\r\n    `timeslot_availability_history_id` Nullable(Int64),\r\n\r\n    `scanned_piece_count` Nullable(Int32),\r\n\r\n    `seller_id` Nullable(String),\r\n\r\n    `seller_name` Nullable(String),\r\n\r\n    `heavy_type` Nullable(String),\r\n\r\n    `first_driver_id` Nullable(Int64),\r\n\r\n    `cod_settlement_date` Nullable(DateTime64(6)),\r\n\r\n    `cod_settlement_reference` Nullable(String),\r\n\r\n    `wallet_settlement_date` Nullable(DateTime64(6)),\r\n\r\n    `wallet_settlement_reference` Nullable(String),\r\n\r\n    `chargeable_weight` Nullable(Decimal(38,\r\n 2)),\r\n\r\n    `height` Nullable(Decimal(38,\r\n 2)),\r\n\r\n    `length` Nullable(Decimal(38,\r\n 2)),\r\n\r\n    `width` Nullable(Decimal(38,\r\n 2)),\r\n\r\n    `provided_weight` Nullable(Decimal(38,\r\n 2)),\r\n\r\n    `volumetric_weight` Nullable(Decimal(38,\r\n 2)),\r\n\r\n    `dimension_unit` Nullable(String),\r\n\r\n    `package_type_id` Nullable(Int64),\r\n\r\n    `order_piece_count` Nullable(Int32),\r\n\r\n    `delivered_to_photo_id` Nullable(Int64),\r\n\r\n    `delivery_signature_id` Nullable(Int64),\r\n\r\n    `sender_photo_id` Nullable(Int64),\r\n\r\n    `sender_signature_id` Nullable(Int64),\r\n\r\n    `from_warehouse_id` Nullable(Int64),\r\n\r\n    `to_warehouse_id` Nullable(Int64),\r\n\r\n    `first_ofd_date` Nullable(DateTime64(6)),\r\n\r\n    `last_ofd_date` Nullable(DateTime64(6)),\r\n\r\n    `encrypted_id` Nullable(String),\r\n\r\n    `eta_id` Nullable(Int64),\r\n\r\n    `item_payment_id` Nullable(Int64),\r\n\r\n    `from_area_id` Nullable(Int64),\r\n\r\n    `to_area_id` Nullable(Int64),\r\n\r\n    `last_status_updated_user_id` Nullable(Int64),\r\n\r\n    `order_transfer_id` Nullable(Int64),\r\n\r\n    `external_user_name` Nullable(String),\r\n\r\n    `receipt_id` Nullable(Int64),\r\n\r\n    `receipt_number` Nullable(String),\r\n\r\n    `from_city` Nullable(String),\r\n\r\n    `to_city` Nullable(String),\r\n\r\n    `logistic_type` Nullable(String),\r\n\r\n    `back_id` Nullable(Int64),\r\n\r\n    `head_id` Nullable(Int64),\r\n\r\n    `reverse_code` Nullable(String),\r\n\r\n    `psf_status` Nullable(String),\r\n\r\n    `request_details` Nullable(String),\r\n\r\n    `storfox_sale_order_id` Nullable(String),\r\n\r\n    `route_distance` Nullable(Int64),\r\n\r\n    `is_no_service_area` Nullable(UInt8),\r\n\r\n    `recipient_city_changed` Nullable(UInt8),\r\n\r\n    `source_id` Nullable(String),\r\n\r\n    `source_type` Nullable(Int32),\r\n\r\n    `sms_verification_number` Nullable(String),\r\n\r\n    `sms_verified` Nullable(UInt8),\r\n\r\n    `audit_version` Nullable(Int64),\r\n\r\n    `manifest` Nullable(String),\r\n\r\n    `agent` Nullable(String),\r\n\r\n    `placed_storage_address` Nullable(String),\r\n\r\n    `last_mile_warehouse_id` Nullable(Int64),\r\n\r\n    `solr_index_request_uuid` Nullable(String),\r\n\r\n    `solr_index_version` Nullable(Int64),\r\n\r\n    `driver_fee_id` Nullable(Int64),\r\n\r\n    `_sign` Int8 MATERIALIZED 1,\r\n\r\n    `_version` UInt64 MATERIALIZED 1\r\n)\r\nENGINE = ReplacingMergeTree(_version)\r\nORDER BY tuple(id)\r\nSETTINGS index_granularity = 8192\r\n\r\n` table ddl \r\n\r\n* Create view statement which lead to the error: `create materialized view shipox.orders_vw\r\nengine = ReplacingMergeTree \r\npartition by toYYYYMM(created_date) \r\norder by (created_date) \r\npopulate as  \r\nselect status, count() as order_counts, created_date from shipox.orders \r\ngroup by status, created_date ;`\r\n\r\n\r\n**Error message **\r\nSQL Error [1002]: ClickHouse exception, code: 1002, host: 35.172.98.140, port: 8123; Code: 48. DB::Exception: Create table query allowed only for ReplacingMergeTree engine and from synchronization thread. (NOT_IMPLEMENTED) (version 21.9.2.17 (official build))\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29401/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29401/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29386","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29386/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29386/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29386/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29386","id":1007301773,"node_id":"I_kwDOA5dJV848CjSN","number":29386,"title":"Inaccurate type conversion between DateTime64 and Float/Decimal","user":{"login":"zhicwu","id":4270380,"node_id":"MDQ6VXNlcjQyNzAzODA=","avatar_url":"https://avatars.githubusercontent.com/u/4270380?v=4","gravatar_id":"","url":"https://api.github.com/users/zhicwu","html_url":"https://github.com/zhicwu","followers_url":"https://api.github.com/users/zhicwu/followers","following_url":"https://api.github.com/users/zhicwu/following{/other_user}","gists_url":"https://api.github.com/users/zhicwu/gists{/gist_id}","starred_url":"https://api.github.com/users/zhicwu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/zhicwu/subscriptions","organizations_url":"https://api.github.com/users/zhicwu/orgs","repos_url":"https://api.github.com/users/zhicwu/repos","events_url":"https://api.github.com/users/zhicwu/events{/privacy}","received_events_url":"https://api.github.com/users/zhicwu/received_events","type":"User","site_admin":false},"labels":[{"id":1397894054,"node_id":"MDU6TGFiZWwxMzk3ODk0MDU0","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unfinished%20code","name":"unfinished code","color":"ff8800","default":false,"description":""},{"id":1481221764,"node_id":"MDU6TGFiZWwxNDgxMjIxNzY0","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-datetime","name":"comp-datetime","color":"b5bcff","default":false,"description":"date & time & timezone related"}],"state":"open","locked":false,"assignee":{"login":"Enmk","id":1110183,"node_id":"MDQ6VXNlcjExMTAxODM=","avatar_url":"https://avatars.githubusercontent.com/u/1110183?v=4","gravatar_id":"","url":"https://api.github.com/users/Enmk","html_url":"https://github.com/Enmk","followers_url":"https://api.github.com/users/Enmk/followers","following_url":"https://api.github.com/users/Enmk/following{/other_user}","gists_url":"https://api.github.com/users/Enmk/gists{/gist_id}","starred_url":"https://api.github.com/users/Enmk/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Enmk/subscriptions","organizations_url":"https://api.github.com/users/Enmk/orgs","repos_url":"https://api.github.com/users/Enmk/repos","events_url":"https://api.github.com/users/Enmk/events{/privacy}","received_events_url":"https://api.github.com/users/Enmk/received_events","type":"User","site_admin":false},"assignees":[{"login":"Enmk","id":1110183,"node_id":"MDQ6VXNlcjExMTAxODM=","avatar_url":"https://avatars.githubusercontent.com/u/1110183?v=4","gravatar_id":"","url":"https://api.github.com/users/Enmk","html_url":"https://github.com/Enmk","followers_url":"https://api.github.com/users/Enmk/followers","following_url":"https://api.github.com/users/Enmk/following{/other_user}","gists_url":"https://api.github.com/users/Enmk/gists{/gist_id}","starred_url":"https://api.github.com/users/Enmk/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Enmk/subscriptions","organizations_url":"https://api.github.com/users/Enmk/orgs","repos_url":"https://api.github.com/users/Enmk/repos","events_url":"https://api.github.com/users/Enmk/events{/privacy}","received_events_url":"https://api.github.com/users/Enmk/received_events","type":"User","site_admin":false}],"milestone":null,"comments":5,"created_at":"2021-09-26T07:07:27Z","updated_at":"2021-09-27T00:15:07Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"It seems ClickHouse has trouble to convert float to DateTime64, regardless the value is positive or negative. I can reproduce the same issue on both 21.3 and 21.9.\r\n\r\n```sql\r\nf4dd7c849ef6 :) select toDateTime64(1, 3)\r\n┌──────toDateTime64(1, 3)─┐\r\n│ 1970-01-01 00:00:01.000 │\r\n└─────────────────────────┘\r\n\r\nf4dd7c849ef6 :) select toDateTime64(1.1, 3)\r\n┌────toDateTime64(1.1, 3)─┐\r\n│ 1970-01-01 00:00:01.100 │\r\n└─────────────────────────┘\r\n\r\nf4dd7c849ef6 :) select toDateTime64(1.01, 3)\r\n┌───toDateTime64(1.01, 3)─┐\r\n│ 1970-01-01 00:00:01.010 │\r\n└─────────────────────────┘\r\n\r\nf4dd7c849ef6 :) select toDateTime64(1.001, 3) -- expected result: 1970-01-01 00:00:01.001\r\n┌──toDateTime64(1.001, 3)─┐\r\n│ 1970-01-01 00:00:01.000 │\r\n└─────────────────────────┘\r\n\r\nf4dd7c849ef6 :) select toDateTime64(1.005, 3) -- expected result: 1970-01-01 00:00:01.005\r\n┌──toDateTime64(1.005, 3)─┐\r\n│ 1970-01-01 00:00:01.004 │\r\n└─────────────────────────┘\r\n\r\nf4dd7c849ef6 :) select toDateTime64(-1, 3)\r\n┌─────toDateTime64(-1, 3)─┐\r\n│ 1969-12-31 23:59:59.000 │\r\n└─────────────────────────┘\r\n\r\nf4dd7c849ef6 :) select toDateTime64(-1.1, 3) -- expected result: 1969-12-31 23:59:58.900, or 1969-12-31 23:59:59.000 if negative nanos is not supported on purpose\r\n┌───toDateTime64(-1.1, 3)─┐\r\n│ 1970-01-01 00:00:00.000 │\r\n└─────────────────────────┘\r\n\r\nf4dd7c849ef6 :) select toDateTime64(-1.01, 3) -- expected result: 1969-12-31 23:59:58.990, or 1969-12-31 23:59:59.000 if negative nanos is not supported on purpose\r\n┌──toDateTime64(-1.01, 3)─┐\r\n│ 1970-01-01 00:00:00.000 │\r\n└─────────────────────────┘\r\n\r\nf4dd7c849ef6 :) select toDateTime64(-1.001, 3) -- expected result: 1969-12-31 23:59:58.999, or 1969-12-31 23:59:59.000 if negative nanos is not supported on purpose\r\n┌─toDateTime64(-1.001, 3)─┐\r\n│ 1970-01-01 00:00:00.000 │\r\n└─────────────────────────┘\r\n\r\nf4dd7c849ef6 :) select toDateTime64(-1.005, 3) -- expected result: 1969-12-31 23:59:58.995, or 1969-12-31 23:59:59.000 if negative nanos is not supported on purpose\r\n┌─toDateTime64(-1.005, 3)─┐\r\n│ 1970-01-01 00:00:00.000 │\r\n└─────────────────────────┘\r\n```\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29386/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29386/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29385","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29385/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29385/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29385/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29385","id":1007299857,"node_id":"I_kwDOA5dJV848Ci0R","number":29385,"title":"In the system.query_log, you can see that the number of rows before and after the insert is inconsistent, but there is no exception information","user":{"login":"MrSsunlight","id":32731294,"node_id":"MDQ6VXNlcjMyNzMxMjk0","avatar_url":"https://avatars.githubusercontent.com/u/32731294?v=4","gravatar_id":"","url":"https://api.github.com/users/MrSsunlight","html_url":"https://github.com/MrSsunlight","followers_url":"https://api.github.com/users/MrSsunlight/followers","following_url":"https://api.github.com/users/MrSsunlight/following{/other_user}","gists_url":"https://api.github.com/users/MrSsunlight/gists{/gist_id}","starred_url":"https://api.github.com/users/MrSsunlight/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/MrSsunlight/subscriptions","organizations_url":"https://api.github.com/users/MrSsunlight/orgs","repos_url":"https://api.github.com/users/MrSsunlight/repos","events_url":"https://api.github.com/users/MrSsunlight/events{/privacy}","received_events_url":"https://api.github.com/users/MrSsunlight/received_events","type":"User","site_admin":false},"labels":[{"id":845247686,"node_id":"MDU6TGFiZWw4NDUyNDc2ODY=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/usability","name":"usability","color":"ebf28c","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":4,"created_at":"2021-09-26T06:58:31Z","updated_at":"2021-09-28T01:48:54Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Use the http protocol to insert data into the MergeTree table through insert. Why do you see that the results of write_rows and result_rows are inconsistent from the system.query_log, and no abnormal information can be seen;\r\n\r\n`INSERT INTO table1 FORMAT Protobuf SETTINGS format_schema='test.proto.tt'`\r\n\r\n```\r\nWITH '9be0eaf4-2d77-48c1-b888-d06e219cd327' AS id\r\nSELECT \r\n    read_rows, \r\n    read_bytes, \r\n    written_rows, \r\n    formatReadableSize(written_bytes) AS w_size, \r\n    result_rows, \r\n    formatReadableSize(result_bytes) AS r_size, \r\n    formatReadableSize(memory_usage) AS mem, \r\n    exception_code, \r\n    exception\r\nFROM system.query_log\r\nWHERE (query_id = id) AND (type = 2)\r\n\r\n┌─read_rows─┬─read_bytes─┬─written_rows─┬─w_size────┬─result_rows─┬─r_size────┬─mem────────┬─exception_code─┬─exception─┐\r\n│         0 │          0 │       185408 │ 44.01 MiB │       21027 │ 12.32 MiB │ 169.01 MiB │              0 │           │\r\n└───────────┴────────────┴──────────────┴───────────┴─────────────┴───────────┴────────────┴────────────────┴───────────┘\r\n\r\n1 rows in set. Elapsed: 0.052 sec. Processed 303.77 thousand rows, 34.96 MB (5.88 million rows/s., 676.95 MB/s.) \r\n```\r\n\r\n`show processlist`\r\n\r\n```\r\n┌─is_initial_query─┬─user────┬─query_id─────────────────────────────┬─address──────────┬──port─┬─initial_user─┬─initial_query_id─────────────────────┬─initial_address──┬─initial_port─┬─interface─┬─os_user─┬─client_hostname─┬─client_name─┬─client_revision─┬─client_version_major─┬─client_version_minor─┬─client_version_patch─┬─http_method─┬─http_user_agent────┬─quota_key─┬─────elapsed─┬─is_cancelled─┬─read_rows─┬─read_bytes─┬─total_rows_approx─┬─written_rows─┬─written_bytes─┬─memory_usage─┬─peak_memory_usage─┬─query───────────────────────────────────────────────────────────────────────────────────────────┬─thread_ids─┬─ProfileEvents.Names────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┬─ProfileEvents.Values───────────────────────────────────────────────────────────────────────────────────────────────┬─Settings.Names─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┬─Settings.Values────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\r\n│                1 │ default │ 9be0eaf4-2d77-48c1-b888-d06e219cd327 │ ::ffff:127.0.0.6 │ 51491 │ default      │ 9be0eaf4-2d77-48c1-b888-d06e219cd327 │ ::ffff:127.0.0.6 │        51491 │         2 │         │                 │             │               0 │                    0 │                    0 │                    0 │           2 │ Go-http-client/1.1 │           │ 0.870222596 │            0 │         0 │          0 │                 0 │        61651 │      28386347 │     28892709 │         177216919 │ INSERT INTO table1 FORMAT Protobuf SETTINGS format_schema='test.proto.tt'\r\n │ [186]      │ ['Query','InsertQuery','FileOpen','WriteBufferFromFileDescriptorWrite','WriteBufferFromFileDescriptorWriteBytes','IOBufferAllocs','IOBufferAllocBytes','ArenaAllocChunks','ArenaAllocBytes','FunctionExecute','CreatedWriteBufferOrdinary','DiskWriteElapsedMicroseconds','InsertedRows','InsertedBytes','ZooKeeperTransactions','ZooKeeperCreate','ZooKeeperMulti','MergeTreeDataWriterRows','MergeTreeDataWriterUncompressedBytes','MergeTreeDataWriterCompressedBytes','MergeTreeDataWriterBlocks','ContextLock','RWLockAcquiredReadLocks'] │ [1,1,539,576,3601263,1596,304090500,47,4304896,77,539,6871,61651,28386347,9,5,4,51845,26841463,3580813,3,1489,507] │ ['use_uncompressed_cache','background_pool_size','load_balancing','allow_suspicious_low_cardinality_types','distributed_aggregation_memory_efficient','skip_unavailable_shards','log_queries','format_schema','max_bytes_before_external_group_by','max_bytes_before_external_sort','max_execution_time','max_memory_usage','max_memory_usage_for_all_queries','allow_experimental_data_skipping_indices'] │ ['1','32','random','1','1','1','1','cdns.proto:dnsMessage','64424509440','64424509440','3000','96636764160','96636764160','1'] │\r\n└──────────────────┴─────────┴──────────────────────────────────────┴──────────────────┴───────┴──────────────┴──────────────────────────────────────┴──────────────────┴──────────────┴───────────┴─────────┴─────────────────┴─────────────┴─────────────────┴──────────────────────┴──────────────────────┴──────────────────────┴─────────────┴────────────────────┴───────────┴─────────────┴──────────────┴───────────┴────────────┴───────────────────┴──────────────┴───────────────┴──────────────┴───────────────────┴─────────────────────────────────────────────────────────────────────────────────────────────────┴────────────┴────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\r\n```\r\n\r\n\r\n\r\n\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29385/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29385/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29378","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29378/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29378/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29378/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29378","id":1007229174,"node_id":"I_kwDOA5dJV848CRj2","number":29378,"title":"clickhouse-local build small enough to fit in a Lambda function","user":{"login":"occasionallydavid","id":62972099,"node_id":"MDQ6VXNlcjYyOTcyMDk5","avatar_url":"https://avatars.githubusercontent.com/u/62972099?v=4","gravatar_id":"","url":"https://api.github.com/users/occasionallydavid","html_url":"https://github.com/occasionallydavid","followers_url":"https://api.github.com/users/occasionallydavid/followers","following_url":"https://api.github.com/users/occasionallydavid/following{/other_user}","gists_url":"https://api.github.com/users/occasionallydavid/gists{/gist_id}","starred_url":"https://api.github.com/users/occasionallydavid/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/occasionallydavid/subscriptions","organizations_url":"https://api.github.com/users/occasionallydavid/orgs","repos_url":"https://api.github.com/users/occasionallydavid/repos","events_url":"https://api.github.com/users/occasionallydavid/events{/privacy}","received_events_url":"https://api.github.com/users/occasionallydavid/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":19,"created_at":"2021-09-26T00:14:40Z","updated_at":"2021-11-08T17:03:33Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"**Use case**\r\n\r\n`clickhouse-local` is probably the most powerful logs analysis tool I've ever come across, and it seems to obviate most of the pain with running a full ClickHouse installation (ops work, ETL) without sacrificing much (if any?) performance for offline batch tasks.\r\n\r\nFor use cases where large amount of logs are stored in object stores like GCS or S3, ability to streaming read from object store and process with `clickhouse-local` is very desirable: no large expensive VMs running a permanent database with a copy of the original data.\r\n\r\nThis raises the possibility: can ClickHouse be made totally serverless? It is very cheap to run short S3/GCS scan jobs from Lambda or Cloud Functions. Many organizations already use this pattern, but usually they write custom code to run in Lambda, but ClickHouse already provides for many use cases in a much nicer form. However current ClickHouse binary is much too large to fit in a Lambda ZIP file (current max: 50mb, vs. 300mb+ for current official binaries). \r\n\r\n\r\n**Describe the solution you'd like**\r\n\r\nPotentially a custom build, or simply some documentation steps (PGO build?), to slim down `clickhouse-local` to read only from S3/GCS/URLs and enough functionality disabled so it will fit within 50mb. Is it possible? I see lots of template-heavy C++. Perhaps this is why binary is so large, and it won't change :)\r\n\r\n**Describe alternatives you've considered**\r\n\r\nObvious alternative is spinning up a container or spot instance to run a job, but this requires inventing some ops framework for managing the VMs and containers. Lambda functions can be fed e.g. by SNS, auto-scaled according to queue of user queries with zero management.\r\n\r\n**Additional context**\r\n\r\nNone. Low priority, just an idea, but one I've already tried because it makes so much sense over here.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29378/reactions","total_count":4,"+1":4,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29378/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29377","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29377/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29377/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29377/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29377","id":1007224023,"node_id":"I_kwDOA5dJV848CQTX","number":29377,"title":"clickhouse-local silently fails for some queries when input is not a regular file descriptor","user":{"login":"occasionallydavid","id":62972099,"node_id":"MDQ6VXNlcjYyOTcyMDk5","avatar_url":"https://avatars.githubusercontent.com/u/62972099?v=4","gravatar_id":"","url":"https://api.github.com/users/occasionallydavid","html_url":"https://github.com/occasionallydavid","followers_url":"https://api.github.com/users/occasionallydavid/followers","following_url":"https://api.github.com/users/occasionallydavid/following{/other_user}","gists_url":"https://api.github.com/users/occasionallydavid/gists{/gist_id}","starred_url":"https://api.github.com/users/occasionallydavid/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/occasionallydavid/subscriptions","organizations_url":"https://api.github.com/users/occasionallydavid/orgs","repos_url":"https://api.github.com/users/occasionallydavid/repos","events_url":"https://api.github.com/users/occasionallydavid/events{/privacy}","received_events_url":"https://api.github.com/users/occasionallydavid/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""},{"id":845247686,"node_id":"MDU6TGFiZWw4NDUyNDc2ODY=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/usability","name":"usability","color":"ebf28c","default":false,"description":""}],"state":"open","locked":false,"assignee":{"login":"FArthur-cmd","id":58165623,"node_id":"MDQ6VXNlcjU4MTY1NjIz","avatar_url":"https://avatars.githubusercontent.com/u/58165623?v=4","gravatar_id":"","url":"https://api.github.com/users/FArthur-cmd","html_url":"https://github.com/FArthur-cmd","followers_url":"https://api.github.com/users/FArthur-cmd/followers","following_url":"https://api.github.com/users/FArthur-cmd/following{/other_user}","gists_url":"https://api.github.com/users/FArthur-cmd/gists{/gist_id}","starred_url":"https://api.github.com/users/FArthur-cmd/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/FArthur-cmd/subscriptions","organizations_url":"https://api.github.com/users/FArthur-cmd/orgs","repos_url":"https://api.github.com/users/FArthur-cmd/repos","events_url":"https://api.github.com/users/FArthur-cmd/events{/privacy}","received_events_url":"https://api.github.com/users/FArthur-cmd/received_events","type":"User","site_admin":false},"assignees":[{"login":"FArthur-cmd","id":58165623,"node_id":"MDQ6VXNlcjU4MTY1NjIz","avatar_url":"https://avatars.githubusercontent.com/u/58165623?v=4","gravatar_id":"","url":"https://api.github.com/users/FArthur-cmd","html_url":"https://github.com/FArthur-cmd","followers_url":"https://api.github.com/users/FArthur-cmd/followers","following_url":"https://api.github.com/users/FArthur-cmd/following{/other_user}","gists_url":"https://api.github.com/users/FArthur-cmd/gists{/gist_id}","starred_url":"https://api.github.com/users/FArthur-cmd/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/FArthur-cmd/subscriptions","organizations_url":"https://api.github.com/users/FArthur-cmd/orgs","repos_url":"https://api.github.com/users/FArthur-cmd/repos","events_url":"https://api.github.com/users/FArthur-cmd/events{/privacy}","received_events_url":"https://api.github.com/users/FArthur-cmd/received_events","type":"User","site_admin":false}],"milestone":null,"comments":12,"created_at":"2021-09-25T23:48:25Z","updated_at":"2021-09-30T11:32:08Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"**Describe what's wrong**\r\n\r\nA query is observed to silently fail by returning no results when `clickhouse-local` stdin is connected to a pipe, whereas when fed the same input via a regular file descriptor, the query succeeds as expected.\r\n\r\nIt appears an error is being internally silenced that should propagate, as the simple test case below produces an error with the same configuration, whereas the (attached) complex query fails silently.\r\n\r\nHow to determine if a query will require multiple scans of the input data? It is impossible in this use case, input data is 500GB of concatenated zstd input.\r\n\r\n**Does it reproduce on recent release?**\r\n\r\nYes. ClickHouse client version 21.9.4.35 (official build).\r\n\r\n**How to reproduce**\r\n\r\n#### Simple test case showing sensible error\r\n\r\n```bash\r\ncat > b.csv <<EOF\r\n\"name\",\"age\"\r\n\"George\",\"38\"\r\n\"Gemma\",\"36\"\r\nEOF\r\n\r\nzstd b.csv\r\n\r\n# WORKS (fd 0 = regular file)\r\n<b.csv.zst clickhouse-local -q \"CREATE TABLE t(name String, age Int64) ENGINE=File(CSVWithNames,stdin,'zstd'); SELECT * FROM t; SELECT * FROM t;\"\r\n\r\n# SHOWS ERROR ON SECOND QUERY (fd 0 = pipe)\r\ncat b.csv | zstd | clickhouse-local -q \"CREATE TABLE t(name String, age Int64) ENGINE=File(CSVWithNames,stdin,'zstd'); SELECT * FROM t; SELECT * FROM t;\"\r\n```\r\n\r\n#### Complex test case that silently fails\r\n\r\nCommand line: `clickhouse-local --input_format_allow_errors_num=10000 --input_format_allow_errors_ratio=0.01  --max_memory_usage=0 --query ...`\r\n\r\nInput data: `obf2.csv.zst` (attached) and `data/GeoIP*.csv` (attached in data.zip)\r\n\r\n\r\n[data.zip](https://github.com/ClickHouse/ClickHouse/files/7230489/data.zip)\r\n[obf2.csv.zst.zip](https://github.com/ClickHouse/ClickHouse/files/7230490/obf2.csv.zst.zip) (wrapped in a ZIP because silly GitHub filters)\r\n\r\nQuery:\r\n\r\n```sql\r\n        CREATE TABLE table_raw(\r\n            timestamp String,\r\n            cdn_id Int64,\r\n            edge_loc String,\r\n            ip_address String,\r\n            method String,\r\n            protocol String,\r\n            domain String,\r\n            path String NOT NULL,\r\n            status_code Int64,\r\n            cache_status String,\r\n            cache_age Int64,\r\n            response_size Int64,\r\n            request_time Float64,\r\n            tcp_rtt Int64,\r\n            user_agent String,\r\n            referrer String,\r\n            log_version String\r\n        )\r\n        ENGINE = File(TabSeparated, stdin, 'zstd');\r\nCREATE VIEW table AS\r\n        SELECT\r\n            timestamp,\r\n            cdn_id,\r\n            edge_loc,\r\n            -- Handle corrupted IP addresses.\r\n            CASE\r\n                WHEN match(ip_address, '^[0-9.]+$') THEN\r\n                    toIPv4(ip_address)\r\n                ELSE\r\n                    0\r\n            END ip_address,\r\n            method,\r\n            protocol,\r\n            domain,\r\n            path,\r\n            status_code,\r\n            cache_status,\r\n            cache_age,\r\n            response_size,\r\n            request_time,\r\n            tcp_rtt,\r\n            user_agent,\r\n            referrer,\r\n            log_version\r\n        FROM table_raw;\r\n-- dictGetUInt32('geoip_country_blocks_ipv4', 'geoname_id', tuple(IPv4StringToNum(ip))) AS geoname_id,\r\n-- dictGetString('geoip_country_locations_en', 'locale_code', toUInt64(geoname_id)) AS locale_code,\r\n-- dictGetString('geoip_country_locations_en', 'continent_code', toUInt64(geoname_id)) AS continent_code,\r\n-- dictGetString('geoip_country_locations_en', 'continent_name', toUInt64(geoname_id)) AS continent_name,\r\n-- dictGetString('geoip_country_locations_en', 'country_iso_code', toUInt64(geoname_id)) AS country_iso_code,\r\n-- dictGetString('geoip_country_locations_en', 'country_name', toUInt64(geoname_id)) AS country_name,\r\n-- dictGetUInt8('geoip_country_locations_en', 'is_in_european_union', toUInt64(geoname_id)) AS is_in_european_union\r\n\r\nCREATE DICTIONARY geoip_country_blocks_ipv4\r\n(\r\n    network String,\r\n    geoname_id UInt32,\r\n    registered_country_geoname_id UInt32,\r\n    represented_country_geoname_id UInt32,\r\n    is_anonymous_proxy UInt8,\r\n    is_satellite_provider UInt8\r\n)\r\nPRIMARY KEY network\r\nSOURCE(FILE(path './data/GeoLite2-Country-Blocks-IPv4.csv' format 'CSVWithNames'))\r\nLAYOUT(ip_trie)\r\nLIFETIME(86400);\r\nCREATE DICTIONARY geoip_country_locations_en\r\n(\r\n    geoname_id UInt32,\r\n    locale_code String,\r\n    continent_code String,\r\n    continent_name String,\r\n    country_iso_code String,\r\n    country_name String,\r\n    is_in_european_union UInt8\r\n)\r\nPRIMARY KEY geoname_id\r\nSOURCE(FILE(path './data/GeoLite2-Country-Locations-en.csv' format 'CSVWithNames'))\r\nLAYOUT(hashed)\r\nLIFETIME(86400);\r\nWITH results AS (\r\n        SELECT\r\n            dictGetUInt32('geoip_country_blocks_ipv4', 'geoname_id', tuple((ip_address))) AS geoname_id,\r\n            COUNT(DISTINCT ip_address) unique_ips,\r\n            COUNT(*) request_count,\r\n            CASE\r\n                WHEN (LENGTH(extracted_bitrate) > 0) THEN\r\n                    'MPEG-TS'\r\n                WHEN (path LIKE '%.m3u8%') THEN\r\n                    'Playlist'\r\n                ELSE\r\n                    'Unknown'\r\n            END traffic_class,\r\n            CASE\r\n                WHEN (LENGTH(extracted_bitrate) > 0) THEN\r\n                    toInt64(extracted_bitrate)\r\n                ELSE\r\n                    NULL\r\n            END bitrate,\r\n            SUM(response_size) / 1e12 total_tb\r\n        FROM (\r\n            SELECT\r\n                *,\r\n                extract(path, 'media-[^_]+_b([0-9]+)') extracted_bitrate\r\n            FROM table\r\n        )\r\n        GROUP BY geoname_id, traffic_class, extracted_bitrate\r\n        ORDER BY geoname_id, traffic_class, bitrate DESC\r\n    )\r\n    SELECT\r\n        dictGetString('geoip_country_locations_en', 'country_name', toUInt64(geoname_id)) AS country_name,\r\n        traffic_class,\r\n        bitrate,\r\n        unique_ips,\r\n        request_count,\r\n        total_tb,\r\n        total_tb / (SELECT SUM(total_tb) FROM results) pct\r\n    FROM results;\r\n```\r\n\r\n\r\n**Expected behavior**\r\n\r\n`clickhouse-local` prints error about failed query due to lack of seeking, or\r\n\r\n`clickhouse-local` indicates which part of query caused multiple scan\r\n\r\n**Additional context**\r\n\r\nX/Y problem: the desire is to streamily read >300 zstd-compressed log files from S3 and feed them to ClickHouse without any ETL step. Built-in table access method does not appear to allow stitching multiple URLs together into one stream. Built-in method also seems to download complete file before beginning processing. Perhaps there is better solution than concatenating the input into a pipe? Perhaps VIEW of UNION SELECT? I don't know","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29377/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29377/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29332","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29332/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29332/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29332/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29332","id":1006403256,"node_id":"I_kwDOA5dJV847_H64","number":29332,"title":"Pushdown of predicate may produce wrong queries with subqueries to distributed tables.","user":{"login":"CurtizJ","id":20361854,"node_id":"MDQ6VXNlcjIwMzYxODU0","avatar_url":"https://avatars.githubusercontent.com/u/20361854?v=4","gravatar_id":"","url":"https://api.github.com/users/CurtizJ","html_url":"https://github.com/CurtizJ","followers_url":"https://api.github.com/users/CurtizJ/followers","following_url":"https://api.github.com/users/CurtizJ/following{/other_user}","gists_url":"https://api.github.com/users/CurtizJ/gists{/gist_id}","starred_url":"https://api.github.com/users/CurtizJ/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/CurtizJ/subscriptions","organizations_url":"https://api.github.com/users/CurtizJ/orgs","repos_url":"https://api.github.com/users/CurtizJ/repos","events_url":"https://api.github.com/users/CurtizJ/events{/privacy}","received_events_url":"https://api.github.com/users/CurtizJ/received_events","type":"User","site_admin":false},"labels":[{"id":386401505,"node_id":"MDU6TGFiZWwzODY0MDE1MDU=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/bug","name":"bug","color":"ee0701","default":true,"description":"Confirmed user-visible misbehaviour in official release"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-09-24T12:15:48Z","updated_at":"2021-09-24T15:06:00Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"**How to reproduce**\r\n\r\n```sql\r\ncreate table t_local(id UInt32, s String) engine = MergeTree order by id;\r\ncreate table t_dist (id UInt32, s String) engine = Distributed(test_cluster_two_shards, currentDatabase(), t_local);\r\n```\r\n\r\n```sql\r\nSELECT *\r\nFROM\r\n(\r\n    SELECT\r\n        id,\r\n        count()\r\n    FROM t_dist\r\n    GROUP BY id\r\n)\r\nWHERE id IN (\r\n    SELECT id\r\n    FROM t_dist\r\n    WHERE notEmpty(s)\r\n)\r\nSETTINGS enable_optimize_predicate_expression = 1, distributed_product_mode = 'deny'\r\n\r\nQuery id: c7e63a5c-a5d9-43d3-a057-62bab34074b1\r\n\r\n\r\n0 rows in set. Elapsed: 0.002 sec. \r\n\r\nReceived exception from server (version 21.11.1):\r\nCode: 288. DB::Exception: Received from localhost:9000. DB::Exception: Double-distributed IN/JOIN subqueries is denied (distributed_product_mode = 'deny'). You may rewrite query to use local tables in subqueries, or use GLOBAL keyword, or set distributed_product_mode to suitable value.: While processing  t_dist: While processing id IN (SELECT id FROM t_dist WHERE notEmpty(s)). (DISTRIBUTED_IN_JOIN_SUBQUERY_DENIED)\r\n```\r\n\r\n```sql\r\nSELECT *\r\nFROM\r\n(\r\n    SELECT\r\n        id,\r\n        count()\r\n    FROM t_dist\r\n    GROUP BY id\r\n)\r\nWHERE id IN (\r\n    SELECT id\r\n    FROM t_dist\r\n    WHERE notEmpty(s)\r\n)\r\nSETTINGS enable_optimize_predicate_expression = 0, distributed_product_mode = 'deny'\r\n\r\nQuery id: d56c20ea-d375-4308-8785-149f4527717f\r\n\r\nOk.\r\n\r\n0 rows in set. Elapsed: 0.007 sec. \r\n```\r\n\r\nIt's because of rewriting:\r\n\r\n```sql\r\n┌─explain────────────────────────────────────────────────────────────────────────────────┐\r\n│ SELECT                                                                                 │\r\n│     id,                                                                                │\r\n│     `count()`                                                                          │\r\n│ FROM                                                                                   │\r\n│ (                                                                                      │\r\n│     SELECT                                                                             │\r\n│         id,                                                                            │\r\n│         count()                                                                        │\r\n│     FROM t_dist                                                                        │\r\n│     WHERE id GLOBAL IN ((                                                              │\r\n│         SELECT id                                                                      │\r\n│         FROM t_dist AS dist                                                            │\r\n│         WHERE notEmpty(s)                                                              │\r\n│     ) AS _subquery19)                                                                  │\r\n│     GROUP BY id                                                                        │\r\n│ )                                                                                      │\r\n│ WHERE id IN ((                                                                         │\r\n│     SELECT id                                                                          │\r\n│     FROM t_dist AS dist                                                                │\r\n│     WHERE notEmpty(s)                                                                  │\r\n│ ) AS _subquery18)                                                                      │\r\n│ SETTINGS enable_optimize_predicate_expression = 1, distributed_product_mode = 'global' │\r\n└────────────────────────────────────────────────────────────────────────────────────────┘\r\n```\r\n\r\nHowever, pushdown predicate should be disable also for `distributed_product_mode = 'local'`, because in some cases wrong queries may be produced:\r\n\r\n```sql\r\nEXPLAIN SYNTAX\r\nSELECT *\r\nFROM\r\n(\r\n    SELECT\r\n        id,\r\n        count()\r\n    FROM t_dist\r\n    GROUP BY id\r\n        WITH TOTALS\r\n)\r\nWHERE id IN (\r\n    SELECT id\r\n    FROM t_dist AS dist\r\n    WHERE notEmpty(s)\r\n)\r\nSETTINGS enable_optimize_predicate_expression = 1, distributed_product_mode = 'local'\r\n\r\nQuery id: 787466de-0223-4673-ac5c-a81362b15197\r\n\r\n┌─explain───────────────────────────────────────────────────────────────────────────────┐\r\n│ SELECT                                                                                │\r\n│     id,                                                                               │\r\n│     `count()`                                                                         │\r\n│ FROM                                                                                  │\r\n│ (                                                                                     │\r\n│     SELECT                                                                            │\r\n│         id,                                                                           │\r\n│         count()                                                                       │\r\n│     FROM t_dist                                                                       │\r\n│     GROUP BY id                                                                       │\r\n│         WITH TOTALS                                                                   │\r\n│     HAVING id IN ((                                                                   │\r\n│         SELECT id                                                                     │\r\n│         FROM default.t_local AS dist                                                  │\r\n│         WHERE notEmpty(s)                                                             │\r\n│     ) AS _subquery23)                                                                 │\r\n│ )                                                                                     │\r\n│ WHERE id IN ((                                                                        │\r\n│     SELECT id                                                                         │\r\n│     FROM t_dist AS dist                                                               │\r\n│     WHERE notEmpty(s)                                                                 │\r\n│ ) AS _subquery22)                                                                     │\r\n│ SETTINGS enable_optimize_predicate_expression = 1, distributed_product_mode = 'local' │\r\n└───────────────────────────────────────────────────────────────────────────────────────┘\r\n```\r\n\r\nIn this query predicate can't be converted from `HAVING` to `WHERE`, because of `WITH TOTALS` and table identifier is rewritten to local because of `distributed_product_mode = 'local'`. But `HAVING` is executing on initiator unlike of `WHERE` and it's not correct.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29332/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29332/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29320","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29320/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29320/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29320/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29320","id":1006262477,"node_id":"I_kwDOA5dJV847-ljN","number":29320,"title":"HDFS engine fails with Kerberos is used","user":{"login":"jiangdaokun","id":55648713,"node_id":"MDQ6VXNlcjU1NjQ4NzEz","avatar_url":"https://avatars.githubusercontent.com/u/55648713?v=4","gravatar_id":"","url":"https://api.github.com/users/jiangdaokun","html_url":"https://github.com/jiangdaokun","followers_url":"https://api.github.com/users/jiangdaokun/followers","following_url":"https://api.github.com/users/jiangdaokun/following{/other_user}","gists_url":"https://api.github.com/users/jiangdaokun/gists{/gist_id}","starred_url":"https://api.github.com/users/jiangdaokun/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jiangdaokun/subscriptions","organizations_url":"https://api.github.com/users/jiangdaokun/orgs","repos_url":"https://api.github.com/users/jiangdaokun/repos","events_url":"https://api.github.com/users/jiangdaokun/events{/privacy}","received_events_url":"https://api.github.com/users/jiangdaokun/received_events","type":"User","site_admin":false},"labels":[{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2021-09-24T09:22:00Z","updated_at":"2021-10-18T02:18:54Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"ClickHouse server version: 21.8.3.44\r\n\r\nI want to use HDFS engine on Clickhouse, My HDFS cluster contains Kerberos,When I closed Kerberos, I can get HDFS data ;\r\nHowever, when I open Kerberos, the query is error. I execute this command on the machine successfully\r\ncommand:\r\nkinit -R -t \"/etc/hdfs1/conf/hdfs.keytab\" -k hdfs/tdh1@TDHTEST|| kinit -t \"/etc/hdfs1/conf/hdfs.keytab\" -k hdfs/tdh1@TDHTEST\r\n\r\nerror info:\r\nCode: 36, e.displayText() = DB::Exception: kinit failure: kinit -R -t \"/etc/hdfs1/conf/hdfs.keytab\" -k hdfs/tdh1@TDHTEST|| kinit -t \"/etc/hdfs1/conf/hdfs.keytab\" -k hdfs/tdh1@TDHTEST (version 21.8.3.44 (official build)) (from 172.0.0.1:58685) (in query: select * from da.base_agent_info_oper_hdfs FORMAT TabSeparatedWithNamesAndTypes ), Stack trace (when copying this message, always include the lines below):\r\n\r\n\r\ncreate table sql:\r\nCREATE TABLE da.base_agent_info_oper_hdfs\r\n(\r\n    `agent_no` String,\r\n    `agent_name` String,\r\n    `agent_type` String,\r\n    `phoneno` String,\r\n    `hdatasign` String,\r\n    `hloadtime` String,\r\n    `hbatchdate` String,\r\n    `hdatasrc` String\r\n)\r\nENGINE = HDFS('hdfs://172.0.0.1:8020/inceptor1/user/hive/warehouse/da.db/hbxyoper/base_agent_info_oper/*', 'ORC');\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29320/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29320/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29315","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29315/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29315/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29315/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29315","id":1006139353,"node_id":"I_kwDOA5dJV847-HfZ","number":29315,"title":"Segmentation fault (11) with RabbitMQ engine table","user":{"login":"Oinari","id":1106550,"node_id":"MDQ6VXNlcjExMDY1NTA=","avatar_url":"https://avatars.githubusercontent.com/u/1106550?v=4","gravatar_id":"","url":"https://api.github.com/users/Oinari","html_url":"https://github.com/Oinari","followers_url":"https://api.github.com/users/Oinari/followers","following_url":"https://api.github.com/users/Oinari/following{/other_user}","gists_url":"https://api.github.com/users/Oinari/gists{/gist_id}","starred_url":"https://api.github.com/users/Oinari/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Oinari/subscriptions","organizations_url":"https://api.github.com/users/Oinari/orgs","repos_url":"https://api.github.com/users/Oinari/repos","events_url":"https://api.github.com/users/Oinari/events{/privacy}","received_events_url":"https://api.github.com/users/Oinari/received_events","type":"User","site_admin":false},"labels":[{"id":1234601830,"node_id":"MDU6TGFiZWwxMjM0NjAxODMw","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/crash","name":"crash","color":"082b68","default":false,"description":"Crash / segfault / abort"},{"id":1446279638,"node_id":"MDU6TGFiZWwxNDQ2Mjc5NjM4","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-3rdparty-libs","name":"comp-3rdparty-libs","color":"b5bcff","default":false,"description":"Related to libraries used by ClickHouse"},{"id":2314441866,"node_id":"MDU6TGFiZWwyMzE0NDQxODY2","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-rabbitmq","name":"comp-rabbitmq","color":"b5bcff","default":false,"description":""},{"id":3260776666,"node_id":"MDU6TGFiZWwzMjYwNzc2NjY2","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/potential%20bug","name":"potential bug","color":"ffc080","default":false,"description":"To be reviewed by developers and confirmed/rejected."}],"state":"open","locked":false,"assignee":{"login":"kssenii","id":54203879,"node_id":"MDQ6VXNlcjU0MjAzODc5","avatar_url":"https://avatars.githubusercontent.com/u/54203879?v=4","gravatar_id":"","url":"https://api.github.com/users/kssenii","html_url":"https://github.com/kssenii","followers_url":"https://api.github.com/users/kssenii/followers","following_url":"https://api.github.com/users/kssenii/following{/other_user}","gists_url":"https://api.github.com/users/kssenii/gists{/gist_id}","starred_url":"https://api.github.com/users/kssenii/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kssenii/subscriptions","organizations_url":"https://api.github.com/users/kssenii/orgs","repos_url":"https://api.github.com/users/kssenii/repos","events_url":"https://api.github.com/users/kssenii/events{/privacy}","received_events_url":"https://api.github.com/users/kssenii/received_events","type":"User","site_admin":false},"assignees":[{"login":"kssenii","id":54203879,"node_id":"MDQ6VXNlcjU0MjAzODc5","avatar_url":"https://avatars.githubusercontent.com/u/54203879?v=4","gravatar_id":"","url":"https://api.github.com/users/kssenii","html_url":"https://github.com/kssenii","followers_url":"https://api.github.com/users/kssenii/followers","following_url":"https://api.github.com/users/kssenii/following{/other_user}","gists_url":"https://api.github.com/users/kssenii/gists{/gist_id}","starred_url":"https://api.github.com/users/kssenii/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kssenii/subscriptions","organizations_url":"https://api.github.com/users/kssenii/orgs","repos_url":"https://api.github.com/users/kssenii/repos","events_url":"https://api.github.com/users/kssenii/events{/privacy}","received_events_url":"https://api.github.com/users/kssenii/received_events","type":"User","site_admin":false}],"milestone":null,"comments":5,"created_at":"2021-09-24T06:48:52Z","updated_at":"2022-01-09T17:38:59Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"**Describe what's wrong**\r\nSegmentation fault (11) error when trying to get data from a table with RabbitMQ engine.\r\n\r\n**Does it reproduce on recent release?**\r\nYes, 21.9.3.30\r\n\r\n**How to reproduce**\r\n1. Create a table \r\n```\r\nCREATE TABLE dev.rabbitmq_queue (\r\n    `import_json` String\r\n)\r\nENGINE = RabbitMQ SETTINGS rabbitmq_host_port = '192.168.0.10:5672',\r\n                            rabbitmq_exchange_type = 'direct',                            \r\n                            rabbitmq_exchange_name = 'import_events',\r\n                            rabbitmq_routing_key_list = 'import_events',\r\n                            rabbitmq_format = 'JSONAsString',\r\n                            rabbitmq_num_consumers = 3;\r\n```\r\n2. Try to select on several time\r\n```\r\n:) select * from dev.rabbitmq_queue;\r\n\r\nSELECT *\r\nFROM dev.rabbitmq_queue\r\n\r\nQuery id: 221944dc-fcb7-448a-b9eb-3132dc3b56e3\r\n\r\nOk.\r\n\r\n0 rows in set. Elapsed: 0.004 sec. \r\n\r\n:) select * from audit_import_dev.rabbitmq_queue;\r\n\r\nSELECT *\r\nFROM audit_import_dev.rabbitmq_queue\r\n\r\nQuery id: b84afb0f-6964-4b81-a513-cf2a2ca67f53\r\n\r\nConnecting to database audit_import_dev at 192.168.10.153:9000 as user default.\r\nException on client:\r\nCode: 210. DB::NetException: Connection refused (192.168.10.153:9000). (NETWORK_ERROR)\r\n\r\nConnecting to database audit_import_dev at 192.168.10.153:9000 as user default.\r\nCode: 210. DB::NetException: Connection refused (192.168.10.153:9000). (NETWORK_ERROR)\r\n```\r\n3. Get error.\r\n\r\n* Which ClickHouse server version to use\r\n21.9.3.30\r\n\r\n**Expected behavior**\r\n\r\n> A clear and concise description of what you expected to happen.\r\n\r\n**Error message and/or stacktrace**\r\n```\r\n2021.09.24 09:36:17.729041 [ 13444 ] {} <Error> StorageRabbitMQ (rabbitmq_queue): Channel  error: connection lost\r\n2021.09.24 09:36:17.729091 [ 13444 ] {} <Error> StorageRabbitMQ (rabbitmq_queue): Channel  error: connection lost\r\n2021.09.24 09:36:17.729111 [ 13444 ] {} <Error> StorageRabbitMQ (rabbitmq_queue): Consumer failed on channel 1_0_jszgdneskjaowxnvmzfranujnhecmpsa. Reason: connection lost\r\n2021.09.24 09:36:17.729132 [ 13444 ] {} <Error> StorageRabbitMQ (rabbitmq_queue): Channel 1_0_jszgdneskjaowxnvmzfranujnhecmpsa error: connection lost\r\n2021.09.24 09:36:17.729157 [ 13444 ] {} <Error> StorageRabbitMQ (rabbitmq_queue): Library error report: connection lost\r\n2021.09.24 09:36:17.856382 [ 15130 ] {} <Fatal> BaseDaemon: ########################################\r\n2021.09.24 09:36:17.856456 [ 15130 ] {} <Fatal> BaseDaemon: (version 21.9.3.30 (official build), build id: 81039AF87A01EB4B61B52813A0E168AC9D46C3BC) (from thread 13443) (no query) Received signal Segmentation fault (11)\r\n2021.09.24 09:36:17.856489 [ 15130 ] {} <Fatal> BaseDaemon: Address: NULL pointer. Access: read. Address not mapped to object.\r\n2021.09.24 09:36:17.856518 [ 15130 ] {} <Fatal> BaseDaemon: Stack trace: 0x15a60bb9 0x15a5cf2d 0x15a52aff 0x15a5293b 0x15a5b865 0x11367b72 0x113715bd 0x1073a220 0x1073c297 0x1073d0d2 0x93a815f 0x93aba43 0x7f1775d4aea5 0x7f17756679fd\r\n2021.09.24 09:36:17.856823 [ 15130 ] {} <Fatal> BaseDaemon: 1. std::__1::vector<char, std::__1::allocator<char> >& std::__1::deque<std::__1::vector<char, std::__1::allocator<char> >, std::__1::allocator<std::__1::vector<char, std::__1::allocator<char> > > >::emplace_back<char const*&, char const*>(char const*&, char const*&&) @ 0x15a60bb9 in /usr/bin/clickhouse\r\n2021.09.24 09:36:17.856856 [ 15130 ] {} <Fatal> BaseDaemon: 2. AMQP::TcpResolver::send(char const*, unsigned long) @ 0x15a5cf2d in /usr/bin/clickhouse\r\n2021.09.24 09:36:17.856883 [ 15130 ] {} <Fatal> BaseDaemon: 3. AMQP::ConnectionImpl::send(AMQP::Frame const&) @ 0x15a52aff in /usr/bin/clickhouse\r\n2021.09.24 09:36:17.856905 [ 15130 ] {} <Fatal> BaseDaemon: 4. AMQP::ConnectionImpl::ConnectionImpl(AMQP::Connection*, AMQP::ConnectionHandler*, AMQP::Login const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) @ 0x15a5293b in /usr/bin/clickhouse\r\n2021.09.24 09:36:17.856924 [ 15130 ] {} <Fatal> BaseDaemon: 5. AMQP::TcpConnection::TcpConnection(AMQP::TcpHandler*, AMQP::Address const&) @ 0x15a5b865 in /usr/bin/clickhouse\r\n2021.09.24 09:36:17.856966 [ 15130 ] {} <Fatal> BaseDaemon: 6. DB::StorageRabbitMQ::restoreConnection(bool) @ 0x11367b72 in /usr/bin/clickhouse\r\n2021.09.24 09:36:17.856985 [ 15130 ] {} <Fatal> BaseDaemon: 7. DB::StorageRabbitMQ::streamingToViewsFunc() @ 0x113715bd in /usr/bin/clickhouse\r\n2021.09.24 09:36:17.857006 [ 15130 ] {} <Fatal> BaseDaemon: 8. DB::BackgroundSchedulePoolTaskInfo::execute() @ 0x1073a220 in /usr/bin/clickhouse\r\n2021.09.24 09:36:17.857023 [ 15130 ] {} <Fatal> BaseDaemon: 9. DB::BackgroundSchedulePool::threadFunction() @ 0x1073c297 in /usr/bin/clickhouse\r\n2021.09.24 09:36:17.857038 [ 15130 ] {} <Fatal> BaseDaemon: 10. ? @ 0x1073d0d2 in /usr/bin/clickhouse\r\n2021.09.24 09:36:17.857059 [ 15130 ] {} <Fatal> BaseDaemon: 11. ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) @ 0x93a815f in /usr/bin/clickhouse\r\n2021.09.24 09:36:17.857074 [ 15130 ] {} <Fatal> BaseDaemon: 12. ? @ 0x93aba43 in /usr/bin/clickhouse\r\n2021.09.24 09:36:17.857192 [ 15130 ] {} <Fatal> BaseDaemon: 13. start_thread @ 0x7ea5 in /usr/lib64/libpthread-2.17.so\r\n2021.09.24 09:36:17.857218 [ 15130 ] {} <Fatal> BaseDaemon: 14. __clone @ 0xfe9fd in /usr/lib64/libc-2.17.so\r\n2021.09.24 09:36:18.041700 [ 15130 ] {} <Fatal> BaseDaemon: Checksum of the binary: 01C4CC39E7C1C73FEDDD9FDB4397D6B8, integrity check passed.\r\n2021.09.24 09:36:27.855711 [ 13444 ] {} <Error> StorageRabbitMQ (rabbitmq_queue): Library error report: connection lost\r\n2021.09.24 09:36:38.097763 [ 13273 ] {} <Fatal> Application: Child process was terminated by signal 11.\r\n\r\n```\r\n\r\n\r\n**Additional context**\r\n\r\n> Add any other context about the problem here.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29315/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29315/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29314","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29314/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29314/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29314/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29314","id":1006131829,"node_id":"I_kwDOA5dJV847-Fp1","number":29314,"title":"Unable to use field name in where clause of a view created by another views","user":{"login":"nkthien","id":19279051,"node_id":"MDQ6VXNlcjE5Mjc5MDUx","avatar_url":"https://avatars.githubusercontent.com/u/19279051?v=4","gravatar_id":"","url":"https://api.github.com/users/nkthien","html_url":"https://github.com/nkthien","followers_url":"https://api.github.com/users/nkthien/followers","following_url":"https://api.github.com/users/nkthien/following{/other_user}","gists_url":"https://api.github.com/users/nkthien/gists{/gist_id}","starred_url":"https://api.github.com/users/nkthien/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/nkthien/subscriptions","organizations_url":"https://api.github.com/users/nkthien/orgs","repos_url":"https://api.github.com/users/nkthien/repos","events_url":"https://api.github.com/users/nkthien/events{/privacy}","received_events_url":"https://api.github.com/users/nkthien/received_events","type":"User","site_admin":false},"labels":[{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-09-24T06:36:36Z","updated_at":"2021-09-24T07:57:01Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"**Describe the unexpected behaviour**\r\nI have a view which is created from 2 other views (which are joined together).\r\nWhen I select from that view, it return normally but when I add a where clause which contains a field that is in that view, clickhouse throw exception said that: Missing column ... while processing query.\r\n\r\n**How to reproduce**\r\n* Which ClickHouse server version to use: yandex/clickhouse-server:21.7.6.39\r\n* Step to reproduce:\r\n```\r\n-- create a sample database and insert some mock data\r\nCREATE DATABASE view_error_example;\r\n\r\nCREATE TABLE view_error_example.employees\r\n(\r\n    `emp_id` UInt32,\r\n    `name` String,\r\n    `dept_id` UInt32,\r\n    `salary_id` UInt32\r\n)\r\nENGINE = MergeTree()\r\nORDER BY emp_id;\r\n\r\nCREATE TABLE view_error_example.departments\r\n(\r\n    `id` UInt32,\r\n    `name` String\r\n)\r\nENGINE = MergeTree\r\nORDER BY id;\r\n\r\nCREATE TABLE view_error_example.salaries\r\n(\r\n    `id` UInt32,\r\n    `amount` Float32\r\n)\r\nENGINE = MergeTree\r\nORDER BY id;\r\n\r\nINSERT INTO view_error_example.employees VALUES(1, 'John', 1, 1),(2, 'David', 1, 2),(3, 'Marry', 2, 3);\r\n\r\nINSERT INTO view_error_example.departments VALUES(1, 'Dev'),(2, 'Sale');\r\n\r\nINSERT INTO view_error_example.salaries VALUES(1, 99.0)(2, 123.0),(3, 80.5);\r\n```\r\n- create some views that lead to unexpected behavior:\r\n```\r\n-- create first view from 'employees' and 'departments' table:\r\nCREATE VIEW view_error_example.first_view AS\r\nSELECT *\r\nFROM view_error_example.employees AS e\r\nINNER JOIN view_error_example.departments AS d ON e.dept_id = d.id;\r\n\r\n-- create second view from 'employees' and 'salaries' table:\r\nCREATE VIEW view_error_example.second_view AS\r\nSELECT *\r\nFROM view_error_example.employees AS e\r\nINNER JOIN view_error_example.salaries AS s ON e.salary_id = s.id;\r\n\r\n-- create a view which is a joined view between the 2 above views:\r\nCREATE VIEW view_error_example.view_from_views AS\r\nSELECT *\r\nFROM view_error_example.first_view AS v1\r\nINNER JOIN view_error_example.second_view AS v2 ON v1.emp_id = v2.emp_id;\r\n```\r\nThe above table return a table like this:\r\n```\r\n┌─emp_id─┬─name──┬─dept_id─┬─salary_id─┬─id─┬─d.name─┬─v2.emp_id─┬─v2.name─┬─v2.dept_id─┬─v2.salary_id─┬─v2.id─┬─amount─┐\r\n│      1 │ John  │       1 │         1 │  1 │ Dev    │         1 │ John    │          1 │            1 │     1 │     99 │\r\n│      2 │ David │       1 │         2 │  1 │ Dev    │         2 │ David   │          1 │            2 │     2 │    123 │\r\n│      3 │ Marry │       2 │         3 │  2 │ Sale   │         3 │ Marry   │          2 │            3 │     3 │   80.5 │\r\n└────────┴───────┴─────────┴───────────┴────┴────────┴───────────┴─────────┴────────────┴──────────────┴───────┴────────┘\r\n\r\n```\r\n\r\n**Expected behavior**\r\nwhen i select: \r\n```\r\nSELECT v2.name\r\nFROM view_error_example.view_from_views\r\n```\r\nit's works fine:\r\n```\r\n┌─v2.name─┐\r\n│ John    │\r\n│ David   │\r\n│ Marry   │\r\n└─────────┘\r\n\r\n```\r\nbut when i select:\r\n```\r\nSELECT v2.name\r\nFROM view_error_example.view_from_views\r\nWHERE v2.name = 'John'\r\n```\r\n=> throw exception:  \r\nReceived exception from server (version 21.7.6):\r\n`\r\nCode: 47. DB::Exception: Received from localhost:9001. DB::Exception: Missing columns: 'v2.name' while processing query: 'SELECT emp_id FROM view_error_example.employees AS e ALL INNER JOIN view_error_example.departments AS d ON dept_id = id WHERE `v2.name` = 'John'', required columns: 'emp_id' 'dept_id' 'id' 'v2.name', maybe you meant: ['emp_id','dept_id'], joined columns: 'id' 'd.name'.\r\n`\r\n\r\nExpected behavior: it should return :\r\n```\r\n┌─v2.name─┐\r\n│ John    │\r\n└─────────┘\r\n```\r\n\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29314/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29314/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29287","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29287/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29287/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29287/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29287","id":1005197343,"node_id":"I_kwDOA5dJV8476hgf","number":29287,"title":"Connection reset by peer: While executing HDFS","user":{"login":"jiangdaokun","id":55648713,"node_id":"MDQ6VXNlcjU1NjQ4NzEz","avatar_url":"https://avatars.githubusercontent.com/u/55648713?v=4","gravatar_id":"","url":"https://api.github.com/users/jiangdaokun","html_url":"https://github.com/jiangdaokun","followers_url":"https://api.github.com/users/jiangdaokun/followers","following_url":"https://api.github.com/users/jiangdaokun/following{/other_user}","gists_url":"https://api.github.com/users/jiangdaokun/gists{/gist_id}","starred_url":"https://api.github.com/users/jiangdaokun/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jiangdaokun/subscriptions","organizations_url":"https://api.github.com/users/jiangdaokun/orgs","repos_url":"https://api.github.com/users/jiangdaokun/repos","events_url":"https://api.github.com/users/jiangdaokun/events{/privacy}","received_events_url":"https://api.github.com/users/jiangdaokun/received_events","type":"User","site_admin":false},"labels":[{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""},{"id":2192299304,"node_id":"MDU6TGFiZWwyMTkyMjk5MzA0","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-hdfs","name":"comp-hdfs","color":"b5bcff","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":4,"created_at":"2021-09-23T09:17:21Z","updated_at":"2021-09-24T07:10:37Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"ClickHouse server version: 21.8.3.44\r\nI want to use HDFS engine on Clickhouse, Here is the configuration information I added:\r\n<hdfs>\r\n        <hadoop_kerberos_keytab>/etc/hdfs1/conf/hdfs.keytab</hadoop_kerberos_keytab>\r\n        <hadoop_kerberos_principal>hdfs/tdh1@TDHTEST</hadoop_kerberos_principal>\r\n        <hadoop_security_authentication>kerberos</hadoop_security_authentication>\r\n        <hadoop_kerberos_kinit_command>kinit</hadoop_kerberos_kinit_command>\r\n        <libhdfs3_conf>/etc/clickhouse-server/hdfs-site.xml</libhdfs3_conf>\r\n</hdfs>\r\n\r\nIf my table on hive is empty, the query is OK ; but, if I insert into the hive table, the query will report an error:\r\n\r\nFail to read from HDFS: hdfs://127.0.0.1:8020, file path: /inceptor1/user/hive/warehouse/da.db/hbpangkun/base_agent_info/000000_0. Error: HdfsIOException: InputStreamImpl: cannot read file: /inceptor1/user/hive/warehouse/da.db/hbpangkun/base_agent_info/000000_0, from position 0, size: 1048576.\tCaused by: HdfsIOException: InputStreamImpl: all nodes have been tried and no valid replica can be read for Block: [block pool ID: BP-1374395306-127.0.0.1-1593786532593 block ID 1081074342_7334015].\t\tCaused by: HdfsNetworkException: Read 8 bytes failed from \"172.30.83.204:50010\": (errno: 104) Connection reset by peer: While executing HDFS (version 21.8.3.44 (official build))\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29287/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29287/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29269","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29269/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29269/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29269/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29269","id":1004541315,"node_id":"I_kwDOA5dJV8474BWD","number":29269,"title":"Index or partition filter doesn't work on `where` clause like `(index_key, partition_key)=(v1,v2)`","user":{"login":"lingtaolf","id":87509571,"node_id":"MDQ6VXNlcjg3NTA5NTcx","avatar_url":"https://avatars.githubusercontent.com/u/87509571?v=4","gravatar_id":"","url":"https://api.github.com/users/lingtaolf","html_url":"https://github.com/lingtaolf","followers_url":"https://api.github.com/users/lingtaolf/followers","following_url":"https://api.github.com/users/lingtaolf/following{/other_user}","gists_url":"https://api.github.com/users/lingtaolf/gists{/gist_id}","starred_url":"https://api.github.com/users/lingtaolf/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/lingtaolf/subscriptions","organizations_url":"https://api.github.com/users/lingtaolf/orgs","repos_url":"https://api.github.com/users/lingtaolf/repos","events_url":"https://api.github.com/users/lingtaolf/events{/privacy}","received_events_url":"https://api.github.com/users/lingtaolf/received_events","type":"User","site_admin":false},"labels":[{"id":386401507,"node_id":"MDU6TGFiZWwzODY0MDE1MDc=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/enhancement","name":"enhancement","color":"84b6eb","default":true,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-09-22T17:23:04Z","updated_at":"2021-09-22T23:21:53Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Describe what's wrong**\r\n\r\nWhen we put the primary key and another column in one tuple to filter data, the primary  key index wouldn't work and partition filter is as same.  \r\nThe sql which index or partition filter wouldn't work is like below:\r\n```sql\r\nSELECT * FROM t WHERE (primary_key, other_column) = (v1, v2);\r\n```\r\n----\r\n**How to reproduce**\r\nCreate table   \r\n```sql\r\ncreate table test.test (id UInt32, value String, log_date Date)   Engine=MergeTree() order by id partition by log_date settings index_granularity=3\r\n```  \r\nInsert data  \r\n```sql\r\n insert into test.test values (1, 'A','2021-01-01'),(2,'B','2021-01-01'),(3,'C','2021-01-01'),(4,'D','2021-01-02'),(5,'E','2021-01-02')\r\n```  \r\nQuery   \r\n```\r\nselect * from test.test where (id, value) = (1, 'A');  \r\nOR\r\nselect * from test.test where (log_date, value) = ('2021-01-01', 'A');  \r\n```  \r\nAfter querying, we can get the `read_rows` by querying table `system.query_log` with the `query_id` .    \r\n`select query, read_rows from system.query_log where query_id='<query_id>' and type=2;`  \r\n\r\nWe can find the query `select * from test.test where (id, value) = (1, 'A')` will read all 5 rows, but `select * from test.test where id = 1 and value = 'A' ` will only read 3 rows.\r\n\r\n----  \r\n\r\n**Expected behavior**\r\n\r\n```text\r\n┌─query─────────────────────────────────────────────────┬─read_rows─┐\r\n│ select * from test.test where (id, value) = (1, 'A'); │         3 │\r\n└───────────────────────────────────────────────────────┴───────────┘\r\n```\r\n\r\n**Actual get**\r\n```text\r\n┌─query─────────────────────────────────────────────────┬─read_rows─┐\r\n│ select * from test.test where (id, value) = (1, 'A'); │         5 │\r\n└───────────────────────────────────────────────────────┴───────────┘\r\n```\r\n\r\n----\r\n\r\n**Additional context**\r\nWe found this problem while using clickhouse-copier. It will check partition data on shard use query like `select 1 from t where (k1, k2,...) = (v1,v2,...)` and the progress will take a long time to get the result ,even if we just copy one partition.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29269/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29269/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29263","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29263/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29263/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29263/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29263","id":1004374726,"node_id":"I_kwDOA5dJV8473YrG","number":29263,"title":"DB::Exception: No interserver IO endpoint named DataPartsExchange","user":{"login":"EminemJK","id":33885904,"node_id":"MDQ6VXNlcjMzODg1OTA0","avatar_url":"https://avatars.githubusercontent.com/u/33885904?v=4","gravatar_id":"","url":"https://api.github.com/users/EminemJK","html_url":"https://github.com/EminemJK","followers_url":"https://api.github.com/users/EminemJK/followers","following_url":"https://api.github.com/users/EminemJK/following{/other_user}","gists_url":"https://api.github.com/users/EminemJK/gists{/gist_id}","starred_url":"https://api.github.com/users/EminemJK/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/EminemJK/subscriptions","organizations_url":"https://api.github.com/users/EminemJK/orgs","repos_url":"https://api.github.com/users/EminemJK/repos","events_url":"https://api.github.com/users/EminemJK/events{/privacy}","received_events_url":"https://api.github.com/users/EminemJK/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2021-09-22T14:34:52Z","updated_at":"2021-09-24T01:50:24Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Both server01 and server02 are running properly，an error occurred on server03 only：\r\n```\r\n2021.09.22 22:19:30.719479 [ 432 ] {} <Error> InterserverIOHTTPHandler: Code: 221, e.displayText() = DB::Exception: No interserver IO endpoint named DataPartsExchange:/clickhouse/tables/01-01/dlb_ZC_ZGB_IISlogs/replicas/cluster01-01-1, Stack trace (when copying this message, always include the lines below):\r\n\r\n0. DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, bool) @ 0x8d3151a in /usr/bin/clickhouse\r\n1. DB::InterserverIOHandler::getEndpoint(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) @ 0x10644c16 in /usr/bin/clickhouse\r\n2. DB::InterserverIOHTTPHandler::processQuery(DB::HTTPServerRequest&, DB::HTTPServerResponse&, DB::InterserverIOHTTPHandler::Output&) @ 0x106444c1 in /usr/bin/clickhouse\r\n3. DB::InterserverIOHTTPHandler::handleRequest(DB::HTTPServerRequest&, DB::HTTPServerResponse&) @ 0x10644f63 in /usr/bin/clickhouse\r\n4. DB::HTTPServerConnection::run() @ 0x106b6a10 in /usr/bin/clickhouse\r\n5. Poco::Net::TCPServerConnection::start() @ 0x133869cf in /usr/bin/clickhouse\r\n6. Poco::Net::TCPServerDispatcher::run() @ 0x1338845a in /usr/bin/clickhouse\r\n7. Poco::PooledThread::run() @ 0x134bb2d9 in /usr/bin/clickhouse\r\n8. Poco::ThreadImpl::runnableEntry(void*) @ 0x134b756a in /usr/bin/clickhouse\r\n9. start_thread @ 0x9609 in /usr/lib/x86_64-linux-gnu/libpthread-2.31.so\r\n10. clone @ 0x122293 in /usr/lib/x86_64-linux-gnu/libc-2.31.so\r\n (version 21.7.6.39 (official build))\r\n\r\n```\r\nmetrika.xml\r\n```\r\n<yandex>\r\n    <!-- 集群配置 -->\r\n     <clickhouse_remote_servers>\r\n        <cluster_3s_1r>\r\n            <!-- 数据分片1  -->\r\n            <shard>\r\n                <internal_replication>true</internal_replication>\r\n                <replica>\r\n                    <host>server01</host>\r\n                    <port>9000</port>\r\n                    <user>default</user>\r\n                    <password>_CLUster0369</password>\r\n                </replica>\r\n                <replica>\r\n                    <host>server03</host>\r\n                    <port>9001</port>\r\n                    <user>default</user>\r\n                    <password>_CLUster0369</password>\r\n                </replica>\r\n            </shard>\r\n            <!-- 数据分片2  -->\r\n            <shard>\r\n                <internal_replication>true</internal_replication>\r\n                <replica>\r\n                    <host>server02</host>\r\n                    <port>9000</port>\r\n                    <user>default</user>\r\n                    <password>_CLUster0369</password>\r\n                </replica>\r\n                <replica>\r\n                    <host>server01</host>\r\n                    <port>9001</port>\r\n                    <user>default</user>\r\n                    <password>_CLUster0369</password>\r\n                </replica>\r\n            </shard>\r\n            <!-- 数据分片3  -->\r\n            <shard>\r\n                <internal_replication>true</internal_replication>\r\n                <replica>\r\n                    <host>server03</host>\r\n                    <port>9000</port>\r\n                    <user>default</user>\r\n                    <password>_CLUster0369</password>\r\n                </replica>\r\n                <replica>\r\n                    <host>server02</host>\r\n                    <port>9001</port>\r\n                    <user>default</user>\r\n                    <password>_CLUster0369</password>\r\n                </replica>\r\n            </shard>\r\n        </cluster_3s_1r>\r\n    </clickhouse_remote_servers>\r\n\r\n    <!-- zookeeper_servers所有实例配置都一样 -->\r\n    <zookeeper-servers>\r\n        <node index=\"1\">\r\n            <host>172.16.13.10</host>\r\n            <port>2181</port>\r\n        </node>\r\n        <node index=\"2\">\r\n            <host>172.16.13.11</host>\r\n            <port>2181</port>\r\n        </node>\r\n        <node index=\"3\">\r\n            <host>172.16.13.12</host>\r\n            <port>2181</port>\r\n        </node>\r\n    </zookeeper-servers>\r\n    \r\n    <!-- marcos每个实例配置不一样 分片1, 副本1 -->   \r\n    <macros>\r\n        <layer>01</layer>\r\n        <shard>03</shard>\r\n        <replica>cluster01-03-1</replica>\r\n    </macros>\r\n\r\n\r\n    <networks>\r\n        <ip>::/0</ip>\r\n    </networks>\r\n\r\n    <!-- 数据压缩算法  -->\r\n    <clickhouse_compression>\r\n        <case>\r\n            <min_part_size>10000000000</min_part_size>\r\n            <min_part_size_ratio>0.01</min_part_size_ratio>\r\n            <method>lz4</method>\r\n        </case>\r\n    </clickhouse_compression>\r\n\r\n</yandex>\r\n```\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29263/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29263/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29226","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29226/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29226/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29226/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29226","id":1002772275,"node_id":"I_kwDOA5dJV847xRcz","number":29226,"title":"Creating a view fails with EMPTY_LIST_OF_COLUMNS_QUERIED (even though they are there)","user":{"login":"wirtsi","id":276751,"node_id":"MDQ6VXNlcjI3Njc1MQ==","avatar_url":"https://avatars.githubusercontent.com/u/276751?v=4","gravatar_id":"","url":"https://api.github.com/users/wirtsi","html_url":"https://github.com/wirtsi","followers_url":"https://api.github.com/users/wirtsi/followers","following_url":"https://api.github.com/users/wirtsi/following{/other_user}","gists_url":"https://api.github.com/users/wirtsi/gists{/gist_id}","starred_url":"https://api.github.com/users/wirtsi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/wirtsi/subscriptions","organizations_url":"https://api.github.com/users/wirtsi/orgs","repos_url":"https://api.github.com/users/wirtsi/repos","events_url":"https://api.github.com/users/wirtsi/events{/privacy}","received_events_url":"https://api.github.com/users/wirtsi/received_events","type":"User","site_admin":false},"labels":[{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-09-21T16:01:24Z","updated_at":"2021-09-22T12:29:37Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"**Describe the unexpected behaviour**\r\nI am using the Star Schema Benchmark dataset and am trying to do this\r\n\r\n* Instead of generating the lineorder_flat table and populating it with data, I would like to create a VIEW\r\n\r\n\r\n**How to reproduce**\r\n* Version 21.11.1.8140 with revision 54456, no build id, PID 65909\r\n* CLI\r\n\r\n```\r\nCREATE VIEW lineorder_flat_view\r\nAS SELECT\r\n    l.LO_ORDERKEY AS LO_ORDERKEY,\r\n    l.LO_LINENUMBER AS LO_LINENUMBER,\r\n    l.LO_CUSTKEY AS LO_CUSTKEY,\r\n    l.LO_PARTKEY AS LO_PARTKEY,\r\n    l.LO_SUPPKEY AS LO_SUPPKEY,\r\n    l.LO_ORDERDATE AS LO_ORDERDATE,\r\n    l.LO_ORDERPRIORITY AS LO_ORDERPRIORITY,\r\n    l.LO_SHIPPRIORITY AS LO_SHIPPRIORITY,\r\n    l.LO_QUANTITY AS LO_QUANTITY,\r\n    l.LO_EXTENDEDPRICE AS LO_EXTENDEDPRICE,\r\n    l.LO_ORDTOTALPRICE AS LO_ORDTOTALPRICE,\r\n    l.LO_DISCOUNT AS LO_DISCOUNT,\r\n    l.LO_REVENUE AS LO_REVENUE,\r\n    l.LO_SUPPLYCOST AS LO_SUPPLYCOST,\r\n    l.LO_TAX AS LO_TAX,\r\n    l.LO_COMMITDATE AS LO_COMMITDATE,\r\n    l.LO_SHIPMODE AS LO_SHIPMODE,\r\n    c.C_NAME AS C_NAME,\r\n    c.C_ADDRESS AS C_ADDRESS,\r\n    c.C_CITY AS C_CITY,\r\n    c.C_NATION AS C_NATION,\r\n    c.C_REGION AS C_REGION,\r\n    c.C_PHONE AS C_PHONE,\r\n    c.C_MKTSEGMENT AS C_MKTSEGMENT,\r\n    s.S_NAME AS S_NAME,\r\n    s.S_ADDRESS AS S_ADDRESS,\r\n    s.S_CITY AS S_CITY,\r\n    s.S_NATION AS S_NATION,\r\n    s.S_REGION AS S_REGION,\r\n    s.S_PHONE AS S_PHONE,\r\n    p.P_NAME AS P_NAME,\r\n    p.P_MFGR AS P_MFGR,\r\n    p.P_CATEGORY AS P_CATEGORY,\r\n    p.P_BRAND AS P_BRAND,\r\n    p.P_COLOR AS P_COLOR,\r\n    p.P_TYPE AS P_TYPE,\r\n    p.P_SIZE AS P_SIZE,\r\n    p.P_CONTAINER AS P_CONTAINER\r\nFROM lineorder AS l\r\nINNER JOIN customer AS c ON c.C_CUSTKEY = l.LO_CUSTKEY\r\nINNER JOIN supplier AS s ON s.S_SUPPKEY = l.LO_SUPPKEY\r\nINNER JOIN part AS p ON p.P_PARTKEY = l.LO_PARTKEY;\r\n```\r\n\r\nGives me these errors in the server console\r\n\r\n```\r\n2021.09.21 17:59:47.848269 [ 1994917 ] {6ada474d-9c2d-4cac-bc7c-a6fc76d783bb} <Error> executeQuery: Code: 51. DB::Exception: Empty list of columns in SELECT query. (EMPTY_LIST_OF_COLUMNS_QUERIED) (version 21.11.1.8140 (official build)) (from 127.0.0.1:63175) (in query: CREATE VIEW lineorder_flat_view AS SELECT l.LO_ORDERKEY AS LO_ORDERKEY, l.LO_LINENUMBER AS LO_LINENUMBER, l.LO_CUSTKEY AS LO_CUSTKEY, l.LO_PARTKEY AS LO_PARTKEY, l.LO_SUPPKEY AS LO_SUPPKEY, l.LO_ORDERDATE AS LO_ORDERDATE, l.LO_ORDERPRIORITY AS LO_ORDERPRIORITY, l.LO_SHIPPRIORITY AS LO_SHIPPRIORITY, l.LO_QUANTITY AS LO_QUANTITY, l.LO_EXTENDEDPRICE AS LO_EXTENDEDPRICE, l.LO_ORDTOTALPRICE AS LO_ORDTOTALPRICE, l.LO_DISCOUNT AS LO_DISCOUNT, l.LO_REVENUE AS LO_REVENUE, l.LO_SUPPLYCOST AS LO_SUPPLYCOST, l.LO_TAX AS LO_TAX, l.LO_COMMITDATE AS LO_COMMITDATE, l.LO_SHIPMODE AS LO_SHIPMODE, c.C_NAME AS C_NAME, c.C_ADDRESS AS C_ADDRESS, c.C_CITY AS C_CITY, c.C_NATION AS C_NATION, c.C_REGION AS C_REGION, c.C_PHONE AS C_PHONE, c.C_MKTSEGMENT AS C_MKTSEGMENT, s.S_NAME AS S_NAME, s.S_ADDRESS AS S_ADDRESS, s.S_CITY AS S_CITY, s.S_NATION AS S_NATION, s.S_REGION AS S_REGION, s.S_PHONE AS S_PHONE, p.P_NAME AS P_NAME, p.P_MFGR AS P_MFGR, p.P_CATEGORY AS P_CATEGORY, p.P_BRAND AS P_BRAND, p.P_COLOR AS P_COLOR, p.P_TYPE AS P_TYPE, p.P_SIZE AS P_SIZE, p.P_CONTAINER AS P_CONTAINER FROM lineorder AS l INNER JOIN customer AS c ON c.C_CUSTKEY = l.LO_CUSTKEY INNER JOIN supplier AS s ON s.S_SUPPKEY = l.LO_SUPPKEY INNER JOIN part AS p ON p.P_PARTKEY = l.LO_PARTKEY;), Stack trace (when copying this message, always include the lines below):\r\n\r\n<Empty trace>\r\n\r\n2021.09.21 17:59:47.848379 [ 1994917 ] {6ada474d-9c2d-4cac-bc7c-a6fc76d783bb} <Error> TCPHandler: Code: 51. DB::Exception: Empty list of columns in SELECT query. (EMPTY_LIST_OF_COLUMNS_QUERIED), Stack trace (when copying this message, always include the lines below):\r\n\r\n<Empty trace>\r\n```\r\n\r\n\r\n**Expected behavior**\r\nI would expect the creation of the view to succeed\r\n\r\n\r\nThanks :-)\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29226/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29226/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29210","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29210/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29210/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29210/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29210","id":1001891901,"node_id":"I_kwDOA5dJV847t6g9","number":29210,"title":"MergeTreeSink.cpp:22:24: address does not point to an object of type StorageMergeTree","user":{"login":"tavplubix","id":14847450,"node_id":"MDQ6VXNlcjE0ODQ3NDUw","avatar_url":"https://avatars.githubusercontent.com/u/14847450?v=4","gravatar_id":"","url":"https://api.github.com/users/tavplubix","html_url":"https://github.com/tavplubix","followers_url":"https://api.github.com/users/tavplubix/followers","following_url":"https://api.github.com/users/tavplubix/following{/other_user}","gists_url":"https://api.github.com/users/tavplubix/gists{/gist_id}","starred_url":"https://api.github.com/users/tavplubix/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tavplubix/subscriptions","organizations_url":"https://api.github.com/users/tavplubix/orgs","repos_url":"https://api.github.com/users/tavplubix/repos","events_url":"https://api.github.com/users/tavplubix/events{/privacy}","received_events_url":"https://api.github.com/users/tavplubix/received_events","type":"User","site_admin":false},"labels":[{"id":1955634273,"node_id":"MDU6TGFiZWwxOTU1NjM0Mjcz","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/testing","name":"testing","color":"c9a224","default":false,"description":"Special issue with list of bugs found by CI"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-09-21T05:29:09Z","updated_at":"2021-10-22T09:19:33Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"https://clickhouse-test-reports.s3.yandex.net/0/1932d29ed14cac2c694779d48dc072d3d3a89809/stress_test_(undefined).html#fail1\r\n\r\n```\r\n../src/Storages/MergeTree/MergeTreeSink.cpp:22:24: runtime error: member access within address 0x7f61644ef270 which does not point to an object of type 'DB::StorageMergeTree'\r\n0x7f61644ef270: note: object has invalid vptr\r\n 00 00 00 00  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  00 00 00 00\r\n              ^~~~~~~~~~~~~~~~~~~~~~~\r\n              invalid vptr\r\n    #0 0x1c0ce91b in DB::MergeTreeSink::consume(DB::Chunk) obj-x86_64-linux-gnu/../src/Storages/MergeTree/MergeTreeSink.cpp:22:32\r\n    #1 0x1c26d759 in DB::ISink::work() obj-x86_64-linux-gnu/../src/Processors/ISink.cpp:47:9\r\n    #2 0x1b0de6c3 in DB::PushingToSinkBlockOutputStream::write(DB::Block const&) obj-x86_64-linux-gnu/../src/DataStreams/PushingToSinkBlockOutputStream.h:40:27\r\n    #3 0x1b0e681d in DB::PushingToViewsBlockOutputStream::write(DB::Block const&) obj-x86_64-linux-gnu/../src/DataStreams/PushingToViewsBlockOutputStream.cpp:255:21\r\n    #4 0x1b0f3a48 in DB::AddingDefaultBlockOutputStream::write(DB::Block const&) obj-x86_64-linux-gnu/../src/DataStreams/AddingDefaultBlockOutputStream.cpp:25:13\r\n    #5 0x1b0f4498 in DB::SquashingBlockOutputStream::finalize() obj-x86_64-linux-gnu/../src/DataStreams/SquashingBlockOutputStream.cpp:30:17\r\n    #6 0x1b0f48e7 in DB::SquashingBlockOutputStream::writeSuffix() obj-x86_64-linux-gnu/../src/DataStreams/SquashingBlockOutputStream.cpp:50:5\r\n    #7 0x1c2b9c78 in DB::executeJob(DB::IProcessor*) obj-x86_64-linux-gnu/../src/Processors/Executors/PipelineExecutor.cpp:88:20\r\n    #8 0x1c2b9b66 in DB::PipelineExecutor::addJob(DB::ExecutingGraph::Node*)::$_0::operator()() const obj-x86_64-linux-gnu/../src/Processors/Executors/PipelineExecutor.cpp:105:13\r\n    #9 0x1c2b9b66 in decltype(std::__1::forward<DB::PipelineExecutor::addJob(DB::ExecutingGraph::Node*)::$_0&>(fp)()) std::__1::__invoke<DB::PipelineExecutor::addJob(DB::ExecutingGraph::Node*)::$_0&>(DB::PipelineExecutor::addJob(DB::ExecutingGraph::Node*)::$_0&) obj-x86_64-linux-gnu/../contrib/libcxx/include/type_traits:3676:1\r\n    #10 0x1c2b8107 in std::__1::__function::__policy_func<void ()>::operator()() const obj-x86_64-linux-gnu/../contrib/libcxx/include/functional:2221:16\r\n    #11 0x1c2b8107 in std::__1::function<void ()>::operator()() const obj-x86_64-linux-gnu/../contrib/libcxx/include/functional:2560:12\r\n    #12 0x1c2b8107 in DB::PipelineExecutor::executeStepImpl(unsigned long, unsigned long, std::__1::atomic<bool>*) obj-x86_64-linux-gnu/../src/Processors/Executors/PipelineExecutor.cpp:597:17\r\n    #13 0x1c2ba549 in DB::PipelineExecutor::executeSingleThread(unsigned long, unsigned long) obj-x86_64-linux-gnu/../src/Processors/Executors/PipelineExecutor.cpp:485:5\r\n    #14 0x1c2ba549 in DB::PipelineExecutor::executeImpl(unsigned long)::$_4::operator()() const obj-x86_64-linux-gnu/../src/Processors/Executors/PipelineExecutor.cpp:788:21\r\n    #15 0x1c2ba549 in decltype(std::__1::forward<DB::PipelineExecutor::executeImpl(unsigned long)::$_4&>(fp)()) std::__1::__invoke_constexpr<DB::PipelineExecutor::executeImpl(unsigned long)::$_4&>(DB::PipelineExecutor::executeImpl(unsigned long)::$_4&) obj-x86_64-linux-gnu/../contrib/libcxx/include/type_traits:3682:1\r\n    #16 0x1c2ba422 in decltype(auto) std::__1::__apply_tuple_impl<DB::PipelineExecutor::executeImpl(unsigned long)::$_4&, std::__1::tuple<>&>(DB::PipelineExecutor::executeImpl(unsigned long)::$_4&, std::__1::tuple<>&, std::__1::__tuple_indices<>) obj-x86_64-linux-gnu/../contrib/libcxx/include/tuple:1415:1\r\n    #17 0x1c2ba422 in decltype(auto) std::__1::apply<DB::PipelineExecutor::executeImpl(unsigned long)::$_4&, std::__1::tuple<>&>(DB::PipelineExecutor::executeImpl(unsigned long)::$_4&, std::__1::tuple<>&) obj-x86_64-linux-gnu/../contrib/libcxx/include/tuple:1424:1\r\n    #18 0x1c2ba422 in ThreadFromGlobalPool::ThreadFromGlobalPool<DB::PipelineExecutor::executeImpl(unsigned long)::$_4>(DB::PipelineExecutor::executeImpl(unsigned long)::$_4&&)::'lambda'()::operator()() obj-x86_64-linux-gnu/../src/Common/ThreadPool.h:188:13\r\n    #19 0x1c2ba422 in decltype(std::__1::forward<DB::PipelineExecutor::executeImpl(unsigned long)::$_4>(fp)()) std::__1::__invoke<ThreadFromGlobalPool::ThreadFromGlobalPool<DB::PipelineExecutor::executeImpl(unsigned long)::$_4>(DB::PipelineExecutor::executeImpl(unsigned long)::$_4&&)::'lambda'()&>(DB::PipelineExecutor::executeImpl(unsigned long)::$_4&&) obj-x86_64-linux-gnu/../contrib/libcxx/include/type_traits:3676:1\r\n    #20 0xc730a79 in std::__1::__function::__policy_func<void ()>::operator()() const obj-x86_64-linux-gnu/../contrib/libcxx/include/functional:2221:16\r\n    #21 0xc730a79 in std::__1::function<void ()>::operator()() const obj-x86_64-linux-gnu/../contrib/libcxx/include/functional:2560:12\r\n    #22 0xc730a79 in ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) obj-x86_64-linux-gnu/../src/Common/ThreadPool.cpp:274:17\r\n    #23 0xc733481 in void ThreadPoolImpl<std::__1::thread>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda0'()::operator()() const obj-x86_64-linux-gnu/../src/Common/ThreadPool.cpp:139:73\r\n    #24 0xc733481 in decltype(std::__1::forward<void>(fp)()) std::__1::__invoke<void ThreadPoolImpl<std::__1::thread>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda0'()>(void&&) obj-x86_64-linux-gnu/../contrib/libcxx/include/type_traits:3676:1\r\n    #25 0xc733481 in void std::__1::__thread_execute<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, void ThreadPoolImpl<std::__1::thread>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda0'()>(std::__1::tuple<void, void ThreadPoolImpl<std::__1::thread>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda0'()>&, std::__1::__tuple_indices<>) obj-x86_64-linux-gnu/../contrib/libcxx/include/thread:280:5\r\n    #26 0xc733481 in void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, void ThreadPoolImpl<std::__1::thread>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda0'()> >(void*) obj-x86_64-linux-gnu/../contrib/libcxx/include/thread:291:5\r\n    #27 0x7f6661b74608 in start_thread (/lib/x86_64-linux-gnu/libpthread.so.0+0x9608)\r\n    #28 0x7f6661a9b292 in __clone (/lib/x86_64-linux-gnu/libc.so.6+0x122292)\r\n\r\nSUMMARY: UndefinedBehaviorSanitizer: undefined-behavior ../src/Storages/MergeTree/MergeTreeSink.cpp:22:24 in \r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29210/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29210/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29189","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29189/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29189/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29189/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29189","id":1000915523,"node_id":"I_kwDOA5dJV847qMJD","number":29189,"title":"Broken UTF8 character in string make LIKE works incorrectly","user":{"login":"filimonov","id":1549571,"node_id":"MDQ6VXNlcjE1NDk1NzE=","avatar_url":"https://avatars.githubusercontent.com/u/1549571?v=4","gravatar_id":"","url":"https://api.github.com/users/filimonov","html_url":"https://github.com/filimonov","followers_url":"https://api.github.com/users/filimonov/followers","following_url":"https://api.github.com/users/filimonov/following{/other_user}","gists_url":"https://api.github.com/users/filimonov/gists{/gist_id}","starred_url":"https://api.github.com/users/filimonov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/filimonov/subscriptions","organizations_url":"https://api.github.com/users/filimonov/orgs","repos_url":"https://api.github.com/users/filimonov/repos","events_url":"https://api.github.com/users/filimonov/events{/privacy}","received_events_url":"https://api.github.com/users/filimonov/received_events","type":"User","site_admin":false},"labels":[{"id":785082162,"node_id":"MDU6TGFiZWw3ODUwODIxNjI=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-documentation","name":"comp-documentation","color":"b5bcff","default":false,"description":"Used to run automatic builds of the documentation"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-09-20T12:31:49Z","updated_at":"2021-09-20T20:32:14Z","closed_at":null,"author_association":"COLLABORATOR","active_lock_reason":null,"body":"> https://clickhouse.com/docs/en/sql-reference/functions/string-search-functions/#function-like\r\n> `_` indicates any one byte.\r\n\r\nit's not. It looks like it [uses UTF8](https://github.com/google/re2/blob/123d379e288f3c113c26dca952d78ad5f4fc98fd/re2/re2.h#L59-L62) by default \r\n\r\nand `_` matches a single character (not a single byte)\r\n\r\n```\r\n\r\nWITH \r\n  'Любя, съешь щипцы, — вздохнёт мэр, — кайф жгуч' as s1,\r\n  'Любя\\xFF\\xFF\\xFFщипцы' as s2,\r\n  '%Л__я%щ_п_ы%' as like_expr1,\r\n  /* '%Л__я%\\xFF%щ_п_ы%' as like_expr2,  --  OptimizedRegularExpression: cannot compile re2: Л..я.*�.*щ.п.ы, error: invalid UTF-8. */\r\n  'Л..я.*щ.п.ы' as regexp1\r\n  /* 'Л..я.*\\xFF.*щ.п.ы' as regexp2 --  OptimizedRegularExpression: cannot compile re2: Л..я.*�.*щ.п.ы, error: invalid UTF-8. */\r\nSELECT \r\n  s1 LIKE like_expr1,\r\n  s1 ILIKE like_expr1,\r\n  s2 LIKE like_expr1,\r\n  s2 ILIKE like_expr1,\r\n  match(s1, regexp1),\r\n  match(s2, regexp1);\r\n\r\n\r\nQuery id: 2928950e-df47-4e61-aeff-3a671d8d5d1a\r\n\r\nRow 1:\r\n──────\r\nlike(s1, like_expr1):  1\r\nilike(s1, like_expr1): 1\r\nlike(s2, like_expr1):  0\r\nilike(s2, like_expr1): 0\r\nmatch(s1, regexp1):    1\r\nmatch(s2, regexp1):    0\r\n\r\n1 rows in set. Elapsed: 0.003 sec. \r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29189/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29189/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29188","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29188/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29188/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29188/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29188","id":1000833928,"node_id":"I_kwDOA5dJV847p4OI","number":29188,"title":"Ability to use aliases in user-defined functions (CREATE FUNCTION statement)","user":{"login":"vpanfilov","id":11993879,"node_id":"MDQ6VXNlcjExOTkzODc5","avatar_url":"https://avatars.githubusercontent.com/u/11993879?v=4","gravatar_id":"","url":"https://api.github.com/users/vpanfilov","html_url":"https://github.com/vpanfilov","followers_url":"https://api.github.com/users/vpanfilov/followers","following_url":"https://api.github.com/users/vpanfilov/following{/other_user}","gists_url":"https://api.github.com/users/vpanfilov/gists{/gist_id}","starred_url":"https://api.github.com/users/vpanfilov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vpanfilov/subscriptions","organizations_url":"https://api.github.com/users/vpanfilov/orgs","repos_url":"https://api.github.com/users/vpanfilov/repos","events_url":"https://api.github.com/users/vpanfilov/events{/privacy}","received_events_url":"https://api.github.com/users/vpanfilov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":{"login":"kitaisreal","id":22458333,"node_id":"MDQ6VXNlcjIyNDU4MzMz","avatar_url":"https://avatars.githubusercontent.com/u/22458333?v=4","gravatar_id":"","url":"https://api.github.com/users/kitaisreal","html_url":"https://github.com/kitaisreal","followers_url":"https://api.github.com/users/kitaisreal/followers","following_url":"https://api.github.com/users/kitaisreal/following{/other_user}","gists_url":"https://api.github.com/users/kitaisreal/gists{/gist_id}","starred_url":"https://api.github.com/users/kitaisreal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kitaisreal/subscriptions","organizations_url":"https://api.github.com/users/kitaisreal/orgs","repos_url":"https://api.github.com/users/kitaisreal/repos","events_url":"https://api.github.com/users/kitaisreal/events{/privacy}","received_events_url":"https://api.github.com/users/kitaisreal/received_events","type":"User","site_admin":false},"assignees":[{"login":"kitaisreal","id":22458333,"node_id":"MDQ6VXNlcjIyNDU4MzMz","avatar_url":"https://avatars.githubusercontent.com/u/22458333?v=4","gravatar_id":"","url":"https://api.github.com/users/kitaisreal","html_url":"https://github.com/kitaisreal","followers_url":"https://api.github.com/users/kitaisreal/followers","following_url":"https://api.github.com/users/kitaisreal/following{/other_user}","gists_url":"https://api.github.com/users/kitaisreal/gists{/gist_id}","starred_url":"https://api.github.com/users/kitaisreal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kitaisreal/subscriptions","organizations_url":"https://api.github.com/users/kitaisreal/orgs","repos_url":"https://api.github.com/users/kitaisreal/repos","events_url":"https://api.github.com/users/kitaisreal/events{/privacy}","received_events_url":"https://api.github.com/users/kitaisreal/received_events","type":"User","site_admin":false}],"milestone":null,"comments":2,"created_at":"2021-09-20T11:01:53Z","updated_at":"2021-10-20T09:39:12Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Starting with Clickhouse  version 21.10, it is possible to define custom function with lambda-expression inside CREATE FUNCTION statement. But it is not possible to use aliases inside lambda-expressions:\r\n```sql\r\nCREATE FUNCTION testAlias AS x -> (((x * 2) AS x_doubled) + x_doubled)\r\n\r\nReceived exception from server (version 21.10.1):\r\nCode: 47. DB::Exception: Received from localhost:9000. DB::Exception: Identifier `x_doubled` does not exist in arguments. (UNKNOWN_IDENTIFIER)\r\n```\r\n\r\nIt would be perfect if it was possible to place all aliases before main lambda expression. I mean something like that:\r\n```sql\r\nCREATE FUNCTION testAlias AS x ->\r\nWITH\r\n  x * 2 AS x_doubled,\r\n  pow(x,2) AS x_squared\r\nRETURN\r\n  x_doubled + x_squared\r\n```\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29188/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29188/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29187","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29187/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29187/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29187/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29187","id":1000816211,"node_id":"I_kwDOA5dJV847pz5T","number":29187,"title":"Conversion between DateTime64 and Date32 is not supported yet","user":{"login":"vpanfilov","id":11993879,"node_id":"MDQ6VXNlcjExOTkzODc5","avatar_url":"https://avatars.githubusercontent.com/u/11993879?v=4","gravatar_id":"","url":"https://api.github.com/users/vpanfilov","html_url":"https://github.com/vpanfilov","followers_url":"https://api.github.com/users/vpanfilov/followers","following_url":"https://api.github.com/users/vpanfilov/following{/other_user}","gists_url":"https://api.github.com/users/vpanfilov/gists{/gist_id}","starred_url":"https://api.github.com/users/vpanfilov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vpanfilov/subscriptions","organizations_url":"https://api.github.com/users/vpanfilov/orgs","repos_url":"https://api.github.com/users/vpanfilov/repos","events_url":"https://api.github.com/users/vpanfilov/events{/privacy}","received_events_url":"https://api.github.com/users/vpanfilov/received_events","type":"User","site_admin":false},"labels":[{"id":1397894054,"node_id":"MDU6TGFiZWwxMzk3ODk0MDU0","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unfinished%20code","name":"unfinished code","color":"ff8800","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":5,"created_at":"2021-09-20T10:40:09Z","updated_at":"2021-09-30T07:15:25Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Conversion from DateTime64 to Date32 is not supported yet, so it is not possible at all to get date from extended range of DateTime64, dates will be narrowed to somewhere between 1970-2105 range.\r\n\r\n```sql\r\nSELECT toDate32(now64())\r\n```\r\n```sql\r\nReceived exception from server (version 21.10.1):\r\nCode: 70. DB::Exception: Received from localhost:9000. DB::Exception: Unsupported data type in conversion function: While processing toDate32(now64()). (CANNOT_CONVERT_TYPE)\r\n```\r\n\r\nConversion of value from extended range with `toDate()`\r\n```sql\r\nSELECT toDate(toDateTime64('1925-01-01 12:34:56', 3))\r\n\r\n┌─toDate(toDateTime64('1925-01-01 12:34:56', 3))─┐\r\n│                                     2104-06-07 │\r\n└────────────────────────────────────────────────┘\r\n```\r\n\r\nConversion of value from extended range with `toDateTime()`\r\n```sql\r\nSELECT toDateTime(toDateTime64('1925-01-01 12:34:56', 3))\r\n\r\n┌─toDateTime(toDateTime64('1925-01-01 12:34:56', 3))─┐\r\n│                                2061-02-06 19:03:12 │\r\n└────────────────────────────────────────────────────┘\r\n```\r\n\r\nTested on Clickhouse version:\r\n```sql\r\nSELECT version()\r\n┌─version()────┐\r\n│ 21.10.1.8013 │\r\n└──────────────┘\r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29187/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29187/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29185","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29185/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29185/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29185/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29185","id":1000592055,"node_id":"I_kwDOA5dJV847o9K3","number":29185,"title":"How to control MySQL Connection Pool Settings","user":{"login":"eqinox76","id":5861557,"node_id":"MDQ6VXNlcjU4NjE1NTc=","avatar_url":"https://avatars.githubusercontent.com/u/5861557?v=4","gravatar_id":"","url":"https://api.github.com/users/eqinox76","html_url":"https://github.com/eqinox76","followers_url":"https://api.github.com/users/eqinox76/followers","following_url":"https://api.github.com/users/eqinox76/following{/other_user}","gists_url":"https://api.github.com/users/eqinox76/gists{/gist_id}","starred_url":"https://api.github.com/users/eqinox76/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/eqinox76/subscriptions","organizations_url":"https://api.github.com/users/eqinox76/orgs","repos_url":"https://api.github.com/users/eqinox76/repos","events_url":"https://api.github.com/users/eqinox76/events{/privacy}","received_events_url":"https://api.github.com/users/eqinox76/received_events","type":"User","site_admin":false},"labels":[{"id":785082162,"node_id":"MDU6TGFiZWw3ODUwODIxNjI=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-documentation","name":"comp-documentation","color":"b5bcff","default":false,"description":"Used to run automatic builds of the documentation"}],"state":"open","locked":false,"assignee":{"login":"kitaisreal","id":22458333,"node_id":"MDQ6VXNlcjIyNDU4MzMz","avatar_url":"https://avatars.githubusercontent.com/u/22458333?v=4","gravatar_id":"","url":"https://api.github.com/users/kitaisreal","html_url":"https://github.com/kitaisreal","followers_url":"https://api.github.com/users/kitaisreal/followers","following_url":"https://api.github.com/users/kitaisreal/following{/other_user}","gists_url":"https://api.github.com/users/kitaisreal/gists{/gist_id}","starred_url":"https://api.github.com/users/kitaisreal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kitaisreal/subscriptions","organizations_url":"https://api.github.com/users/kitaisreal/orgs","repos_url":"https://api.github.com/users/kitaisreal/repos","events_url":"https://api.github.com/users/kitaisreal/events{/privacy}","received_events_url":"https://api.github.com/users/kitaisreal/received_events","type":"User","site_admin":false},"assignees":[{"login":"kitaisreal","id":22458333,"node_id":"MDQ6VXNlcjIyNDU4MzMz","avatar_url":"https://avatars.githubusercontent.com/u/22458333?v=4","gravatar_id":"","url":"https://api.github.com/users/kitaisreal","html_url":"https://github.com/kitaisreal","followers_url":"https://api.github.com/users/kitaisreal/followers","following_url":"https://api.github.com/users/kitaisreal/following{/other_user}","gists_url":"https://api.github.com/users/kitaisreal/gists{/gist_id}","starred_url":"https://api.github.com/users/kitaisreal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kitaisreal/subscriptions","organizations_url":"https://api.github.com/users/kitaisreal/orgs","repos_url":"https://api.github.com/users/kitaisreal/repos","events_url":"https://api.github.com/users/kitaisreal/events{/privacy}","received_events_url":"https://api.github.com/users/kitaisreal/received_events","type":"User","site_admin":false}],"milestone":null,"comments":4,"created_at":"2021-09-20T05:42:22Z","updated_at":"2021-09-22T15:38:22Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"**Describe the issue**\r\nI am trying to find out how to control the settings for a mysql data engine.\r\nI see the settings in [MySQLSettings.h](https://github.com/ClickHouse/ClickHouse/blob/2a8f3553264637da204d5ec782847325742e9190/src/Storages/MySQL/MySQLSettings.h) but am unable to set them via the [settings parameter](https://clickhouse.tech/docs/en/sql-reference/statements/alter/setting/) like\r\n```sql\r\nCREATE DATABASE external ENGINE = MySQL(\r\n'host:3306', 'database', 'user', 'pw'\r\n) settings connection_pool_size=1\r\n```\r\n```\r\nReceived exception from server (version 21.8.5):\r\nCode: 501. DB::Exception: Received from localhost:9000. DB::Exception: Cannot create MySQL database, because Code: 36, e.displayText() = DB::Exception: Unknown setting connection_pool_size for database MySQL, \r\n```\r\n\r\n**Additional context**\r\nRoot cause that i am trying to solve is that we are running out of connections on our MySQL server\r\n```\r\n2021-09-17T11:32:31.889464Z 3143172 [Warning] [MY-000000] [Server] Too many connections\r\n2021-09-17T11:32:31.891585Z 3143173 [Warning] [MY-000000] [Server] Too many connections\r\n2021-09-17T11:32:31.893878Z 3143174 [Warning] [MY-000000] [Server] Too many connections\r\n```\r\nWhich is caused by our clickhouse instance:\r\n```\r\n2021.09.17 13:32:31.889632 [ 89987 ] {85c412a7-d884-4e0f-9118-53521bf29a99} <Error> mysqlxx::Pool: mysqlxx::ConnectionFailed\r\n2021.09.17 13:32:31.889682 [ 89987 ] {85c412a7-d884-4e0f-9118-53521bf29a99} <Warning> Application: Connection to tca@xtp-db-01:3306 as user clickhouse \r\nfailed.\r\n2021.09.17 13:32:31.889694 [ 89987 ] {85c412a7-d884-4e0f-9118-53521bf29a99} <Error> Application: Connection to all replicas failed 1 times\r\n2021.09.17 13:32:31.889900 [ 36856 ] {7bc4a174-e61e-4b5c-89b5-ae6ea5ad21a2} <Information> executeQuery: Read 2676 rows, 15.68 KiB in 0.018890694 sec., \r\n141657 rows/sec., 830.02 KiB/sec.\r\n2021.09.17 13:32:31.891722 [ 89987 ] {85c412a7-d884-4e0f-9118-53521bf29a99} <Error> mysqlxx::Pool: mysqlxx::ConnectionFailed\r\n2021.09.17 13:32:31.891757 [ 89987 ] {85c412a7-d884-4e0f-9118-53521bf29a99} <Warning> Application: Connection to tca@xtp-db-01:3306 as user clickhouse \r\nfailed.\r\n2021.09.17 13:32:31.891769 [ 89987 ] {85c412a7-d884-4e0f-9118-53521bf29a99} <Error> Application: Connection to all replicas failed 2 times\r\n2021.09.17 13:32:31.894000 [ 89987 ] {85c412a7-d884-4e0f-9118-53521bf29a99} <Error> mysqlxx::Pool: mysqlxx::ConnectionFailed\r\n2021.09.17 13:32:31.894029 [ 89987 ] {85c412a7-d884-4e0f-9118-53521bf29a99} <Warning> Application: Connection to tca@xtp-db-01:3306 as user clickhouse \r\nfailed.\r\n2021.09.17 13:32:31.894041 [ 89987 ] {85c412a7-d884-4e0f-9118-53521bf29a99} <Error> Application: Connection to all replicas failed 3 times\r\n2021.09.17 13:32:31.894373 [ 57667 ] {85c412a7-d884-4e0f-9118-53521bf29a99} <Error> executeQuery: Poco::Exception. Code: 1000, e.code() = 0, Exception: Connections to all replicas failed: database@host:3306 as user clickhouse (version 21.9.2.17 (official build)) (from [::ffff:192.168.138.25]:59610) (in query: ... ), Stack trace (when copying this message, always include the lines below):\r\n``` \r\nWe have configured a database as mysql engine. And i am not sure if the mysql conntion pool is shared between all tables in this database or if there is one connection pool per table.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29185/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29185/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29183","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29183/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29183/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29183/events","html_url":"https://github.com/ClickHouse/ClickHouse/pull/29183","id":1000447056,"node_id":"PR_kwDOA5dJV84r8C5c","number":29183,"title":"Add weighted random queue","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":1876999755,"node_id":"MDU6TGFiZWwxODc2OTk5NzU1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/pr-not-for-changelog","name":"pr-not-for-changelog","color":"007700","default":false,"description":"This PR should not be mentioned in the changelog"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-09-19T23:17:38Z","updated_at":"2021-09-28T18:02:40Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"draft":true,"pull_request":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/pulls/29183","html_url":"https://github.com/ClickHouse/ClickHouse/pull/29183","diff_url":"https://github.com/ClickHouse/ClickHouse/pull/29183.diff","patch_url":"https://github.com/ClickHouse/ClickHouse/pull/29183.patch","merged_at":null},"body":"Changelog category (leave one):\r\n- Not for changelog (changelog entry is not required)\r\n\r\n\r\nDevelopment of resource pools.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29183/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29183/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29131","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29131/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29131/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29131/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29131","id":999301663,"node_id":"I_kwDOA5dJV847kCIf","number":29131,"title":"LowCardinality(Nullable(FixedString(x))) use slow serialized hash table","user":{"login":"UnamedRus","id":9449405,"node_id":"MDQ6VXNlcjk0NDk0MDU=","avatar_url":"https://avatars.githubusercontent.com/u/9449405?v=4","gravatar_id":"","url":"https://api.github.com/users/UnamedRus","html_url":"https://github.com/UnamedRus","followers_url":"https://api.github.com/users/UnamedRus/followers","following_url":"https://api.github.com/users/UnamedRus/following{/other_user}","gists_url":"https://api.github.com/users/UnamedRus/gists{/gist_id}","starred_url":"https://api.github.com/users/UnamedRus/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/UnamedRus/subscriptions","organizations_url":"https://api.github.com/users/UnamedRus/orgs","repos_url":"https://api.github.com/users/UnamedRus/repos","events_url":"https://api.github.com/users/UnamedRus/events{/privacy}","received_events_url":"https://api.github.com/users/UnamedRus/received_events","type":"User","site_admin":false},"labels":[{"id":756395244,"node_id":"MDU6TGFiZWw3NTYzOTUyNDQ=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/performance","name":"performance","color":"c2e0c6","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-09-17T12:31:04Z","updated_at":"2021-09-17T12:31:04Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Describe the situation**\r\nWhen you do GROUP BY multiple LC nullable FixedString clickhouse is using serialized hash table instead of hash table optimized for fixed width types.\r\n\r\n**How to reproduce**\r\nClickHouse version 21.10\r\n```\r\n CREATE TABLE default.test_lc_group\r\n(\r\n    `a` LowCardinality(FixedString(4)),\r\n    `b` LowCardinality(FixedString(4)),\r\n    `c` LowCardinality(Nullable(FixedString(4))),\r\n    `d` LowCardinality(Nullable(FixedString(4))),\r\n    `e` Nullable(FixedString(4)),\r\n    `f` Nullable(FixedString(4))\r\n)\r\nENGINE = MergeTree\r\nORDER BY tuple()\r\nSETTINGS index_granularity = 8192;\r\n\r\nINSERT INTO test_lc_group SELECT toString(number % 10000) as a, toString(rand() % 10000) b,a,b,a,b FROM numbers(1000000);\r\n\r\n\r\nSELECT count()\r\nFROM test_lc_group\r\nGROUP BY\r\n    a,\r\n    b\r\nFORMAT `Null`\r\n\r\n[LAPTOP-] 2021.09.17 15:26:16.510280 [ 3470 ] {40fe13a0-bc5b-493a-aa06-da00c94165c1} <Trace> Aggregator: Aggregation method: low_cardinality_keys128\r\n[LAPTOP-] 2021.09.17 15:26:16.883290 [ 623 ] {40fe13a0-bc5b-493a-aa06-da00c94165c1} <Debug> MemoryTracker: Peak memory usage (for query): 133.80 MiB.\r\n\r\n\r\n0 rows in set. Elapsed: 0.380 sec. Processed 1.00 million rows, 5.27 MB (2.63 million rows/s., 13.88 MB/s.)\r\n\r\nSELECT count()\r\nFROM test_lc_group\r\nGROUP BY\r\n    c,\r\n    d\r\nFORMAT `Null`\r\n\r\n[LAPTOP-] 2021.09.17 15:26:51.706846 [ 3473 ] {b9736114-2220-4d1d-a209-a2bb81af5c97} <Trace> Aggregator: Aggregation method: serialized\r\n[LAPTOP-] 2021.09.17 15:26:52.313788 [ 623 ] {b9736114-2220-4d1d-a209-a2bb81af5c97} <Debug> MemoryTracker: Peak memory usage (for query): 189.83 MiB.\r\nOk.\r\n\r\n0 rows in set. Elapsed: 0.614 sec. Processed 1.00 million rows, 5.27 MB (1.63 million rows/s., 8.59 MB/s.)\r\n\r\nSELECT count()\r\nFROM test_lc_group\r\nGROUP BY\r\n    e,\r\n    f\r\nFORMAT `Null`\r\n\r\n[LAPTOP-] 2021.09.17 15:27:14.896015 [ 796 ] {100a1210-0b41-45ab-a9c9-25ff431fb8cf} <Trace> Aggregator: Aggregation method: nullable_keys128\r\n\r\n[LAPTOP-] 2021.09.17 15:27:15.140888 [ 623 ] {100a1210-0b41-45ab-a9c9-25ff431fb8cf} <Debug> MemoryTracker: Peak memory usage (for query): 138.14 MiB.\r\n\r\n\r\n0 rows in set. Elapsed: 0.249 sec. Processed 1.00 million rows, 10.00 MB (4.02 million rows/s., 40.21 MB/s.)\r\n```\r\n\r\n**Expected performance**\r\nThe ~same as for LC(FixedString) or Nullable(FixedString)\r\n\r\n**Additional context**\r\nRelated https://github.com/ClickHouse/ClickHouse/issues/15005\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29131/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29131/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29114","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29114/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29114/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29114/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29114","id":999036441,"node_id":"I_kwDOA5dJV847jBYZ","number":29114,"title":"isuuse with grants to system tables","user":{"login":"filimonov","id":1549571,"node_id":"MDQ6VXNlcjE1NDk1NzE=","avatar_url":"https://avatars.githubusercontent.com/u/1549571?v=4","gravatar_id":"","url":"https://api.github.com/users/filimonov","html_url":"https://github.com/filimonov","followers_url":"https://api.github.com/users/filimonov/followers","following_url":"https://api.github.com/users/filimonov/following{/other_user}","gists_url":"https://api.github.com/users/filimonov/gists{/gist_id}","starred_url":"https://api.github.com/users/filimonov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/filimonov/subscriptions","organizations_url":"https://api.github.com/users/filimonov/orgs","repos_url":"https://api.github.com/users/filimonov/repos","events_url":"https://api.github.com/users/filimonov/events{/privacy}","received_events_url":"https://api.github.com/users/filimonov/received_events","type":"User","site_admin":false},"labels":[{"id":845267693,"node_id":"MDU6TGFiZWw4NDUyNjc2OTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/st-need-info","name":"st-need-info","color":"e5b890","default":false,"description":"We need extra data to continue"},{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""},{"id":2011606513,"node_id":"MDU6TGFiZWwyMDExNjA2NTEz","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-rbac","name":"comp-rbac","color":"b5bcff","default":false,"description":"Access control related"},{"id":2825253639,"node_id":"MDU6TGFiZWwyODI1MjUzNjM5","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/v21.3-affected","name":"v21.3-affected","color":"c2bfff","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-09-17T07:27:18Z","updated_at":"2021-09-17T08:27:48Z","closed_at":null,"author_association":"COLLABORATOR","active_lock_reason":null,"body":"Demo user have no grants to system database:\r\n\r\n```\r\nclickhouse-client --host github.demo.trial.altinity.cloud --port 9440 --user=demo --password=demo --secure\r\n\r\ngithub :) select * from system.databases;\r\n\r\n┌─name────┬─engine───┬─data_path─────────────────────────┬─metadata_path─────────────────────────┬─uuid─────────────────────────────────┐\r\n│ default │ Ordinary │ /var/lib/clickhouse/data/default/ │ /var/lib/clickhouse/metadata/default/ │ 00000000-0000-0000-0000-000000000000 │\r\n└─────────┴──────────┴───────────────────────────────────┴───────────────────────────────────────┴──────────────────────────────────────┘\r\n\r\n1 rows in set. Elapsed: 0.414 sec. \r\n\r\ngithub :) desc system.databases;\r\n\r\nReceived exception from server (version 21.3.15):\r\nCode: 497. DB::Exception: Received from github.demo.trial.altinity.cloud:9440. DB::Exception: demo: Not enough privileges. To execute this query it's necessary to have grant SHOW COLUMNS ON system.databases. (ACCESS_DENIED)\r\n\r\n``` \r\n\r\n1. it's ok to provide access to some system tables.\r\n1. Quite odd to have the possibility to select data, w/o having the possibility to SHOW COLUMNS.\r\n1. `select from remote` uses describe, and w/o `SHOW COLUMNS` it don't work (while direct selects are possible).","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29114/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29114/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29110","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29110/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29110/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29110/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29110","id":998776709,"node_id":"I_kwDOA5dJV847iB-F","number":29110,"title":"disk & storage_policy sql-driven workflow","user":{"login":"UnamedRus","id":9449405,"node_id":"MDQ6VXNlcjk0NDk0MDU=","avatar_url":"https://avatars.githubusercontent.com/u/9449405?v=4","gravatar_id":"","url":"https://api.github.com/users/UnamedRus","html_url":"https://github.com/UnamedRus","followers_url":"https://api.github.com/users/UnamedRus/followers","following_url":"https://api.github.com/users/UnamedRus/following{/other_user}","gists_url":"https://api.github.com/users/UnamedRus/gists{/gist_id}","starred_url":"https://api.github.com/users/UnamedRus/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/UnamedRus/subscriptions","organizations_url":"https://api.github.com/users/UnamedRus/orgs","repos_url":"https://api.github.com/users/UnamedRus/repos","events_url":"https://api.github.com/users/UnamedRus/events{/privacy}","received_events_url":"https://api.github.com/users/UnamedRus/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-09-16T23:56:03Z","updated_at":"2021-09-18T15:49:59Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Use case**\r\n\r\nAbility to quickly add datasets from remote filesystems without dealing with xml config files.\r\n\r\n**Describe the solution you'd like**\r\n\r\nGive ability to define disks and storage policies via SQL queries, it will be especially useful for remote disks (s3, hdfs, web) and wrapper disks (encrypted, cache)\r\n\r\nLike https://postgrespro.com/docs/enterprise/13/sql-createtablespace","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29110/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29110/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29109","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29109/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29109/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29109/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29109","id":998759341,"node_id":"I_kwDOA5dJV847h9ut","number":29109,"title":"BI tool compatibility with -State datatypes in tables","user":{"login":"UnamedRus","id":9449405,"node_id":"MDQ6VXNlcjk0NDk0MDU=","avatar_url":"https://avatars.githubusercontent.com/u/9449405?v=4","gravatar_id":"","url":"https://api.github.com/users/UnamedRus","html_url":"https://github.com/UnamedRus","followers_url":"https://api.github.com/users/UnamedRus/followers","following_url":"https://api.github.com/users/UnamedRus/following{/other_user}","gists_url":"https://api.github.com/users/UnamedRus/gists{/gist_id}","starred_url":"https://api.github.com/users/UnamedRus/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/UnamedRus/subscriptions","organizations_url":"https://api.github.com/users/UnamedRus/orgs","repos_url":"https://api.github.com/users/UnamedRus/repos","events_url":"https://api.github.com/users/UnamedRus/events{/privacy}","received_events_url":"https://api.github.com/users/UnamedRus/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-09-16T23:19:33Z","updated_at":"2021-09-16T23:20:28Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Use case**\r\n\r\nImprove clickhouse usability with BI tools which doesn't know anything about AggregationFunction data type\r\n\r\n> A clear and concise description of what is the intended usage scenario is.\r\n\r\n**Describe the solution you'd like**\r\n\r\n`auto_finalize_aggregation_states` setting which will do the following:\r\n\r\n1. For `system.tables`, `DESC table_name` return not AggregationFunction(xxxx), but resulting type.\r\n2. For columns with AggregationFunction datatype:\r\n2.1. For non-aggregation queries will transparently apply finalizeAggregation() function.\r\n2.2. For aggregation queries will transparently apply -Merge combinator for aggregation functions around them. \r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29109/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29109/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29079","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29079/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29079/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29079/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29079","id":998307939,"node_id":"I_kwDOA5dJV847gPhj","number":29079,"title":"dctionary ip_trie layout support ip range","user":{"login":"pengliaoye","id":2573426,"node_id":"MDQ6VXNlcjI1NzM0MjY=","avatar_url":"https://avatars.githubusercontent.com/u/2573426?v=4","gravatar_id":"","url":"https://api.github.com/users/pengliaoye","html_url":"https://github.com/pengliaoye","followers_url":"https://api.github.com/users/pengliaoye/followers","following_url":"https://api.github.com/users/pengliaoye/following{/other_user}","gists_url":"https://api.github.com/users/pengliaoye/gists{/gist_id}","starred_url":"https://api.github.com/users/pengliaoye/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pengliaoye/subscriptions","organizations_url":"https://api.github.com/users/pengliaoye/orgs","repos_url":"https://api.github.com/users/pengliaoye/repos","events_url":"https://api.github.com/users/pengliaoye/events{/privacy}","received_events_url":"https://api.github.com/users/pengliaoye/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":{"login":"kitaisreal","id":22458333,"node_id":"MDQ6VXNlcjIyNDU4MzMz","avatar_url":"https://avatars.githubusercontent.com/u/22458333?v=4","gravatar_id":"","url":"https://api.github.com/users/kitaisreal","html_url":"https://github.com/kitaisreal","followers_url":"https://api.github.com/users/kitaisreal/followers","following_url":"https://api.github.com/users/kitaisreal/following{/other_user}","gists_url":"https://api.github.com/users/kitaisreal/gists{/gist_id}","starred_url":"https://api.github.com/users/kitaisreal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kitaisreal/subscriptions","organizations_url":"https://api.github.com/users/kitaisreal/orgs","repos_url":"https://api.github.com/users/kitaisreal/repos","events_url":"https://api.github.com/users/kitaisreal/events{/privacy}","received_events_url":"https://api.github.com/users/kitaisreal/received_events","type":"User","site_admin":false},"assignees":[{"login":"kitaisreal","id":22458333,"node_id":"MDQ6VXNlcjIyNDU4MzMz","avatar_url":"https://avatars.githubusercontent.com/u/22458333?v=4","gravatar_id":"","url":"https://api.github.com/users/kitaisreal","html_url":"https://github.com/kitaisreal","followers_url":"https://api.github.com/users/kitaisreal/followers","following_url":"https://api.github.com/users/kitaisreal/following{/other_user}","gists_url":"https://api.github.com/users/kitaisreal/gists{/gist_id}","starred_url":"https://api.github.com/users/kitaisreal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kitaisreal/subscriptions","organizations_url":"https://api.github.com/users/kitaisreal/orgs","repos_url":"https://api.github.com/users/kitaisreal/repos","events_url":"https://api.github.com/users/kitaisreal/events{/privacy}","received_events_url":"https://api.github.com/users/kitaisreal/received_events","type":"User","site_admin":false}],"milestone":null,"comments":1,"created_at":"2021-09-16T14:51:43Z","updated_at":"2021-09-26T03:27:41Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"> (you don't have to strictly follow this form)\r\n\r\n**Use case**\r\n\r\nprovince: beijing\r\nip start: 240c:0:0:0:0:0:0:0\r\nip end: 240c:000f:ffff:ffff:ffff:ffff:ffff:ffff\r\n\r\nipv6: 240c:0:0:0:0:0:0:1\r\n\r\nwe want using ipv6, check if address range in start and end. then get the province.\r\n\r\n**Describe the solution you'd like**\r\n\r\ncurrently the ip_trie layout only support cidr. can support ip range. \r\n\r\n**Describe alternatives you've considered**\r\n\r\nor dictionary range hashed  support ipv6 and ipv4\r\n\r\n**Additional context**\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29079/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29079/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29074","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29074/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29074/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29074/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29074","id":998170914,"node_id":"I_kwDOA5dJV847fuEi","number":29074,"title":"Historical stock market price data, collected by Andy Pavlo","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":3360106261,"node_id":"MDU6TGFiZWwzMzYwMTA2MjYx","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/dataset","name":"dataset","color":"00CCCC","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":8,"created_at":"2021-09-16T12:45:38Z","updated_at":"2021-09-18T13:19:32Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"Add this dataset to the docs: https://www.cs.cmu.edu/~pavlo/datasets/stocks/\r\nThe size is quite small (under 1 GB).","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29074/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29074/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29068","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29068/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29068/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29068/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29068","id":997975758,"node_id":"I_kwDOA5dJV847e-bO","number":29068,"title":"INFORMATION SCHEMA enhancement","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":3086255531,"node_id":"MDU6TGFiZWwzMDg2MjU1NTMx","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/warmup%20task","name":"warmup task","color":"FBCA04","default":false,"description":"The task for new ClickHouse team members. Low risk, moderate complexity, no urgency."}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-09-16T09:14:06Z","updated_at":"2021-09-16T09:14:25Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"**Use case**\r\n\r\nFor #9336\r\nContinuation of #9770\r\n\r\n**Describe the solution you'd like**\r\n\r\nAdd tables `COLLATIONS` (from system.collations) and `CHARACTER_SETS` (with single row with UTF-8).\r\nAdd tables `COLUMN_PRIVILEGES` and `TABLE_PRIVILEGES`, `SCHEMA_PRIVILEGES`, `USER_PRIVILEGES`.\r\n\r\nMake a database engine that will support case insensitive table names.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29068/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29068/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29064","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29064/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29064/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29064/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29064","id":997509220,"node_id":"I_kwDOA5dJV847dMhk","number":29064,"title":"Add Maglev consistent hash as SQL function.","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":1507867504,"node_id":"MDU6TGFiZWwxNTA3ODY3NTA0","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/st-hold","name":"st-hold","color":"e5b890","default":false,"description":"We've paused the work on issue for some reason"}],"state":"open","locked":false,"assignee":{"login":"ucasfl","id":22127746,"node_id":"MDQ6VXNlcjIyMTI3NzQ2","avatar_url":"https://avatars.githubusercontent.com/u/22127746?v=4","gravatar_id":"","url":"https://api.github.com/users/ucasfl","html_url":"https://github.com/ucasfl","followers_url":"https://api.github.com/users/ucasfl/followers","following_url":"https://api.github.com/users/ucasfl/following{/other_user}","gists_url":"https://api.github.com/users/ucasfl/gists{/gist_id}","starred_url":"https://api.github.com/users/ucasfl/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ucasfl/subscriptions","organizations_url":"https://api.github.com/users/ucasfl/orgs","repos_url":"https://api.github.com/users/ucasfl/repos","events_url":"https://api.github.com/users/ucasfl/events{/privacy}","received_events_url":"https://api.github.com/users/ucasfl/received_events","type":"User","site_admin":false},"assignees":[{"login":"ucasfl","id":22127746,"node_id":"MDQ6VXNlcjIyMTI3NzQ2","avatar_url":"https://avatars.githubusercontent.com/u/22127746?v=4","gravatar_id":"","url":"https://api.github.com/users/ucasfl","html_url":"https://github.com/ucasfl","followers_url":"https://api.github.com/users/ucasfl/followers","following_url":"https://api.github.com/users/ucasfl/following{/other_user}","gists_url":"https://api.github.com/users/ucasfl/gists{/gist_id}","starred_url":"https://api.github.com/users/ucasfl/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ucasfl/subscriptions","organizations_url":"https://api.github.com/users/ucasfl/orgs","repos_url":"https://api.github.com/users/ucasfl/repos","events_url":"https://api.github.com/users/ucasfl/events{/privacy}","received_events_url":"https://api.github.com/users/ucasfl/received_events","type":"User","site_admin":false}],"milestone":null,"comments":5,"created_at":"2021-09-15T20:53:24Z","updated_at":"2021-09-16T19:49:40Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"**Use case**\r\n\r\nMake it available along with the existing `yandexConsistentHash` and `jumpConsistentHash`.\r\nTo experiment with it before integrating to #26748 for better cache affinity in #28961.\r\n\r\n**Describe the solution you'd like**\r\n\r\nExample implementation is available in Envoy Proxy:\r\nhttps://github.com/envoyproxy/envoy/blob/master/source/common/upstream/maglev_lb.h\r\nhttps://github.com/envoyproxy/envoy/blob/master/source/common/upstream/maglev_lb.cc\r\n\r\nSee:\r\nhttps://blog.acolyer.org/2016/03/21/maglev-a-fast-and-reliable-software-network-load-balancer/","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29064/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29064/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29037","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29037/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29037/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29037/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29037","id":996707461,"node_id":"I_kwDOA5dJV847aIyF","number":29037,"title":"21.9.2.17 clickhouse-extract-from-config cant read xml without strict .xml extension","user":{"login":"moonbaseDelta","id":44047940,"node_id":"MDQ6VXNlcjQ0MDQ3OTQw","avatar_url":"https://avatars.githubusercontent.com/u/44047940?v=4","gravatar_id":"","url":"https://api.github.com/users/moonbaseDelta","html_url":"https://github.com/moonbaseDelta","followers_url":"https://api.github.com/users/moonbaseDelta/followers","following_url":"https://api.github.com/users/moonbaseDelta/following{/other_user}","gists_url":"https://api.github.com/users/moonbaseDelta/gists{/gist_id}","starred_url":"https://api.github.com/users/moonbaseDelta/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/moonbaseDelta/subscriptions","organizations_url":"https://api.github.com/users/moonbaseDelta/orgs","repos_url":"https://api.github.com/users/moonbaseDelta/repos","events_url":"https://api.github.com/users/moonbaseDelta/events{/privacy}","received_events_url":"https://api.github.com/users/moonbaseDelta/received_events","type":"User","site_admin":false},"labels":[{"id":845247686,"node_id":"MDU6TGFiZWw4NDUyNDc2ODY=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/usability","name":"usability","color":"ebf28c","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2021-09-15T06:27:29Z","updated_at":"2021-09-27T20:02:10Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Hi, \r\n\r\nI'm using `clickhouse-extract-from-config` to validate configs generated by Puppet, in previous versions of clickhouse-server (for instance, 21.2.4.6) the util works just fine with temporary files - Puppet tends to store them with names like `<filename.extension><somehash-or-smth>` before it actually replacing previous version - but current build (21.9.2.17) just gives error based on file extension, not the actual data or syntax. \r\n\r\nThat works:\r\n`/bin/clickhouse-extract-from-config --key=that_key_does_not_exist --try --config-file /etc/clickhouse-server/users.xml`\r\n\r\nThis gives an error for the same file but without straight .xml at the end:\r\n`/bin/clickhouse-extract-from-config --key=that_key_does_not_exist --try --config-file users.xml123`\r\n`Code: 347. DB::Exception: Unknown format of './users.xml123' config. (CANNOT_LOAD_CONFIG) (version 21.9.2.17 (official build))`\r\n\r\nEven funnier that config without an extension at all works nicely too: \r\n`/bin/clickhouse-extract-from-config --key=that_key_does_not_exist --try --config-file usersconfig`\r\n\r\n\r\nI'm working with CentOS7 environment, but it seems that the problem rely entirely on ClickHouse version and will be reproducible at any distro.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29037/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29037/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29022","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29022/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29022/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29022/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29022","id":996080787,"node_id":"I_kwDOA5dJV847XvyT","number":29022,"title":"Terminate called for uncaught exception: `WriteBufferFromHTTPServerResponse`","user":{"login":"tavplubix","id":14847450,"node_id":"MDQ6VXNlcjE0ODQ3NDUw","avatar_url":"https://avatars.githubusercontent.com/u/14847450?v=4","gravatar_id":"","url":"https://api.github.com/users/tavplubix","html_url":"https://github.com/tavplubix","followers_url":"https://api.github.com/users/tavplubix/followers","following_url":"https://api.github.com/users/tavplubix/following{/other_user}","gists_url":"https://api.github.com/users/tavplubix/gists{/gist_id}","starred_url":"https://api.github.com/users/tavplubix/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tavplubix/subscriptions","organizations_url":"https://api.github.com/users/tavplubix/orgs","repos_url":"https://api.github.com/users/tavplubix/repos","events_url":"https://api.github.com/users/tavplubix/events{/privacy}","received_events_url":"https://api.github.com/users/tavplubix/received_events","type":"User","site_admin":false},"labels":[{"id":2104602822,"node_id":"MDU6TGFiZWwyMTA0NjAyODIy","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/fuzz","name":"fuzz","color":"abc4ea","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-09-14T14:21:27Z","updated_at":"2021-09-14T14:21:27Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"https://clickhouse-test-reports.s3.yandex.net/0/4204e20f06850a139db9cd17aac5de592a3dfa44/stress_test_(address).html#fail1\r\n```\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.14 14:17:19.492103 [ 523 ] {} <Fatal> BaseDaemon: (version 21.11.1.8075 (official build), build id: BEA0A58D774FE51C6B409A1FD0985C8E3A67836B) (from thread 3289) Terminate called for uncaught exception:\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.14 14:17:19.502255 [ 523 ] {} <Fatal> BaseDaemon: Code: 24. DB::Exception: Cannot write to ostream at offset 1003974. (CANNOT_WRITE_TO_OSTREAM), Stack trace (when copying this message, always include the lines below):\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.14 14:17:19.502814 [ 523 ] {} <Fatal> BaseDaemon: \r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.14 14:17:19.503320 [ 523 ] {} <Fatal> BaseDaemon: 0. ./obj-x86_64-linux-gnu/../contrib/libcxx/include/exception:133: Poco::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int) @ 0x2d025189 in /usr/bin/clickhouse\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.14 14:17:19.503885 [ 523 ] {} <Fatal> BaseDaemon: 1. ./obj-x86_64-linux-gnu/../src/Common/Exception.cpp:59: DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, bool) @ 0xb66aea8 in /usr/bin/clickhouse\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.14 14:17:19.504484 [ 523 ] {} <Fatal> BaseDaemon: 2. ./obj-x86_64-linux-gnu/../src/IO/WriteBufferFromOStream.cpp:22: DB::WriteBufferFromOStream::nextImpl() @ 0xb8cfc73 in /usr/bin/clickhouse\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.14 14:17:19.505025 [ 523 ] {} <Fatal> BaseDaemon: 3. ./obj-x86_64-linux-gnu/../src/IO/BufferBase.h:39: DB::WriteBufferFromHTTPServerResponse::nextImpl() @ 0x259b6f80 in /usr/bin/clickhouse\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.14 14:17:19.505425 [ 523 ] {} <Fatal> BaseDaemon: 4. ./obj-x86_64-linux-gnu/../src/IO/BufferBase.h:39: DB::WriteBufferFromHTTPServerResponse::finalize() @ 0x259b7de3 in /usr/bin/clickhouse\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.14 14:17:19.505966 [ 523 ] {} <Fatal> BaseDaemon: 5. ./obj-x86_64-linux-gnu/../src/Server/HTTP/WriteBufferFromHTTPServerResponse.cpp:201: DB::WriteBufferFromHTTPServerResponse::~WriteBufferFromHTTPServerResponse() @ 0x259b81a5 in /usr/bin/clickhouse\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.14 14:17:48.312553 [ 523 ] {} <Fatal> BaseDaemon: 6. ./obj-x86_64-linux-gnu/../contrib/libcxx/include/memory:2518: DB::HTTPHandler::handleRequest(DB::HTTPServerRequest&, DB::HTTPServerResponse&) @ 0x258af771 in /usr/bin/clickhouse\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.14 14:17:48.320063 [ 523 ] {} <Fatal> BaseDaemon: 7. ./obj-x86_64-linux-gnu/../src/Server/HTTP/HTTPServerConnection.cpp:0: DB::HTTPServerConnection::run() @ 0x259a86af in /usr/bin/clickhouse\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.14 14:17:48.320607 [ 523 ] {} <Fatal> BaseDaemon: 8. ./obj-x86_64-linux-gnu/../contrib/poco/Net/src/TCPServerConnection.cpp:57: Poco::Net::TCPServerConnection::start() @ 0x2ce5a8ef in /usr/bin/clickhouse\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.14 14:17:48.323269 [ 523 ] {} <Fatal> BaseDaemon: 9. ./obj-x86_64-linux-gnu/../contrib/libcxx/include/memory:1397: Poco::Net::TCPServerDispatcher::run() @ 0x2ce5b5e1 in /usr/bin/clickhouse\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.14 14:17:48.324435 [ 523 ] {} <Fatal> BaseDaemon: 10. ./obj-x86_64-linux-gnu/../contrib/poco/Foundation/src/ThreadPool.cpp:0: Poco::PooledThread::run() @ 0x2d151ba6 in /usr/bin/clickhouse\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.14 14:17:48.324828 [ 523 ] {} <Fatal> BaseDaemon: 11. ./obj-x86_64-linux-gnu/../contrib/poco/Foundation/src/Thread_POSIX.cpp:0: Poco::ThreadImpl::runnableEntry(void*) @ 0x2d14b0ba in /usr/bin/clickhouse\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.14 14:17:48.325340 [ 523 ] {} <Fatal> BaseDaemon: 12. start_thread @ 0x9609 in /usr/lib/x86_64-linux-gnu/libpthread-2.31.so\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.14 14:17:48.326024 [ 523 ] {} <Fatal> BaseDaemon: 13. clone @ 0x122293 in /usr/lib/x86_64-linux-gnu/libc-2.31.so\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.14 14:17:48.328287 [ 523 ] {} <Fatal> BaseDaemon:  (version 21.11.1.8075 (official build))\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.14 14:17:48.440602 [ 30542 ] {} <Fatal> BaseDaemon: ########################################\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.14 14:17:48.447010 [ 30542 ] {} <Fatal> BaseDaemon: (version 21.11.1.8075 (official build), build id: BEA0A58D774FE51C6B409A1FD0985C8E3A67836B) (from thread 3289) (query_id: 881bddf5-9e20-4490-a104-34adc873d2c7) Received signal Aborted (6)\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.14 14:17:48.447536 [ 30542 ] {} <Fatal> BaseDaemon: \r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.14 14:17:48.488324 [ 30542 ] {} <Fatal> BaseDaemon: Stack trace: 0x7f395749318b 0x7f3957472859 0x219b2ea9 0x32da7368 0x32da727a 0xb5c97fb 0x259b84e6 0x258af771 0x259a86af 0x2ce5a8ef 0x2ce5b5e1 0x2d151ba6 0x2d14b0ba 0x7f3957648609 0x7f395756f293\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.14 14:17:48.489258 [ 30542 ] {} <Fatal> BaseDaemon: 3. gsignal @ 0x4618b in /usr/lib/x86_64-linux-gnu/libc-2.31.so\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.14 14:17:48.491493 [ 30542 ] {} <Fatal> BaseDaemon: 4. abort @ 0x25859 in /usr/lib/x86_64-linux-gnu/libc-2.31.so\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.14 14:17:48.629453 [ 30542 ] {} <Fatal> BaseDaemon: 5. ./obj-x86_64-linux-gnu/../base/daemon/BaseDaemon.cpp:0: terminate_handler() @ 0x219b2ea9 in /usr/bin/clickhouse\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.14 14:17:48.855681 [ 30542 ] {} <Fatal> BaseDaemon: 6. ./obj-x86_64-linux-gnu/../contrib/libcxxabi/src/cxa_handlers.cpp:61: std::__terminate(void (*)()) @ 0x32da7368 in /usr/bin/clickhouse\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.14 14:17:48.988109 [ 30542 ] {} <Fatal> BaseDaemon: 7.1. inlined from ./obj-x86_64-linux-gnu/../contrib/libcxxabi/src/include/atomic_support.h:78: void (*std::__1::(anonymous namespace)::__libcpp_atomic_load<void (*)()>(void (* const*)(), int))()\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.14 14:17:48.995897 [ 30542 ] {} <Fatal> BaseDaemon: 7.2. inlined from ../contrib/libcxxabi/src/cxa_handlers.cpp:49: std::get_terminate()\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.14 14:17:48.999955 [ 30542 ] {} <Fatal> BaseDaemon: 7. ../contrib/libcxxabi/src/cxa_handlers.cpp:92: std::terminate() @ 0x32da727a in /usr/bin/clickhouse\r\n/var/log/clickhouse-server/clickhouse-server.log.2:2021.09.14 14:18:11.066109 [ 520 ] {} <Fatal> Application: Child process was terminated by signal 6.\r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29022/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29022/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29011","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29011/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29011/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29011/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29011","id":995892801,"node_id":"I_kwDOA5dJV847XB5B","number":29011,"title":"Does clickhouse support querying the partition table of hive? How to write the sql?","user":{"login":"1069355234","id":7828170,"node_id":"MDQ6VXNlcjc4MjgxNzA=","avatar_url":"https://avatars.githubusercontent.com/u/7828170?v=4","gravatar_id":"","url":"https://api.github.com/users/1069355234","html_url":"https://github.com/1069355234","followers_url":"https://api.github.com/users/1069355234/followers","following_url":"https://api.github.com/users/1069355234/following{/other_user}","gists_url":"https://api.github.com/users/1069355234/gists{/gist_id}","starred_url":"https://api.github.com/users/1069355234/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/1069355234/subscriptions","organizations_url":"https://api.github.com/users/1069355234/orgs","repos_url":"https://api.github.com/users/1069355234/repos","events_url":"https://api.github.com/users/1069355234/events{/privacy}","received_events_url":"https://api.github.com/users/1069355234/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-09-14T11:12:34Z","updated_at":"2021-09-14T11:12:34Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Does clickhouse support querying the partition table of hive? How to write the sql?\r\n\r\nThe sql of the non-partitioned table I used is as follows:\r\n`select\r\n\t*\r\nfrom\r\n\thdfs('hdfs://hive@hdfs:8020/user/hive/warehouse/xx_default.db/table/*',\r\n\t'CustomSeparated',\r\n\t'id Int32, name String, age Int32')  order by id SETTINGS format_custom_field_delimiter = '\\x01',format_custom_escaping_rule='CSV';`","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29011/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29011/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29006","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29006/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29006/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29006/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/29006","id":995722819,"node_id":"I_kwDOA5dJV847WYZD","number":29006,"title":"Port mechanism of `try node` in `DatabaseReplicatedDDLWorker ` to `DDLWorker`","user":{"login":"kafka1991","id":30043615,"node_id":"MDQ6VXNlcjMwMDQzNjE1","avatar_url":"https://avatars.githubusercontent.com/u/30043615?v=4","gravatar_id":"","url":"https://api.github.com/users/kafka1991","html_url":"https://github.com/kafka1991","followers_url":"https://api.github.com/users/kafka1991/followers","following_url":"https://api.github.com/users/kafka1991/following{/other_user}","gists_url":"https://api.github.com/users/kafka1991/gists{/gist_id}","starred_url":"https://api.github.com/users/kafka1991/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kafka1991/subscriptions","organizations_url":"https://api.github.com/users/kafka1991/orgs","repos_url":"https://api.github.com/users/kafka1991/repos","events_url":"https://api.github.com/users/kafka1991/events{/privacy}","received_events_url":"https://api.github.com/users/kafka1991/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-09-14T08:10:33Z","updated_at":"2021-09-14T08:23:16Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"Difference between DatabaseReplicatedDDLWorker and DDLWorker contains one of the following item:\r\n> After creation of an entry in DDL queue initiator tries to execute the entry locally\r\n  and other hosts wait for query to finish on initiator host.\r\n  If query succeed on initiator, then all hosts must execute it, so they will retry until query succeed.    We assume that cluster \r\n  is homogeneous, so if replicas are in consistent state and query succeed on one host,\r\n  then all hosts can execute it (maybe after several retries).\r\n\r\nHow about port this mechanism to `DDLWorker` ?\r\n\r\nThe main consideration I think is the **Backward Compatibility** of the existing unfinished DDLTask in quene. But we can  Introduce a flag in DDLEntry, or difference prefix of the DDLEntry(e.g. `query_new`) to distinguish the 'version' of DDLTask.\r\n\r\nwhat do you think ? @alesapin ","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29006/reactions","total_count":2,"+1":2,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/29006/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28989","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28989/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28989/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28989/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/28989","id":994963868,"node_id":"MDU6SXNzdWU5OTQ5NjM4Njg=","number":28989,"title":"Add `ntile` window function (was: Alternative of  ntile()  in clickhouse)","user":{"login":"DonyDong996","id":90320113,"node_id":"MDQ6VXNlcjkwMzIwMTEz","avatar_url":"https://avatars.githubusercontent.com/u/90320113?v=4","gravatar_id":"","url":"https://api.github.com/users/DonyDong996","html_url":"https://github.com/DonyDong996","followers_url":"https://api.github.com/users/DonyDong996/followers","following_url":"https://api.github.com/users/DonyDong996/following{/other_user}","gists_url":"https://api.github.com/users/DonyDong996/gists{/gist_id}","starred_url":"https://api.github.com/users/DonyDong996/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/DonyDong996/subscriptions","organizations_url":"https://api.github.com/users/DonyDong996/orgs","repos_url":"https://api.github.com/users/DonyDong996/repos","events_url":"https://api.github.com/users/DonyDong996/events{/privacy}","received_events_url":"https://api.github.com/users/DonyDong996/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""},{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":2607635731,"node_id":"MDU6TGFiZWwyNjA3NjM1NzMx","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-window-functions","name":"comp-window-functions","color":"b5bcff","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-09-13T14:29:33Z","updated_at":"2021-11-10T00:02:49Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"I'm moving SQL code from SQLSERVER to clickhouse,\r\nis there an alternative of window function ntile() in clickhouse?\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28989/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28989/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28967","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28967/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28967/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28967/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/28967","id":994672368,"node_id":"MDU6SXNzdWU5OTQ2NzIzNjg=","number":28967,"title":"Should we support numeric literals in form of 1_000_000? (with underscore separator of groups).","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":644208617,"node_id":"MDU6TGFiZWw2NDQyMDg2MTc=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/easy%20task","name":"easy task","color":"0e8a16","default":false,"description":"Good for first contributors"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2021-09-13T09:38:54Z","updated_at":"2022-01-28T13:34:59Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"Pros:\r\n- it is convenient to type and read numbers this way;\r\n- Ada, Perl, C++, Go and Rust already support that;\r\n- can support thousands as well as lakhs and crores;\r\n\r\nCons:\r\n- standard SQL does not have this support;\r\n- PostgreSQL treat `SELECT 1_000_000` as number one with `_000_000` alias: http://sqlfiddle.com/#!17/0a28f/400\r\n- C++ has `1'000'000` instead of `1_000_000`;\r\n\r\nWhat do you think?\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28967/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28967/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28964","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28964/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28964/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28964/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/28964","id":994599739,"node_id":"MDU6SXNzdWU5OTQ1OTk3Mzk=","number":28964,"title":"LAION-400-Million Open Dataset of images.","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":785082162,"node_id":"MDU6TGFiZWw3ODUwODIxNjI=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-documentation","name":"comp-documentation","color":"b5bcff","default":false,"description":"Used to run automatic builds of the documentation"},{"id":3360106261,"node_id":"MDU6TGFiZWwzMzYwMTA2MjYx","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/dataset","name":"dataset","color":"00CCCC","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2021-09-13T08:23:30Z","updated_at":"2021-10-17T00:26:59Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"https://laion.ai/laion-400-open-dataset/\r\n\r\nThe dataset contains 400 million of annotated 256x256 px images.\r\n\r\nClickHouse is never recommended to store images. That's why we need this dataset to explore and push the boundaries.\r\nIt can also be used to test executable User Defined Functions (available since version 21.11-testing) and explore how we can do machine learning inside the database.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28964/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28964/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28961","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28961/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28961/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28961/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/28961","id":994542467,"node_id":"MDU6SXNzdWU5OTQ1NDI0Njc=","number":28961,"title":"Local cache for remote filesystem (RFC)","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":{"login":"kssenii","id":54203879,"node_id":"MDQ6VXNlcjU0MjAzODc5","avatar_url":"https://avatars.githubusercontent.com/u/54203879?v=4","gravatar_id":"","url":"https://api.github.com/users/kssenii","html_url":"https://github.com/kssenii","followers_url":"https://api.github.com/users/kssenii/followers","following_url":"https://api.github.com/users/kssenii/following{/other_user}","gists_url":"https://api.github.com/users/kssenii/gists{/gist_id}","starred_url":"https://api.github.com/users/kssenii/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kssenii/subscriptions","organizations_url":"https://api.github.com/users/kssenii/orgs","repos_url":"https://api.github.com/users/kssenii/repos","events_url":"https://api.github.com/users/kssenii/events{/privacy}","received_events_url":"https://api.github.com/users/kssenii/received_events","type":"User","site_admin":false},"assignees":[{"login":"kssenii","id":54203879,"node_id":"MDQ6VXNlcjU0MjAzODc5","avatar_url":"https://avatars.githubusercontent.com/u/54203879?v=4","gravatar_id":"","url":"https://api.github.com/users/kssenii","html_url":"https://github.com/kssenii","followers_url":"https://api.github.com/users/kssenii/followers","following_url":"https://api.github.com/users/kssenii/following{/other_user}","gists_url":"https://api.github.com/users/kssenii/gists{/gist_id}","starred_url":"https://api.github.com/users/kssenii/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kssenii/subscriptions","organizations_url":"https://api.github.com/users/kssenii/orgs","repos_url":"https://api.github.com/users/kssenii/repos","events_url":"https://api.github.com/users/kssenii/events{/privacy}","received_events_url":"https://api.github.com/users/kssenii/received_events","type":"User","site_admin":false}],"milestone":null,"comments":6,"created_at":"2021-09-13T07:17:40Z","updated_at":"2022-01-19T00:03:13Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"A directory on local filesystem can be set up to hold a cache for remote filesystem up to specified size.\r\n\r\n**Proposed implementation**\r\n\r\nIt contains immutable write-once files with paths:\r\n\r\n`cache_path/012/0123456789abcdef0123456789abcdef/111111_last`\r\n\r\nWhere:\r\n\r\n`cache_path` - configured location;\r\n`0123456789abcdef0123456789abcdef` - SipHash128 of file path on the remote filesystem (as seen by the user of `IDisk` interface);\r\n`012` - first three hex letters of the hash;\r\n`111111` - start offset of the cached segment in the file in decimal;\r\n`_last` - if it is the last segment in file at the time it was read, so we know that the file ends there;\r\n\r\nThe cache acts like an adaptor of the remote filesystem and adapts the following methods:\r\n- read - when file is read, the contiguous read segments are also saved in cache and the overlapping segments that are already in cache are reused;\r\n- write (optionally) - when file is written, it is also saved in cache;\r\n- append - mark the last file segment as not last; then similar to write;\r\n- remove - when file is deleted, it is removed from cache;\r\n- rename and hardlink - to keep cached data usable when path changes we apply the corresponding renames and hardlinks in cache.\r\n\r\nIf a file is being read, multiple cache entries can be created:\r\n- if seek was made and we have read multiple contiguous segments;\r\n- if part of file was already in cache but we are reading overlapping segment: we read and save the remaining segments to separate cache entries;\r\n\r\nThe cache can use simple LRU eviction with whole segments as entries. So, large segments are cached and evicted as a whole. But we can split large segments prematurally (when writing new cache entries) - e.g. by 16 MiB threshold.\r\n\r\nThe metadata about cache is kept in memory: the set of all entries and the last usage time. On server restart, we load the list of files in cache and the cache is continued to be usable but we lost the information about the last usage time per entry. For this case, we should initialize last usage time to zero and on cache eviction - evict random entries with no information about last usage time.\r\n\r\nThe max size of the cache can be set up both in bytes (main use case) and in the number of entries (safety threshold just in case to save memory on cache metadata and the number of inodes).\r\n\r\nReadSettings can be implemented to control cache usage:\r\n- should a query use cache on reading if it is available (this setting is mostly for testing and comparison);\r\n- should a query save read data in cache (e.g. it can be disabled for non-important long queries);\r\n- should a query save written data in cache (for INSERT queries);\r\n- thresholds to disable saving data in cache by the estimated read/write size;\r\n\r\nThe cache is set up in config on VFS (`disk`) level, maybe as a wrapper on another disk (similarly to encrypted disk). For example, it will allow to choose whether to cache encrypted or non-encrypted data from encrypted filesystems.\r\n\r\n**Notes**\r\n\r\n- We use local filesystem for cache. We expect that the cache will also take the advantage of the OS page cache.\r\n- We assume that the files are immutable or (less important case) mutable but append-only. Looks like it works fine.\r\n- The last access time is save only in memory. Alternatively we can use `atime` in filesystem but it's an overkill.\r\n- Looks like it's unnecessary to write any checksums in cache as we already have tons of checksums on other levels;\r\n- We use external (logical) filesystem path as a cache key. We can also think about using internal object names for object-storage VFS as cache key. But the former is more versatile (composable).\r\n- We allow hardlinks. To keep things simple we can avoid bothering with correctly calculating the size of cache entries - so the actual size will be lower than calculated.\r\n- The cache can be fragmented but we don't care at all (the fragmentation will be moderate and it should work fine).\r\n- The cache may lock concurrent readers of the overlapping ranges so the one will read and cache data and the subsequent readers will reuse it.\r\n\r\n**Further directions**\r\n\r\n- Allow to keep small files in memory and set up a smaller cache size for data in memory;\r\n- A setting to limit the max amount of cached data per query;\r\n- Other algorithms instead of LRU (e.g. segmented LRU, exp-smoothed LFU) and allow to tune cache importance per query.\r\n- Sometimes it may be slow to write data into local filesystem while reading from remote filesystem. We can maintain a separate buffer of write tasks and background thread to do it and it can deliberately drop dome writes.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28961/reactions","total_count":13,"+1":13,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28961/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28959","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28959/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28959/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28959/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/28959","id":994526286,"node_id":"MDU6SXNzdWU5OTQ1MjYyODY=","number":28959,"title":"Different result for If and IfOrDefault aggregate combinators on nullable condition","user":{"login":"ykichanov","id":630255,"node_id":"MDQ6VXNlcjYzMDI1NQ==","avatar_url":"https://avatars.githubusercontent.com/u/630255?v=4","gravatar_id":"","url":"https://api.github.com/users/ykichanov","html_url":"https://github.com/ykichanov","followers_url":"https://api.github.com/users/ykichanov/followers","following_url":"https://api.github.com/users/ykichanov/following{/other_user}","gists_url":"https://api.github.com/users/ykichanov/gists{/gist_id}","starred_url":"https://api.github.com/users/ykichanov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ykichanov/subscriptions","organizations_url":"https://api.github.com/users/ykichanov/orgs","repos_url":"https://api.github.com/users/ykichanov/repos","events_url":"https://api.github.com/users/ykichanov/events{/privacy}","received_events_url":"https://api.github.com/users/ykichanov/received_events","type":"User","site_admin":false},"labels":[{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-09-13T07:00:07Z","updated_at":"2021-09-13T07:00:07Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"If condition for aggregate function is null, it will be ignored, but with \"OrDefault\" combinator - result will be different:\r\n\r\n**How to reproduce**\r\n\r\n```\r\nselect uniqIf(nullable, if(number <= 0, null, 1))          zeroExpected,\r\n       uniqIfOrDefault(nullable, if(number <= 0, null, 1)) zeroExpected2,\r\n       groupArray(nullable)                                nullableArray,\r\n       groupArray(number)                                  numberArray,\r\n       groupArray(if(number <= 0, null, 1))                condArray\r\n\r\nfrom (\r\n      select if(number == 0, 1, null) as nullable, number from system.numbers limit 1\r\n         )\r\n```\r\n```\r\n┌─zeroExpected─┬─zeroExpected2─┬─nullableArray─┬─numberArray─┬─condArray─┐\r\n│            1 │             0 │ [1]           │ [0]         │ []        │\r\n└──────────────┴───────────────┴───────────────┴─────────────┴───────────┘\r\n```\r\n\r\n* Which ClickHouse server version to use\r\nv21.7.5.29-stable\r\n\r\n**Expected behavior**\r\nExpected to get same result with uniIf and uniqIfOrDefault or error on using Null value as condition","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28959/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28959/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28935","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28935/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28935/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28935/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/28935","id":994165881,"node_id":"MDU6SXNzdWU5OTQxNjU4ODE=","number":28935,"title":"MySQL interface not compatible with PHP's MySQLi Client","user":{"login":"schien-dong","id":7111291,"node_id":"MDQ6VXNlcjcxMTEyOTE=","avatar_url":"https://avatars.githubusercontent.com/u/7111291?v=4","gravatar_id":"","url":"https://api.github.com/users/schien-dong","html_url":"https://github.com/schien-dong","followers_url":"https://api.github.com/users/schien-dong/followers","following_url":"https://api.github.com/users/schien-dong/following{/other_user}","gists_url":"https://api.github.com/users/schien-dong/gists{/gist_id}","starred_url":"https://api.github.com/users/schien-dong/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/schien-dong/subscriptions","organizations_url":"https://api.github.com/users/schien-dong/orgs","repos_url":"https://api.github.com/users/schien-dong/repos","events_url":"https://api.github.com/users/schien-dong/events{/privacy}","received_events_url":"https://api.github.com/users/schien-dong/received_events","type":"User","site_admin":false},"labels":[{"id":1397894054,"node_id":"MDU6TGFiZWwxMzk3ODk0MDU0","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unfinished%20code","name":"unfinished code","color":"ff8800","default":false,"description":""},{"id":2121263626,"node_id":"MDU6TGFiZWwyMTIxMjYzNjI2","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-mysql","name":"comp-mysql","color":"b5bcff","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2021-09-12T13:55:12Z","updated_at":"2022-01-21T06:37:23Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"The standard MySQL client works on ClickHouse over port 9004. The PHP client sends additional connection requirements that cause an exception. Subsequently a connection to ClickHouse cannot be established because ClickHouse does not Fully mimic a MySQL server.\r\n\r\n    <?php\r\n\r\n    $db=mysqli_connect('45.56.117.27:9004','default','***','mytest');\r\n    var_dump($db);\r\n\r\nPartial output:\r\n    ...\r\n    [\"stat\"]=>\r\n  string(125) \"0#00000Code: 48. DB::Exception: Command [ERRFMT] is not implemented. (NOT_IMPLEMENTED) (version 21.9.2.17 (official build))\"\r\n    ...\r\n\r\nIs it possible to implement ERRFMT, or at least Ignore the command without throwing an exception?\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28935/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28935/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28932","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28932/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28932/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28932/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/28932","id":994150253,"node_id":"MDU6SXNzdWU5OTQxNTAyNTM=","number":28932,"title":"PROJECTION Compression (skip indexes and settings ?)","user":{"login":"UnamedRus","id":9449405,"node_id":"MDQ6VXNlcjk0NDk0MDU=","avatar_url":"https://avatars.githubusercontent.com/u/9449405?v=4","gravatar_id":"","url":"https://api.github.com/users/UnamedRus","html_url":"https://github.com/UnamedRus","followers_url":"https://api.github.com/users/UnamedRus/followers","following_url":"https://api.github.com/users/UnamedRus/following{/other_user}","gists_url":"https://api.github.com/users/UnamedRus/gists{/gist_id}","starred_url":"https://api.github.com/users/UnamedRus/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/UnamedRus/subscriptions","organizations_url":"https://api.github.com/users/UnamedRus/orgs","repos_url":"https://api.github.com/users/UnamedRus/repos","events_url":"https://api.github.com/users/UnamedRus/events{/privacy}","received_events_url":"https://api.github.com/users/UnamedRus/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":3045757785,"node_id":"MDU6TGFiZWwzMDQ1NzU3Nzg1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-projections","name":"comp-projections","color":"b5bcff","default":false,"description":""}],"state":"open","locked":false,"assignee":{"login":"amosbird","id":5085485,"node_id":"MDQ6VXNlcjUwODU0ODU=","avatar_url":"https://avatars.githubusercontent.com/u/5085485?v=4","gravatar_id":"","url":"https://api.github.com/users/amosbird","html_url":"https://github.com/amosbird","followers_url":"https://api.github.com/users/amosbird/followers","following_url":"https://api.github.com/users/amosbird/following{/other_user}","gists_url":"https://api.github.com/users/amosbird/gists{/gist_id}","starred_url":"https://api.github.com/users/amosbird/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/amosbird/subscriptions","organizations_url":"https://api.github.com/users/amosbird/orgs","repos_url":"https://api.github.com/users/amosbird/repos","events_url":"https://api.github.com/users/amosbird/events{/privacy}","received_events_url":"https://api.github.com/users/amosbird/received_events","type":"User","site_admin":false},"assignees":[{"login":"amosbird","id":5085485,"node_id":"MDQ6VXNlcjUwODU0ODU=","avatar_url":"https://avatars.githubusercontent.com/u/5085485?v=4","gravatar_id":"","url":"https://api.github.com/users/amosbird","html_url":"https://github.com/amosbird","followers_url":"https://api.github.com/users/amosbird/followers","following_url":"https://api.github.com/users/amosbird/following{/other_user}","gists_url":"https://api.github.com/users/amosbird/gists{/gist_id}","starred_url":"https://api.github.com/users/amosbird/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/amosbird/subscriptions","organizations_url":"https://api.github.com/users/amosbird/orgs","repos_url":"https://api.github.com/users/amosbird/repos","events_url":"https://api.github.com/users/amosbird/events{/privacy}","received_events_url":"https://api.github.com/users/amosbird/received_events","type":"User","site_admin":false}],"milestone":null,"comments":2,"created_at":"2021-09-12T12:47:17Z","updated_at":"2022-01-09T18:05:05Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Use case**\r\n\r\nAllow users to set Compression, index and settings for projections.\r\n\r\n\r\n**Describe the solution you'd like**\r\n\r\n```\r\nCREATE TABLE xxx_proj\r\n(\r\n    `key` UInt32,\r\n    `value` UInt64,\r\n    PROJECTION proj\r\n    (key UInt32 CODEC (T64,LZ4),\r\n     value UInt64 CODEC(T64,LZ4),\r\n    INDEX idx_mm value TYPE minmax GRANULARITY 1000\r\n    )\r\n    (\r\n        SELECT\r\n            key,\r\n            sum(value)\r\n        GROUP BY key\r\n    ) SETTINGS index_granularity = 1024\r\n)\r\nENGINE = MergeTree\r\nORDER BY key\r\n\r\nCREATE TABLE xxx_proj\r\n(\r\n    `key` UInt32,\r\n    `value` UInt64,\r\n    PROJECTION proj\r\n    (key UInt32 CODEC (T64,LZ4),\r\n     value UInt64 CODEC(T64,LZ4),\r\n    INDEX idx_mm value TYPE minmax GRANULARITY 1000\r\n    ) AS\r\n        SELECT\r\n            key,\r\n            sum(value)\r\n        GROUP BY key\r\n    SETTINGS index_granularity = 1024\r\n)\r\nENGINE = MergeTree\r\nORDER BY key\r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28932/reactions","total_count":2,"+1":2,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28932/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28913","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28913/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28913/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28913/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/28913","id":994035761,"node_id":"MDU6SXNzdWU5OTQwMzU3NjE=","number":28913,"title":"Negative LIMIT specification.","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":3086255531,"node_id":"MDU6TGFiZWwzMDg2MjU1NTMx","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/warmup%20task","name":"warmup task","color":"FBCA04","default":false,"description":"The task for new ClickHouse team members. Low risk, moderate complexity, no urgency."}],"state":"open","locked":false,"assignee":{"login":"Joeywzr","id":37319050,"node_id":"MDQ6VXNlcjM3MzE5MDUw","avatar_url":"https://avatars.githubusercontent.com/u/37319050?v=4","gravatar_id":"","url":"https://api.github.com/users/Joeywzr","html_url":"https://github.com/Joeywzr","followers_url":"https://api.github.com/users/Joeywzr/followers","following_url":"https://api.github.com/users/Joeywzr/following{/other_user}","gists_url":"https://api.github.com/users/Joeywzr/gists{/gist_id}","starred_url":"https://api.github.com/users/Joeywzr/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Joeywzr/subscriptions","organizations_url":"https://api.github.com/users/Joeywzr/orgs","repos_url":"https://api.github.com/users/Joeywzr/repos","events_url":"https://api.github.com/users/Joeywzr/events{/privacy}","received_events_url":"https://api.github.com/users/Joeywzr/received_events","type":"User","site_admin":false},"assignees":[{"login":"Joeywzr","id":37319050,"node_id":"MDQ6VXNlcjM3MzE5MDUw","avatar_url":"https://avatars.githubusercontent.com/u/37319050?v=4","gravatar_id":"","url":"https://api.github.com/users/Joeywzr","html_url":"https://github.com/Joeywzr","followers_url":"https://api.github.com/users/Joeywzr/followers","following_url":"https://api.github.com/users/Joeywzr/following{/other_user}","gists_url":"https://api.github.com/users/Joeywzr/gists{/gist_id}","starred_url":"https://api.github.com/users/Joeywzr/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Joeywzr/subscriptions","organizations_url":"https://api.github.com/users/Joeywzr/orgs","repos_url":"https://api.github.com/users/Joeywzr/repos","events_url":"https://api.github.com/users/Joeywzr/events{/privacy}","received_events_url":"https://api.github.com/users/Joeywzr/received_events","type":"User","site_admin":false}],"milestone":null,"comments":9,"created_at":"2021-09-12T03:50:26Z","updated_at":"2021-09-28T19:08:14Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"**Use case**\r\n\r\n`LIMIT -10`\r\n\\- return 10 last records (regardless of total number of records).\r\n\r\nCan be combined with negative offset (but not with positive offset).\r\n\r\n**Describe the solution you'd like**\r\n\r\nJust implement it.\r\n\r\n**Describe alternatives you've considered**\r\n\r\n`SELECT * (SELECT ... ORDER BY x DESC LIMIT 10) ORDER BY x ASC`\r\n\r\nBut it's more cumbersome.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28913/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28913/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28912","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28912/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28912/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28912/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/28912","id":994035648,"node_id":"MDU6SXNzdWU5OTQwMzU2NDg=","number":28912,"title":"Automatically invoking On Cluster on local tables when DDL is executed on a Distributed table","user":{"login":"schien-dong","id":7111291,"node_id":"MDQ6VXNlcjcxMTEyOTE=","avatar_url":"https://avatars.githubusercontent.com/u/7111291?v=4","gravatar_id":"","url":"https://api.github.com/users/schien-dong","html_url":"https://github.com/schien-dong","followers_url":"https://api.github.com/users/schien-dong/followers","following_url":"https://api.github.com/users/schien-dong/following{/other_user}","gists_url":"https://api.github.com/users/schien-dong/gists{/gist_id}","starred_url":"https://api.github.com/users/schien-dong/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/schien-dong/subscriptions","organizations_url":"https://api.github.com/users/schien-dong/orgs","repos_url":"https://api.github.com/users/schien-dong/repos","events_url":"https://api.github.com/users/schien-dong/events{/privacy}","received_events_url":"https://api.github.com/users/schien-dong/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":1401254412,"node_id":"MDU6TGFiZWwxNDAxMjU0NDEy","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-dddl","name":"comp-dddl","color":"b5bcff","default":false,"description":"Distributed DDL feature"},{"id":1634829961,"node_id":"MDU6TGFiZWwxNjM0ODI5OTYx","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-distributed","name":"comp-distributed","color":"b5bcff","default":false,"description":"Distributed tables"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":8,"created_at":"2021-09-12T03:49:26Z","updated_at":"2021-09-16T16:07:53Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Setup:\r\n\r\nShard 1:\r\ncreate table test_slice(x UInt32) Engine=ReplicatedMergeTree('/s1-r1','rep1') order by x;\r\ncreate table test as test_slice engine=Distributed(mycluster, testdb, test_slice,rand());\r\n\r\nShard 2:\r\n\r\ncreate table test_slice(x UInt32) Engine=ReplicatedMergeTree('/s1-r1','rep2') order by x;\r\ncreate table test as test_slice engine=Distributed(mycluster, testdb, test_slice,rand());\r\n\r\nCurrently the Distributed table \"test\" neatly abstracts away the local tables. Insert and Select statements can run directly against the combined \"test\" table.\r\n\r\nHowever, when deleting a record from the test table, \"Mutation is not allowed\" on a Distributed table. A distributed DDL is needed in this case:\r\n\r\nalter table test_slice on cluster mycluster delete where 1;\r\n\r\nThis exposes the \"local\" tables and creates inconsistency to the application layer.\r\n\r\nWhen an application is prototyped on a MergeTree table, the Updates and Deletes will have to be altered when moving to a cluster.\r\n\r\nSuggested solution:\r\nAllow a setting in clickhouse-server/config.xml, something like:\r\n<cluster_ddl_forwarding>true</cluster_ddl_forwarding>\r\n\r\nWhen this setting is enabled, this query:\r\n    update table test delete where 1;\r\nis interpreted as:\r\n    update table test_slice on cluster mycluster delete where 1;\r\n\r\nThe Distributed table \"test\" has all the information to perform this rewrite.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28912/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28912/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28896","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28896/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28896/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28896/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/28896","id":993870136,"node_id":"MDU6SXNzdWU5OTM4NzAxMzY=","number":28896,"title":"\"fire and forget\" mode for `insert ... select`","user":{"login":"filimonov","id":1549571,"node_id":"MDQ6VXNlcjE1NDk1NzE=","avatar_url":"https://avatars.githubusercontent.com/u/1549571?v=4","gravatar_id":"","url":"https://api.github.com/users/filimonov","html_url":"https://github.com/filimonov","followers_url":"https://api.github.com/users/filimonov/followers","following_url":"https://api.github.com/users/filimonov/following{/other_user}","gists_url":"https://api.github.com/users/filimonov/gists{/gist_id}","starred_url":"https://api.github.com/users/filimonov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/filimonov/subscriptions","organizations_url":"https://api.github.com/users/filimonov/orgs","repos_url":"https://api.github.com/users/filimonov/repos","events_url":"https://api.github.com/users/filimonov/events{/privacy}","received_events_url":"https://api.github.com/users/filimonov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-09-11T15:46:52Z","updated_at":"2021-09-11T15:47:42Z","closed_at":null,"author_association":"COLLABORATOR","active_lock_reason":null,"body":"Special setting to fire long-running `insert... select` or `create table... as select` asynchronously, without waiting query to finish. \r\n\r\nThat waiting locks the connection, which anyway may be timeouted and the status of the result is checked in system processes / query_log. \r\n\r\n\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28896/reactions","total_count":3,"+1":3,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28896/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28855","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28855/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28855/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28855/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/28855","id":993146395,"node_id":"MDU6SXNzdWU5OTMxNDYzOTU=","number":28855,"title":"Flushing intermediate or partial result for queries with GROUP BY or ORDER BY.","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-09-10T11:29:19Z","updated_at":"2021-09-10T11:29:19Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"**Use case**\r\n\r\n- Streaming queries (that we don't have).\r\n- Filling aggregated materialized views.\r\n\r\n**Describe the solution you'd like**\r\n\r\nSome sections in query to specify:\r\n- do flushing for every N groups or every N of input rows or every amount of real time passed (e.g. every second) or on some other criteria based on data;\r\n- output result on current part of data and start processing next part of data from scratch or output intermediate accumulated result.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28855/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28855/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28801","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28801/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28801/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28801/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/28801","id":992231775,"node_id":"MDU6SXNzdWU5OTIyMzE3NzU=","number":28801,"title":"default password requiers removal otherwise \" DB::Exception: More than one field of 'password' \"","user":{"login":"den-crane","id":19737682,"node_id":"MDQ6VXNlcjE5NzM3Njgy","avatar_url":"https://avatars.githubusercontent.com/u/19737682?v=4","gravatar_id":"","url":"https://api.github.com/users/den-crane","html_url":"https://github.com/den-crane","followers_url":"https://api.github.com/users/den-crane/followers","following_url":"https://api.github.com/users/den-crane/following{/other_user}","gists_url":"https://api.github.com/users/den-crane/gists{/gist_id}","starred_url":"https://api.github.com/users/den-crane/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/den-crane/subscriptions","organizations_url":"https://api.github.com/users/den-crane/orgs","repos_url":"https://api.github.com/users/den-crane/repos","events_url":"https://api.github.com/users/den-crane/events{/privacy}","received_events_url":"https://api.github.com/users/den-crane/received_events","type":"User","site_admin":false},"labels":[{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""},{"id":1807683251,"node_id":"MDU6TGFiZWwxODA3NjgzMjUx","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/doc-alert","name":"doc-alert","color":"e51068","default":false,"description":"PR where any documentation work is needed or proceeded"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-09-09T13:33:21Z","updated_at":"2021-11-02T19:46:06Z","closed_at":null,"author_association":"COLLABORATOR","active_lock_reason":null,"body":"```\r\napt-get install clickhouse-server=21.1.9.41 clickhouse-client=21.1.9.41 clickhouse-common-static=21.1.9.41\r\n\r\necho -n \"abc\" | sha256sum | tr -d '-'\r\nba7816bf8f01cfea414140de5dae2223b00361a396177a9cb410ff61f20015ad\r\n\r\n<?xml version=\"1.0\"?>\r\n<yandex>\r\n    <users>\r\n        <default>           \r\n          <password_sha256_hex>ba7816bf8f01cfea414140de5dae2223b00361a396177a9cb410ff61f20015ad</password_sha256_hex>\r\n        </default>\r\n    </users>      \r\n</yandex>  \r\n\r\nclickhouse-client --password=abc -q 'select 1'\r\n1\r\n\r\n/etc/init.d/clickhouse-server stop\r\n\r\napt-get install clickhouse-server=21.3.16.5 clickhouse-client=21.3.16.5 clickhouse-common-static=21.3.16.5\r\n\r\n/etc/init.d/clickhouse-server start\r\n\r\ncat /var/log/clickhouse-server/clickhouse-server.err.log\r\n2021.09.09 13:30:13.548582 [ 25829 ] {} <Error> Application: DB::Exception: More than one field of 'password', 'password_sha256_hex', 'password_double_sha1_hex', 'no_password', 'ldap' are used to specify password for user default. Must be only one of them.\r\n\r\n<?xml version=\"1.0\"?>\r\n<yandex>\r\n    <users>\r\n        <default>\r\n\t    <password remove=\"1\"/>\r\n            <password_sha256_hex>ba7816bf8f01cfea414140de5dae2223b00361a396177a9cb410ff61f20015ad</password_sha256_hex>\r\n\r\n        </default>\r\n    </users>\r\n</yandex>\r\n\r\nclickhouse-client --password=abc -q 'select 1'\r\n1\r\n```\r\n\r\nProbably it was introduced with LDAP.\r\nNow default password in users.xml is messing up with password_sha256_hex.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28801/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28801/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28800","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28800/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28800/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28800/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/28800","id":992221906,"node_id":"MDU6SXNzdWU5OTIyMjE5MDY=","number":28800,"title":"Partitioning pruning with explicit partition expression","user":{"login":"filimonov","id":1549571,"node_id":"MDQ6VXNlcjE1NDk1NzE=","avatar_url":"https://avatars.githubusercontent.com/u/1549571?v=4","gravatar_id":"","url":"https://api.github.com/users/filimonov","html_url":"https://github.com/filimonov","followers_url":"https://api.github.com/users/filimonov/followers","following_url":"https://api.github.com/users/filimonov/following{/other_user}","gists_url":"https://api.github.com/users/filimonov/gists{/gist_id}","starred_url":"https://api.github.com/users/filimonov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/filimonov/subscriptions","organizations_url":"https://api.github.com/users/filimonov/orgs","repos_url":"https://api.github.com/users/filimonov/repos","events_url":"https://api.github.com/users/filimonov/events{/privacy}","received_events_url":"https://api.github.com/users/filimonov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2021-09-09T13:25:24Z","updated_at":"2021-09-09T14:14:39Z","closed_at":null,"author_association":"COLLABORATOR","active_lock_reason":null,"body":"```sql\r\ncreate table test_partitioning engine=MergeTree ORDER BY number PARTITION BY cityHash64(number) % 100 as select * from numbers(10000);\r\n\r\nset send_logs_level = 'debug';\r\n\r\nselect count() from test_partitioning where cityHash64(number) % 100 = 1;\r\n\r\n-- Selected 1/100 parts by partition key, 1 parts by primary key, 1/1 marks by primary key, 1 marks to read from 1 ranges\r\n--  (•‿•)\r\n\r\nselect count() from test_partitioning where cityHash64(number) % 100 = 2;\r\n\r\n-- Selected 1/100 parts by partition key, 1 parts by primary key, 1/1 marks by primary key, 1 marks to read from 1 ranges\r\n--  (•‿•)\r\n\r\nselect count() from test_partitioning where cityHash64(number) % 100 IN (1,2);\r\n\r\n-- Selected 100/100 parts by partition key, 100 parts by primary key, 100/100 marks by primary key, 100 marks to read from 100 ranges\r\n-- ಠ_ಠ \r\n\r\nselect count() from test_partitioning where cityHash64(number) % 100 < 2;\r\n\r\n-- Selected 100/100 parts by partition key, 100 parts by primary key, 100/100 marks by primary key, 100 marks to read from 100 ranges\r\n-- ಠ_ಠ \r\n```\r\n\r\nRelated: #16253\r\n\r\n/cc @amosbird ","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28800/reactions","total_count":2,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":2,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28800/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28777","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28777/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28777/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28777/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/28777","id":992007467,"node_id":"MDU6SXNzdWU5OTIwMDc0Njc=","number":28777,"title":"Unknown identifier in aggregate function error when using same alias in different levels of query","user":{"login":"siradjev","id":10959667,"node_id":"MDQ6VXNlcjEwOTU5NjY3","avatar_url":"https://avatars.githubusercontent.com/u/10959667?v=4","gravatar_id":"","url":"https://api.github.com/users/siradjev","html_url":"https://github.com/siradjev","followers_url":"https://api.github.com/users/siradjev/followers","following_url":"https://api.github.com/users/siradjev/following{/other_user}","gists_url":"https://api.github.com/users/siradjev/gists{/gist_id}","starred_url":"https://api.github.com/users/siradjev/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/siradjev/subscriptions","organizations_url":"https://api.github.com/users/siradjev/orgs","repos_url":"https://api.github.com/users/siradjev/repos","events_url":"https://api.github.com/users/siradjev/events{/privacy}","received_events_url":"https://api.github.com/users/siradjev/received_events","type":"User","site_admin":false},"labels":[{"id":386401505,"node_id":"MDU6TGFiZWwzODY0MDE1MDU=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/bug","name":"bug","color":"ee0701","default":true,"description":"Confirmed user-visible misbehaviour in official release"},{"id":1365579236,"node_id":"MDU6TGFiZWwxMzY1NTc5MjM2","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/minor","name":"minor","color":"FFF8F8","default":false,"description":"Priority: minor"},{"id":1507867504,"node_id":"MDU6TGFiZWwxNTA3ODY3NTA0","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/st-hold","name":"st-hold","color":"e5b890","default":false,"description":"We've paused the work on issue for some reason"},{"id":2532986061,"node_id":"MDU6TGFiZWwyNTMyOTg2MDYx","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-query-syntax","name":"comp-query-syntax","color":"b5bcff","default":false,"description":"Relates to query parse / aliases resolution etc."}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-09-09T09:34:00Z","updated_at":"2022-01-18T22:42:02Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"When same alias names are used in different levels of query in some cases \"unknown identifier\" errors are received.\r\n\r\n**Does it reproduce on recent release?**\r\nYes, reproduces on all builds 21.3, 21.8, latest 21.9 too. \r\n\r\n**How to reproduce**\r\n\r\n```\r\nchserver :) SELECT\r\n:-]     sum(q0.a2) AS a1,\r\n:-]     sum(q0.a1) AS a9\r\n:-] FROM\r\n:-] (\r\n:-]     SELECT\r\n:-]         1 AS a1,\r\n:-]         2 AS a2\r\n:-] ) AS q0\r\n:-] ;\r\n\r\nSELECT\r\n    sum(q0.a2) AS a1,\r\n    sum(q0.a1) AS a9\r\nFROM\r\n(\r\n    SELECT\r\n        1 AS a1,\r\n        2 AS a2\r\n) AS q0\r\n\r\nQuery id: cd2ff574-fcb3-4027-8fee-7a105bccde53\r\n\r\n\r\nReceived exception from server (version 21.8.5):\r\nCode: 47. DB::Exception: Received from chserver:9000. DB::Exception: Unknown identifier 'a1' in aggregate function 'sum(a1) AS a9'.\r\n\r\n0 rows in set. Elapsed: 0.121 sec.\r\n\r\nchserver :) SELECT\r\n:-]     (q0.a2) AS a1,\r\n:-]     (q0.a1) AS a9\r\n:-] FROM\r\n:-] (\r\n:-]     SELECT\r\n:-]         1 AS a1,\r\n:-]         2 AS a2\r\n:-] ) AS q0\r\n:-] ;\r\n\r\nSELECT\r\n    q0.a2 AS a1,\r\n    q0.a1 AS a9\r\nFROM\r\n(\r\n    SELECT\r\n        1 AS a1,\r\n        2 AS a2\r\n) AS q0\r\n\r\nQuery id: ec6a030a-d8e2-4ad1-b7de-35bb74831ba6\r\n\r\n┌─a1─┬─a9─┐\r\n│  2 │  1 │\r\n└────┴────┘\r\n\r\n1 rows in set. Elapsed: 0.121 sec.\r\n\r\nchserver :)\r\n```\r\n\r\n**Expected behavior**\r\nIt should work disregarding of order of columns in query. \r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28777/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28777/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28775","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28775/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28775/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28775/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/28775","id":991952486,"node_id":"MDU6SXNzdWU5OTE5NTI0ODY=","number":28775,"title":"select mutations timeout ","user":{"login":"dzt-studio","id":84053867,"node_id":"MDQ6VXNlcjg0MDUzODY3","avatar_url":"https://avatars.githubusercontent.com/u/84053867?v=4","gravatar_id":"","url":"https://api.github.com/users/dzt-studio","html_url":"https://github.com/dzt-studio","followers_url":"https://api.github.com/users/dzt-studio/followers","following_url":"https://api.github.com/users/dzt-studio/following{/other_user}","gists_url":"https://api.github.com/users/dzt-studio/gists{/gist_id}","starred_url":"https://api.github.com/users/dzt-studio/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dzt-studio/subscriptions","organizations_url":"https://api.github.com/users/dzt-studio/orgs","repos_url":"https://api.github.com/users/dzt-studio/repos","events_url":"https://api.github.com/users/dzt-studio/events{/privacy}","received_events_url":"https://api.github.com/users/dzt-studio/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2021-09-09T08:36:18Z","updated_at":"2021-09-09T14:25:59Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"![image](https://user-images.githubusercontent.com/84053867/132652239-d83ca8b9-cd8a-4e49-b0d7-41b04336b35b.png)\r\n\r\nmutation Unable to query normally！！！！\r\n\r\nversion: 21.1.2.15","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28775/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28775/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28766","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28766/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28766/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28766/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/28766","id":991681609,"node_id":"MDU6SXNzdWU5OTE2ODE2MDk=","number":28766,"title":"Any plan to optimize ReplacingMergeTree's performance?","user":{"login":"yiguolei","id":9208457,"node_id":"MDQ6VXNlcjkyMDg0NTc=","avatar_url":"https://avatars.githubusercontent.com/u/9208457?v=4","gravatar_id":"","url":"https://api.github.com/users/yiguolei","html_url":"https://github.com/yiguolei","followers_url":"https://api.github.com/users/yiguolei/followers","following_url":"https://api.github.com/users/yiguolei/following{/other_user}","gists_url":"https://api.github.com/users/yiguolei/gists{/gist_id}","starred_url":"https://api.github.com/users/yiguolei/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yiguolei/subscriptions","organizations_url":"https://api.github.com/users/yiguolei/orgs","repos_url":"https://api.github.com/users/yiguolei/repos","events_url":"https://api.github.com/users/yiguolei/events{/privacy}","received_events_url":"https://api.github.com/users/yiguolei/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2021-09-09T02:08:43Z","updated_at":"2021-09-09T10:22:41Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"In our cases, a lot of data is from MySQL, there are inserts, updates or deletes , we use Replacing Merge Tree to store the data, but every SQL need add keyword FINAL to ensure the result is correct.\r\n\r\nThe performance is very poor... Is there any plan to improve it's performance? \r\n\r\nThe feature is strongly expected !!!!","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28766/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28766/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28764","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28764/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28764/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28764/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/28764","id":991535831,"node_id":"MDU6SXNzdWU5OTE1MzU4MzE=","number":28764,"title":"'Unexpected' parts got detached as 'ignored'","user":{"login":"SaltTan","id":20357526,"node_id":"MDQ6VXNlcjIwMzU3NTI2","avatar_url":"https://avatars.githubusercontent.com/u/20357526?v=4","gravatar_id":"","url":"https://api.github.com/users/SaltTan","html_url":"https://github.com/SaltTan","followers_url":"https://api.github.com/users/SaltTan/followers","following_url":"https://api.github.com/users/SaltTan/following{/other_user}","gists_url":"https://api.github.com/users/SaltTan/gists{/gist_id}","starred_url":"https://api.github.com/users/SaltTan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/SaltTan/subscriptions","organizations_url":"https://api.github.com/users/SaltTan/orgs","repos_url":"https://api.github.com/users/SaltTan/repos","events_url":"https://api.github.com/users/SaltTan/events{/privacy}","received_events_url":"https://api.github.com/users/SaltTan/received_events","type":"User","site_admin":false},"labels":[{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-09-08T21:12:16Z","updated_at":"2021-09-08T21:12:16Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"I noticed that ClickHouse detaches parts that are not present in ZooKeeper as 'ignored'.\r\nI believe it used to detach them as 'unexpected'.\r\nI would like to get the old behaviour back because different prefixes make it easier to deal with detached parts.\r\n\r\nHere is an example from 21.8.4:\r\n```\r\n2021.08.25 16:13:06.081957 [ 1778425 ] {} <Warning> db.table: The local set of parts of table db.table doesn't look like the set of parts in ZooKeeper: 249.00 rows of 1.02 million total rows in filesystem are suspicious. There are 2 unexpected parts with 249 rows (1 of them is not just-written with 242 rows), 0 missing parts (with 0 blocks).\r\n2021.08.25 16:13:06.081986 [ 1778425 ] {} <Error> db.table: Renaming unexpected part all_65271_65327_14 to ignored_all_65271_65327_14\r\n2021.08.25 16:13:06.082088 [ 1778425 ] {} <Error> db.table: Renaming unexpected part all_65327_65327_0 to ignored_all_65327_65327_0\r\n```\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28764/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28764/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28763","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28763/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28763/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28763/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/28763","id":991457814,"node_id":"MDU6SXNzdWU5OTE0NTc4MTQ=","number":28763,"title":"Allow to create a user that cannot change its own grants, roles and password.","user":{"login":"alexey-milovidov","id":18581488,"node_id":"MDQ6VXNlcjE4NTgxNDg4","avatar_url":"https://avatars.githubusercontent.com/u/18581488?v=4","gravatar_id":"","url":"https://api.github.com/users/alexey-milovidov","html_url":"https://github.com/alexey-milovidov","followers_url":"https://api.github.com/users/alexey-milovidov/followers","following_url":"https://api.github.com/users/alexey-milovidov/following{/other_user}","gists_url":"https://api.github.com/users/alexey-milovidov/gists{/gist_id}","starred_url":"https://api.github.com/users/alexey-milovidov/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alexey-milovidov/subscriptions","organizations_url":"https://api.github.com/users/alexey-milovidov/orgs","repos_url":"https://api.github.com/users/alexey-milovidov/repos","events_url":"https://api.github.com/users/alexey-milovidov/events{/privacy}","received_events_url":"https://api.github.com/users/alexey-milovidov/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":2011606513,"node_id":"MDU6TGFiZWwyMDExNjA2NTEz","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-rbac","name":"comp-rbac","color":"b5bcff","default":false,"description":"Access control related"},{"id":2588720302,"node_id":"MDU6TGFiZWwyNTg4NzIwMzAy","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/cloud","name":"cloud","color":"006b75","default":false,"description":"Important for Cloud"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-09-08T19:27:27Z","updated_at":"2021-09-08T19:27:27Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"**Use case**\r\n\r\nInitial user for managed ClickHouse.\r\n\r\n**Describe the solution you'd like**\r\n\r\nSome syntax to mark user as readonly.","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28763/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28763/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28749","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28749/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28749/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28749/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/28749","id":991164176,"node_id":"MDU6SXNzdWU5OTExNjQxNzY=","number":28749,"title":"some question about clickhouse-local","user":{"login":"shadowDy","id":18388143,"node_id":"MDQ6VXNlcjE4Mzg4MTQz","avatar_url":"https://avatars.githubusercontent.com/u/18388143?v=4","gravatar_id":"","url":"https://api.github.com/users/shadowDy","html_url":"https://github.com/shadowDy","followers_url":"https://api.github.com/users/shadowDy/followers","following_url":"https://api.github.com/users/shadowDy/following{/other_user}","gists_url":"https://api.github.com/users/shadowDy/gists{/gist_id}","starred_url":"https://api.github.com/users/shadowDy/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/shadowDy/subscriptions","organizations_url":"https://api.github.com/users/shadowDy/orgs","repos_url":"https://api.github.com/users/shadowDy/repos","events_url":"https://api.github.com/users/shadowDy/events{/privacy}","received_events_url":"https://api.github.com/users/shadowDy/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""},{"id":2079355812,"node_id":"MDU6TGFiZWwyMDc5MzU1ODEy","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-local","name":"comp-local","color":"b5bcff","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-09-08T13:51:06Z","updated_at":"2021-09-09T07:58:40Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"1: How to control the number of writes in stdin mode (how many entries can be input before flushing to the disk)\r\n\r\n2: How to trigger forced merge to a single part, or force merge to a single part before exiting (one part, one folder)\r\n\r\n3: How will min not be reached when exiting_ insert_ block_ size_ The number of rows is flushed to the disk\r\n\r\n4: How to set to execute optimize when exiting and clean up the old version data after merge","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28749/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28749/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28748","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28748/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28748/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28748/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/28748","id":991154477,"node_id":"MDU6SXNzdWU5OTExNTQ0Nzc=","number":28748,"title":"Nondeterministic values in cte yield inconsistent results","user":{"login":"wol-e","id":52048829,"node_id":"MDQ6VXNlcjUyMDQ4ODI5","avatar_url":"https://avatars.githubusercontent.com/u/52048829?v=4","gravatar_id":"","url":"https://api.github.com/users/wol-e","html_url":"https://github.com/wol-e","followers_url":"https://api.github.com/users/wol-e/followers","following_url":"https://api.github.com/users/wol-e/following{/other_user}","gists_url":"https://api.github.com/users/wol-e/gists{/gist_id}","starred_url":"https://api.github.com/users/wol-e/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/wol-e/subscriptions","organizations_url":"https://api.github.com/users/wol-e/orgs","repos_url":"https://api.github.com/users/wol-e/repos","events_url":"https://api.github.com/users/wol-e/events{/privacy}","received_events_url":"https://api.github.com/users/wol-e/received_events","type":"User","site_admin":false},"labels":[{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-09-08T13:42:07Z","updated_at":"2021-09-08T13:49:21Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Hi.\r\n\r\nMy clickhouse version is: 21.3.5.42\r\n\r\nI am not sure if this behaviour is intended, but for me it is very much unexpected: When using WITH statements to create cte's whose result is not deterministic, the result can change even when referring to the same cte expression:\r\n\r\n\r\n````\r\nWITH cte_number AS (\r\nSELECT\r\n    number\r\nFROM (SELECT number from system.numbers LIMIT 100)\r\nORDER BY\r\n    rand32()\r\nLIMIT 1\r\n)\r\n\r\nSELECT\r\n    (SELECT number FROM cte_number) AS number1,\r\n    number AS number2\r\nFROM\r\n    cte_number;\r\n\r\n-- Expected result: \r\n--\r\n-- │ number1 │ number 2 │\r\n-- │ 42 │  42 │\r\n-- \r\n-- 42 just as an example, as the output is a random number .\r\n-- However, I expect number1 and number 2 to always be identical, as they come from the same `table` cte_number.\r\n-- In the actual output, number 1 and number2 are two independent random numbers: \r\n\r\n-- Actual result (for example):\r\n--\r\n-- │ number1 │ number 2 │\r\n-- │ 11 │  72 │\r\n````\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28748/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28748/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28724","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28724/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28724/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28724/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/28724","id":990828411,"node_id":"MDU6SXNzdWU5OTA4Mjg0MTE=","number":28724,"title":"When I use functions to partition, how do I specify my partition key?","user":{"login":"liumengkai","id":31892927,"node_id":"MDQ6VXNlcjMxODkyOTI3","avatar_url":"https://avatars.githubusercontent.com/u/31892927?v=4","gravatar_id":"","url":"https://api.github.com/users/liumengkai","html_url":"https://github.com/liumengkai","followers_url":"https://api.github.com/users/liumengkai/followers","following_url":"https://api.github.com/users/liumengkai/following{/other_user}","gists_url":"https://api.github.com/users/liumengkai/gists{/gist_id}","starred_url":"https://api.github.com/users/liumengkai/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/liumengkai/subscriptions","organizations_url":"https://api.github.com/users/liumengkai/orgs","repos_url":"https://api.github.com/users/liumengkai/repos","events_url":"https://api.github.com/users/liumengkai/events{/privacy}","received_events_url":"https://api.github.com/users/liumengkai/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2021-09-08T07:56:13Z","updated_at":"2021-09-08T12:01:47Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"This is my create table sql:\r\n\r\nCREATE TABLE IF NOT EXISTS adt_postback_event ON CLUSTER adt_ch_cluster1\r\n(\r\n`create_time`               Int32,\r\n`app_id`                    String,\r\n`country`                   String,\r\n`type`                      String,\r\n`event_name`                String,\r\n`campaign_id`               Int32,\r\n`advertiser_id`             Int32,\r\n`publisher_id`              Int32,           \r\n`platform`                  TINYINT,\r\n`traffic_type`              TINYINT,       \r\n`traffic_type_demand`       TINYINT,\r\n`retargeting`               TINYINT,\r\n`device_id`                 String)\r\nENGINE = ReplicatedMergeTree('/clickhouse/tables/{shard}/adt_postback_event', '{replica}')\r\nPARTITION BY (formatDateTime(toDateTime(toUnixTimestamp(create_time)),'%Y%m%d'))\r\nORDER BY tuple()\r\n\r\n\r\nYou can see that I use a formatDateTime(toDateTime(toUnixTimestamp(create_time))) to partition,but how can I specify my partition key?\r\n\r\neg:\r\nI want to get 20210902 data,I try this.but it tells me partition is not a known column\r\nselect * from adt_postback_event_all where partition = '20210902'\r\n\r\nHow can I figure out the partition key in this situation?\r\n\r\ncould someone give me some advice?  thanks a lot!","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28724/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28724/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28722","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28722/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28722/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28722/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/28722","id":990813010,"node_id":"MDU6SXNzdWU5OTA4MTMwMTA=","number":28722,"title":"Insert failed on WSL2 and NTFS - Cannot set modification time for file","user":{"login":"sscobici","id":644913,"node_id":"MDQ6VXNlcjY0NDkxMw==","avatar_url":"https://avatars.githubusercontent.com/u/644913?v=4","gravatar_id":"","url":"https://api.github.com/users/sscobici","html_url":"https://github.com/sscobici","followers_url":"https://api.github.com/users/sscobici/followers","following_url":"https://api.github.com/users/sscobici/following{/other_user}","gists_url":"https://api.github.com/users/sscobici/gists{/gist_id}","starred_url":"https://api.github.com/users/sscobici/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/sscobici/subscriptions","organizations_url":"https://api.github.com/users/sscobici/orgs","repos_url":"https://api.github.com/users/sscobici/repos","events_url":"https://api.github.com/users/sscobici/events{/privacy}","received_events_url":"https://api.github.com/users/sscobici/received_events","type":"User","site_admin":false},"labels":[{"id":2659581656,"node_id":"MDU6TGFiZWwyNjU5NTgxNjU2","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-wsl","name":"comp-wsl","color":"b5bcff","default":false,"description":"Windows subsystem for Linux related issues"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-09-08T07:35:57Z","updated_at":"2021-09-08T12:02:08Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Hi,\r\nI installed Ubuntu on Windows using WSL2 and installed clickhouse version 21.8.4.51.\r\nI created simple create table and inserted the data successfully into default storage policy which is on ext4 in Ubuntu.\r\n\r\nI then configured new clickhouse storage policy for NTFS disk and created a table with that policy successfully.\r\n```\r\nfile: - /etc/clickhouse-server/config.d/storage.xml\r\n\r\n<yandex>\r\n  <storage_configuration>\r\n    <disks>\r\n      <default>\r\n         <keep_free_space_bytes>1024</keep_free_space_bytes>\r\n      </default>\r\n      <diskd>\r\n         <path>/mnt/d/clickhouse</path>\r\n      </diskd>\r\n    </disks>\r\n    <policies>\r\n      <diskd_policy>\r\n        <volumes>  \r\n          <diskd_volume>\r\n            <disk>diskd</disk>\r\n          </diskd_volume>\r\n        </volumes>\r\n      </diskd_policy>\r\n    </policies>\r\n  </storage_configuration>\r\n</yandex>\r\n```\r\n\r\nWhen I try to insert some data into the table I get the following error:\r\n`Cannot set modification time for file: /mnt/d/clickhouse/store/ee2/ee2ccc87-3bc0-4341-ae2c-cc873bc08341/tmp_insert_20210706_1_1_0/, errno: 1, strerror: Operation not permitted`\r\n\r\nDisk D is mounted in Ubuntu with default options:\r\n`(rw,noatime,dirsync,aname=drvfs;path=D:\\;uid=1000;gid=1000;symlinkroot=/mnt/,mmap,access=client,msize=65536,trans=fd,rfd=8,wfd=8)`\r\n\r\nI've created a simple c++ program in Ubuntu and it had updated modtime for that folder successfully, atime was not modified because of noatime mount setting:\r\n```\r\n#include <iostream>\r\n#include <utime.h>\r\n\r\nint main() {\r\n    struct utimbuf tb;\r\n    tb.actime  = 1630738133;\r\n    tb.modtime = 1630738133;\r\n    int result = utime(\"/mnt/d/clickhouse/store/ee2/ee2ccc87-3bc0-4341-ae2c-cc873bc08341/tmp_insert_20210706_1_1_0/\", &tb);\r\n    if (result != 0)\r\n        std::cout << \"Error: \" << result << std::endl;\r\n    return 0;\r\n}\r\n```\r\n\r\nWhat can be the reason for the clickhouse error?","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28722/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28722/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28720","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28720/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28720/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28720/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/28720","id":990771662,"node_id":"MDU6SXNzdWU5OTA3NzE2NjI=","number":28720,"title":"Different behavior when working with arrays","user":{"login":"rchadin","id":51192142,"node_id":"MDQ6VXNlcjUxMTkyMTQy","avatar_url":"https://avatars.githubusercontent.com/u/51192142?v=4","gravatar_id":"","url":"https://api.github.com/users/rchadin","html_url":"https://github.com/rchadin","followers_url":"https://api.github.com/users/rchadin/followers","following_url":"https://api.github.com/users/rchadin/following{/other_user}","gists_url":"https://api.github.com/users/rchadin/gists{/gist_id}","starred_url":"https://api.github.com/users/rchadin/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rchadin/subscriptions","organizations_url":"https://api.github.com/users/rchadin/orgs","repos_url":"https://api.github.com/users/rchadin/repos","events_url":"https://api.github.com/users/rchadin/events{/privacy}","received_events_url":"https://api.github.com/users/rchadin/received_events","type":"User","site_admin":false},"labels":[{"id":386401505,"node_id":"MDU6TGFiZWwzODY0MDE1MDU=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/bug","name":"bug","color":"ee0701","default":true,"description":"Confirmed user-visible misbehaviour in official release"},{"id":1365579236,"node_id":"MDU6TGFiZWwxMzY1NTc5MjM2","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/minor","name":"minor","color":"FFF8F8","default":false,"description":"Priority: minor"},{"id":1401233890,"node_id":"MDU6TGFiZWwxNDAxMjMzODkw","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-arrays","name":"comp-arrays","color":"b5bcff","default":false,"description":"Arrays / array joins / higher order"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2021-09-08T06:38:01Z","updated_at":"2021-09-10T02:42:52Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"```\r\nSELECT version()\r\n─version()─┐\r\n│ 21.8.5.7  │\r\n└───────────┘\r\n```\r\nWe have a request, as a result of which we get an array.\r\nWhen getting an item using a computed value, there is no value\r\n```\r\nSELECT\r\n    arrayMap(x -> x, [[1], [2], [3]]) AS x,\r\n    toTypeName(x),\r\n    x[3 - 2] AS y,\r\n    x[toInt64(1)] AS yy,\r\n    x[toUInt8(1)] AS yyy\r\n\r\n┌─x─────────────┬─toTypeName(arrayMap(lambda(tuple(x), x), [[1], [2], [3]]))─┬─y──┬─yy─┬─yyy─┐\r\n│ [[1],[2],[3]] │ Array(Array(UInt8))                                        │ [] │ [] │ [1] │\r\n└───────────────┴────────────────────────────────────────────────────────────┴────┴────┴─────┘\r\n```\r\nHowever, when the array is explicitly specified, the value is present.\r\nThe types are the same.\r\n```\r\nSELECT\r\n    [[1], [2], [3]] AS x,\r\n    toTypeName(x),\r\n    x[3 - 2] AS y,\r\n    x[toInt64(1)] AS yy,\r\n    x[toInt8(1)] AS yyy\r\n\r\n┌─x─────────────┬─toTypeName([[1], [2], [3]])─┬─y───┬─yy──┬─yyy─┐\r\n│ [[1],[2],[3]] │ Array(Array(UInt8))         │ [1] │ [1] │ [1] │\r\n└───────────────┴─────────────────────────────┴─────┴─────┴─────┘\r\n```\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28720/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28720/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28703","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28703/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28703/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28703/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/28703","id":990126848,"node_id":"MDU6SXNzdWU5OTAxMjY4NDg=","number":28703,"title":"How can I provide specific settings for kafka topic with dots in name?","user":{"login":"tinurcity","id":90271259,"node_id":"MDQ6VXNlcjkwMjcxMjU5","avatar_url":"https://avatars.githubusercontent.com/u/90271259?v=4","gravatar_id":"","url":"https://api.github.com/users/tinurcity","html_url":"https://github.com/tinurcity","followers_url":"https://api.github.com/users/tinurcity/followers","following_url":"https://api.github.com/users/tinurcity/following{/other_user}","gists_url":"https://api.github.com/users/tinurcity/gists{/gist_id}","starred_url":"https://api.github.com/users/tinurcity/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tinurcity/subscriptions","organizations_url":"https://api.github.com/users/tinurcity/orgs","repos_url":"https://api.github.com/users/tinurcity/repos","events_url":"https://api.github.com/users/tinurcity/events{/privacy}","received_events_url":"https://api.github.com/users/tinurcity/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""},{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":1334071168,"node_id":"MDU6TGFiZWwxMzM0MDcxMTY4","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-kafka","name":"comp-kafka","color":"b5bcff","default":false,"description":"Kafka Engine"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2021-09-07T15:53:40Z","updated_at":"2021-09-09T08:01:04Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"I tried provide sass configuration for topic with name like 'team.topic', but unsuccessfully\r\nI also tried replace dot with underscore.    \r\n<yandex>\r\n  <kafka replace=\"replace\">\r\n    <debug>broker,cgrp</debug>\r\n    <auto_offset_reset>earliest</auto_offset_reset>\r\n  </kafka>\r\n  <kafka_team.topic>\r\n    <security_protocol>SASL_SSL</security_protocol>\r\n    <sasl_mechanism>PLAIN</sasl_mechanism>\r\n    <sasl_username>some_sasl_username</sasl_username>\r\n    <sasl_password>some_sasl_password</sasl_password>\r\n    <ssl_ca_location>/path/to/extra_ca.crt</ssl_ca_location>\r\n  </kafka_team.topic>\r\n</yandex>\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28703/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28703/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28702","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28702/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28702/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28702/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/28702","id":990112626,"node_id":"MDU6SXNzdWU5OTAxMTI2MjY=","number":28702,"title":"More control over Dictionary updates","user":{"login":"scf37","id":1148465,"node_id":"MDQ6VXNlcjExNDg0NjU=","avatar_url":"https://avatars.githubusercontent.com/u/1148465?v=4","gravatar_id":"","url":"https://api.github.com/users/scf37","html_url":"https://github.com/scf37","followers_url":"https://api.github.com/users/scf37/followers","following_url":"https://api.github.com/users/scf37/following{/other_user}","gists_url":"https://api.github.com/users/scf37/gists{/gist_id}","starred_url":"https://api.github.com/users/scf37/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/scf37/subscriptions","organizations_url":"https://api.github.com/users/scf37/orgs","repos_url":"https://api.github.com/users/scf37/repos","events_url":"https://api.github.com/users/scf37/events{/privacy}","received_events_url":"https://api.github.com/users/scf37/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":1351463315,"node_id":"MDU6TGFiZWwxMzUxNDYzMzE1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-dictionary","name":"comp-dictionary","color":"b5bcff","default":false,"description":"Dictionaries"}],"state":"open","locked":false,"assignee":{"login":"kitaisreal","id":22458333,"node_id":"MDQ6VXNlcjIyNDU4MzMz","avatar_url":"https://avatars.githubusercontent.com/u/22458333?v=4","gravatar_id":"","url":"https://api.github.com/users/kitaisreal","html_url":"https://github.com/kitaisreal","followers_url":"https://api.github.com/users/kitaisreal/followers","following_url":"https://api.github.com/users/kitaisreal/following{/other_user}","gists_url":"https://api.github.com/users/kitaisreal/gists{/gist_id}","starred_url":"https://api.github.com/users/kitaisreal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kitaisreal/subscriptions","organizations_url":"https://api.github.com/users/kitaisreal/orgs","repos_url":"https://api.github.com/users/kitaisreal/repos","events_url":"https://api.github.com/users/kitaisreal/events{/privacy}","received_events_url":"https://api.github.com/users/kitaisreal/received_events","type":"User","site_admin":false},"assignees":[{"login":"kitaisreal","id":22458333,"node_id":"MDQ6VXNlcjIyNDU4MzMz","avatar_url":"https://avatars.githubusercontent.com/u/22458333?v=4","gravatar_id":"","url":"https://api.github.com/users/kitaisreal","html_url":"https://github.com/kitaisreal","followers_url":"https://api.github.com/users/kitaisreal/followers","following_url":"https://api.github.com/users/kitaisreal/following{/other_user}","gists_url":"https://api.github.com/users/kitaisreal/gists{/gist_id}","starred_url":"https://api.github.com/users/kitaisreal/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kitaisreal/subscriptions","organizations_url":"https://api.github.com/users/kitaisreal/orgs","repos_url":"https://api.github.com/users/kitaisreal/repos","events_url":"https://api.github.com/users/kitaisreal/events{/privacy}","received_events_url":"https://api.github.com/users/kitaisreal/received_events","type":"User","site_admin":false}],"milestone":null,"comments":2,"created_at":"2021-09-07T15:36:29Z","updated_at":"2022-01-08T11:15:23Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"**Use case**\r\n\r\nFor some analytical applications aggregating queries must be run on consistent database which includes consistent dictionaries. While ensuring MergeTree tables consistency is straightforward, it is not so easy for dictionaries.\r\n\r\nBasically, there are only two options to enforce dictionary consistency:\r\na) SYSTEM RELOAD DICTIONARY\r\nb) wait `lifetime` seconds for incremental dictionary update.\r\n\r\nFirst approach works but is inefficient - even if we know only one row has been changed we have to reload entire dictionary contents.\r\nSecond is even slower.\r\n\r\n**Describe the solution you'd like**\r\n\r\nAdd `SYSTEM UPDATE DICTIONARY` command that triggers dictionary update as if dictionary `lifetime` interval expired.\r\n\r\n**Describe alternatives you've considered**\r\n\r\n- `SYSTEM RELOAD DICTIONARY` and try to keep dictionaries small\r\n\r\n**Additional context**\r\n\r\nMore complex solutions might include MQ as a data source for dictionary or extending `Clickhouse` data source to push updates to connected Dictionary immediately on insert.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28702/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28702/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28701","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28701/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28701/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28701/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/28701","id":990071029,"node_id":"MDU6SXNzdWU5OTAwNzEwMjk=","number":28701,"title":"Can't create non persistent Join table with join_any_take_last_row flag","user":{"login":"kolsys","id":6312063,"node_id":"MDQ6VXNlcjYzMTIwNjM=","avatar_url":"https://avatars.githubusercontent.com/u/6312063?v=4","gravatar_id":"","url":"https://api.github.com/users/kolsys","html_url":"https://github.com/kolsys","followers_url":"https://api.github.com/users/kolsys/followers","following_url":"https://api.github.com/users/kolsys/following{/other_user}","gists_url":"https://api.github.com/users/kolsys/gists{/gist_id}","starred_url":"https://api.github.com/users/kolsys/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kolsys/subscriptions","organizations_url":"https://api.github.com/users/kolsys/orgs","repos_url":"https://api.github.com/users/kolsys/repos","events_url":"https://api.github.com/users/kolsys/events{/privacy}","received_events_url":"https://api.github.com/users/kolsys/received_events","type":"User","site_admin":false},"labels":[{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-09-07T14:52:55Z","updated_at":"2021-09-07T14:53:29Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Describe the unexpected behaviour**\r\nCreating Join table is impossible if `join_any_take_last_row` and `persistent` provided at same time.\r\n\r\n**How to reproduce**\r\nVersion: 21.3.15, 21.9.1.7803\r\n\r\nCreate table with Join Engine:\r\n\r\n```\r\ncreate table test (id UInt64, val String) ENGINE = Join(ANY, LEFT, id) SETTINGS join_any_take_last_row=1, persistent=0\r\n```\r\n\r\n**Expected behavior**\r\n```\r\nCREATE TABLE test\r\n(\r\n    `id` UInt64,\r\n    `val` String\r\n)\r\nENGINE = Join(ANY, LEFT, id)\r\nSETTINGS join_any_take_last_row = 1, persistent = 0\r\n\r\nQuery id: 0b50d73f-20e4-4aff-b039-84f42a11acb0\r\n\r\nOk.\r\n\r\n0 rows in set. Elapsed: 0.003 sec.\r\n```\r\n\r\n**Error message and/or stacktrace**\r\n\r\n```\r\nReceived exception from server (version 21.9.1):\r\nCode: 115. DB::Exception: Received from localhost:9000. DB::Exception: Unknown setting join_any_take_last_row: for storage Join. (UNKNOWN_SETTING)\r\n```\r\n\r\n**Additional context**\r\nBoth flags works ok if provided separately.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28701/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28701/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28693","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28693/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28693/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28693/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/28693","id":989946357,"node_id":"MDU6SXNzdWU5ODk5NDYzNTc=","number":28693,"title":"Named tuples not returning values for virtual (ALIAS or calculated on fly DEFAULT/MATERIALIZED) columns.","user":{"login":"UnamedRus","id":9449405,"node_id":"MDQ6VXNlcjk0NDk0MDU=","avatar_url":"https://avatars.githubusercontent.com/u/9449405?v=4","gravatar_id":"","url":"https://api.github.com/users/UnamedRus","html_url":"https://github.com/UnamedRus","followers_url":"https://api.github.com/users/UnamedRus/followers","following_url":"https://api.github.com/users/UnamedRus/following{/other_user}","gists_url":"https://api.github.com/users/UnamedRus/gists{/gist_id}","starred_url":"https://api.github.com/users/UnamedRus/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/UnamedRus/subscriptions","organizations_url":"https://api.github.com/users/UnamedRus/orgs","repos_url":"https://api.github.com/users/UnamedRus/repos","events_url":"https://api.github.com/users/UnamedRus/events{/privacy}","received_events_url":"https://api.github.com/users/UnamedRus/received_events","type":"User","site_admin":false},"labels":[{"id":386401505,"node_id":"MDU6TGFiZWwzODY0MDE1MDU=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/bug","name":"bug","color":"ee0701","default":true,"description":"Confirmed user-visible misbehaviour in official release"}],"state":"open","locked":false,"assignee":{"login":"CurtizJ","id":20361854,"node_id":"MDQ6VXNlcjIwMzYxODU0","avatar_url":"https://avatars.githubusercontent.com/u/20361854?v=4","gravatar_id":"","url":"https://api.github.com/users/CurtizJ","html_url":"https://github.com/CurtizJ","followers_url":"https://api.github.com/users/CurtizJ/followers","following_url":"https://api.github.com/users/CurtizJ/following{/other_user}","gists_url":"https://api.github.com/users/CurtizJ/gists{/gist_id}","starred_url":"https://api.github.com/users/CurtizJ/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/CurtizJ/subscriptions","organizations_url":"https://api.github.com/users/CurtizJ/orgs","repos_url":"https://api.github.com/users/CurtizJ/repos","events_url":"https://api.github.com/users/CurtizJ/events{/privacy}","received_events_url":"https://api.github.com/users/CurtizJ/received_events","type":"User","site_admin":false},"assignees":[{"login":"CurtizJ","id":20361854,"node_id":"MDQ6VXNlcjIwMzYxODU0","avatar_url":"https://avatars.githubusercontent.com/u/20361854?v=4","gravatar_id":"","url":"https://api.github.com/users/CurtizJ","html_url":"https://github.com/CurtizJ","followers_url":"https://api.github.com/users/CurtizJ/followers","following_url":"https://api.github.com/users/CurtizJ/following{/other_user}","gists_url":"https://api.github.com/users/CurtizJ/gists{/gist_id}","starred_url":"https://api.github.com/users/CurtizJ/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/CurtizJ/subscriptions","organizations_url":"https://api.github.com/users/CurtizJ/orgs","repos_url":"https://api.github.com/users/CurtizJ/repos","events_url":"https://api.github.com/users/CurtizJ/events{/privacy}","received_events_url":"https://api.github.com/users/CurtizJ/received_events","type":"User","site_admin":false}],"milestone":null,"comments":1,"created_at":"2021-09-07T12:45:25Z","updated_at":"2021-09-08T16:22:53Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Describe what's wrong**\r\n\r\nNamed tuples also doesn't work if you use column which has to be calculated on fly.\r\n\r\n**Does it reproduce on recent release?**\r\n\r\nYes,\r\nClickhouse version 21.10\r\n\r\n**How to reproduce**\r\n\r\n```\r\nDROP TABLE named_tuples_bug;\r\n\r\nCREATE TABLE named_tuples_bug (`a` Tuple(s Tuple(d String), i Tuple(x UInt64))) ENGINE = MergeTree ORDER BY tuple();\r\n\r\nINSERT INTO named_tuples_bug VALUES ((('y'), (10)));\r\n\r\nALTER TABLE named_tuples_bug ADD COLUMN f  Tuple(s Tuple(d String), i Tuple(x UInt64)) ALIAS a;\r\n\r\nSELECT *, a.s.d,a.i.x, f, f.s, f.s.d, f.i.x, f.1.1 as d FROM named_tuples_bug;\r\n\r\n┌─a────────────┬─a.s.d─┬─a.i.x─┬─f────────────┬─f.s──┬─f.s.d─┬─f.i.x─┬─d─┐\r\n│ (('y'),(10)) │ y     │    10 │ (('y'),(10)) │ ('') │       │     0 │ y │\r\n└──────────────┴───────┴───────┴──────────────┴──────┴───────┴───────┴───┘\r\n\r\nALTER TABLE named_tuples_bug DROP COLUMN f;\r\nALTER TABLE named_tuples_bug ADD COLUMN f  Tuple(s Tuple(d String), i Tuple(x UInt64)) MATERIALIZED a;\r\n\r\nSELECT *, a.s.d,a.i.x, f, f.s, f.s.d, f.i.x, f.1.1 as d FROM named_tuples_bug;\r\n\r\n┌─a────────────┬─a.s.d─┬─a.i.x─┬─f────────────┬─f.s──┬─f.s.d─┬─f.i.x─┬─d─┐\r\n│ (('y'),(10)) │ y     │    10 │ (('y'),(10)) │ ('') │       │     0 │ y │\r\n└──────────────┴───────┴───────┴──────────────┴──────┴───────┴───────┴───┘\r\n\r\n\r\nALTER TABLE named_tuples_bug DROP COLUMN f;\r\nALTER TABLE named_tuples_bug ADD COLUMN f  Tuple(s Tuple(d String), i Tuple(x UInt64)) DEFAULT a;\r\n\r\n\r\n\r\nALTER TABLE named_tuples_bug UPDATE f=f WHERE 1;\r\n\r\nSELECT *, a.s.d,a.i.x, f, f.s, f.s.d, f.i.x, f.1.1 as d FROM named_tuples_bug;\r\n\r\n┌─a────────────┬─f────────────┬─a.s.d─┬─a.i.x─┬─f────────────┬─f.s───┬─f.s.d─┬─f.i.x─┬─d─┐\r\n│ (('y'),(10)) │ (('y'),(10)) │ y     │    10 │ (('y'),(10)) │ ('y') │ y     │    10 │ y │\r\n└──────────────┴──────────────┴───────┴───────┴──────────────┴───────┴───────┴───────┴───┘\r\n```\r\n\r\n**Expected behavior**\r\n\r\nColumn will return column values.\r\n\r\n**Additional context**\r\n\r\nRelated https://github.com/ClickHouse/ClickHouse/issues/24607\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28693/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28693/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28687","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28687/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28687/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28687/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/28687","id":989896008,"node_id":"MDU6SXNzdWU5ODk4OTYwMDg=","number":28687,"title":"Alias columns in view do not work in some contexts","user":{"login":"tavplubix","id":14847450,"node_id":"MDQ6VXNlcjE0ODQ3NDUw","avatar_url":"https://avatars.githubusercontent.com/u/14847450?v=4","gravatar_id":"","url":"https://api.github.com/users/tavplubix","html_url":"https://github.com/tavplubix","followers_url":"https://api.github.com/users/tavplubix/followers","following_url":"https://api.github.com/users/tavplubix/following{/other_user}","gists_url":"https://api.github.com/users/tavplubix/gists{/gist_id}","starred_url":"https://api.github.com/users/tavplubix/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tavplubix/subscriptions","organizations_url":"https://api.github.com/users/tavplubix/orgs","repos_url":"https://api.github.com/users/tavplubix/repos","events_url":"https://api.github.com/users/tavplubix/events{/privacy}","received_events_url":"https://api.github.com/users/tavplubix/received_events","type":"User","site_admin":false},"labels":[{"id":386401505,"node_id":"MDU6TGFiZWwzODY0MDE1MDU=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/bug","name":"bug","color":"ee0701","default":true,"description":"Confirmed user-visible misbehaviour in official release"},{"id":1842603313,"node_id":"MDU6TGFiZWwxODQyNjAzMzEz","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-alias-columns","name":"comp-alias-columns","color":"b5bcff","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-09-07T11:44:43Z","updated_at":"2021-09-08T10:26:41Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"body":"```\r\n:) create view alias (dummy int, n alias dummy) as select * from system.one\r\n:) select n from alias\r\n\r\n┌─n─┐\r\n│ 0 │\r\n└───┘\r\n\r\n1 rows in set. Elapsed: 0.015 sec. \r\n\r\n:) select * from alias where n=0\r\n\r\nReceived exception from server (version 21.10.1):\r\nCode: 47. DB::Exception: Received from localhost:9000. DB::Exception: Missing columns: 'n' while processing query: 'SELECT dummy FROM system.one WHERE n = 0', required columns: 'dummy' 'n', maybe you meant: ['dummy']. (UNKNOWN_IDENTIFIER)\r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28687/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28687/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28684","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28684/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28684/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28684/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/28684","id":989851034,"node_id":"MDU6SXNzdWU5ODk4NTEwMzQ=","number":28684,"title":"It's not possible to subtract fractional number from DateTime64","user":{"login":"UnamedRus","id":9449405,"node_id":"MDQ6VXNlcjk0NDk0MDU=","avatar_url":"https://avatars.githubusercontent.com/u/9449405?v=4","gravatar_id":"","url":"https://api.github.com/users/UnamedRus","html_url":"https://github.com/UnamedRus","followers_url":"https://api.github.com/users/UnamedRus/followers","following_url":"https://api.github.com/users/UnamedRus/following{/other_user}","gists_url":"https://api.github.com/users/UnamedRus/gists{/gist_id}","starred_url":"https://api.github.com/users/UnamedRus/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/UnamedRus/subscriptions","organizations_url":"https://api.github.com/users/UnamedRus/orgs","repos_url":"https://api.github.com/users/UnamedRus/repos","events_url":"https://api.github.com/users/UnamedRus/events{/privacy}","received_events_url":"https://api.github.com/users/UnamedRus/received_events","type":"User","site_admin":false},"labels":[{"id":1481221764,"node_id":"MDU6TGFiZWwxNDgxMjIxNzY0","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-datetime","name":"comp-datetime","color":"b5bcff","default":false,"description":"date & time & timezone related"},{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":{"login":"Enmk","id":1110183,"node_id":"MDQ6VXNlcjExMTAxODM=","avatar_url":"https://avatars.githubusercontent.com/u/1110183?v=4","gravatar_id":"","url":"https://api.github.com/users/Enmk","html_url":"https://github.com/Enmk","followers_url":"https://api.github.com/users/Enmk/followers","following_url":"https://api.github.com/users/Enmk/following{/other_user}","gists_url":"https://api.github.com/users/Enmk/gists{/gist_id}","starred_url":"https://api.github.com/users/Enmk/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Enmk/subscriptions","organizations_url":"https://api.github.com/users/Enmk/orgs","repos_url":"https://api.github.com/users/Enmk/repos","events_url":"https://api.github.com/users/Enmk/events{/privacy}","received_events_url":"https://api.github.com/users/Enmk/received_events","type":"User","site_admin":false},"assignees":[{"login":"Enmk","id":1110183,"node_id":"MDQ6VXNlcjExMTAxODM=","avatar_url":"https://avatars.githubusercontent.com/u/1110183?v=4","gravatar_id":"","url":"https://api.github.com/users/Enmk","html_url":"https://github.com/Enmk","followers_url":"https://api.github.com/users/Enmk/followers","following_url":"https://api.github.com/users/Enmk/following{/other_user}","gists_url":"https://api.github.com/users/Enmk/gists{/gist_id}","starred_url":"https://api.github.com/users/Enmk/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Enmk/subscriptions","organizations_url":"https://api.github.com/users/Enmk/orgs","repos_url":"https://api.github.com/users/Enmk/repos","events_url":"https://api.github.com/users/Enmk/events{/privacy}","received_events_url":"https://api.github.com/users/Enmk/received_events","type":"User","site_admin":false}],"milestone":null,"comments":5,"created_at":"2021-09-07T10:47:49Z","updated_at":"2021-11-20T13:42:03Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"**Describe the unexpected behaviour**\r\nClickhouse either ignore, either produce wrong result if you would try to subtract fractional number from it.\r\n\r\n**How to reproduce**\r\n```\r\nWITH toDateTime64('2021-09-07 13:41:50.926', 3) AS time\r\nSELECT\r\n    time - 1,\r\n    time - 0.1 AS no_affect,\r\n    time - toDecimal64(0.1, 3) AS uncorrect_result\r\n\r\nQuery id: 721844ef-9039-46d7-8b37-6bdbf8ad5651\r\n\r\n┌──────────minus(time, 1)─┬───────────────no_affect─┬────────uncorrect_result─┐\r\n│ 2021-09-07 13:41:49.926 │ 2021-09-07 13:41:50.926 │ 2283-11-11 10:46:37.248 │\r\n└─────────────────────────┴─────────────────────────┴─────────────────────────┘\r\n\r\nWITH toDateTime64('2021-09-07 13:41:50.926', 3) AS time\r\nSELECT time - time\r\n\r\nQuery id: f22bdc80-eae7-4106-85bc-68547a90c3ab\r\n\r\n\r\n0 rows in set. Elapsed: 0.002 sec.\r\n\r\nReceived exception from server (version 21.10.1):\r\nCode: 43. DB::Exception: Received from localhost:9000. DB::Exception: Illegal types DateTime64(3) and DateTime64(3) of arguments of function minus: While processing (toDateTime64('2021-09-07 13:41:50.926', 3) AS time) - time. (ILLEGAL_TYPE_OF_ARGUMENT)\r\n\r\nWITH toDateTime('2021-09-07 13:41:50') AS time\r\nSELECT time - time\r\n\r\nQuery id: 43029272-e2e4-4f0c-a001-72e1f3394663\r\n\r\n┌─minus(time, time)─┐\r\n│                 0 │\r\n└───────────────────┘\r\n```\r\n\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28684/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28684/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28682","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28682/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28682/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28682/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/28682","id":989834225,"node_id":"MDU6SXNzdWU5ODk4MzQyMjU=","number":28682,"title":"Deleting data from a Join table","user":{"login":"iva3682","id":1547944,"node_id":"MDQ6VXNlcjE1NDc5NDQ=","avatar_url":"https://avatars.githubusercontent.com/u/1547944?v=4","gravatar_id":"","url":"https://api.github.com/users/iva3682","html_url":"https://github.com/iva3682","followers_url":"https://api.github.com/users/iva3682/followers","following_url":"https://api.github.com/users/iva3682/following{/other_user}","gists_url":"https://api.github.com/users/iva3682/gists{/gist_id}","starred_url":"https://api.github.com/users/iva3682/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/iva3682/subscriptions","organizations_url":"https://api.github.com/users/iva3682/orgs","repos_url":"https://api.github.com/users/iva3682/repos","events_url":"https://api.github.com/users/iva3682/events{/privacy}","received_events_url":"https://api.github.com/users/iva3682/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-09-07T10:25:47Z","updated_at":"2021-09-07T10:26:13Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Greetings! Such a question: can I delete data from a Join type table with a composite key by one field from this key?\r\n\r\nFor example, there is a table:\r\n\r\n```\r\nCREATE TABLE product_data_add_join\r\n(\r\n    `domen_id` UInt16,\r\n    `vendor_code_hash` FixedString(16),\r\n    `data_hash` FixedString(16)\r\n)\r\nENGINE = Join(ANTI, LEFT, domen_id, vendor_code_hash, data_hash);\r\n```\r\nI want to delete rows with domen_id = 1:\r\n`ALTER TABLE product_data_add_join DELETE WHERE domen_id = 1;`\r\n\r\nThanks!","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28682/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28682/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28671","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28671/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28671/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28671/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/28671","id":989529413,"node_id":"MDU6SXNzdWU5ODk1Mjk0MTM=","number":28671,"title":"Improve gRPC compression support","user":{"login":"zhicwu","id":4270380,"node_id":"MDQ6VXNlcjQyNzAzODA=","avatar_url":"https://avatars.githubusercontent.com/u/4270380?v=4","gravatar_id":"","url":"https://api.github.com/users/zhicwu","html_url":"https://github.com/zhicwu","followers_url":"https://api.github.com/users/zhicwu/followers","following_url":"https://api.github.com/users/zhicwu/following{/other_user}","gists_url":"https://api.github.com/users/zhicwu/gists{/gist_id}","starred_url":"https://api.github.com/users/zhicwu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/zhicwu/subscriptions","organizations_url":"https://api.github.com/users/zhicwu/orgs","repos_url":"https://api.github.com/users/zhicwu/repos","events_url":"https://api.github.com/users/zhicwu/events{/privacy}","received_events_url":"https://api.github.com/users/zhicwu/received_events","type":"User","site_admin":false},"labels":[{"id":520905553,"node_id":"MDU6TGFiZWw1MjA5MDU1NTM=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/feature","name":"feature","color":"1d76db","default":false,"description":null},{"id":3330617087,"node_id":"MDU6TGFiZWwzMzMwNjE3MDg3","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-grpc","name":"comp-grpc","color":"b5bcff","default":false,"description":""}],"state":"open","locked":false,"assignee":{"login":"vitlibar","id":45142681,"node_id":"MDQ6VXNlcjQ1MTQyNjgx","avatar_url":"https://avatars.githubusercontent.com/u/45142681?v=4","gravatar_id":"","url":"https://api.github.com/users/vitlibar","html_url":"https://github.com/vitlibar","followers_url":"https://api.github.com/users/vitlibar/followers","following_url":"https://api.github.com/users/vitlibar/following{/other_user}","gists_url":"https://api.github.com/users/vitlibar/gists{/gist_id}","starred_url":"https://api.github.com/users/vitlibar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vitlibar/subscriptions","organizations_url":"https://api.github.com/users/vitlibar/orgs","repos_url":"https://api.github.com/users/vitlibar/repos","events_url":"https://api.github.com/users/vitlibar/events{/privacy}","received_events_url":"https://api.github.com/users/vitlibar/received_events","type":"User","site_admin":false},"assignees":[{"login":"vitlibar","id":45142681,"node_id":"MDQ6VXNlcjQ1MTQyNjgx","avatar_url":"https://avatars.githubusercontent.com/u/45142681?v=4","gravatar_id":"","url":"https://api.github.com/users/vitlibar","html_url":"https://github.com/vitlibar","followers_url":"https://api.github.com/users/vitlibar/followers","following_url":"https://api.github.com/users/vitlibar/following{/other_user}","gists_url":"https://api.github.com/users/vitlibar/gists{/gist_id}","starred_url":"https://api.github.com/users/vitlibar/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vitlibar/subscriptions","organizations_url":"https://api.github.com/users/vitlibar/orgs","repos_url":"https://api.github.com/users/vitlibar/repos","events_url":"https://api.github.com/users/vitlibar/events{/privacy}","received_events_url":"https://api.github.com/users/vitlibar/received_events","type":"User","site_admin":false}],"milestone":null,"comments":7,"created_at":"2021-09-07T02:11:25Z","updated_at":"2021-10-22T08:43:48Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"Could you consider to improve gRPC compression support by implementing below features?\r\n1. __Client-side compression__\r\n   It seems setting compression algorithm at client-side is currently not supported. Regardless what algorithm suggested by client, supported or not, the server always uses the same compression algorithm declared in its configuration file.\r\n   https://github.com/ClickHouse/ClickHouse/blob/9e496910a0ddbe7d75b911d2a5a9b34c75b852d6/programs/server/config.xml#L197-L203\r\n   It's better to let the client to choose compression algorithm/level based on actual needs in runtime, instead of changing server-side configuration. For example, the default compression algorithm seems having problem with many UInt64 numbers, as I noticed nearly 4x times performance boost on client side after disabling compression.\r\n\r\n<details>\r\n<summary>Benchmarks</summary>\r\n\r\nBelow `10k` actually means ~50,000 rows :p\r\n  \r\n[With compression(algorithm=deflate, level=medium)]\r\n\r\n``` bash\r\nBenchmark                           (connection)                       (format)  (mode)  (protocol)  (transport)   Mode  Cnt   Score   Error  Units\r\nLoad.select10kStringRows                   reuse     RowBinaryWithNamesAndTypes    sync        GRPC        netty  thrpt   20  53.792 ± 3.366  ops/s\r\nLoad.select10kStringRows                   reuse     RowBinaryWithNamesAndTypes    sync        GRPC       okhttp  thrpt   20  51.828 ± 4.240  ops/s\r\nLoad.select10kStringRows                   reuse  TabSeparatedWithNamesAndTypes    sync        GRPC        netty  thrpt   20  42.187 ± 2.607  ops/s\r\nLoad.select10kStringRows                   reuse  TabSeparatedWithNamesAndTypes    sync        GRPC       okhttp  thrpt   20  43.462 ± 2.374  ops/s\r\nLoad.select10kTimestampRows                reuse     RowBinaryWithNamesAndTypes    sync        GRPC        netty  thrpt   20  48.733 ± 2.236  ops/s\r\nLoad.select10kTimestampRows                reuse     RowBinaryWithNamesAndTypes    sync        GRPC       okhttp  thrpt   20  46.617 ± 2.624  ops/s\r\nLoad.select10kTimestampRows                reuse  TabSeparatedWithNamesAndTypes    sync        GRPC        netty  thrpt   20  19.798 ± 1.287  ops/s\r\nLoad.select10kTimestampRows                reuse  TabSeparatedWithNamesAndTypes    sync        GRPC       okhttp  thrpt   20  18.954 ± 1.274  ops/s\r\nLoad.select10kUInt64Rows                   reuse     RowBinaryWithNamesAndTypes    sync        GRPC        netty  thrpt   20  33.013 ± 1.643  ops/s\r\nLoad.select10kUInt64Rows                   reuse     RowBinaryWithNamesAndTypes    sync        GRPC       okhttp  thrpt   20  32.878 ± 1.909  ops/s\r\nLoad.select10kUInt64Rows                   reuse  TabSeparatedWithNamesAndTypes    sync        GRPC        netty  thrpt   20  44.841 ± 2.386  ops/s\r\nLoad.select10kUInt64Rows                   reuse  TabSeparatedWithNamesAndTypes    sync        GRPC       okhttp  thrpt   20  44.555 ± 2.471  ops/s\r\n```\r\n\r\n[Without compression(algorithm=none, level=none)]\r\n\r\n``` bash\r\nBenchmark                           (connection)                       (format)  (mode)  (protocol)  (transport)   Mode  Cnt    Score   Error  Units\r\nLoad.select10kStringRows                   reuse     RowBinaryWithNamesAndTypes    sync        GRPC        netty  thrpt   20   82.786 ± 4.334  ops/s\r\nLoad.select10kStringRows                   reuse     RowBinaryWithNamesAndTypes    sync        GRPC       okhttp  thrpt   20   70.753 ± 4.797  ops/s\r\nLoad.select10kStringRows                   reuse  TabSeparatedWithNamesAndTypes    sync        GRPC        netty  thrpt   20   60.482 ± 4.466  ops/s\r\nLoad.select10kStringRows                   reuse  TabSeparatedWithNamesAndTypes    sync        GRPC       okhttp  thrpt   20   52.046 ± 2.540  ops/s\r\nLoad.select10kTimestampRows                reuse     RowBinaryWithNamesAndTypes    sync        GRPC        netty  thrpt   20   99.147 ± 5.190  ops/s\r\nLoad.select10kTimestampRows                reuse     RowBinaryWithNamesAndTypes    sync        GRPC       okhttp  thrpt   20   86.454 ± 5.485  ops/s\r\nLoad.select10kTimestampRows                reuse  TabSeparatedWithNamesAndTypes    sync        GRPC        netty  thrpt   20   48.739 ± 3.207  ops/s\r\nLoad.select10kTimestampRows                reuse  TabSeparatedWithNamesAndTypes    sync        GRPC       okhttp  thrpt   20   29.759 ± 1.812  ops/s\r\nLoad.select10kUInt64Rows                   reuse     RowBinaryWithNamesAndTypes    sync        GRPC        netty  thrpt   20  121.422 ± 6.465  ops/s\r\nLoad.select10kUInt64Rows                   reuse     RowBinaryWithNamesAndTypes    sync        GRPC       okhttp  thrpt   20   73.226 ± 3.930  ops/s\r\nLoad.select10kUInt64Rows                   reuse  TabSeparatedWithNamesAndTypes    sync        GRPC        netty  thrpt   20   66.267 ± 4.822  ops/s\r\nLoad.select10kUInt64Rows                   reuse  TabSeparatedWithNamesAndTypes    sync        GRPC       okhttp  thrpt   20   56.022 ± 4.188  ops/s\r\n```\r\n\r\n</details>\r\n\r\n2. __More compression algorithms__\r\n    Looks like gRPC server does not support compression algorithm like Brotli, Lz4, and Zstd according to:\r\n    https://github.com/ClickHouse/ClickHouse/blob/9e496910a0ddbe7d75b911d2a5a9b34c75b852d6/src/Server/GRPCServer.cpp#L95-L107.\r\n\r\n3. __Additional option to return raw data(e.g. compressed data in `output`)__\r\n   This is very useful when you want to dump data from database into a compressed file. We just need to stream compressed data into a file on disk, without additional decompression & compression in the middle. This makes huge different when exporting large data sets, and similarly for importing.\r\n   I can add a hack to support this in Java client, but I think maybe it's better to add options to benefit all clients.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28671/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28671/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28635","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28635/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28635/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28635/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/28635","id":988701631,"node_id":"MDU6SXNzdWU5ODg3MDE2MzE=","number":28635,"title":"Abnormal join sql can not be cancelled","user":{"login":"ljcui","id":15341849,"node_id":"MDQ6VXNlcjE1MzQxODQ5","avatar_url":"https://avatars.githubusercontent.com/u/15341849?v=4","gravatar_id":"","url":"https://api.github.com/users/ljcui","html_url":"https://github.com/ljcui","followers_url":"https://api.github.com/users/ljcui/followers","following_url":"https://api.github.com/users/ljcui/following{/other_user}","gists_url":"https://api.github.com/users/ljcui/gists{/gist_id}","starred_url":"https://api.github.com/users/ljcui/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ljcui/subscriptions","organizations_url":"https://api.github.com/users/ljcui/orgs","repos_url":"https://api.github.com/users/ljcui/repos","events_url":"https://api.github.com/users/ljcui/events{/privacy}","received_events_url":"https://api.github.com/users/ljcui/received_events","type":"User","site_admin":false},"labels":[{"id":1357578153,"node_id":"MDU6TGFiZWwxMzU3NTc4MTUz","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/comp-joins","name":"comp-joins","color":"b5bcff","default":false,"description":"JOINs"},{"id":1575085465,"node_id":"MDU6TGFiZWwxNTc1MDg1NDY1","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/unexpected%20behaviour","name":"unexpected behaviour","color":"e088ca","default":false,"description":""}],"state":"open","locked":false,"assignee":{"login":"vdimir","id":7023786,"node_id":"MDQ6VXNlcjcwMjM3ODY=","avatar_url":"https://avatars.githubusercontent.com/u/7023786?v=4","gravatar_id":"","url":"https://api.github.com/users/vdimir","html_url":"https://github.com/vdimir","followers_url":"https://api.github.com/users/vdimir/followers","following_url":"https://api.github.com/users/vdimir/following{/other_user}","gists_url":"https://api.github.com/users/vdimir/gists{/gist_id}","starred_url":"https://api.github.com/users/vdimir/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vdimir/subscriptions","organizations_url":"https://api.github.com/users/vdimir/orgs","repos_url":"https://api.github.com/users/vdimir/repos","events_url":"https://api.github.com/users/vdimir/events{/privacy}","received_events_url":"https://api.github.com/users/vdimir/received_events","type":"User","site_admin":false},"assignees":[{"login":"vdimir","id":7023786,"node_id":"MDQ6VXNlcjcwMjM3ODY=","avatar_url":"https://avatars.githubusercontent.com/u/7023786?v=4","gravatar_id":"","url":"https://api.github.com/users/vdimir","html_url":"https://github.com/vdimir","followers_url":"https://api.github.com/users/vdimir/followers","following_url":"https://api.github.com/users/vdimir/following{/other_user}","gists_url":"https://api.github.com/users/vdimir/gists{/gist_id}","starred_url":"https://api.github.com/users/vdimir/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/vdimir/subscriptions","organizations_url":"https://api.github.com/users/vdimir/orgs","repos_url":"https://api.github.com/users/vdimir/repos","events_url":"https://api.github.com/users/vdimir/events{/privacy}","received_events_url":"https://api.github.com/users/vdimir/received_events","type":"User","site_admin":false}],"milestone":null,"comments":5,"created_at":"2021-09-06T03:17:09Z","updated_at":"2021-09-08T12:29:49Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"(you don't have to strictly follow this form)\r\n\r\n**Describe the unexpected behaviour**\r\n\r\nsql like this：\r\n`\r\nselect w1.id\r\nFROM\r\n(\r\n    SELECT 'test' as id FROM numbers(10000000)\r\n) w1\r\nglobal left join \r\n(\r\n    SELECT 'test' as id FROM numbers(10000000)\r\n) w2 \r\non w1.id = w2.id\r\nlimit 10;\r\n`\r\nIt runs for several hours and consumes a lot of CPU，must be restarted to recover.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28635/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28635/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28631","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28631/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28631/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28631/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/28631","id":988498769,"node_id":"MDU6SXNzdWU5ODg0OTg3Njk=","number":28631,"title":"Clickhouse do not delete the stale IPs from distributed_queue tables which previously assigned to clickhouse containers ","user":{"login":"chandrabhushansingh16","id":57935627,"node_id":"MDQ6VXNlcjU3OTM1NjI3","avatar_url":"https://avatars.githubusercontent.com/u/57935627?v=4","gravatar_id":"","url":"https://api.github.com/users/chandrabhushansingh16","html_url":"https://github.com/chandrabhushansingh16","followers_url":"https://api.github.com/users/chandrabhushansingh16/followers","following_url":"https://api.github.com/users/chandrabhushansingh16/following{/other_user}","gists_url":"https://api.github.com/users/chandrabhushansingh16/gists{/gist_id}","starred_url":"https://api.github.com/users/chandrabhushansingh16/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/chandrabhushansingh16/subscriptions","organizations_url":"https://api.github.com/users/chandrabhushansingh16/orgs","repos_url":"https://api.github.com/users/chandrabhushansingh16/repos","events_url":"https://api.github.com/users/chandrabhushansingh16/events{/privacy}","received_events_url":"https://api.github.com/users/chandrabhushansingh16/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":10,"created_at":"2021-09-05T12:30:03Z","updated_at":"2021-09-08T05:52:44Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"> You have to provide the following information whenever possible.\r\n\r\n**Describe what's wrong**\r\n\r\nThere are many containers running on production server on 2+1 clusters.\r\nThe 2 instances of clickhouse is also running on different hosts.\r\nIPs reshuffling happened and Clickhouse got new containers IPs assigned and the previously assigned IPs are now assigned to other containers.\r\nClickhouse still has the replica information of old IPs in distributed_queue table and hence it causes the high RSS memory and CPU\r\n\r\n**Does it reproduce on recent release?**\r\nReproduced on Server : 20.12.4 revision 54442.\r\n\r\n[The list of releases](https://github.com/ClickHouse/ClickHouse/blob/master/utils/list-versions/version_date.tsv)\r\n\r\n**Enable crash reporting**\r\nNA\r\n\r\n**How to reproduce**\r\n\r\n* Which ClickHouse server version to use : 20.12.4 revision 54442.\r\n* Which interface to use, if matters : NA\r\n* Non-default settings, if any : NA\r\n* `CREATE TABLE` statements for all tables involved : NA\r\n* Sample data for all these tables, use [clickhouse-obfuscator](https://github.com/ClickHouse/ClickHouse/blob/master/programs/obfuscator/Obfuscator.cpp#L42-L80) if necessary\r\n* Queries to run that lead to unexpected result\r\n`select * FROM system.distribution_queue FORMAT PrettyCompact`\r\n**Expected behavior**\r\nNo stale data should be present in distributed_queue tables\r\n> A clear and concise description of what you expected to happen.\r\n\r\n**Error message and/or stacktrace**\r\n\r\n> If applicable, add screenshots to help explain your problem.\r\n\r\n**Additional context**\r\n\r\n> Add any other context about the problem here.\r\n","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28631/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28631/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28626","repository_url":"https://api.github.com/repos/ClickHouse/ClickHouse","labels_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28626/labels{/name}","comments_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28626/comments","events_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28626/events","html_url":"https://github.com/ClickHouse/ClickHouse/issues/28626","id":988335672,"node_id":"MDU6SXNzdWU5ODgzMzU2NzI=","number":28626,"title":"Import from S3, replace \"-\" with NULL during parse for each row.","user":{"login":"ecc256","id":15874603,"node_id":"MDQ6VXNlcjE1ODc0NjAz","avatar_url":"https://avatars.githubusercontent.com/u/15874603?v=4","gravatar_id":"","url":"https://api.github.com/users/ecc256","html_url":"https://github.com/ecc256","followers_url":"https://api.github.com/users/ecc256/followers","following_url":"https://api.github.com/users/ecc256/following{/other_user}","gists_url":"https://api.github.com/users/ecc256/gists{/gist_id}","starred_url":"https://api.github.com/users/ecc256/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ecc256/subscriptions","organizations_url":"https://api.github.com/users/ecc256/orgs","repos_url":"https://api.github.com/users/ecc256/repos","events_url":"https://api.github.com/users/ecc256/events{/privacy}","received_events_url":"https://api.github.com/users/ecc256/received_events","type":"User","site_admin":false},"labels":[{"id":386401510,"node_id":"MDU6TGFiZWwzODY0MDE1MTA=","url":"https://api.github.com/repos/ClickHouse/ClickHouse/labels/question","name":"question","color":"bfdadc","default":true,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-09-04T17:28:07Z","updated_at":"2021-09-04T17:28:07Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Guys,\r\nI need to import nginx logs into clickhouse from S3 bucket.\r\nNULL is represented as `\"-\"` for all column types (`String`, `Int`, etc.)\r\nWhat would be the best and easiest way to do it?\r\nIs there smth. like global rule (or for S3 function only) to replace `\"-\"` with `NULL` during parse?\r\nI want to avoid replacing `INSERT INTO {table} SELECT *` with if statements for each column.\r\nI don’t see anything relevant in [CSV](https://clickhouse.tech/docs/en/interfaces/formats/#csv) and [Template](https://clickhouse.tech/docs/en/interfaces/formats/#format-template)\r\n\r\nCSV rows are:\r\n```\r\n\"2021-09-07T00:00:00.525+00:00\",\"3ab323865c685546bef91670a737807e\",\"PASSED\",\"~.\",\"xyz.com\",\"1.2.3.4\",\"-\",\"GET ... HTTP/1.1\",\"0.014\",\"10.20.30.40:80\",\"4550\",\"774\",\"0.000\",\"0.016\",\"200\",\"200\",\"4101\",\"Ref\",\"Ua\",\"XFF\"\r\n\"2021-09-07T00:00:00.526+00:00\",\"1e45ee4f85c5130c6fd5dbacbe147e78\",\"-\",\"~.\",\"xyz.com\",\"5.6.7.8\",\"-\",\"GET ... HTTP/1.1\",\"0.000\",\"-\",\"-\",\"-\",\"-\",\"-\",\"-\",\"444\",\"0\",\"-\",\"-\",\"-\"\r\n```\r\nimport is done via:\r\n```\r\nINSERT INTO {table}\r\nSELECT *\r\nFROM s3(\r\n  '...',\r\n  '...',\r\n  '...',\r\n  'CSV',\r\n  '\r\ntime_iso8601_msec DateTime, \r\nrequest_id String,\r\nlimit_req_status String,\r\n...\r\n',\r\n  'gzip')\r\nSETTINGS date_time_input_format='best_effort';\r\n```","reactions":{"url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28626/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/ClickHouse/ClickHouse/issues/28626/timeline","performed_via_github_app":null}]
